{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification,AutoConfig\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score,precision_recall_fscore_support\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-927ab0163adb9fdb\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-927ab0163adb9fdb/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 204.45it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('csv',data_files='dataset_propositionattribution_nerfeatures.csv',delimiter=',',column_names=[\"claim\",\"premise\",\"label\",\"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\",\"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\",\"url\", \"entities\",\"entity_map\",\"gem_exp\",\"gem_label\",\"gpt_label\",\"gpt_exp\",\"gold_exp\",\"entity_map_ev\",\"entity_ev\",\"split\"],skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "133f9357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-927ab0163adb9fdb/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-d013d5114fa105ab.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-927ab0163adb9fdb/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-16f9acbdd82fea07.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-927ab0163adb9fdb/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-47c7de469e4087a2.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01252e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\"claim\", \"premise\", \"label\", \"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\"]\n",
    "all_columns = dataset[\"train\"].column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-927ab0163adb9fdb/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-649518d62ec57bf1.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-927ab0163adb9fdb/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-6d678bc04ef470ab.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-927ab0163adb9fdb/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-43db5994e2921eed.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 2, 'entailment': 0, 'neutral': 1}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 2,\n",
    "    \"entailment\": 0,\n",
    "    \"neutral\": 1\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e15010ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='sjrhuschlee/flan-t5-base-mnli'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "        # Extracting claim and evidence texts\n",
    "        claim = item['claim'] \n",
    "        evidences = item['premise']\n",
    "        item['premise']=evidences\n",
    "        item['claim']=claim\n",
    "        additional_features = [\n",
    "            \"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\"]\n",
    "    \n",
    "        for feature in additional_features:\n",
    "            if feature in item:\n",
    "                claim += \"[SEP]\" + str(item[feature])\n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "            evidences,claim,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "         # Construct the output item\n",
    "        output_item = {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),  # Remove batch dimension\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),  # Remove batch dimension\n",
    "            'claim': claim,  # Include augmented claim text\n",
    "            'evidences': evidences  # Include original evidence text\n",
    "        }\n",
    "        \n",
    "        if 'label' in item:\n",
    "            output_item['label'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return output_item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62421eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "T5ForSequenceClassification(\n",
       "  (transformer): T5Model(\n",
       "    (shared): Embedding(32128, 768)\n",
       "    (encoder): T5Stack(\n",
       "      (embed_tokens): Embedding(32128, 768)\n",
       "      (block): ModuleList(\n",
       "        (0): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 12)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (6): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (7): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (8): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (9): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (10): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (11): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): T5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (decoder): T5Stack(\n",
       "      (embed_tokens): Embedding(32128, 768)\n",
       "      (block): ModuleList(\n",
       "        (0): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 12)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (6): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (7): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (8): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (9): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (10): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (11): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): T5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (classification_head): T5ClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"sjrhuschlee/flan-t5-base-mnli\"\n",
    "config = AutoConfig.from_pretrained(\n",
    "    model_name, num_labels=len(label2id), id2label=id2label, label2id=label2id\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=512)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,ignore_mismatched_sizes=True,config=config, trust_remote_code=True)\n",
    "device = \"cuda:0\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    if isinstance(\n",
    "        logits, tuple\n",
    "    ):  # if the model also returns hidden_states or attentions\n",
    "        logits = logits[0]\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, predictions, average=\"weighted\"\n",
    "    )\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "\n",
    "\n",
    "    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f5cf584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([   37,  1832, 10229,    13,     3,  6296,  2917,    75,  5167,    11,\n",
       "            82,    52,    52,   107,   993,     8,  5798,   485,    13,     8,\n",
       "             3, 19437,  2647, 18270,    16,     8,   123,  1225,   109,    11,\n",
       "           483,     8,   455,   120,    11, 13809,  1809,    12,   993,     8,\n",
       "             3, 31970,   485,    13,     8,  1133,    11,  6313,     8, 12515,\n",
       "          1504,     5,     1,   499,    52,    52,   107,  1832,  1043,    19,\n",
       "          1664,   261,    16, 26309,   494,    12,   199,  1172,     8,  3179,\n",
       "            13,     8,  1133,     5,  6306,   134,  8569,   908,   632,  6306,\n",
       "           134,  8569,   908,   632,  6306,   134,  8569,   908,   632,  6306,\n",
       "           134,  8569,   908,   632,  6306,   134,  8569,   908,   632,  6306,\n",
       "           134,  8569,   908,   632,  6306,   134,  8569,   908,   632,  6306,\n",
       "           134,  8569,   908,   632,  6306,   134,  8569,   908,   632,  6306,\n",
       "           134,  8569,   908,   632,  6306,   134,  8569,   908,   632,  6306,\n",
       "           134,  8569,   908,   632,     1,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'claim': 'Myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0',\n",
       " 'evidences': 'The essential oils of frankincense and myrrh increase the fluidity of the lipid bilayer in the cuticle and change the orderly and dense structure to increase the permeability of the skin and decrease the barrier effect.',\n",
       " 'label': tensor(0)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3045\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3045' max='3045' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3045/3045 41:33, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.621600</td>\n",
       "      <td>0.806743</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.697783</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.685793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.202500</td>\n",
       "      <td>2.131911</td>\n",
       "      <td>0.593548</td>\n",
       "      <td>0.709982</td>\n",
       "      <td>0.593548</td>\n",
       "      <td>0.632680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.127700</td>\n",
       "      <td>2.305449</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.722168</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.671757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.277700</td>\n",
       "      <td>2.257205</td>\n",
       "      <td>0.640860</td>\n",
       "      <td>0.697590</td>\n",
       "      <td>0.640860</td>\n",
       "      <td>0.660059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.109100</td>\n",
       "      <td>2.811687</td>\n",
       "      <td>0.640860</td>\n",
       "      <td>0.683135</td>\n",
       "      <td>0.640860</td>\n",
       "      <td>0.654617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>3.183029</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.691073</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.662603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.319775</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.698999</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.684415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>3.111924</td>\n",
       "      <td>0.662366</td>\n",
       "      <td>0.691910</td>\n",
       "      <td>0.662366</td>\n",
       "      <td>0.674187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.474607</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.689917</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.661756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.544796</td>\n",
       "      <td>0.662366</td>\n",
       "      <td>0.684944</td>\n",
       "      <td>0.662366</td>\n",
       "      <td>0.670027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.760703</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.684646</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.662697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>3.961890</td>\n",
       "      <td>0.647312</td>\n",
       "      <td>0.677117</td>\n",
       "      <td>0.647312</td>\n",
       "      <td>0.657664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.051730</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.682075</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.661282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.071486</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.676691</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.659203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.072245</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.676691</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.659203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/10.4.3_flant5/checkpoint-203\n",
      "Configuration saved in /home/elson/10.4.3_flant5/checkpoint-203/config.json\n",
      "Model weights saved in /home/elson/10.4.3_flant5/checkpoint-203/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/10.4.3_flant5/checkpoint-406\n",
      "Configuration saved in /home/elson/10.4.3_flant5/checkpoint-406/config.json\n",
      "Model weights saved in /home/elson/10.4.3_flant5/checkpoint-406/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/10.4.3_flant5/checkpoint-609\n",
      "Configuration saved in /home/elson/10.4.3_flant5/checkpoint-609/config.json\n",
      "Model weights saved in /home/elson/10.4.3_flant5/checkpoint-609/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/10.4.3_flant5/checkpoint-406] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/10.4.3_flant5/checkpoint-812\n",
      "Configuration saved in /home/elson/10.4.3_flant5/checkpoint-812/config.json\n",
      "Model weights saved in /home/elson/10.4.3_flant5/checkpoint-812/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/10.4.3_flant5/checkpoint-609] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/10.4.3_flant5/checkpoint-1015\n",
      "Configuration saved in /home/elson/10.4.3_flant5/checkpoint-1015/config.json\n",
      "Model weights saved in /home/elson/10.4.3_flant5/checkpoint-1015/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/10.4.3_flant5/checkpoint-812] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/10.4.3_flant5/checkpoint-1218\n",
      "Configuration saved in /home/elson/10.4.3_flant5/checkpoint-1218/config.json\n",
      "Model weights saved in /home/elson/10.4.3_flant5/checkpoint-1218/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/10.4.3_flant5/checkpoint-1015] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/10.4.3_flant5/checkpoint-1421\n",
      "Configuration saved in /home/elson/10.4.3_flant5/checkpoint-1421/config.json\n",
      "Model weights saved in /home/elson/10.4.3_flant5/checkpoint-1421/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/10.4.3_flant5/checkpoint-1218] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/10.4.3_flant5/checkpoint-1624\n",
      "Configuration saved in /home/elson/10.4.3_flant5/checkpoint-1624/config.json\n",
      "Model weights saved in /home/elson/10.4.3_flant5/checkpoint-1624/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/10.4.3_flant5/checkpoint-1827\n",
      "Configuration saved in /home/elson/10.4.3_flant5/checkpoint-1827/config.json\n",
      "Model weights saved in /home/elson/10.4.3_flant5/checkpoint-1827/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/10.4.3_flant5/checkpoint-1624] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/10.4.3_flant5/checkpoint-2030\n",
      "Configuration saved in /home/elson/10.4.3_flant5/checkpoint-2030/config.json\n",
      "Model weights saved in /home/elson/10.4.3_flant5/checkpoint-2030/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/10.4.3_flant5/checkpoint-1827] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/10.4.3_flant5/checkpoint-2233\n",
      "Configuration saved in /home/elson/10.4.3_flant5/checkpoint-2233/config.json\n",
      "Model weights saved in /home/elson/10.4.3_flant5/checkpoint-2233/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/10.4.3_flant5/checkpoint-2030] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/10.4.3_flant5/checkpoint-2436\n",
      "Configuration saved in /home/elson/10.4.3_flant5/checkpoint-2436/config.json\n",
      "Model weights saved in /home/elson/10.4.3_flant5/checkpoint-2436/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/10.4.3_flant5/checkpoint-2233] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/10.4.3_flant5/checkpoint-2639\n",
      "Configuration saved in /home/elson/10.4.3_flant5/checkpoint-2639/config.json\n",
      "Model weights saved in /home/elson/10.4.3_flant5/checkpoint-2639/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/10.4.3_flant5/checkpoint-2436] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/10.4.3_flant5/checkpoint-2842\n",
      "Configuration saved in /home/elson/10.4.3_flant5/checkpoint-2842/config.json\n",
      "Model weights saved in /home/elson/10.4.3_flant5/checkpoint-2842/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/10.4.3_flant5/checkpoint-2639] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/10.4.3_flant5/checkpoint-3045\n",
      "Configuration saved in /home/elson/10.4.3_flant5/checkpoint-3045/config.json\n",
      "Model weights saved in /home/elson/10.4.3_flant5/checkpoint-3045/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/10.4.3_flant5/checkpoint-2842] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/elson/10.4.3_flant5/checkpoint-203 (score: 0.8067428469657898).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='89' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [59/59 1:34:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /home/elson/10.4.3_flant5/best_model/config.json\n",
      "Model weights saved in /home/elson/10.4.3_flant5/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/10.4.3_flant5/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/10.4.3_flant5/best_model/special_tokens_map.json\n",
      "Copy vocab file to /home/elson/10.4.3_flant5/best_model/spiece.model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/10.4.3_flant5/best_model/tokenizer_config.json',\n",
       " '/home/elson/10.4.3_flant5/best_model/special_tokens_map.json',\n",
       " '/home/elson/10.4.3_flant5/best_model/spiece.model',\n",
       " '/home/elson/10.4.3_flant5/best_model/added_tokens.json',\n",
       " '/home/elson/10.4.3_flant5/best_model/tokenizer.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/10.4.3_flant5/',\n",
    "    num_train_epochs=15,\n",
    "    learning_rate=3e-4,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=False,\n",
    "    logging_steps=10,\n",
    "    warmup_ratio=0.06,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/10.4.3_flant5/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/10.4.3_flant5/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63deaea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/10.4.3_flant5/best_model/config.json\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"/home/elson/10.4.3_flant5/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForSequenceClassification\"\n",
      "  ],\n",
      "  \"auto_map\": {\n",
      "    \"AutoModelForSequenceClassification\": \"modeling_t5seq.T5ForSequenceClassification\"\n",
      "  },\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"finetuning_task\": \"mnli\",\n",
      "  \"id2label\": {\n",
      "    \"0\": \"entailment\",\n",
      "    \"1\": \"neutral\",\n",
      "    \"2\": \"contradiction\"\n",
      "  },\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"label2id\": {\n",
      "    \"contradiction\": 2,\n",
      "    \"entailment\": 0,\n",
      "    \"neutral\": 1\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "loading weights file /home/elson/10.4.3_flant5/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing T5ForSequenceClassification.\n",
      "\n",
      "All the weights of T5ForSequenceClassification were initialized from the model checkpoint at /home/elson/10.4.3_flant5/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 8\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/10.4.3_flant5/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path,trust_remote_code=True).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=(array([[ 4.92540956e-01,  3.05404484e-01, -7.58313656e-01],\n",
      "       [ 2.28307414e+00, -4.57488120e-01, -1.56814194e+00],\n",
      "       [ 2.46749210e+00, -1.34779215e+00, -8.60033214e-01],\n",
      "       [-3.68018955e-01, -1.15783334e+00,  1.27487528e+00],\n",
      "       [-2.39270180e-01,  5.21659493e-01, -3.27760041e-01],\n",
      "       [ 2.91717744e+00, -6.80669606e-01, -1.70618391e+00],\n",
      "       [ 2.39236927e+00, -1.08713520e+00, -9.65193689e-01],\n",
      "       [ 2.54804921e+00, -1.76529467e-01, -1.99456453e+00],\n",
      "       [ 1.19203711e+00, -1.30807161e-01, -1.01542616e+00],\n",
      "       [ 2.11511445e+00, -7.75320351e-01, -1.06411576e+00],\n",
      "       [ 1.66960728e+00, -1.75781083e+00,  2.90267766e-01],\n",
      "       [ 2.28002286e+00, -5.48987329e-01, -1.37001705e+00],\n",
      "       [ 1.93361914e+00, -2.00123832e-01, -1.48141694e+00],\n",
      "       [ 2.35907841e+00,  7.53045008e-02, -2.12024927e+00],\n",
      "       [ 2.43031502e+00, -5.11330724e-01, -1.56197000e+00],\n",
      "       [ 8.65169406e-01,  2.04451695e-01, -9.12322402e-01],\n",
      "       [ 1.50313699e+00,  1.84192762e-01, -1.55410409e+00],\n",
      "       [ 2.60717177e+00, -9.44410205e-01, -1.23986292e+00],\n",
      "       [ 2.44172621e+00, -7.01377213e-01, -1.34533203e+00],\n",
      "       [ 1.37603116e+00, -7.52945244e-01, -4.87568140e-01],\n",
      "       [-1.03595483e+00,  4.05933261e-02,  7.04170346e-01],\n",
      "       [ 6.34030938e-01,  1.51721492e-01, -8.41883421e-01],\n",
      "       [ 2.07516551e+00, -9.64034796e-01, -9.88555074e-01],\n",
      "       [-5.42080283e-01, -1.19161165e+00,  1.52557778e+00],\n",
      "       [ 1.10521078e+00, -1.81113911e+00,  8.04884136e-01],\n",
      "       [-7.21771002e-01, -9.36250210e-01,  1.54076862e+00],\n",
      "       [ 2.78110623e+00, -5.67813218e-01, -1.75373363e+00],\n",
      "       [ 1.55198467e+00,  6.74148574e-02, -1.46116185e+00],\n",
      "       [ 2.68019986e+00, -3.98281693e-01, -1.81358457e+00],\n",
      "       [ 1.59375298e+00, -1.28878284e+00, -1.46972492e-01],\n",
      "       [ 1.09160505e-01,  5.97655237e-01, -7.79760182e-01],\n",
      "       [ 2.61361957e+00, -3.83471459e-01, -1.75502777e+00],\n",
      "       [ 1.78048706e+00, -8.40525508e-01, -7.26100743e-01],\n",
      "       [ 7.72896171e-01,  1.01227812e-01, -8.04294229e-01],\n",
      "       [-7.52133667e-01, -3.98640901e-01,  8.46795022e-01],\n",
      "       [ 1.05833185e+00,  3.54150683e-01, -1.31011474e+00],\n",
      "       [ 3.87894928e-01, -5.00988960e-01,  1.00865565e-01],\n",
      "       [ 2.50795507e+00, -1.51366070e-02, -2.10861063e+00],\n",
      "       [ 5.70567966e-01, -1.03617418e+00,  3.53375167e-01],\n",
      "       [ 1.46103251e+00,  2.04024985e-01, -1.44490933e+00],\n",
      "       [ 1.00115788e+00, -1.60672635e-01, -7.62319744e-01],\n",
      "       [ 2.04008842e+00,  3.14439654e-01, -2.06932664e+00],\n",
      "       [ 1.21330011e+00,  7.14368224e-02, -1.24433851e+00],\n",
      "       [-7.34519362e-01, -6.16965294e-01,  1.13767052e+00],\n",
      "       [-9.66998339e-01, -1.51566342e-01,  8.43099892e-01],\n",
      "       [ 2.22479773e+00, -7.30399549e-01, -1.12873793e+00],\n",
      "       [ 1.25175416e+00, -7.68116891e-01, -4.32220250e-01],\n",
      "       [ 2.86667848e+00, -1.04133081e+00, -1.32633364e+00],\n",
      "       [ 2.88065505e+00, -1.09543753e+00, -1.31946468e+00],\n",
      "       [ 9.70815957e-01, -8.63273084e-01,  2.12426260e-02],\n",
      "       [-8.87232065e-01, -4.56842959e-01,  1.05167329e+00],\n",
      "       [ 3.92977625e-01,  5.12321413e-01, -9.73693728e-01],\n",
      "       [ 5.16267478e-01,  1.81125537e-01, -8.02976668e-01],\n",
      "       [ 2.04454994e+00, -8.56960714e-01, -9.09318447e-01],\n",
      "       [-1.72779292e-01, -2.47419849e-01,  3.17205966e-01],\n",
      "       [ 8.83583665e-01, -1.22503889e+00,  3.69118094e-01],\n",
      "       [-4.10336107e-01,  7.61220813e-01, -5.18362284e-01],\n",
      "       [ 2.66878891e+00, -6.31772161e-01, -1.59649348e+00],\n",
      "       [-2.62271285e-01, -5.30001521e-01,  6.62427008e-01],\n",
      "       [ 2.39958906e+00, -1.96718857e-01, -1.84122503e+00],\n",
      "       [ 2.54217458e+00, -8.34952712e-01, -1.45908856e+00],\n",
      "       [ 1.27560580e+00, -8.28236639e-01, -3.45804781e-01],\n",
      "       [ 1.02438271e+00, -7.04845265e-02, -8.44264925e-01],\n",
      "       [ 3.47082943e-01,  1.35540619e-01, -4.08293784e-01],\n",
      "       [-3.62558931e-01,  6.46205783e-01, -4.74439591e-01],\n",
      "       [ 2.52096820e+00, -6.80504680e-01, -1.54010320e+00],\n",
      "       [ 2.84203053e+00, -7.71867990e-01, -1.61336684e+00],\n",
      "       [ 2.56443810e+00, -1.01972766e-01, -1.93175972e+00],\n",
      "       [ 1.50076234e+00, -1.06089735e+00, -2.82678545e-01],\n",
      "       [ 1.29704201e+00, -1.56086946e+00,  4.16936576e-01],\n",
      "       [ 2.56234288e+00, -1.09126770e+00, -1.11860085e+00],\n",
      "       [ 4.18008119e-01,  3.23537827e-01, -7.46857226e-01],\n",
      "       [ 6.75539851e-01,  3.36617768e-01, -9.53931272e-01],\n",
      "       [ 1.94941723e+00, -1.93617925e-01, -1.49296761e+00],\n",
      "       [ 1.70120740e+00, -4.89375174e-01, -1.00740087e+00],\n",
      "       [ 2.35940814e+00, -1.02963817e+00, -1.02781522e+00],\n",
      "       [ 1.26699209e+00, -1.24251135e-01, -9.36351895e-01],\n",
      "       [ 2.58695364e+00, -6.78225040e-01, -1.58658779e+00],\n",
      "       [ 2.89251804e+00, -1.21517837e+00, -1.21033406e+00],\n",
      "       [ 8.68285894e-01,  1.15129761e-01, -8.55232775e-01],\n",
      "       [ 2.51720023e+00, -6.03445292e-01, -1.51757622e+00],\n",
      "       [ 1.94520938e+00, -1.29258841e-01, -1.50497305e+00],\n",
      "       [ 1.03984582e+00,  1.28135890e-01, -1.04953671e+00],\n",
      "       [ 1.85321915e+00, -1.38530660e+00, -2.52317339e-01],\n",
      "       [ 2.84155202e+00, -9.02832627e-01, -1.53078389e+00],\n",
      "       [ 3.84369701e-01,  1.76445581e-02, -3.76479447e-01],\n",
      "       [ 1.40667927e+00, -6.91951036e-01, -4.90273923e-01],\n",
      "       [ 1.05937469e+00, -7.19272792e-01, -3.34383696e-01],\n",
      "       [ 1.02934134e+00,  7.75903821e-01, -1.68870354e+00],\n",
      "       [ 1.06452835e+00,  1.10625476e-02, -8.87003422e-01],\n",
      "       [ 2.53616118e+00, -1.34436643e+00, -9.10728753e-01],\n",
      "       [ 2.53628278e+00, -1.07536912e+00, -1.10582888e+00],\n",
      "       [ 8.47646594e-01, -6.24048054e-01, -2.68983066e-01],\n",
      "       [ 2.88968086e+00, -9.87837434e-01, -1.43613279e+00],\n",
      "       [ 1.01345807e-01,  5.05830586e-01, -6.05734110e-01],\n",
      "       [ 1.70807421e-01,  5.06951571e-01, -7.05516756e-01],\n",
      "       [ 9.66619402e-02, -1.19053471e+00,  8.55737329e-01],\n",
      "       [ 9.43095013e-02, -3.05527568e-01,  9.64450166e-02],\n",
      "       [ 2.70819116e+00, -1.09682035e+00, -1.17408061e+00],\n",
      "       [ 2.15013433e+00, -7.59763300e-01, -1.13505733e+00],\n",
      "       [ 2.21651614e-01, -1.72811115e+00,  1.43605471e+00],\n",
      "       [ 2.10338640e+00, -5.53583324e-01, -1.28650475e+00],\n",
      "       [ 2.84933615e+00, -9.74353313e-01, -1.40298426e+00],\n",
      "       [ 5.54921269e-01,  2.27589801e-01, -7.87836254e-01],\n",
      "       [ 2.34747577e+00, -1.84632704e-01, -1.81106496e+00],\n",
      "       [ 2.54229474e+00, -9.37253237e-01, -1.31198990e+00],\n",
      "       [ 2.35737705e+00, -1.74263918e+00, -3.53206843e-01],\n",
      "       [ 4.69212145e-01, -1.71074778e-01, -2.27837041e-01],\n",
      "       [ 2.10020137e+00, -9.36818063e-01, -9.59042609e-01],\n",
      "       [ 2.21033597e+00, -7.75392175e-01, -1.15836620e+00],\n",
      "       [ 9.79976475e-01, -8.38556364e-02, -6.82815194e-01],\n",
      "       [ 2.29568410e+00, -1.50352359e-01, -1.84326625e+00],\n",
      "       [ 1.96502340e+00, -4.85959649e-01, -1.26203716e+00],\n",
      "       [ 1.90742338e+00, -5.39367080e-01, -1.09860301e+00],\n",
      "       [ 2.88037038e+00, -6.76021039e-01, -1.68745708e+00],\n",
      "       [ 2.65658641e+00, -4.98620212e-01, -1.75037467e+00],\n",
      "       [ 2.56587005e+00, -8.72206330e-01, -1.29294145e+00],\n",
      "       [ 1.85587490e+00, -6.03654444e-01, -1.08436179e+00],\n",
      "       [ 1.23005998e+00, -5.46223521e-01, -4.75845754e-01],\n",
      "       [ 2.56750584e+00, -7.89566994e-01, -1.43223858e+00],\n",
      "       [ 3.16004485e-01, -3.94800931e-01,  4.70398068e-02],\n",
      "       [ 2.73146558e+00, -1.07884955e+00, -1.26002073e+00],\n",
      "       [ 2.38744998e+00, -5.40295467e-02, -1.93787622e+00],\n",
      "       [-7.66491592e-01,  4.25816417e-01,  9.37530026e-02],\n",
      "       [ 2.20669627e+00, -8.60597730e-01, -1.12618291e+00],\n",
      "       [ 2.26537800e+00, -4.43316638e-01, -1.43966353e+00],\n",
      "       [ 1.47937047e+00, -4.30885553e-01, -8.61383080e-01],\n",
      "       [ 2.61899114e+00, -4.02719349e-01, -1.84251428e+00],\n",
      "       [ 2.36634660e+00, -8.61689746e-01, -1.19891703e+00],\n",
      "       [ 1.55849528e+00,  2.49908075e-01, -1.62989581e+00],\n",
      "       [ 1.27899086e+00, -5.41260004e-01, -6.03729725e-01],\n",
      "       [-6.19230151e-01, -1.06829536e+00,  1.41562998e+00],\n",
      "       [ 2.55788255e+00, -1.45282373e-01, -2.01644087e+00],\n",
      "       [-1.63498557e+00,  9.25834715e-01,  1.79643124e-01],\n",
      "       [ 2.22995687e+00, -5.72440684e-01, -1.28023064e+00],\n",
      "       [-3.25429916e-01, -8.37287828e-02,  2.92538851e-01],\n",
      "       [ 1.46603453e+00, -4.74158734e-01, -8.12870622e-01],\n",
      "       [-3.32914740e-01, -6.47296011e-01,  8.21317136e-01],\n",
      "       [-7.57465884e-02,  6.15030751e-02, -9.16420594e-02],\n",
      "       [ 2.81839490e+00, -8.94090176e-01, -1.45698142e+00],\n",
      "       [ 2.28456283e+00, -5.02766132e-01, -1.40970588e+00],\n",
      "       [-2.01512245e-03, -1.11014891e+00,  9.78962243e-01],\n",
      "       [-3.63460600e-01,  9.11212325e-01, -6.95126057e-01],\n",
      "       [ 2.78588605e+00, -5.01143515e-01, -1.82137024e+00],\n",
      "       [ 2.01022983e+00, -1.05315077e+00, -7.29377747e-01],\n",
      "       [ 2.16557789e+00, -6.37271941e-01, -1.22847950e+00],\n",
      "       [ 2.60350347e-01, -4.01280969e-02, -2.28843063e-01],\n",
      "       [ 7.01581240e-01, -7.47694373e-01,  4.60755154e-02],\n",
      "       [ 2.30897307e+00, -7.27413177e-01, -1.28311777e+00],\n",
      "       [-3.55314225e-01,  9.43769589e-02,  9.32899415e-02],\n",
      "       [ 1.86179686e+00, -4.15018380e-01, -1.14562082e+00],\n",
      "       [ 2.52488041e+00, -1.36044979e+00, -8.79270613e-01],\n",
      "       [ 2.67810249e+00, -4.42530334e-01, -1.77600169e+00],\n",
      "       [ 1.69842291e+00, -5.06515145e-01, -9.72730696e-01],\n",
      "       [ 2.71505427e+00, -1.02773583e+00, -1.22183967e+00],\n",
      "       [ 2.77112627e+00, -1.25809598e+00, -1.09311426e+00],\n",
      "       [ 2.24052119e+00, -1.33518982e+00, -5.55950522e-01],\n",
      "       [ 2.50261378e+00, -4.57259417e-01, -1.71325707e+00],\n",
      "       [ 4.96695898e-02, -2.05815569e-01,  8.97051021e-02],\n",
      "       [-9.83439624e-01, -8.74465466e-01,  1.41433489e+00],\n",
      "       [-4.83965665e-01, -9.60292220e-01,  1.29185009e+00],\n",
      "       [ 2.69749910e-01, -1.59394240e+00,  1.20375717e+00],\n",
      "       [ 1.05249989e+00, -9.76944864e-02, -8.35859179e-01],\n",
      "       [-3.15110415e-01, -9.25984085e-01,  9.98521566e-01],\n",
      "       [ 7.29946256e-01,  4.13333714e-01, -1.05537939e+00],\n",
      "       [-9.39587831e-01,  1.16680590e-02,  6.78456128e-01],\n",
      "       [ 2.49656177e+00, -1.00981975e+00, -1.15743709e+00],\n",
      "       [-2.60304034e-01,  3.21770340e-01, -1.29656613e-01],\n",
      "       [ 4.73281592e-01, -7.80032396e-01,  2.44010821e-01],\n",
      "       [ 1.25750291e+00, -1.10952711e+00, -5.56479432e-02],\n",
      "       [-1.52538106e-01, -8.15020144e-01,  8.71998966e-01],\n",
      "       [ 1.93469858e+00, -1.15183794e+00, -5.35214424e-01],\n",
      "       [ 4.17712986e-01, -3.08238193e-02, -4.06750500e-01],\n",
      "       [ 2.59554219e+00, -7.08226740e-01, -1.52429092e+00],\n",
      "       [ 2.96518850e+00, -1.16126323e+00, -1.29216146e+00],\n",
      "       [ 1.23182750e+00,  7.42269233e-02, -1.13895643e+00],\n",
      "       [ 2.65860105e+00, -9.76625502e-01, -1.37878847e+00],\n",
      "       [ 1.03973842e+00, -1.38035595e+00,  3.59070122e-01],\n",
      "       [ 1.63289452e+00,  2.60279298e-01, -1.68247843e+00],\n",
      "       [ 1.97916663e+00, -1.28429151e+00, -3.84507954e-01],\n",
      "       [ 9.81900275e-01, -2.02871785e-01, -6.47670448e-01],\n",
      "       [ 3.25154722e-01, -1.08222079e+00,  5.67166150e-01],\n",
      "       [ 6.52664065e-01, -1.20170891e+00,  5.01324832e-01],\n",
      "       [ 3.72727573e-01,  1.39942944e+00, -1.61913550e+00],\n",
      "       [-9.61394429e-01, -8.22975993e-01,  1.54861188e+00],\n",
      "       [ 2.59663534e+00, -5.84440231e-01, -1.55031419e+00],\n",
      "       [ 2.27849650e+00, -5.79366446e-01, -1.37288046e+00],\n",
      "       [ 2.81291676e+00, -8.25319171e-01, -1.50957942e+00],\n",
      "       [-7.16918111e-01,  5.52985191e-01,  3.26785892e-02],\n",
      "       [ 1.92374098e+00, -5.21823764e-01, -1.12380528e+00],\n",
      "       [-6.89545810e-01, -2.28387371e-01,  6.51413918e-01],\n",
      "       [ 1.81973207e+00, -4.70845640e-01, -1.20083857e+00],\n",
      "       [ 2.65474772e+00, -1.17843235e+00, -1.02531374e+00],\n",
      "       [ 8.57037365e-01, -5.59803426e-01, -2.40809366e-01],\n",
      "       [-2.13429719e-01, -9.63195026e-01,  9.77896631e-01],\n",
      "       [ 2.78120136e+00, -6.91485822e-01, -1.59069276e+00],\n",
      "       [ 3.31338316e-01,  1.56866586e+00, -1.88200343e+00],\n",
      "       [ 2.76087451e+00, -8.43681991e-01, -1.52506685e+00],\n",
      "       [ 2.18297219e+00, -1.25299752e+00, -6.94629908e-01],\n",
      "       [ 1.55078065e+00, -1.26769051e-01, -1.16777527e+00],\n",
      "       [ 2.52793026e+00, -9.93337691e-01, -1.12434840e+00],\n",
      "       [ 2.66018128e+00, -1.56678110e-01, -2.05231071e+00],\n",
      "       [ 4.35025811e-01,  5.65003231e-02, -4.27394152e-01],\n",
      "       [ 2.01973844e+00, -5.77245295e-01, -1.17747605e+00],\n",
      "       [-7.70317793e-01, -6.07546985e-01,  1.18192887e+00],\n",
      "       [ 3.61634605e-02,  4.60718155e-01, -5.79266131e-01],\n",
      "       [ 2.06040311e+00,  1.66790187e-01, -1.90788233e+00],\n",
      "       [ 2.37540936e+00, -7.45067298e-01, -1.31178784e+00],\n",
      "       [ 2.94861078e+00, -7.09559679e-01, -1.75761068e+00],\n",
      "       [ 6.17732573e-03,  5.07133067e-01, -5.96699357e-01],\n",
      "       [ 1.59029162e+00, -6.53069377e-01, -6.88216031e-01],\n",
      "       [ 1.43351877e+00, -6.14061132e-02, -1.15071321e+00],\n",
      "       [ 2.00960875e+00, -5.25694132e-01, -1.20282197e+00],\n",
      "       [ 2.00551248e+00,  7.63093829e-01, -2.30879211e+00],\n",
      "       [ 2.96090913e+00, -1.00880563e+00, -1.46068180e+00],\n",
      "       [-1.36270630e+00, -1.42690569e-01,  1.09880686e+00],\n",
      "       [-1.00007021e+00, -4.02653903e-01,  1.03804302e+00],\n",
      "       [ 1.86569631e+00, -1.21929812e+00, -4.60030288e-01],\n",
      "       [ 2.62271929e+00, -3.08898449e-01, -1.87363815e+00],\n",
      "       [ 2.29486108e+00, -1.01637173e+00, -8.98214936e-01],\n",
      "       [ 2.41245341e+00, -3.47211540e-01, -1.69649506e+00],\n",
      "       [ 2.22376466e+00, -6.89237237e-01, -1.16494417e+00],\n",
      "       [ 4.87696342e-02, -1.37046778e+00,  1.09623945e+00],\n",
      "       [ 2.72523212e+00, -1.20220876e+00, -1.09116399e+00],\n",
      "       [ 1.77888620e+00,  2.43597254e-01, -1.81660903e+00],\n",
      "       [ 2.46935892e+00,  1.74970359e-01, -2.25788546e+00],\n",
      "       [ 2.86117435e+00, -8.52835059e-01, -1.51921904e+00],\n",
      "       [ 1.21016622e-01,  2.81764179e-01, -4.79611129e-01],\n",
      "       [ 2.52756506e-01, -1.11422837e+00,  7.47597516e-01],\n",
      "       [ 1.61235020e-01, -3.02300781e-01,  3.13334167e-02],\n",
      "       [ 2.53393102e+00, -5.18340528e-01, -1.58605003e+00],\n",
      "       [ 2.79940987e+00, -8.48094821e-01, -1.56932020e+00],\n",
      "       [ 2.08316731e+00, -4.79789376e-01, -1.34208763e+00],\n",
      "       [ 1.04845333e+00, -1.77682531e+00,  6.81305051e-01]], dtype=float32), array([[[-0.01319537,  0.00725581, -0.11476006, ...,  0.05265224,\n",
      "          0.00979701,  0.00370948],\n",
      "        [ 0.08610372,  0.15311976, -0.09001147, ..., -0.01822553,\n",
      "         -0.14078915, -0.10110056],\n",
      "        [ 0.00251203,  0.00736126,  0.00571174, ...,  0.00541728,\n",
      "         -0.00525194, -0.01269124],\n",
      "        ...,\n",
      "        [ 0.0130858 ,  0.08998307, -0.09897518, ...,  0.0458893 ,\n",
      "         -0.04293285,  0.06363849],\n",
      "        [ 0.0130858 ,  0.08998307, -0.09897518, ...,  0.0458893 ,\n",
      "         -0.04293285,  0.06363849],\n",
      "        [ 0.0130858 ,  0.08998307, -0.09897518, ...,  0.0458893 ,\n",
      "         -0.04293285,  0.06363849]],\n",
      "\n",
      "       [[-0.3355037 ,  0.14468181, -0.16173002, ...,  0.14698811,\n",
      "         -0.11276584, -0.10657471],\n",
      "        [-0.17831443, -0.14254175, -0.13802132, ...,  0.02085612,\n",
      "         -0.01879786,  0.09712791],\n",
      "        [-0.29312277, -0.05125964, -0.01368399, ...,  0.17059901,\n",
      "         -0.04667456,  0.00105478],\n",
      "        ...,\n",
      "        [-0.00258438,  0.26578298, -0.11600979, ...,  0.41042393,\n",
      "          0.02769524, -0.00103277],\n",
      "        [-0.00258438,  0.26578298, -0.11600979, ...,  0.41042393,\n",
      "          0.02769524, -0.00103277],\n",
      "        [-0.00258438,  0.26578298, -0.11600979, ...,  0.41042393,\n",
      "          0.02769524, -0.00103277]],\n",
      "\n",
      "       [[-0.20683911, -0.04973303, -0.22394606, ...,  0.03189734,\n",
      "          0.077718  , -0.06747594],\n",
      "        [-0.07939205, -0.07555002, -0.15738668, ...,  0.12191705,\n",
      "          0.11132762,  0.05042435],\n",
      "        [-0.250211  , -0.11450969, -0.15842003, ..., -0.01046768,\n",
      "         -0.04198025, -0.05447032],\n",
      "        ...,\n",
      "        [ 0.03136045,  0.19210339, -0.04768658, ...,  0.3034719 ,\n",
      "         -0.01482982,  0.0233983 ],\n",
      "        [ 0.03136045,  0.19210339, -0.04768658, ...,  0.3034719 ,\n",
      "         -0.01482982,  0.0233983 ],\n",
      "        [ 0.03136045,  0.19210339, -0.04768658, ...,  0.3034719 ,\n",
      "         -0.01482982,  0.0233983 ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-0.05018618,  0.00830574, -0.16545005, ..., -0.14348878,\n",
      "          0.05653495,  0.08409573],\n",
      "        [-0.02281745, -0.03514257, -0.0095261 , ...,  0.04229761,\n",
      "          0.10664301,  0.23826456],\n",
      "        [ 0.08827361, -0.27034572,  0.01125202, ..., -0.07147969,\n",
      "         -0.1160823 ,  0.23613213],\n",
      "        ...,\n",
      "        [ 0.02783352,  0.02464056, -0.0292964 , ...,  0.40012765,\n",
      "         -0.05317743,  0.0772416 ],\n",
      "        [ 0.02783352,  0.02464056, -0.0292964 , ...,  0.40012765,\n",
      "         -0.05317743,  0.0772416 ],\n",
      "        [ 0.02783352,  0.02464056, -0.0292964 , ...,  0.40012765,\n",
      "         -0.05317743,  0.0772416 ]],\n",
      "\n",
      "       [[-0.14200458, -0.18695132,  0.20818906, ..., -0.02029108,\n",
      "         -0.13012956, -0.14384274],\n",
      "        [-0.19991913, -0.11726525,  0.04496269, ..., -0.05761641,\n",
      "         -0.1863833 , -0.07515904],\n",
      "        [ 0.02873353, -0.09209646,  0.02794036, ..., -0.06949135,\n",
      "         -0.06886276, -0.12964486],\n",
      "        ...,\n",
      "        [ 0.00322447,  0.12609449,  0.04179568, ...,  0.10632508,\n",
      "         -0.11583956,  0.00278618],\n",
      "        [ 0.00322447,  0.12609449,  0.04179568, ...,  0.10632508,\n",
      "         -0.11583956,  0.00278618],\n",
      "        [ 0.00322447,  0.12609449,  0.04179568, ...,  0.10632508,\n",
      "         -0.11583956,  0.00278618]],\n",
      "\n",
      "       [[-0.06833031, -0.06807388, -0.14902915, ...,  0.03503844,\n",
      "          0.0630094 , -0.23012997],\n",
      "        [ 0.06882862, -0.15011057, -0.25832942, ...,  0.11642345,\n",
      "         -0.12667091, -0.17014056],\n",
      "        [ 0.18487778, -0.0111741 , -0.30622953, ...,  0.05457722,\n",
      "         -0.23408042, -0.09572572],\n",
      "        ...,\n",
      "        [ 0.06293926,  0.05986693, -0.12654349, ...,  0.26944205,\n",
      "         -0.16273983,  0.01072696],\n",
      "        [ 0.06293926,  0.05986693, -0.12654349, ...,  0.26944205,\n",
      "         -0.16273983,  0.01072696],\n",
      "        [ 0.06293926,  0.05986693, -0.12654349, ...,  0.26944205,\n",
      "         -0.16273983,  0.01072696]]], dtype=float32)), label_ids=array([0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 2,\n",
      "       0, 1, 2, 2, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 2, 1, 0, 0,\n",
      "       0, 2, 0, 0, 2, 2, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 2, 1, 0, 1, 2,\n",
      "       0, 0, 2, 2, 0, 0, 1, 1, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "       2, 1, 0, 0, 2, 0, 0, 0, 2, 0, 0, 1, 2, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "       1, 0, 1, 0, 1, 0, 0, 0, 2, 2, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2,\n",
      "       0, 1, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 2, 2, 0, 0, 0, 0, 1, 1,\n",
      "       0, 0, 0, 1, 0, 2, 2, 2, 0, 0, 0, 1, 0, 0, 2, 0, 2, 0, 1, 0, 0, 0,\n",
      "       0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 1, 0, 0, 0, 0, 1, 1, 2, 0, 0,\n",
      "       0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 2]), metrics={'test_loss': 0.9525502324104309, 'test_accuracy': 0.5897435897435898, 'test_precision': 0.5367610347367432, 'test_recall': 0.5897435897435898, 'test_f1': 0.5531889305857308, 'test_runtime': 7.6449, 'test_samples_per_second': 30.609, 'test_steps_per_second': 3.924})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "808dd68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48fb2163",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions_array = np.array(test_results.predictions[0])\n",
    "\n",
    "predictions_tensor = torch.tensor(predictions_array).to(torch.float32)\n",
    "probabilities = torch.softmax(predictions_tensor, dim=-1)\n",
    "\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed6cfde2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")  # Adjust xticklabels and yticklabels as needed\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "346c6d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_save = []\n",
    "for idx in range(len(test_data)):\n",
    "    item = dataset['test'][idx]\n",
    "    actual_label = item['label']\n",
    "    predicted_label = predictions[idx]\n",
    "    claim = item['claim'] \n",
    "    premise = item['premise'] \n",
    "    category = item['category']\n",
    "    \n",
    "    # Append the information as a dictionary to the list\n",
    "    data_to_save.append({\n",
    "        'Claim': claim,\n",
    "        'Premise': premise,\n",
    "        'Actual Label': actual_label,\n",
    "        'Predicted Label': predicted_label,\n",
    "        'Category' : category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_to_save)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/home/elson/results/10.4.3_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4543aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correctly classified instances\n",
    "correctly_classified = df[df['Actual Label'] == df['Predicted Label']]\n",
    "\n",
    "# Calculate misclassified instances\n",
    "misclassified = df[df['Actual Label'] != df['Predicted Label']]\n",
    "\n",
    "# Count the number of correctly classified and misclassified by category\n",
    "correct_classification_counts = correctly_classified['Category'].value_counts()\n",
    "misclassification_counts = misclassified['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad099d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           34\n",
       "Bone health              16\n",
       "Cancer                   12\n",
       "Fitness                   9\n",
       "Throat                    9\n",
       "Neurological health       8\n",
       "Cardiovascular Health     7\n",
       "Diabetes                  7\n",
       "Skin                      7\n",
       "Hair                      6\n",
       "Ear                       6\n",
       "COVID                     4\n",
       "Women' s Health           3\n",
       "Mental Health             3\n",
       "Blood                     3\n",
       "Muscles                   2\n",
       "Men's health              1\n",
       "Eye                       1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d45817c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           17\n",
       "Skin                     17\n",
       "Eye                       8\n",
       "Blood                     6\n",
       "Fitness                   6\n",
       "Hair                      6\n",
       "Diabetes                  5\n",
       "Men's health              5\n",
       "Cardiovascular Health     5\n",
       "Bone health               5\n",
       "Muscles                   4\n",
       "Women' s Health           3\n",
       "Vascular                  3\n",
       "Dental Health             3\n",
       "COVID                     2\n",
       "Neurological health       1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
