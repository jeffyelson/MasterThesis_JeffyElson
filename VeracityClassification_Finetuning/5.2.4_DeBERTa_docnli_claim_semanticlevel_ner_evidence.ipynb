{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-056e0caec74e8696\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-056e0caec74e8696/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 206.43it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('csv',data_files='dataset_semanticattribution_nerfeatures_split.csv',delimiter=',',column_names=[\"claim\",\"premise\",\"label\",\"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\",\"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\",\"url\", \"entities\",\"entity_map\",\"gold_exp\",\"gem_exp\",\"gem_label\",\"entity_map_ev\",\"entity_ev\",\"split\"],skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e2914c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'gold_exp', 'gem_exp', 'gem_label', 'entity_map_ev', 'entity_ev', 'split'],\n",
       "        num_rows: 2322\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57d56e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'test',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['split']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ce96b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-056e0caec74e8696/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-2a2c42dfce2e5962.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-056e0caec74e8696/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-30c3c2aed9ee6058.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-056e0caec74e8696/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-2aa654a7b533269e.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'gold_exp', 'gem_exp', 'gem_label', 'entity_map_ev', 'entity_ev', 'split'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'gold_exp', 'gem_exp', 'gem_label', 'entity_map_ev', 'entity_ev', 'split'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'gold_exp', 'gem_exp', 'gem_label', 'entity_map_ev', 'entity_ev', 'split'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41f1db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['claim', 'premise', 'label','category','counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat']\n",
    "all_columns = train_dataset.column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-056e0caec74e8696/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-eaf2fe21fc99ebf8.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-056e0caec74e8696/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-bf10d96784ce70fc.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-056e0caec74e8696/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-c1a900171b843a98.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 1, 'entailment': 0, 'neutral': 1}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 1,\n",
    "    \"entailment\": 0,\n",
    "    \"neutral\": 1\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='MoritzLaurer/DeBERTa-v3-base-mnli-fever-docnli-ling-2c'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "        # Extracting claim and evidence texts\n",
    "        category = item['category'].lower()\n",
    "\n",
    "        claim = item['claim']\n",
    "        premise = item['premise'].replace('\\n', '').replace('[','').replace(']','')\n",
    "        additional_features = [\n",
    "            'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat']\n",
    "    \n",
    "        for feature in additional_features:\n",
    "            if feature in item:\n",
    "                premise += \"[SEP]\" + str(item[feature])\n",
    "        item['claim']=claim\n",
    "        item['premise']=premise        \n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "             premise, claim,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "        item['input_ids'] = inputs['input_ids'].squeeze()  # Remove batch dimension\n",
    "        item['attention_mask']= inputs['attention_mask'].squeeze() # Remove batch dimension\n",
    "        \n",
    "        output_item = {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),  # Remove batch dimension\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),  # Remove batch dimension\n",
    "            'claim': claim,  # Include augmented claim text\n",
    "            'evidences': premise  # Include original evidence text\n",
    "        }\n",
    "        \n",
    "        if 'label' in item:\n",
    "            output_item['label'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return output_item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62421eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DebertaV2ForSequenceClassification(\n",
       "  (deberta): DebertaV2Model(\n",
       "    (embeddings): DebertaV2Embeddings(\n",
       "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaV2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (1): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (2): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (3): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (4): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (5): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (6): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (7): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (8): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (9): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (10): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (11): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (pooler): ContextPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): StableDropout()\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): StableDropout()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"MoritzLaurer/DeBERTa-v3-base-mnli-fever-docnli-ling-2c\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=2, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    bal_accuracy = balanced_accuracy_score(labels,preds)\n",
    "\n",
    "    return {\"accuracy\": acc, \"balanced_accuracy\":bal_accuracy, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17c5e0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([     1,   2600,   3405,  16876,    667,  37198,  61593,    261,   1149,\n",
       "            260,    346,  29597,   6848,  37198,  61593,    261,    273,    260,\n",
       "            346,  37741,  37198,  61593,  16876,    667,  37198,  61593,    261,\n",
       "            916,    260,    346, 117259,  34984,  37198,  61593,    261,    749,\n",
       "            260,    346,  10490,  73907,   8007,  37198,  61593,    261,   1130,\n",
       "            260,    346,   1407,   3359,  73907,   8007,  37198,  61593,    261,\n",
       "            851,    260, 100066,    263,  98237,   1830,   6725,    263,   5134,\n",
       "          30055,  77487,    532,   4014,    271,    547,  52263,  16224,    265,\n",
       "          86207,  14178,    268,    260,  97818,   4379,    261,    273,    260,\n",
       "          43923,  23399,    429,   8068,   1068,    268,    265,  88327,   1917,\n",
       "         110269,    287,    260,  57909,   4765,  12100,   2148,    263,  25348,\n",
       "          20413,   1563,    265,    917,    263,    308,    266,  84530,  62542,\n",
       "            275,  98237,    287,  41462,    667,  65073,  44845,  22317,    285,\n",
       "          36774,    260,  70298,  40149,    294,  32799,  22280,    270,   9560,\n",
       "           2926,    260,  29466,  32531,  11238,   5750,    261,   1149,    260,\n",
       "            346,  35339,    261,    716,    260,    346,  29700,    261,    851,\n",
       "            260,    346,  43713,  15150,    261,   1130,    260,    346,   5794,\n",
       "            261,    749,    260,   9048,   5341,    293,   4613,   4950,    294,\n",
       "            716,    260,  98237,    452,   4366,  52114,  72408,    260,  44233,\n",
       "           4765,  39151,    261,    909,    260,    346,  42595,  39151,    261,\n",
       "            662,    260,    346,  42595,  39151,    261,    749,    260,    346,\n",
       "          11209,  60641,    261,    749,    260, 100066,    287,  15726,   2209,\n",
       "           5858,  25499,   3004,    909,  74742,    318,  13238,  37198,    198,\n",
       "            133,   5900,    346,    260,  43427,    285,    294,   1007,    262,\n",
       "           1857,    265,   1471,   1567,    264,    262,   2626,  41529,  28479,\n",
       "            270,    262,   5937,    263,   1035,    265,   1721,   4253,    260,\n",
       "          95126,    263, 121470,   1506,    265,  88609,   1080,    260,  12768,\n",
       "          19573,    268,   4086,  60761,   2767,  15808,    260,    346,   7413,\n",
       "            261,    829,    260, 100066,    263,  98237,    283,  11882,    267,\n",
       "            572,    260,      2,    767,      2,    767,      2,    767,      2,\n",
       "            767,      2,    767,      2,    767,      2,    767,      2,    767,\n",
       "              2,    767,      2,    767,      2,    767,      2,    767,      2,\n",
       "            573,  52341,   1830,   1080,    269,   1359,    427,    267,  17847,\n",
       "            633,    264,    408,   1300,    262,   2658,    265,    262,   1158,\n",
       "            260,      2,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'claim': 'Myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.',\n",
       " 'evidences': '; UnkoviÄ‡, N.; DimkiÄ‡, I.; JanaÄ‡koviÄ‡, P.; GavriloviÄ‡, M.; StanojeviÄ‡, O.; VukojeviÄ‡, J. Frankincense and myrrh essential oils and burn incense fume against micro-inhabitants of sacral ambients.Shameem, I. Phytochemical & therapeutic potentials of Murr makki (.Oxidative stress and immunotoxic effects of lead and their amelioration with myrrh (Commiphora molmol) emulsion.Essential Oils: Magical Ingredients for Skin Care.Chakravarty, N.; Kellogg, C.; Alvarez, J.; Equils, O.; Morgan, M. UV Protection by Natural Products: C. myrrha Oil Versus Sunscreen.Hamidpour, R.; Hamidpour, S.; Hamidpour, M.; Shahlari, M. Frankincense (ä¹³é¦™ RÇ” XiÄ\\x81ng;.species): From the selection of traditional applications to the novel phytotherapy for the prevention and treatment of serious diseases.Chemistry and immunomodulatory activity of frankincense oil.Compositions containing Boswellia extracts.; Cooper, E. Frankincense and myrrh as remedies in children.[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0',\n",
       " 'label': tensor(0)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1530\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1530' max='1530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1530/1530 12:36, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.442800</td>\n",
       "      <td>0.555738</td>\n",
       "      <td>0.750538</td>\n",
       "      <td>0.744155</td>\n",
       "      <td>0.767742</td>\n",
       "      <td>0.750538</td>\n",
       "      <td>0.755604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.282400</td>\n",
       "      <td>0.637850</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.727753</td>\n",
       "      <td>0.754328</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.746158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.277400</td>\n",
       "      <td>0.603609</td>\n",
       "      <td>0.767742</td>\n",
       "      <td>0.751980</td>\n",
       "      <td>0.776078</td>\n",
       "      <td>0.767742</td>\n",
       "      <td>0.770744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.202400</td>\n",
       "      <td>1.008567</td>\n",
       "      <td>0.744086</td>\n",
       "      <td>0.712701</td>\n",
       "      <td>0.745398</td>\n",
       "      <td>0.744086</td>\n",
       "      <td>0.744710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.080100</td>\n",
       "      <td>1.453202</td>\n",
       "      <td>0.722581</td>\n",
       "      <td>0.705003</td>\n",
       "      <td>0.734868</td>\n",
       "      <td>0.722581</td>\n",
       "      <td>0.726969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.061000</td>\n",
       "      <td>1.937304</td>\n",
       "      <td>0.686022</td>\n",
       "      <td>0.697744</td>\n",
       "      <td>0.729865</td>\n",
       "      <td>0.686022</td>\n",
       "      <td>0.695235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>1.898196</td>\n",
       "      <td>0.724731</td>\n",
       "      <td>0.721594</td>\n",
       "      <td>0.748255</td>\n",
       "      <td>0.724731</td>\n",
       "      <td>0.731216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>2.004688</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.722756</td>\n",
       "      <td>0.750840</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.745271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.051456</td>\n",
       "      <td>0.735484</td>\n",
       "      <td>0.734603</td>\n",
       "      <td>0.759413</td>\n",
       "      <td>0.735484</td>\n",
       "      <td>0.741810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>2.106236</td>\n",
       "      <td>0.744086</td>\n",
       "      <td>0.734351</td>\n",
       "      <td>0.759527</td>\n",
       "      <td>0.744086</td>\n",
       "      <td>0.748926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.105528</td>\n",
       "      <td>0.744086</td>\n",
       "      <td>0.727690</td>\n",
       "      <td>0.754650</td>\n",
       "      <td>0.744086</td>\n",
       "      <td>0.747847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.182773</td>\n",
       "      <td>0.739785</td>\n",
       "      <td>0.727815</td>\n",
       "      <td>0.754080</td>\n",
       "      <td>0.739785</td>\n",
       "      <td>0.744450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.236316</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.732749</td>\n",
       "      <td>0.758081</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.746939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.248662</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.732749</td>\n",
       "      <td>0.758081</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.746939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.253531</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.732749</td>\n",
       "      <td>0.758081</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.746939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.4_deberta_docnli/checkpoint-102\n",
      "Configuration saved in /home/elson/5.2.4_deberta_docnli/checkpoint-102/config.json\n",
      "Model weights saved in /home/elson/5.2.4_deberta_docnli/checkpoint-102/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.4_deberta_docnli/checkpoint-204\n",
      "Configuration saved in /home/elson/5.2.4_deberta_docnli/checkpoint-204/config.json\n",
      "Model weights saved in /home/elson/5.2.4_deberta_docnli/checkpoint-204/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.4_deberta_docnli/checkpoint-306\n",
      "Configuration saved in /home/elson/5.2.4_deberta_docnli/checkpoint-306/config.json\n",
      "Model weights saved in /home/elson/5.2.4_deberta_docnli/checkpoint-306/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.2.4_deberta_docnli/checkpoint-102] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/5.2.4_deberta_docnli/checkpoint-204] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.4_deberta_docnli/checkpoint-408\n",
      "Configuration saved in /home/elson/5.2.4_deberta_docnli/checkpoint-408/config.json\n",
      "Model weights saved in /home/elson/5.2.4_deberta_docnli/checkpoint-408/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.4_deberta_docnli/checkpoint-510\n",
      "Configuration saved in /home/elson/5.2.4_deberta_docnli/checkpoint-510/config.json\n",
      "Model weights saved in /home/elson/5.2.4_deberta_docnli/checkpoint-510/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.2.4_deberta_docnli/checkpoint-408] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.4_deberta_docnli/checkpoint-612\n",
      "Configuration saved in /home/elson/5.2.4_deberta_docnli/checkpoint-612/config.json\n",
      "Model weights saved in /home/elson/5.2.4_deberta_docnli/checkpoint-612/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.2.4_deberta_docnli/checkpoint-510] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.4_deberta_docnli/checkpoint-714\n",
      "Configuration saved in /home/elson/5.2.4_deberta_docnli/checkpoint-714/config.json\n",
      "Model weights saved in /home/elson/5.2.4_deberta_docnli/checkpoint-714/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.2.4_deberta_docnli/checkpoint-612] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.4_deberta_docnli/checkpoint-816\n",
      "Configuration saved in /home/elson/5.2.4_deberta_docnli/checkpoint-816/config.json\n",
      "Model weights saved in /home/elson/5.2.4_deberta_docnli/checkpoint-816/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.2.4_deberta_docnli/checkpoint-714] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.4_deberta_docnli/checkpoint-918\n",
      "Configuration saved in /home/elson/5.2.4_deberta_docnli/checkpoint-918/config.json\n",
      "Model weights saved in /home/elson/5.2.4_deberta_docnli/checkpoint-918/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.2.4_deberta_docnli/checkpoint-816] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.4_deberta_docnli/checkpoint-1020\n",
      "Configuration saved in /home/elson/5.2.4_deberta_docnli/checkpoint-1020/config.json\n",
      "Model weights saved in /home/elson/5.2.4_deberta_docnli/checkpoint-1020/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.2.4_deberta_docnli/checkpoint-918] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.4_deberta_docnli/checkpoint-1122\n",
      "Configuration saved in /home/elson/5.2.4_deberta_docnli/checkpoint-1122/config.json\n",
      "Model weights saved in /home/elson/5.2.4_deberta_docnli/checkpoint-1122/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.2.4_deberta_docnli/checkpoint-1020] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.4_deberta_docnli/checkpoint-1224\n",
      "Configuration saved in /home/elson/5.2.4_deberta_docnli/checkpoint-1224/config.json\n",
      "Model weights saved in /home/elson/5.2.4_deberta_docnli/checkpoint-1224/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.2.4_deberta_docnli/checkpoint-1122] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.4_deberta_docnli/checkpoint-1326\n",
      "Configuration saved in /home/elson/5.2.4_deberta_docnli/checkpoint-1326/config.json\n",
      "Model weights saved in /home/elson/5.2.4_deberta_docnli/checkpoint-1326/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.2.4_deberta_docnli/checkpoint-1224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.4_deberta_docnli/checkpoint-1428\n",
      "Configuration saved in /home/elson/5.2.4_deberta_docnli/checkpoint-1428/config.json\n",
      "Model weights saved in /home/elson/5.2.4_deberta_docnli/checkpoint-1428/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.2.4_deberta_docnli/checkpoint-1326] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.4_deberta_docnli/checkpoint-1530\n",
      "Configuration saved in /home/elson/5.2.4_deberta_docnli/checkpoint-1530/config.json\n",
      "Model weights saved in /home/elson/5.2.4_deberta_docnli/checkpoint-1530/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.2.4_deberta_docnli/checkpoint-1428] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/elson/5.2.4_deberta_docnli/checkpoint-306 (score: 0.7677419354838709).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /home/elson/5.2.4_deberta_docnli/best_model/config.json\n",
      "Model weights saved in /home/elson/5.2.4_deberta_docnli/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/5.2.4_deberta_docnli/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/5.2.4_deberta_docnli/best_model/special_tokens_map.json\n",
      "added tokens file saved in /home/elson/5.2.4_deberta_docnli/best_model/added_tokens.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/5.2.4_deberta_docnli/best_model/tokenizer_config.json',\n",
       " '/home/elson/5.2.4_deberta_docnli/best_model/special_tokens_map.json',\n",
       " '/home/elson/5.2.4_deberta_docnli/best_model/spm.model',\n",
       " '/home/elson/5.2.4_deberta_docnli/best_model/added_tokens.json')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/5.2.4_deberta_docnli/',\n",
    "    num_train_epochs=15,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.06,\n",
    "    weight_decay=0.1,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/5.2.4_deberta_docnli/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/5.2.4_deberta_docnli/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63deaea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/5.2.4_deberta_docnli/best_model/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"/home/elson/5.2.4_deberta_docnli/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"entailment\",\n",
      "    \"1\": \"not_entailment\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"entailment\": 0,\n",
      "    \"not_entailment\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file /home/elson/5.2.4_deberta_docnli/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at /home/elson/5.2.4_deberta_docnli/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 16\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/5.2.4_deberta_docnli/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[ 0.666  , -0.6343 ],\n",
      "       [ 0.987  , -0.951  ],\n",
      "       [ 2.3    , -2.215  ],\n",
      "       [-1.039  ,  1.2295 ],\n",
      "       [-0.545  ,  0.6157 ],\n",
      "       [ 2.027  , -1.962  ],\n",
      "       [ 2.373  , -2.293  ],\n",
      "       [ 2.29   , -2.209  ],\n",
      "       [ 1.9375 , -1.876  ],\n",
      "       [ 0.799  , -0.7646 ],\n",
      "       [ 2.195  , -2.117  ],\n",
      "       [ 2.578  , -2.482  ],\n",
      "       [-0.747  ,  0.9    ],\n",
      "       [ 2.373  , -2.287  ],\n",
      "       [ 1.787  , -1.733  ],\n",
      "       [-0.6064 ,  0.7075 ],\n",
      "       [-0.2091 ,  0.2318 ],\n",
      "       [ 1.693  , -1.641  ],\n",
      "       [ 2.457  , -2.37   ],\n",
      "       [ 1.951  , -1.894  ],\n",
      "       [ 0.889  , -0.8643 ],\n",
      "       [ 0.0577 , -0.04428],\n",
      "       [ 2.174  , -2.104  ],\n",
      "       [-1.607  ,  1.84   ],\n",
      "       [ 1.483  , -1.44   ],\n",
      "       [-1.369  ,  1.592  ],\n",
      "       [ 2.633  , -2.535  ],\n",
      "       [ 0.927  , -0.8926 ],\n",
      "       [ 2.127  , -2.057  ],\n",
      "       [ 2.684  , -2.578  ],\n",
      "       [-1.317  ,  1.534  ],\n",
      "       [ 1.293  , -1.262  ],\n",
      "       [ 1.131  , -1.096  ],\n",
      "       [ 1.182  , -1.146  ],\n",
      "       [-0.7505 ,  0.9097 ],\n",
      "       [ 0.4    , -0.3743 ],\n",
      "       [ 1.011  , -0.9775 ],\n",
      "       [ 2.05   , -1.984  ],\n",
      "       [-0.8843 ,  1.062  ],\n",
      "       [-0.31   ,  0.3533 ],\n",
      "       [-0.4478 ,  0.5034 ],\n",
      "       [ 2.174  , -2.102  ],\n",
      "       [ 0.862  , -0.833  ],\n",
      "       [-0.5117 ,  0.5913 ],\n",
      "       [-0.5063 ,  0.583  ],\n",
      "       [ 2.387  , -2.303  ],\n",
      "       [ 1.804  , -1.75   ],\n",
      "       [ 1.9795 , -1.912  ],\n",
      "       [ 2.072  , -2.004  ],\n",
      "       [-1.32   ,  1.533  ],\n",
      "       [ 0.8066 , -0.7783 ],\n",
      "       [ 1.215  , -1.179  ],\n",
      "       [-1.136  ,  1.338  ],\n",
      "       [ 1.454  , -1.413  ],\n",
      "       [-0.3105 ,  0.3489 ],\n",
      "       [ 2.342  , -2.26   ],\n",
      "       [-1.022  ,  1.217  ],\n",
      "       [ 1.798  , -1.743  ],\n",
      "       [ 1.51   , -1.469  ],\n",
      "       [ 1.939  , -1.875  ],\n",
      "       [ 1.648  , -1.603  ],\n",
      "       [-0.946  ,  1.122  ],\n",
      "       [ 1.7    , -1.65   ],\n",
      "       [-0.574  ,  0.6543 ],\n",
      "       [ 0.1967 , -0.1704 ],\n",
      "       [ 2.234  , -2.16   ],\n",
      "       [ 1.061  , -1.038  ],\n",
      "       [ 1.691  , -1.642  ],\n",
      "       [ 1.999  , -1.932  ],\n",
      "       [ 2.238  , -2.162  ],\n",
      "       [ 1.682  , -1.632  ],\n",
      "       [ 1.233  , -1.201  ],\n",
      "       [ 1.132  , -1.096  ],\n",
      "       [-0.383  ,  0.415  ],\n",
      "       [ 1.179  , -1.144  ],\n",
      "       [ 0.6255 , -0.5864 ],\n",
      "       [ 2.037  , -1.97   ],\n",
      "       [ 2.168  , -2.098  ],\n",
      "       [ 2.594  , -2.496  ],\n",
      "       [ 1.633  , -1.583  ],\n",
      "       [ 2.13   , -2.06   ],\n",
      "       [ 2.695  , -2.594  ],\n",
      "       [ 1.374  , -1.331  ],\n",
      "       [ 2.127  , -2.055  ],\n",
      "       [-0.681  ,  0.824  ],\n",
      "       [ 0.1043 , -0.0827 ],\n",
      "       [ 2.43   , -2.342  ],\n",
      "       [ 1.904  , -1.846  ],\n",
      "       [ 0.912  , -0.8857 ],\n",
      "       [ 2.076  , -2.008  ],\n",
      "       [ 2.451  , -2.36   ],\n",
      "       [ 2.125  , -2.055  ],\n",
      "       [-0.2812 ,  0.2898 ],\n",
      "       [ 1.7295 , -1.675  ],\n",
      "       [-0.3442 ,  0.3774 ],\n",
      "       [ 0.8374 , -0.813  ],\n",
      "       [ 0.99   , -0.9517 ],\n",
      "       [-0.591  ,  0.6904 ],\n",
      "       [ 1.561  , -1.513  ],\n",
      "       [ 2.277  , -2.197  ],\n",
      "       [-1.373  ,  1.588  ],\n",
      "       [ 2.19   , -2.115  ],\n",
      "       [ 1.652  , -1.604  ],\n",
      "       [ 1.184  , -1.145  ],\n",
      "       [ 1.944  , -1.877  ],\n",
      "       [ 1.922  , -1.86   ],\n",
      "       [ 1.628  , -1.581  ],\n",
      "       [-1.333  ,  1.55   ],\n",
      "       [ 2.182  , -2.11   ],\n",
      "       [ 2.271  , -2.191  ],\n",
      "       [ 1.21   , -1.176  ],\n",
      "       [ 2.576  , -2.479  ],\n",
      "       [ 1.539  , -1.493  ],\n",
      "       [ 2.295  , -2.215  ],\n",
      "       [ 2.295  , -2.217  ],\n",
      "       [ 1.027  , -1.     ],\n",
      "       [ 2.734  , -2.629  ],\n",
      "       [ 1.5205 , -1.477  ],\n",
      "       [ 2.5    , -2.404  ],\n",
      "       [ 2.047  , -1.981  ],\n",
      "       [ 2.318  , -2.238  ],\n",
      "       [ 1.306  , -1.27   ],\n",
      "       [ 1.794  , -1.741  ],\n",
      "       [ 0.3867 , -0.367  ],\n",
      "       [ 2.123  , -2.05   ],\n",
      "       [ 1.933  , -1.873  ],\n",
      "       [ 0.8657 , -0.8354 ],\n",
      "       [ 2.484  , -2.39   ],\n",
      "       [ 1.628  , -1.582  ],\n",
      "       [ 0.5107 , -0.5005 ],\n",
      "       [ 0.9463 , -0.917  ],\n",
      "       [ 1.706  , -1.655  ],\n",
      "       [ 1.765  , -1.713  ],\n",
      "       [ 0.534  , -0.5137 ],\n",
      "       [ 0.2888 , -0.271  ],\n",
      "       [-0.66   ,  0.7896 ],\n",
      "       [ 1.444  , -1.4    ],\n",
      "       [-1.9    ,  2.135  ],\n",
      "       [-0.9917 ,  1.186  ],\n",
      "       [ 1.514  , -1.471  ],\n",
      "       [ 2.295  , -2.215  ],\n",
      "       [ 1.834  , -1.778  ],\n",
      "       [ 0.9165 , -0.888  ],\n",
      "       [ 2.75   , -2.645  ],\n",
      "       [ 0.698  , -0.6704 ],\n",
      "       [ 0.753  , -0.7246 ],\n",
      "       [-0.8447 ,  1.006  ],\n",
      "       [ 1.206  , -1.172  ],\n",
      "       [ 2.484  , -2.393  ],\n",
      "       [-1.042  ,  1.238  ],\n",
      "       [ 0.942  , -0.901  ],\n",
      "       [ 2.354  , -2.266  ],\n",
      "       [ 2.375  , -2.293  ],\n",
      "       [ 1.443  , -1.399  ],\n",
      "       [ 1.182  , -1.146  ],\n",
      "       [ 2.172  , -2.1    ],\n",
      "       [ 2.145  , -2.07   ],\n",
      "       [-0.2421 ,  0.2703 ],\n",
      "       [ 1.81   , -1.755  ],\n",
      "       [-1.095  ,  1.297  ],\n",
      "       [-1.701  ,  1.929  ],\n",
      "       [-1.264  ,  1.471  ],\n",
      "       [ 1.709  , -1.661  ],\n",
      "       [-0.426  ,  0.474  ],\n",
      "       [ 0.508  , -0.4802 ],\n",
      "       [ 1.161  , -1.126  ],\n",
      "       [ 1.672  , -1.625  ],\n",
      "       [-0.08746,  0.1009 ],\n",
      "       [ 0.9414 , -0.9106 ],\n",
      "       [ 1.649  , -1.599  ],\n",
      "       [-0.986  ,  1.179  ],\n",
      "       [ 0.883  , -0.8496 ],\n",
      "       [-0.813  ,  0.973  ],\n",
      "       [ 2.467  , -2.379  ],\n",
      "       [ 1.637  , -1.59   ],\n",
      "       [-1.026  ,  1.222  ],\n",
      "       [ 1.363  , -1.325  ],\n",
      "       [ 2.23   , -2.156  ],\n",
      "       [ 1.875  , -1.818  ],\n",
      "       [ 0.7905 , -0.7603 ],\n",
      "       [-0.3486 ,  0.3818 ],\n",
      "       [-0.636  ,  0.7534 ],\n",
      "       [-1.026  ,  1.223  ],\n",
      "       [ 0.881  , -0.848  ],\n",
      "       [ 0.569  , -0.5405 ],\n",
      "       [ 2.611  , -2.516  ],\n",
      "       [ 1.833  , -1.774  ],\n",
      "       [ 1.015  , -0.9824 ],\n",
      "       [-0.864  ,  1.028  ],\n",
      "       [ 1.826  , -1.7705 ],\n",
      "       [ 0.9067 , -0.8765 ],\n",
      "       [ 1.823  , -1.767  ],\n",
      "       [ 2.404  , -2.32   ],\n",
      "       [ 1.52   , -1.474  ],\n",
      "       [-1.043  ,  1.239  ],\n",
      "       [ 2.383  , -2.297  ],\n",
      "       [ 1.015  , -0.9863 ],\n",
      "       [ 1.5205 , -1.477  ],\n",
      "       [ 1.552  , -1.503  ],\n",
      "       [ 0.065  , -0.06555],\n",
      "       [ 1.954  , -1.893  ],\n",
      "       [ 2.29   , -2.21   ],\n",
      "       [ 1.012  , -0.9766 ],\n",
      "       [ 2.283  , -2.205  ],\n",
      "       [-0.686  ,  0.8296 ],\n",
      "       [-0.7896 ,  0.9434 ],\n",
      "       [ 2.129  , -2.059  ],\n",
      "       [ 1.153  , -1.119  ],\n",
      "       [ 1.851  , -1.793  ],\n",
      "       [ 0.2935 , -0.2766 ],\n",
      "       [ 1.052  , -1.017  ],\n",
      "       [ 0.1925 , -0.192  ],\n",
      "       [ 2.576  , -2.482  ],\n",
      "       [ 1.717  , -1.664  ],\n",
      "       [-0.347  ,  0.3887 ],\n",
      "       [-0.4158 ,  0.4692 ],\n",
      "       [ 0.392  , -0.372  ],\n",
      "       [ 1.435  , -1.39   ],\n",
      "       [ 2.295  , -2.215  ],\n",
      "       [ 1.664  , -1.614  ],\n",
      "       [ 2.564  , -2.469  ],\n",
      "       [ 1.547  , -1.502  ],\n",
      "       [-0.4907 ,  0.5674 ],\n",
      "       [ 2.756  , -2.648  ],\n",
      "       [ 1.732  , -1.679  ],\n",
      "       [ 2.018  , -1.953  ],\n",
      "       [ 1.67   , -1.622  ],\n",
      "       [-1.658  ,  1.89   ],\n",
      "       [ 1.01   , -0.98   ],\n",
      "       [ 1.266  , -1.23   ],\n",
      "       [ 2.451  , -2.363  ],\n",
      "       [ 1.83   , -1.773  ],\n",
      "       [ 2.006  , -1.942  ],\n",
      "       [ 0.786  , -0.759  ]], dtype=float16), label_ids=array([0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
      "       0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
      "       0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1,\n",
      "       0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "       1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "       0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
      "       0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "       0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
      "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
      "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1]), metrics={'test_loss': 0.9719488620758057, 'test_accuracy': 0.6538461538461539, 'test_balanced_accuracy': 0.5798691454559962, 'test_precision': 0.6309171597633136, 'test_recall': 0.6538461538461539, 'test_f1': 0.6302148302148303, 'test_runtime': 2.3571, 'test_samples_per_second': 99.273, 'test_steps_per_second': 6.364})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73395d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "probabilities = torch.softmax(torch.tensor(test_results.predictions).to(torch.float32), dim=-1)\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)\n",
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb603377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_save = []\n",
    "for idx in range(len(test_data)):\n",
    "    item = dataset['test'][idx]\n",
    "    actual_label = item['label']\n",
    "    predicted_label = predictions[idx]\n",
    "    claim = item['claim'] \n",
    "    premise = item['premise'] \n",
    "    category = item['category']\n",
    "    \n",
    "    # Append the information as a dictionary to the list\n",
    "    data_to_save.append({\n",
    "        'Claim': claim,\n",
    "        'Premise': premise,\n",
    "        'Actual Label': actual_label,\n",
    "        'Predicted Label': predicted_label,\n",
    "        'Category' : category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_to_save)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/home/elson/results/5.2.4_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c23339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correctly classified instances\n",
    "correctly_classified = df[df['Actual Label'] == df['Predicted Label']]\n",
    "\n",
    "# Calculate misclassified instances\n",
    "misclassified = df[df['Actual Label'] != df['Predicted Label']]\n",
    "\n",
    "# Count the number of correctly classified and misclassified by category\n",
    "correct_classification_counts = correctly_classified['Category'].value_counts()\n",
    "misclassification_counts = misclassified['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca0def77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           34\n",
       "Bone health              16\n",
       "Cancer                   12\n",
       "Diabetes                 10\n",
       "Hair                      9\n",
       "Cardiovascular Health     9\n",
       "Throat                    9\n",
       "Fitness                   8\n",
       "Neurological health       7\n",
       "Women' s Health           6\n",
       "COVID                     6\n",
       "Ear                       6\n",
       "Skin                      6\n",
       "Blood                     4\n",
       "Muscles                   3\n",
       "Men's health              3\n",
       "Mental Health             2\n",
       "Eye                       2\n",
       "Vascular                  1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0fddd944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Skin                     18\n",
       "General Health           17\n",
       "Eye                       7\n",
       "Fitness                   7\n",
       "Bone health               5\n",
       "Blood                     5\n",
       "Hair                      3\n",
       "Dental Health             3\n",
       "Cardiovascular Health     3\n",
       "Muscles                   3\n",
       "Men's health              3\n",
       "Diabetes                  2\n",
       "Vascular                  2\n",
       "Neurological health       2\n",
       "Mental Health             1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38b899b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_counts = df['Category'].value_counts()\n",
    "\n",
    "# Calculate ratios\n",
    "correct_classification_ratios = correct_classification_counts / total_counts\n",
    "misclassification_ratios = misclassification_counts / total_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c3598b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blood                    0.444444\n",
      "Bone health              0.761905\n",
      "COVID                    1.000000\n",
      "Cancer                   1.000000\n",
      "Cardiovascular Health    0.750000\n",
      "Dental Health                 NaN\n",
      "Diabetes                 0.833333\n",
      "Ear                      1.000000\n",
      "Eye                      0.222222\n",
      "Fitness                  0.533333\n",
      "General Health           0.666667\n",
      "Hair                     0.750000\n",
      "Men's health             0.500000\n",
      "Mental Health            0.666667\n",
      "Muscles                  0.500000\n",
      "Neurological health      0.777778\n",
      "Skin                     0.250000\n",
      "Throat                   1.000000\n",
      "Vascular                 0.333333\n",
      "Women' s Health          1.000000\n",
      "Name: Category, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(correct_classification_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27602a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blood                    0.555556\n",
      "Bone health              0.238095\n",
      "COVID                         NaN\n",
      "Cancer                        NaN\n",
      "Cardiovascular Health    0.250000\n",
      "Dental Health            1.000000\n",
      "Diabetes                 0.166667\n",
      "Ear                           NaN\n",
      "Eye                      0.777778\n",
      "Fitness                  0.466667\n",
      "General Health           0.333333\n",
      "Hair                     0.250000\n",
      "Men's health             0.500000\n",
      "Mental Health            0.333333\n",
      "Muscles                  0.500000\n",
      "Neurological health      0.222222\n",
      "Skin                     0.750000\n",
      "Throat                        NaN\n",
      "Vascular                 0.666667\n",
      "Women' s Health               NaN\n",
      "Name: Category, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(misclassification_ratios)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
