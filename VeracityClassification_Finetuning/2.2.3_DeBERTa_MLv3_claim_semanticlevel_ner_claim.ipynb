{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score,balanced_accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82806f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jul 29 19:44:17 2024       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:61:00.0 Off |                    0 |\r\n",
      "| N/A   47C    P0    58W / 300W |      0MiB / 32768MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla V100-SXM2...  Off  | 00000000:62:00.0 Off |                    0 |\r\n",
      "| N/A   45C    P0    58W / 300W |      0MiB / 32768MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   2  Tesla V100-SXM2...  Off  | 00000000:89:00.0 Off |                    0 |\r\n",
      "| N/A   44C    P0    61W / 300W |      0MiB / 32768MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   3  Tesla V100-SXM2...  Off  | 00000000:8A:00.0 Off |                    0 |\r\n",
      "| N/A   45C    P0    60W / 300W |      0MiB / 32768MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-31dfe7adddcf5ced\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 208.11it/s]\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-ad71be204b279b28.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-e7b6b615907c24ca.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-bee802838a3bfaea.arrow\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset from the CSV file\n",
    "dataset = load_dataset(\n",
    "    'csv',\n",
    "    data_files='dataset_semanticattribution_nerfeatures_split.csv',\n",
    "    delimiter=',',\n",
    "    column_names=[\n",
    "        \"claim\", \"premise\", \"label\", \"category\", \"count_bf\", \"count_ca\", \"count_dis\",\n",
    "        \"count_food\", \"count_lipid\", \"count_treat\", \"pres_bf\", \"pres_ca\", \"pres_dis\",\n",
    "        \"pres_food\", \"pres_lipid\", \"pres_treat\", \"counte_bf\", \"counte_ca\", \"counte_dis\",\n",
    "        \"counte_food\", \"counte_lipid\", \"counte_treat\", \"prese_bf\", \"prese_ca\", \"prese_dis\",\n",
    "        \"prese_food\", \"prese_lipid\", \"prese_treat\", \"url\", \"entities\", \"entity_map\",\n",
    "        \"gold_exp\", \"gemini_exp\", \"gemini_label\",\"entity_ev\",\"entity_map_ev\", \"split\"\n",
    "    ],\n",
    "    skiprows=1\n",
    ")\n",
    "\n",
    "# Assuming 'split' column contains strings 'train', 'validation', 'test'\n",
    "# Filter the loaded dataset into subsets\n",
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'gold_exp', 'gemini_exp', 'gemini_label', 'entity_ev', 'entity_map_ev', 'split'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f3e71be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41f1db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['claim', 'premise', 'label','category','count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat']\n",
    "all_columns = train_dataset.column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-cff159857da63bad.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-5196dddd45d295bd.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-6da3c8ce03dcb68e.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 2, 'entailment': 0, 'neutral': 1}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 2,\n",
    "    \"entailment\": 0,\n",
    "    \"neutral\": 1\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b5bb17f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "465"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['val']['claim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "        # Extracting claim and evidence texts\n",
    "        category = item['category']\n",
    "\n",
    "        claim = item['claim']\n",
    "        premise = item['premise'].replace('\\n', '').replace('[','').replace(']','')\n",
    "        additional_features = [\n",
    "            \"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\"]\n",
    "    \n",
    "        for feature in additional_features:\n",
    "            if feature in item:\n",
    "                claim += \"[SEP]\" + str(item[feature])\n",
    "        item['claim']=claim\n",
    "        item['premise']=premise        \n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "             premise, claim,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "        item['input_ids'] = inputs['input_ids'].squeeze()  # Remove batch dimension\n",
    "        item['attention_mask']= inputs['attention_mask'].squeeze() # Remove batch dimension\n",
    "        \n",
    "        output_item = {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),  # Remove batch dimension\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),  # Remove batch dimension\n",
    "            'claim': claim,  # Include augmented claim text\n",
    "            'evidences': premise  # Include original evidence text\n",
    "        }\n",
    "        \n",
    "        if 'label' in item:\n",
    "            output_item['label'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return output_item\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62421eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=3, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f72c5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model is on device: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    bal_accuracy = balanced_accuracy_score(labels,preds)\n",
    "\n",
    "    return {\"accuracy\": acc, \"balanced_accuracy\":bal_accuracy, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17c5e0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([     1,   2600,   3405,  16876,    667,  37198,  61593,    261,   1149,\n",
       "            260,    346,  29597,   6848,  37198,  61593,    261,    273,    260,\n",
       "            346,  37741,  37198,  61593,  16876,    667,  37198,  61593,    261,\n",
       "            916,    260,    346, 117259,  34984,  37198,  61593,    261,    749,\n",
       "            260,    346,  10490,  73907,   8007,  37198,  61593,    261,   1130,\n",
       "            260,    346,   1407,   3359,  73907,   8007,  37198,  61593,    261,\n",
       "            851,    260, 100066,    263,  98237,   1830,   6725,    263,   5134,\n",
       "          30055,  77487,    532,   4014,    271,    547,  52263,  16224,    265,\n",
       "          86207,  14178,    268,    260,  97818,   4379,    261,    273,    260,\n",
       "          43923,  23399,    429,   8068,   1068,    268,    265,  88327,   1917,\n",
       "         110269,    287,    260,  57909,   4765,  12100,   2148,    263,  25348,\n",
       "          20413,   1563,    265,    917,    263,    308,    266,  84530,  62542,\n",
       "            275,  98237,    287,  41462,    667,  65073,  44845,  22317,    285,\n",
       "          36774,    260,  70298,  40149,    294,  32799,  22280,    270,   9560,\n",
       "           2926,    260,  29466,  32531,  11238,   5750,    261,   1149,    260,\n",
       "            346,  35339,    261,    716,    260,    346,  29700,    261,    851,\n",
       "            260,    346,  43713,  15150,    261,   1130,    260,    346,   5794,\n",
       "            261,    749,    260,   9048,   5341,    293,   4613,   4950,    294,\n",
       "            716,    260,  98237,    452,   4366,  52114,  72408,    260,  44233,\n",
       "           4765,  39151,    261,    909,    260,    346,  42595,  39151,    261,\n",
       "            662,    260,    346,  42595,  39151,    261,    749,    260,    346,\n",
       "          11209,  60641,    261,    749,    260, 100066,    287,  15726,   2209,\n",
       "           5858,  25499,   3004,    909,  74742,    318,  13238,  37198,    198,\n",
       "            133,   5900,    346,    260,  43427,    285,    294,   1007,    262,\n",
       "           1857,    265,   1471,   1567,    264,    262,   2626,  41529,  28479,\n",
       "            270,    262,   5937,    263,   1035,    265,   1721,   4253,    260,\n",
       "          95126,    263, 121470,   1506,    265,  88609,   1080,    260,  12768,\n",
       "          19573,    268,   4086,  60761,   2767,  15808,    260,    346,   7413,\n",
       "            261,    829,    260, 100066,    263,  98237,    283,  11882,    267,\n",
       "            572,    260,      2,    573,  52341,   1830,   1080,    269,   1359,\n",
       "            427,    267,  17847,    633,    264,    408,   1300,    262,   2658,\n",
       "            265,    262,   1158,    260,      2,    767,      2,    767,      2,\n",
       "            767,      2,    767,      2,    767,      2,    767,      2,    767,\n",
       "              2,    767,      2,    767,      2,    767,      2,    767,      2,\n",
       "            767,      2,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'claim': 'Myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0',\n",
       " 'evidences': '; UnkoviÄ‡, N.; DimkiÄ‡, I.; JanaÄ‡koviÄ‡, P.; GavriloviÄ‡, M.; StanojeviÄ‡, O.; VukojeviÄ‡, J. Frankincense and myrrh essential oils and burn incense fume against micro-inhabitants of sacral ambients.Shameem, I. Phytochemical & therapeutic potentials of Murr makki (.Oxidative stress and immunotoxic effects of lead and their amelioration with myrrh (Commiphora molmol) emulsion.Essential Oils: Magical Ingredients for Skin Care.Chakravarty, N.; Kellogg, C.; Alvarez, J.; Equils, O.; Morgan, M. UV Protection by Natural Products: C. myrrha Oil Versus Sunscreen.Hamidpour, R.; Hamidpour, S.; Hamidpour, M.; Shahlari, M. Frankincense (ä¹³é¦™ RÇ” XiÄ\\x81ng;.species): From the selection of traditional applications to the novel phytotherapy for the prevention and treatment of serious diseases.Chemistry and immunomodulatory activity of frankincense oil.Compositions containing Boswellia extracts.; Cooper, E. Frankincense and myrrh as remedies in children.',\n",
       " 'label': tensor(0)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on device: cuda:0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='765' max='765' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [765/765 11:38, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.626000</td>\n",
       "      <td>0.922672</td>\n",
       "      <td>0.615054</td>\n",
       "      <td>0.498078</td>\n",
       "      <td>0.670324</td>\n",
       "      <td>0.615054</td>\n",
       "      <td>0.629558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.474600</td>\n",
       "      <td>0.819052</td>\n",
       "      <td>0.673118</td>\n",
       "      <td>0.564931</td>\n",
       "      <td>0.707722</td>\n",
       "      <td>0.673118</td>\n",
       "      <td>0.687706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.307100</td>\n",
       "      <td>1.060371</td>\n",
       "      <td>0.660215</td>\n",
       "      <td>0.568264</td>\n",
       "      <td>0.712474</td>\n",
       "      <td>0.660215</td>\n",
       "      <td>0.680949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.180600</td>\n",
       "      <td>1.167763</td>\n",
       "      <td>0.690323</td>\n",
       "      <td>0.509947</td>\n",
       "      <td>0.678375</td>\n",
       "      <td>0.690323</td>\n",
       "      <td>0.681952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.264300</td>\n",
       "      <td>1.345839</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.524478</td>\n",
       "      <td>0.678693</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.664306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.144600</td>\n",
       "      <td>1.625275</td>\n",
       "      <td>0.701075</td>\n",
       "      <td>0.568828</td>\n",
       "      <td>0.703798</td>\n",
       "      <td>0.701075</td>\n",
       "      <td>0.701957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.095900</td>\n",
       "      <td>1.738758</td>\n",
       "      <td>0.686022</td>\n",
       "      <td>0.560384</td>\n",
       "      <td>0.706271</td>\n",
       "      <td>0.686022</td>\n",
       "      <td>0.695185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.024600</td>\n",
       "      <td>2.024776</td>\n",
       "      <td>0.681720</td>\n",
       "      <td>0.571881</td>\n",
       "      <td>0.707600</td>\n",
       "      <td>0.681720</td>\n",
       "      <td>0.692769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.027700</td>\n",
       "      <td>2.265328</td>\n",
       "      <td>0.664516</td>\n",
       "      <td>0.501235</td>\n",
       "      <td>0.657012</td>\n",
       "      <td>0.664516</td>\n",
       "      <td>0.656584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.008800</td>\n",
       "      <td>2.210538</td>\n",
       "      <td>0.686022</td>\n",
       "      <td>0.526300</td>\n",
       "      <td>0.687039</td>\n",
       "      <td>0.686022</td>\n",
       "      <td>0.686510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>2.524528</td>\n",
       "      <td>0.660215</td>\n",
       "      <td>0.549027</td>\n",
       "      <td>0.693447</td>\n",
       "      <td>0.660215</td>\n",
       "      <td>0.674355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>2.538379</td>\n",
       "      <td>0.662366</td>\n",
       "      <td>0.544492</td>\n",
       "      <td>0.691308</td>\n",
       "      <td>0.662366</td>\n",
       "      <td>0.674749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>2.533480</td>\n",
       "      <td>0.668817</td>\n",
       "      <td>0.543806</td>\n",
       "      <td>0.692852</td>\n",
       "      <td>0.668817</td>\n",
       "      <td>0.679537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>2.606633</td>\n",
       "      <td>0.658065</td>\n",
       "      <td>0.526045</td>\n",
       "      <td>0.681319</td>\n",
       "      <td>0.658065</td>\n",
       "      <td>0.668434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>2.644233</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.524976</td>\n",
       "      <td>0.680064</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.666614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.2.3_deberta/checkpoint-51\n",
      "Configuration saved in /home/elson/2.2.3_deberta/checkpoint-51/config.json\n",
      "Model weights saved in /home/elson/2.2.3_deberta/checkpoint-51/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.2.3_deberta/checkpoint-102\n",
      "Configuration saved in /home/elson/2.2.3_deberta/checkpoint-102/config.json\n",
      "Model weights saved in /home/elson/2.2.3_deberta/checkpoint-102/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.3_deberta/checkpoint-51] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.2.3_deberta/checkpoint-153\n",
      "Configuration saved in /home/elson/2.2.3_deberta/checkpoint-153/config.json\n",
      "Model weights saved in /home/elson/2.2.3_deberta/checkpoint-153/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.2.3_deberta/checkpoint-204\n",
      "Configuration saved in /home/elson/2.2.3_deberta/checkpoint-204/config.json\n",
      "Model weights saved in /home/elson/2.2.3_deberta/checkpoint-204/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.3_deberta/checkpoint-153] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.2.3_deberta/checkpoint-255\n",
      "Configuration saved in /home/elson/2.2.3_deberta/checkpoint-255/config.json\n",
      "Model weights saved in /home/elson/2.2.3_deberta/checkpoint-255/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.3_deberta/checkpoint-204] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.2.3_deberta/checkpoint-306\n",
      "Configuration saved in /home/elson/2.2.3_deberta/checkpoint-306/config.json\n",
      "Model weights saved in /home/elson/2.2.3_deberta/checkpoint-306/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.3_deberta/checkpoint-102] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/2.2.3_deberta/checkpoint-255] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.2.3_deberta/checkpoint-357\n",
      "Configuration saved in /home/elson/2.2.3_deberta/checkpoint-357/config.json\n",
      "Model weights saved in /home/elson/2.2.3_deberta/checkpoint-357/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.2.3_deberta/checkpoint-408\n",
      "Configuration saved in /home/elson/2.2.3_deberta/checkpoint-408/config.json\n",
      "Model weights saved in /home/elson/2.2.3_deberta/checkpoint-408/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.3_deberta/checkpoint-357] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.2.3_deberta/checkpoint-459\n",
      "Configuration saved in /home/elson/2.2.3_deberta/checkpoint-459/config.json\n",
      "Model weights saved in /home/elson/2.2.3_deberta/checkpoint-459/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.3_deberta/checkpoint-408] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.2.3_deberta/checkpoint-510\n",
      "Configuration saved in /home/elson/2.2.3_deberta/checkpoint-510/config.json\n",
      "Model weights saved in /home/elson/2.2.3_deberta/checkpoint-510/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.3_deberta/checkpoint-459] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.2.3_deberta/checkpoint-561\n",
      "Configuration saved in /home/elson/2.2.3_deberta/checkpoint-561/config.json\n",
      "Model weights saved in /home/elson/2.2.3_deberta/checkpoint-561/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.3_deberta/checkpoint-510] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.2.3_deberta/checkpoint-612\n",
      "Configuration saved in /home/elson/2.2.3_deberta/checkpoint-612/config.json\n",
      "Model weights saved in /home/elson/2.2.3_deberta/checkpoint-612/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.3_deberta/checkpoint-561] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.2.3_deberta/checkpoint-663\n",
      "Configuration saved in /home/elson/2.2.3_deberta/checkpoint-663/config.json\n",
      "Model weights saved in /home/elson/2.2.3_deberta/checkpoint-663/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.3_deberta/checkpoint-612] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.2.3_deberta/checkpoint-714\n",
      "Configuration saved in /home/elson/2.2.3_deberta/checkpoint-714/config.json\n",
      "Model weights saved in /home/elson/2.2.3_deberta/checkpoint-714/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.3_deberta/checkpoint-663] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.2.3_deberta/checkpoint-765\n",
      "Configuration saved in /home/elson/2.2.3_deberta/checkpoint-765/config.json\n",
      "Model weights saved in /home/elson/2.2.3_deberta/checkpoint-765/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.3_deberta/checkpoint-714] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/elson/2.2.3_deberta/checkpoint-306 (score: 0.7019568445516452).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /home/elson/2.2.3_deberta/best_model/config.json\n",
      "Model weights saved in /home/elson/2.2.3_deberta/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/2.2.3_deberta/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/2.2.3_deberta/best_model/special_tokens_map.json\n",
      "added tokens file saved in /home/elson/2.2.3_deberta/best_model/added_tokens.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/2.2.3_deberta/best_model/tokenizer_config.json',\n",
       " '/home/elson/2.2.3_deberta/best_model/special_tokens_map.json',\n",
       " '/home/elson/2.2.3_deberta/best_model/spm.model',\n",
       " '/home/elson/2.2.3_deberta/best_model/added_tokens.json')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/2.2.3_deberta/',\n",
    "    num_train_epochs=15,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.06,\n",
    "    weight_decay=0.1,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(\"cuda:0\"),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "print(f\"Model is on device: {next(model.parameters()).device}\")\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/2.2.3_deberta/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/2.2.3_deberta/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cdee1665",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/2.2.3_deberta/best_model/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"/home/elson/2.2.3_deberta/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"entailment\",\n",
      "    \"1\": \"neutral\",\n",
      "    \"2\": \"contradiction\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"contradiction\": 2,\n",
      "    \"entailment\": 0,\n",
      "    \"neutral\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file /home/elson/2.2.3_deberta/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at /home/elson/2.2.3_deberta/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 32\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/2.2.3_deberta/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[ 4.1367e+00, -3.3252e-01, -3.5859e+00],\n",
      "       [ 3.8105e+00, -4.0845e-01, -3.6211e+00],\n",
      "       [ 3.5488e+00, -4.2236e-01, -3.2266e+00],\n",
      "       [-1.2969e+00, -1.5635e+00,  2.9941e+00],\n",
      "       [ 3.8223e+00, -2.8174e-01, -3.5020e+00],\n",
      "       [ 5.8867e+00, -1.4102e+00, -4.1680e+00],\n",
      "       [ 5.0781e+00, -1.0742e+00, -3.7734e+00],\n",
      "       [ 6.1133e+00, -2.1309e+00, -3.6777e+00],\n",
      "       [ 6.1875e+00, -2.0117e+00, -3.8418e+00],\n",
      "       [ 5.4102e+00, -1.7178e+00, -3.4160e+00],\n",
      "       [ 6.3086e+00, -2.1172e+00, -3.8516e+00],\n",
      "       [ 6.5352e+00, -2.6426e+00, -3.5977e+00],\n",
      "       [ 5.0156e+00, -2.3145e+00, -2.5508e+00],\n",
      "       [ 6.3711e+00, -2.0645e+00, -3.9141e+00],\n",
      "       [ 4.7305e+00, -7.3828e-01, -3.8320e+00],\n",
      "       [-3.4551e+00,  1.7988e+00,  2.0020e+00],\n",
      "       [ 4.9453e+00, -7.3486e-01, -4.0898e+00],\n",
      "       [-1.0029e+00,  3.5547e+00, -2.4492e+00],\n",
      "       [ 6.5742e+00, -2.2832e+00, -3.9199e+00],\n",
      "       [ 5.4062e+00, -1.4590e+00, -3.7422e+00],\n",
      "       [-2.4297e+00,  4.0078e+00, -1.6045e+00],\n",
      "       [ 3.4062e+00, -2.0618e-01, -3.3652e+00],\n",
      "       [ 5.1523e+00, -1.1572e+00, -3.8457e+00],\n",
      "       [-3.8652e+00,  1.3691e+00,  2.7734e+00],\n",
      "       [-2.4062e+00, -2.5820e+00,  4.8945e+00],\n",
      "       [-3.5098e+00,  2.0176e+00,  1.8320e+00],\n",
      "       [ 6.4883e+00, -2.3691e+00, -3.7695e+00],\n",
      "       [ 6.2148e+00, -1.7148e+00, -4.2305e+00],\n",
      "       [ 5.0430e+00, -1.2715e+00, -3.6465e+00],\n",
      "       [ 6.4414e+00, -2.4766e+00, -3.6289e+00],\n",
      "       [ 1.0098e+00,  1.5312e+00, -2.5527e+00],\n",
      "       [ 5.3633e+00, -1.1406e+00, -3.9844e+00],\n",
      "       [ 5.7852e+00, -1.6064e+00, -3.9473e+00],\n",
      "       [ 5.8672e+00, -2.2168e+00, -3.3691e+00],\n",
      "       [-1.6416e+00,  2.3262e+00, -3.5327e-01],\n",
      "       [ 5.8203e+00, -1.6719e+00, -3.8984e+00],\n",
      "       [ 3.3740e-01, -3.2188e+00,  2.7383e+00],\n",
      "       [ 6.3828e+00, -1.9678e+00, -4.0469e+00],\n",
      "       [-3.0742e+00, -1.7432e+00,  4.8281e+00],\n",
      "       [ 6.1055e+00, -2.6191e+00, -3.3027e+00],\n",
      "       [-2.2773e+00,  2.6602e+00, -1.0675e-01],\n",
      "       [ 5.7383e+00, -1.5039e+00, -3.9902e+00],\n",
      "       [ 4.4336e+00, -2.3223e+00, -1.9824e+00],\n",
      "       [-3.0215e+00, -4.9536e-01,  3.7012e+00],\n",
      "       [-1.4673e-01,  2.7832e+00, -2.5293e+00],\n",
      "       [ 5.7656e+00, -1.8271e+00, -3.7227e+00],\n",
      "       [ 4.4648e+00, -1.2227e+00, -3.0723e+00],\n",
      "       [ 5.5000e+00, -2.4121e+00, -2.9160e+00],\n",
      "       [ 6.2031e+00, -1.9854e+00, -3.8770e+00],\n",
      "       [-4.0344e-02, -3.0508e+00,  2.9766e+00],\n",
      "       [-3.3496e+00,  6.4990e-01,  3.0254e+00],\n",
      "       [ 5.1211e+00, -2.5254e+00, -2.4180e+00],\n",
      "       [ 8.0420e-01,  3.6621e-02, -8.0664e-01],\n",
      "       [ 4.2227e+00,  6.6956e-02, -4.2812e+00],\n",
      "       [ 1.6719e+00,  1.9189e+00, -3.6758e+00],\n",
      "       [ 6.1602e+00, -2.0820e+00, -3.7422e+00],\n",
      "       [-4.1016e+00, -6.5186e-01,  4.8711e+00],\n",
      "       [ 4.9492e+00, -1.0615e+00, -3.6816e+00],\n",
      "       [ 5.4531e+00, -1.3037e+00, -3.9316e+00],\n",
      "       [ 6.1367e+00, -2.1465e+00, -3.7090e+00],\n",
      "       [ 5.9961e+00, -1.7363e+00, -3.9199e+00],\n",
      "       [-2.0156e+00, -1.8330e+00,  3.8887e+00],\n",
      "       [ 3.2949e+00, -1.5979e-01, -3.1504e+00],\n",
      "       [ 1.1572e+00, -3.1250e-01, -8.7793e-01],\n",
      "       [ 2.6699e+00,  3.8965e-01, -3.1602e+00],\n",
      "       [ 6.0547e+00, -1.8291e+00, -3.9043e+00],\n",
      "       [ 5.7852e+00, -1.7188e+00, -3.8066e+00],\n",
      "       [ 5.5391e+00, -2.1152e+00, -3.1934e+00],\n",
      "       [ 6.1758e+00, -2.1836e+00, -3.7109e+00],\n",
      "       [-1.9375e+00, -1.6475e+00,  3.6055e+00],\n",
      "       [ 5.7148e+00, -1.6328e+00, -3.7480e+00],\n",
      "       [ 4.3906e+00,  3.8433e-03, -4.3164e+00],\n",
      "       [ 3.9297e+00,  1.9080e-01, -4.1602e+00],\n",
      "       [ 6.1523e+00, -3.0957e+00, -2.8223e+00],\n",
      "       [-1.5352e+00,  7.8809e-01,  1.0498e+00],\n",
      "       [ 5.8086e+00, -2.3750e+00, -3.1738e+00],\n",
      "       [ 6.0938e+00, -1.9561e+00, -3.8555e+00],\n",
      "       [ 6.2461e+00, -2.0977e+00, -3.9395e+00],\n",
      "       [ 6.4688e+00, -2.3984e+00, -3.7617e+00],\n",
      "       [ 1.7412e+00, -2.6328e+00,  8.7305e-01],\n",
      "       [ 4.8555e+00, -1.9375e+00, -2.8281e+00],\n",
      "       [ 6.2734e+00, -1.9600e+00, -3.9785e+00],\n",
      "       [ 6.3633e+00, -2.1387e+00, -3.9102e+00],\n",
      "       [ 5.9102e+00, -2.1113e+00, -3.5000e+00],\n",
      "       [ 4.7031e+00, -1.4316e+00, -3.1133e+00],\n",
      "       [ 5.1719e+00, -9.6631e-01, -4.0273e+00],\n",
      "       [ 6.3594e+00, -2.2129e+00, -3.8359e+00],\n",
      "       [ 3.5059e+00, -1.8457e+00, -1.5859e+00],\n",
      "       [ 1.2500e+00, -3.6934e+00,  2.2754e+00],\n",
      "       [ 5.5820e+00, -2.4863e+00, -2.9277e+00],\n",
      "       [ 4.6836e+00, -2.0977e+00, -2.6270e+00],\n",
      "       [ 6.1562e+00, -1.8262e+00, -3.9707e+00],\n",
      "       [-7.9785e-01,  8.8037e-01,  8.0078e-02],\n",
      "       [ 5.7617e+00, -1.6406e+00, -3.8398e+00],\n",
      "       [ 5.9609e+00, -1.7568e+00, -3.8984e+00],\n",
      "       [ 4.5586e+00, -1.1289e+00, -3.3984e+00],\n",
      "       [ 6.1172e+00, -2.2363e+00, -3.5742e+00],\n",
      "       [ 5.7861e-01,  3.2539e+00, -3.7305e+00],\n",
      "       [ 5.3438e+00, -2.5391e+00, -2.6680e+00],\n",
      "       [ 5.7070e+00, -1.7451e+00, -3.7441e+00],\n",
      "       [-2.6094e+00, -2.3203e+00,  4.8320e+00],\n",
      "       [ 3.7773e+00, -5.6396e-01, -3.1680e+00],\n",
      "       [ 5.2695e+00, -1.0996e+00, -3.9082e+00],\n",
      "       [ 1.7207e+00,  4.5337e-01, -2.3027e+00],\n",
      "       [ 5.5508e+00, -1.0557e+00, -4.2148e+00],\n",
      "       [ 6.3594e+00, -2.3438e+00, -3.7246e+00],\n",
      "       [ 3.0527e+00, -6.5576e-01, -2.4004e+00],\n",
      "       [-3.1016e+00,  3.7480e+00, -2.1667e-01],\n",
      "       [ 6.1992e+00, -1.9854e+00, -3.8613e+00],\n",
      "       [ 6.2188e+00, -2.2988e+00, -3.6152e+00],\n",
      "       [ 5.6523e+00, -1.3994e+00, -3.9746e+00],\n",
      "       [ 6.2500e+00, -2.0566e+00, -3.8516e+00],\n",
      "       [ 5.8398e+00, -1.7861e+00, -3.7754e+00],\n",
      "       [ 6.2188e+00, -2.1543e+00, -3.7812e+00],\n",
      "       [ 6.2188e+00, -1.6689e+00, -4.2188e+00],\n",
      "       [ 6.4531e+00, -1.9951e+00, -4.0703e+00],\n",
      "       [ 6.5234e+00, -2.8809e+00, -3.3770e+00],\n",
      "       [ 5.8438e+00, -1.3125e+00, -4.2109e+00],\n",
      "       [ 6.2422e+00, -2.0703e+00, -3.8457e+00],\n",
      "       [ 5.8750e+00, -1.9326e+00, -3.6289e+00],\n",
      "       [ 5.5391e+00, -1.7500e+00, -3.5137e+00],\n",
      "       [ 6.0000e+00, -2.2266e+00, -3.4883e+00],\n",
      "       [ 4.0312e+00, -3.0347e-01, -3.6348e+00],\n",
      "       [ 1.1602e+00, -1.6230e+00,  2.7710e-01],\n",
      "       [ 6.2305e+00, -2.3555e+00, -3.5488e+00],\n",
      "       [ 6.3789e+00, -2.6113e+00, -3.5254e+00],\n",
      "       [ 3.8691e+00, -1.6641e+00, -2.0703e+00],\n",
      "       [ 6.3164e+00, -2.2266e+00, -3.7793e+00],\n",
      "       [ 5.8438e+00, -2.0234e+00, -3.4766e+00],\n",
      "       [ 4.1523e+00, -5.2148e-01, -3.6250e+00],\n",
      "       [ 3.4219e+00,  5.2197e-01, -3.9238e+00],\n",
      "       [ 5.1680e+00, -2.0449e+00, -2.9180e+00],\n",
      "       [ 6.3203e+00, -1.9033e+00, -4.0391e+00],\n",
      "       [ 4.2188e+00, -2.2617e+00, -1.8604e+00],\n",
      "       [ 3.0020e+00, -1.8916e+00, -1.1631e+00],\n",
      "       [-2.5918e+00,  2.4939e-01,  2.6230e+00],\n",
      "       [ 5.2109e+00, -2.5430e+00, -2.5547e+00],\n",
      "       [-3.0977e+00, -1.7930e+00,  4.7422e+00],\n",
      "       [ 2.8671e-02,  3.2637e+00, -3.4180e+00],\n",
      "       [-1.9209e+00,  7.9639e-01,  1.3164e+00],\n",
      "       [ 6.1992e+00, -1.8770e+00, -4.0195e+00],\n",
      "       [ 7.1729e-01,  3.6816e+00, -4.4297e+00],\n",
      "       [ 5.9336e+00, -1.9268e+00, -3.7109e+00],\n",
      "       [ 6.4570e+00, -2.2480e+00, -3.8594e+00],\n",
      "       [ 3.9316e+00, -2.8730e+00, -1.0645e+00],\n",
      "       [-1.0352e+00,  2.9785e+00, -1.9209e+00],\n",
      "       [-2.3203e+00, -9.7217e-01,  3.3711e+00],\n",
      "       [ 1.3896e+00, -4.9854e-01, -9.5752e-01],\n",
      "       [ 6.5352e+00, -2.3496e+00, -3.8359e+00],\n",
      "       [-1.4297e+00,  9.9170e-01,  6.2695e-01],\n",
      "       [ 5.2148e+00, -2.4609e+00, -2.5977e+00],\n",
      "       [ 3.8496e+00, -1.7031e+00, -2.1562e+00],\n",
      "       [ 6.5391e+00, -2.7168e+00, -3.5488e+00],\n",
      "       [ 6.3281e+00, -2.2070e+00, -3.8184e+00],\n",
      "       [ 5.8242e+00, -1.6045e+00, -3.9648e+00],\n",
      "       [ 6.0586e+00, -2.4062e+00, -3.3672e+00],\n",
      "       [ 5.8359e+00, -1.9043e+00, -3.6777e+00],\n",
      "       [-1.1240e+00, -3.3398e-01,  1.6670e+00],\n",
      "       [ 5.6719e+00, -1.1025e+00, -4.2852e+00],\n",
      "       [-2.2266e+00, -2.2656e+00,  4.4805e+00],\n",
      "       [-4.1172e+00, -6.6040e-02,  4.3281e+00],\n",
      "       [-2.1680e+00, -3.0527e+00,  5.0742e+00],\n",
      "       [ 5.8594e+00, -1.6006e+00, -3.9844e+00],\n",
      "       [-4.0479e-01,  1.4902e+00, -9.6143e-01],\n",
      "       [ 2.8164e+00, -1.6846e+00, -1.0957e+00],\n",
      "       [ 5.2441e-01, -6.2549e-01,  1.4185e-01],\n",
      "       [ 6.1484e+00, -2.2266e+00, -3.5469e+00],\n",
      "       [ 3.0059e+00, -1.5371e+00, -1.4707e+00],\n",
      "       [ 7.4609e-01,  6.1249e-02, -9.3115e-01],\n",
      "       [ 4.6133e+00, -2.7500e+00, -1.7109e+00],\n",
      "       [-3.5078e+00,  1.1309e+00,  2.6621e+00],\n",
      "       [ 6.0078e+00, -2.1387e+00, -3.5352e+00],\n",
      "       [-2.8965e+00,  4.1172e+00, -8.4570e-01],\n",
      "       [ 4.1719e+00, -4.2969e-01, -3.6328e+00],\n",
      "       [ 6.2695e+00, -1.9170e+00, -4.0156e+00],\n",
      "       [-1.8594e+00,  8.3887e-01,  1.3457e+00],\n",
      "       [ 5.5898e+00, -1.9766e+00, -3.3691e+00],\n",
      "       [-2.1855e+00, -1.8867e+00,  4.0781e+00],\n",
      "       [ 5.5469e+00, -2.1094e+00, -3.1211e+00],\n",
      "       [ 5.1055e+00, -3.1465e+00, -1.7930e+00],\n",
      "       [-2.0117e+00,  2.5645e+00, -2.5684e-01],\n",
      "       [-8.2764e-01, -2.8652e+00,  3.4336e+00],\n",
      "       [-3.1797e+00, -4.6167e-01,  3.7520e+00],\n",
      "       [ 4.7852e+00, -7.1387e-01, -3.8730e+00],\n",
      "       [-6.8311e-01,  3.3359e+00, -2.7402e+00],\n",
      "       [ 6.6445e+00, -2.5020e+00, -3.7754e+00],\n",
      "       [ 5.5625e+00, -2.2520e+00, -3.0137e+00],\n",
      "       [ 6.0000e+00, -1.4229e+00, -4.2695e+00],\n",
      "       [-9.6069e-02,  2.0273e+00, -1.8477e+00],\n",
      "       [ 5.6484e+00, -1.5322e+00, -3.8867e+00],\n",
      "       [ 3.8750e+00, -1.1621e+00, -2.6191e+00],\n",
      "       [ 6.1836e+00, -2.2988e+00, -3.6074e+00],\n",
      "       [ 6.1602e+00, -2.4102e+00, -3.4316e+00],\n",
      "       [ 5.0859e+00, -1.5312e+00, -3.3750e+00],\n",
      "       [-2.9453e+00, -2.3887e+00,  5.2383e+00],\n",
      "       [ 6.0352e+00, -1.7803e+00, -3.9043e+00],\n",
      "       [ 5.0820e+00, -2.0820e+00, -2.8594e+00],\n",
      "       [ 5.0117e+00, -1.1104e+00, -3.7070e+00],\n",
      "       [ 5.3398e+00, -1.2529e+00, -3.8770e+00],\n",
      "       [ 3.6309e+00,  7.6562e-01, -4.3086e+00],\n",
      "       [ 5.4805e+00, -2.8398e+00, -2.4668e+00],\n",
      "       [ 6.0781e+00, -1.5811e+00, -4.1836e+00],\n",
      "       [ 4.7031e+00, -7.4268e-01, -3.7266e+00],\n",
      "       [ 5.4102e+00, -9.3408e-01, -4.2344e+00],\n",
      "       [ 1.2656e+00,  5.8105e-01, -1.8096e+00],\n",
      "       [-2.9141e+00,  2.9277e+00,  2.5757e-01],\n",
      "       [ 5.9492e+00, -2.3984e+00, -3.3574e+00],\n",
      "       [ 4.1289e+00, -7.3779e-01, -3.2676e+00],\n",
      "       [ 6.0781e+00, -1.7695e+00, -4.0039e+00],\n",
      "       [ 5.9922e+00, -1.9834e+00, -3.6641e+00],\n",
      "       [ 4.9375e+00, -5.2686e-01, -4.3164e+00],\n",
      "       [-4.8071e-01,  2.4844e+00, -1.8945e+00],\n",
      "       [ 6.6016e+00, -2.3750e+00, -3.8281e+00],\n",
      "       [ 5.5000e+00, -1.4180e+00, -3.8125e+00],\n",
      "       [ 3.4883e+00, -2.0195e+00, -1.4434e+00],\n",
      "       [ 2.7773e+00, -1.1299e+00, -1.7539e+00],\n",
      "       [ 4.3711e+00, -2.9238e+00, -1.3760e+00],\n",
      "       [ 5.8789e+00, -2.3008e+00, -3.3086e+00],\n",
      "       [ 6.1953e+00, -1.7422e+00, -4.0898e+00],\n",
      "       [ 3.7266e+00, -3.2871e+00, -4.2847e-01],\n",
      "       [ 6.5195e+00, -2.1719e+00, -3.9785e+00],\n",
      "       [ 5.6914e+00, -1.5615e+00, -3.9141e+00],\n",
      "       [ 5.3008e+00, -2.3125e+00, -2.7949e+00],\n",
      "       [ 6.5781e+00, -2.3691e+00, -3.8555e+00],\n",
      "       [ 5.6016e+00, -2.0215e+00, -3.2832e+00],\n",
      "       [ 5.6289e+00, -1.0254e+00, -4.3398e+00],\n",
      "       [ 5.5820e+00, -1.7900e+00, -3.6191e+00],\n",
      "       [-4.0156e+00, -3.6108e-01,  4.5508e+00],\n",
      "       [ 2.5703e+00, -4.5947e-01, -2.1367e+00],\n",
      "       [ 5.1328e+00, -1.0762e+00, -3.9023e+00],\n",
      "       [ 6.2383e+00, -1.9424e+00, -3.9941e+00],\n",
      "       [ 5.7930e+00, -2.1465e+00, -3.3438e+00],\n",
      "       [ 5.4414e+00, -1.8682e+00, -3.2578e+00],\n",
      "       [ 4.8730e-01, -3.5605e+00,  2.7988e+00]], dtype=float16), label_ids=array([0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
      "       0, 1, 2, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 2, 1, 0, 0,\n",
      "       0, 1, 0, 0, 0, 2, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 2, 1, 0, 1, 2,\n",
      "       0, 0, 2, 2, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       2, 1, 0, 1, 2, 0, 0, 0, 0, 0, 0, 1, 2, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "       1, 0, 1, 0, 1, 0, 0, 0, 2, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2,\n",
      "       0, 1, 0, 1, 0, 0, 0, 1, 2, 1, 0, 0, 2, 2, 2, 2, 0, 0, 0, 0, 1, 1,\n",
      "       0, 0, 0, 1, 0, 2, 2, 2, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "       0, 2, 0, 0, 0, 0, 2, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0,\n",
      "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 2, 0, 0,\n",
      "       0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2]), metrics={'test_loss': 1.7717645168304443, 'test_accuracy': 0.6666666666666666, 'test_balanced_accuracy': 0.511429409161007, 'test_precision': 0.6111287670724491, 'test_recall': 0.6666666666666666, 'test_f1': 0.6253800627611662, 'test_runtime': 2.1813, 'test_samples_per_second': 107.274, 'test_steps_per_second': 3.667})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be81d0c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "probabilities = torch.softmax(torch.tensor(test_results.predictions).to(torch.float32), dim=-1)\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)\n",
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef4c67fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_save = []\n",
    "for idx in range(len(test_data)):\n",
    "    item = dataset['test'][idx]\n",
    "    actual_label = item['label']\n",
    "    predicted_label = predictions[idx]\n",
    "    claim = item['claim'] \n",
    "    premise = item['premise'] \n",
    "    category = item['category']\n",
    "    \n",
    "    # Append the information as a dictionary to the list\n",
    "    data_to_save.append({\n",
    "        'Claim': claim,\n",
    "        'Premise': premise,\n",
    "        'Actual Label': actual_label,\n",
    "        'Predicted Label': predicted_label,\n",
    "        'Category' : category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_to_save)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/home/elson/results/2.2.3_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a1a63a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correctly classified instances\n",
    "correctly_classified = df[df['Actual Label'] == df['Predicted Label']]\n",
    "\n",
    "# Calculate misclassified instances\n",
    "misclassified = df[df['Actual Label'] != df['Predicted Label']]\n",
    "\n",
    "# Count the number of correctly classified and misclassified by category\n",
    "correct_classification_counts = correctly_classified['Category'].value_counts()\n",
    "misclassification_counts = misclassified['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c4055e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           35\n",
       "Bone health              13\n",
       "Fitness                  12\n",
       "Cancer                   12\n",
       "Diabetes                 10\n",
       "Throat                    9\n",
       "Neurological health       9\n",
       "Cardiovascular Health     9\n",
       "Skin                      7\n",
       "Ear                       6\n",
       "Hair                      6\n",
       "COVID                     6\n",
       "Men's health              5\n",
       "Eye                       4\n",
       "Blood                     4\n",
       "Women' s Health           4\n",
       "Mental Health             2\n",
       "Dental Health             1\n",
       "Muscles                   1\n",
       "Vascular                  1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "117a1d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Skin                     17\n",
       "General Health           16\n",
       "Bone health               8\n",
       "Hair                      6\n",
       "Eye                       5\n",
       "Blood                     5\n",
       "Muscles                   5\n",
       "Fitness                   3\n",
       "Cardiovascular Health     3\n",
       "Women' s Health           2\n",
       "Diabetes                  2\n",
       "Vascular                  2\n",
       "Dental Health             2\n",
       "Men's health              1\n",
       "Mental Health             1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
