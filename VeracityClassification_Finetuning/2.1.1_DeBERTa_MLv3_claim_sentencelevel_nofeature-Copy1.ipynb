{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f38bead8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr 25 20:15:13 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:61:00.0 Off |                    0 |\n",
      "| N/A   44C    P0    57W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  Off  | 00000000:62:00.0 Off |                    0 |\n",
      "| N/A   45C    P0    58W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  Off  | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   46C    P0    61W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  Off  | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   46C    P0    60W / 300W |      0MiB / 32768MiB |      2%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-879d36f62b7c10e5\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-879d36f62b7c10e5/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 224.27it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('csv',data_files='dataset_sentenceattribution_nerfeatures_split.csv',delimiter=',',column_names=[\"claim\",\"premise\",\"label\",\"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\",\"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\",\"url\", \"entities\",\"entity_map\",\"gem_exp\",\"gem_label\",\"gpt_label\",\"gpt_exp\",\"gold_exp\",\"entity_map_ev\",\"entity_ev\",\"synonym\",\"voice\",\"split\"],skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6af125ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-879d36f62b7c10e5/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-fb25803c856cf927.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-879d36f62b7c10e5/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-fac6a19836873091.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-879d36f62b7c10e5/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-533af6134de82de9.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01252e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\"claim\", \"premise\", \"label\",\"category\"]\n",
    "all_columns = dataset[\"train\"].column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-879d36f62b7c10e5/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-6f83fcc9d805613c.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-879d36f62b7c10e5/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-0b048e19c15ada42.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-879d36f62b7c10e5/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-eed43d973c272d4e.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 2, 'entailment': 0, 'neutral': 1}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 2,\n",
    "    \"entailment\": 0,\n",
    "    \"neutral\": 1\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e15010ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "\n",
    "        claim = item['claim']\n",
    "        evidences = item['premise']\n",
    "        item['premise']=evidences\n",
    "        item['claim']=claim\n",
    "\n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "            evidences,claim,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "        item['input_ids'] = inputs['input_ids'].squeeze()  # Remove batch dimension\n",
    "        item['attention_mask']= inputs['attention_mask'].squeeze() # Remove batch dimension\n",
    "        \n",
    "        if 'label' in item:\n",
    "            item['labels'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62421eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DebertaV2ForSequenceClassification(\n",
       "  (deberta): DebertaV2Model(\n",
       "    (embeddings): DebertaV2Embeddings(\n",
       "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaV2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (1): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (2): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (3): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (4): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (5): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (6): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (7): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (8): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (9): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (10): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (11): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (pooler): ContextPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): StableDropout()\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (dropout): StableDropout()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=512)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=3, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    return {\"accuracy\": acc, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f5cf584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'claim': 'Myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.',\n",
       " 'premise': 'Additionally, laser doppler blood flow measurement showed that the frankincense and myrrh essential oil compound could promote the elimination of capillaries from skin epidermis to dermis by increasing skin blood flow.',\n",
       " 'label': 0,\n",
       " 'category': 'General Health',\n",
       " 'input_ids': tensor([    1,  4081,   261,  5042,   333, 73325,  1452,  2155,  6116,  1938,\n",
       "           272,   262, 88609,   263, 98237,  1830,  1080,  7355,   387,  2655,\n",
       "           262, 12682,   265, 65008,   292,  1158, 53245,   264, 75840,   293,\n",
       "          2376,  1158,  1452,  2155,   260,     2,   573, 52341,  1830,  1080,\n",
       "           269,  1359,   427,   267, 17847,   633,   264,   408,  1300,   262,\n",
       "          2658,   265,   262,  1158,   260,     2,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'labels': tensor(0)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 765\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='765' max='765' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [765/765 11:25, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.937100</td>\n",
       "      <td>1.104352</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>0.630429</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>0.628020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.683500</td>\n",
       "      <td>0.815187</td>\n",
       "      <td>0.647312</td>\n",
       "      <td>0.646477</td>\n",
       "      <td>0.647312</td>\n",
       "      <td>0.646881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.499100</td>\n",
       "      <td>0.896467</td>\n",
       "      <td>0.658065</td>\n",
       "      <td>0.654482</td>\n",
       "      <td>0.658065</td>\n",
       "      <td>0.655082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.252200</td>\n",
       "      <td>1.148587</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.629037</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.635634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.241900</td>\n",
       "      <td>1.234380</td>\n",
       "      <td>0.630108</td>\n",
       "      <td>0.640569</td>\n",
       "      <td>0.630108</td>\n",
       "      <td>0.634870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.271700</td>\n",
       "      <td>1.300878</td>\n",
       "      <td>0.627957</td>\n",
       "      <td>0.642494</td>\n",
       "      <td>0.627957</td>\n",
       "      <td>0.634330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.197500</td>\n",
       "      <td>1.522876</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.665592</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.648961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.176800</td>\n",
       "      <td>1.389540</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.652304</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.650829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.136300</td>\n",
       "      <td>1.650907</td>\n",
       "      <td>0.636559</td>\n",
       "      <td>0.629667</td>\n",
       "      <td>0.636559</td>\n",
       "      <td>0.629136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.060100</td>\n",
       "      <td>1.749669</td>\n",
       "      <td>0.640860</td>\n",
       "      <td>0.652788</td>\n",
       "      <td>0.640860</td>\n",
       "      <td>0.640157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.126400</td>\n",
       "      <td>2.067292</td>\n",
       "      <td>0.636559</td>\n",
       "      <td>0.633541</td>\n",
       "      <td>0.636559</td>\n",
       "      <td>0.635006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.028000</td>\n",
       "      <td>2.483321</td>\n",
       "      <td>0.632258</td>\n",
       "      <td>0.648145</td>\n",
       "      <td>0.632258</td>\n",
       "      <td>0.638712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.017600</td>\n",
       "      <td>2.473957</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.631654</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.636714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.023700</td>\n",
       "      <td>2.585856</td>\n",
       "      <td>0.630108</td>\n",
       "      <td>0.635151</td>\n",
       "      <td>0.630108</td>\n",
       "      <td>0.632322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.023600</td>\n",
       "      <td>2.598255</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>0.626670</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>0.626234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.1.2_deberta/checkpoint-51\n",
      "Configuration saved in /home/elson/2.1.2_deberta/checkpoint-51/config.json\n",
      "Model weights saved in /home/elson/2.1.2_deberta/checkpoint-51/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.1.2_deberta/checkpoint-102\n",
      "Configuration saved in /home/elson/2.1.2_deberta/checkpoint-102/config.json\n",
      "Model weights saved in /home/elson/2.1.2_deberta/checkpoint-102/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.1.2_deberta/checkpoint-51] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.1.2_deberta/checkpoint-153\n",
      "Configuration saved in /home/elson/2.1.2_deberta/checkpoint-153/config.json\n",
      "Model weights saved in /home/elson/2.1.2_deberta/checkpoint-153/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.1.2_deberta/checkpoint-102] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.1.2_deberta/checkpoint-204\n",
      "Configuration saved in /home/elson/2.1.2_deberta/checkpoint-204/config.json\n",
      "Model weights saved in /home/elson/2.1.2_deberta/checkpoint-204/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.1.2_deberta/checkpoint-255\n",
      "Configuration saved in /home/elson/2.1.2_deberta/checkpoint-255/config.json\n",
      "Model weights saved in /home/elson/2.1.2_deberta/checkpoint-255/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.1.2_deberta/checkpoint-204] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.1.2_deberta/checkpoint-306\n",
      "Configuration saved in /home/elson/2.1.2_deberta/checkpoint-306/config.json\n",
      "Model weights saved in /home/elson/2.1.2_deberta/checkpoint-306/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.1.2_deberta/checkpoint-255] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.1.2_deberta/checkpoint-357\n",
      "Configuration saved in /home/elson/2.1.2_deberta/checkpoint-357/config.json\n",
      "Model weights saved in /home/elson/2.1.2_deberta/checkpoint-357/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.1.2_deberta/checkpoint-306] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.1.2_deberta/checkpoint-408\n",
      "Configuration saved in /home/elson/2.1.2_deberta/checkpoint-408/config.json\n",
      "Model weights saved in /home/elson/2.1.2_deberta/checkpoint-408/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.1.2_deberta/checkpoint-357] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.1.2_deberta/checkpoint-459\n",
      "Configuration saved in /home/elson/2.1.2_deberta/checkpoint-459/config.json\n",
      "Model weights saved in /home/elson/2.1.2_deberta/checkpoint-459/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.1.2_deberta/checkpoint-408] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.1.2_deberta/checkpoint-510\n",
      "Configuration saved in /home/elson/2.1.2_deberta/checkpoint-510/config.json\n",
      "Model weights saved in /home/elson/2.1.2_deberta/checkpoint-510/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.1.2_deberta/checkpoint-459] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.1.2_deberta/checkpoint-561\n",
      "Configuration saved in /home/elson/2.1.2_deberta/checkpoint-561/config.json\n",
      "Model weights saved in /home/elson/2.1.2_deberta/checkpoint-561/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.1.2_deberta/checkpoint-510] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.1.2_deberta/checkpoint-612\n",
      "Configuration saved in /home/elson/2.1.2_deberta/checkpoint-612/config.json\n",
      "Model weights saved in /home/elson/2.1.2_deberta/checkpoint-612/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.1.2_deberta/checkpoint-561] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.1.2_deberta/checkpoint-663\n",
      "Configuration saved in /home/elson/2.1.2_deberta/checkpoint-663/config.json\n",
      "Model weights saved in /home/elson/2.1.2_deberta/checkpoint-663/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.1.2_deberta/checkpoint-612] due to args.save_total_limit\n",
      "Model weights saved in /home/elson/2.1.2_deberta/checkpoint-765/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.1.2_deberta/checkpoint-714] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/elson/2.1.2_deberta/checkpoint-153 (score: 0.6580645161290323).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /home/elson/2.1.2_deberta/best_model/config.json\n",
      "Model weights saved in /home/elson/2.1.2_deberta/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/2.1.2_deberta/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/2.1.2_deberta/best_model/special_tokens_map.json\n",
      "added tokens file saved in /home/elson/2.1.2_deberta/best_model/added_tokens.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/2.1.2_deberta/best_model/tokenizer_config.json',\n",
       " '/home/elson/2.1.2_deberta/best_model/special_tokens_map.json',\n",
       " '/home/elson/2.1.2_deberta/best_model/spm.model',\n",
       " '/home/elson/2.1.2_deberta/best_model/added_tokens.json')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/2.1.2_deberta/',\n",
    "    num_train_epochs=15,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.6,\n",
    "    weight_decay=0.1,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/2.1.2_deberta/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/2.1.2_deberta/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63deaea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/2.1.2_deberta/best_model/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"/home/elson/2.1.2_deberta/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"entailment\",\n",
      "    \"1\": \"neutral\",\n",
      "    \"2\": \"contradiction\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"contradiction\": 2,\n",
      "    \"entailment\": 0,\n",
      "    \"neutral\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file /home/elson/2.1.2_deberta/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at /home/elson/2.1.2_deberta/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 32\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/2.1.2_deberta/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[ 0.572  ,  2.562  , -3.387  ],\n",
      "       [ 2.734  , -0.1593 , -2.564  ],\n",
      "       [ 2.633  , -0.628  , -2.018  ],\n",
      "       [-0.287  ,  0.466  , -0.1786 ],\n",
      "       [ 1.583  , -0.0405 , -1.579  ],\n",
      "       [ 3.45   , -0.9087 , -2.4    ],\n",
      "       [ 2.693  , -0.8633 , -1.796  ],\n",
      "       [ 3.693  , -1.578  , -2.021  ],\n",
      "       [ 2.926  , -0.516  , -2.275  ],\n",
      "       [ 0.7104 ,  0.944  , -1.697  ],\n",
      "       [-1.039  , -0.939  ,  1.908  ],\n",
      "       [ 4.26   , -1.89   , -2.21   ],\n",
      "       [ 1.328  , -0.09656, -1.256  ],\n",
      "       [ 3.49   , -1.392  , -1.977  ],\n",
      "       [-0.2627 ,  1.63   , -1.463  ],\n",
      "       [-1.005  ,  1.046  ,  0.1202 ],\n",
      "       [ 3.045  , -0.561  , -2.402  ],\n",
      "       [ 2.229  , -0.5303 , -1.665  ],\n",
      "       [ 4.12   , -1.417  , -2.51   ],\n",
      "       [ 2.318  ,  0.2329 , -2.57   ],\n",
      "       [ 0.6265 ,  1.335  , -2.156  ],\n",
      "       [ 0.3303 ,  0.916  , -1.299  ],\n",
      "       [ 1.061  ,  1.397  , -2.688  ],\n",
      "       [-0.9287 ,  1.367  , -0.3555 ],\n",
      "       [-0.309  , -0.283  ,  0.5317 ],\n",
      "       [-2.26   , -0.746  ,  3.047  ],\n",
      "       [ 4.46   , -1.649  , -2.555  ],\n",
      "       [ 0.8774 ,  0.6904 , -1.652  ],\n",
      "       [ 3.268  , -0.9253 , -2.195  ],\n",
      "       [ 1.173  , -0.5737 , -0.7197 ],\n",
      "       [ 1.188  ,  0.567  , -1.801  ],\n",
      "       [ 3.127  , -0.4194 , -2.59   ],\n",
      "       [ 3.35   , -1.04   , -2.172  ],\n",
      "       [ 2.617  , -1.007  , -1.518  ],\n",
      "       [-0.601  ,  1.4    , -0.7773 ],\n",
      "       [ 2.096  ,  0.0893 , -2.234  ],\n",
      "       [ 0.321  ,  1.032  , -1.345  ],\n",
      "       [ 3.346  , -0.3472 , -2.846  ],\n",
      "       [-1.424  ,  0.07684,  1.471  ],\n",
      "       [ 2.752  , -0.4546 , -2.152  ],\n",
      "       [-0.4446 ,  1.824  , -1.499  ],\n",
      "       [ 1.54   ,  0.8535 , -2.502  ],\n",
      "       [ 1.785  , -0.1317 , -1.666  ],\n",
      "       [-2.236  ,  0.666  ,  1.846  ],\n",
      "       [-0.632  ,  1.845  , -1.151  ],\n",
      "       [ 0.969  ,  1.107  , -2.293  ],\n",
      "       [-0.731  ,  2.7    , -2.062  ],\n",
      "       [ 2.242  , -0.7393 , -1.46   ],\n",
      "       [ 3.28   , -0.711  , -2.418  ],\n",
      "       [-0.4053 , -0.329  ,  0.722  ],\n",
      "       [ 1.286  ,  0.6953 , -2.125  ],\n",
      "       [ 2.383  , -0.9497 , -1.36   ],\n",
      "       [ 1.024  ,  1.543  , -2.764  ],\n",
      "       [ 1.8955 , -0.04172, -1.855  ],\n",
      "       [-0.6973 ,  2.21   , -1.774  ],\n",
      "       [ 2.436  , -0.3704 , -2.06   ],\n",
      "       [ 0.1486 ,  0.837  , -1.049  ],\n",
      "       [ 2.064  ,  0.8506 , -2.99   ],\n",
      "       [ 2.494  , -0.2712 , -2.172  ],\n",
      "       [ 3.428  , -0.961  , -2.314  ],\n",
      "       [ 2.65   , -0.792  , -1.765  ],\n",
      "       [-1.202  , -0.403  ,  1.645  ],\n",
      "       [ 3.008  , -0.4666 , -2.383  ],\n",
      "       [ 0.6587 ,  1.138  , -1.881  ],\n",
      "       [-1.373  ,  1.153  ,  0.3992 ],\n",
      "       [ 3.645  , -0.947  , -2.488  ],\n",
      "       [ 0.00899,  1.138  , -1.172  ],\n",
      "       [ 3.096  , -0.616  , -2.33   ],\n",
      "       [-0.3328 ,  0.915  , -0.4778 ],\n",
      "       [-0.8037 , -0.2247 ,  1.033  ],\n",
      "       [ 1.989  , -0.11975, -1.8545 ],\n",
      "       [-0.972  ,  1.788  , -0.707  ],\n",
      "       [ 0.1462 ,  1.293  , -1.638  ],\n",
      "       [ 0.9346 , -0.2937 , -0.6924 ],\n",
      "       [-0.596  ,  0.0637 ,  0.5615 ],\n",
      "       [ 1.049  ,  1.309  , -2.605  ],\n",
      "       [ 2.64   , -0.894  , -1.7    ],\n",
      "       [ 1.512  ,  0.1602 , -1.682  ],\n",
      "       [ 3.467  , -1.171  , -2.143  ],\n",
      "       [ 1.28   , -0.387  , -0.94   ],\n",
      "       [ 3.361  , -0.886  , -2.314  ],\n",
      "       [ 1.673  ,  0.663  , -2.465  ],\n",
      "       [ 2.715  , -0.3982 , -2.273  ],\n",
      "       [ 3.098  , -0.9883 , -1.997  ],\n",
      "       [ 2.064  ,  0.2292 , -2.324  ],\n",
      "       [-1.003  ,  0.0858 ,  0.9517 ],\n",
      "       [ 3.709  , -1.418  , -2.166  ],\n",
      "       [ 0.4814 ,  1.911  , -2.535  ],\n",
      "       [ 1.089  ,  1.604  , -2.861  ],\n",
      "       [ 3.094  , -0.6157 , -2.312  ],\n",
      "       [ 2.562  , -0.5103 , -2.05   ],\n",
      "       [ 2.906  , -0.582  , -2.262  ],\n",
      "       [-1.001  ,  0.1774 ,  0.9077 ],\n",
      "       [ 2.568  , -0.2043 , -2.29   ],\n",
      "       [ 0.5107 ,  1.981  , -2.75   ],\n",
      "       [ 1.999  , -0.3364 , -1.646  ],\n",
      "       [ 1.448  , -0.5605 , -0.993  ],\n",
      "       [ 0.509  ,  1.657  , -2.4    ],\n",
      "       [ 3.463  , -1.058  , -2.236  ],\n",
      "       [ 3.498  , -0.8906 , -2.441  ],\n",
      "       [-0.1859 , -0.0874 ,  0.2455 ],\n",
      "       [ 0.4365 ,  1.503  , -2.21   ],\n",
      "       [ 3.309  , -0.8857 , -2.244  ],\n",
      "       [ 0.485  ,  1.56   , -2.271  ],\n",
      "       [ 0.674  ,  0.7783 , -1.543  ],\n",
      "       [ 2.434  ,  0.1566 , -2.588  ],\n",
      "       [ 0.3936 ,  2.225  , -2.777  ],\n",
      "       [-0.521  ,  1.299  , -0.796  ],\n",
      "       [ 2.824  , -0.5874 , -2.207  ],\n",
      "       [ 2.504  , -0.574  , -1.812  ],\n",
      "       [ 1.891  ,  0.329  , -2.285  ],\n",
      "       [ 3.994  , -1.362  , -2.418  ],\n",
      "       [ 2.13   , -0.4749 , -1.652  ],\n",
      "       [ 1.484  , -0.2688 , -1.267  ],\n",
      "       [ 2.885  , -0.205  , -2.62   ],\n",
      "       [ 3.055  , -0.0954 , -2.867  ],\n",
      "       [ 4.094  , -1.485  , -2.424  ],\n",
      "       [ 2.963  , -0.707  , -2.133  ],\n",
      "       [ 1.587  ,  0.579  , -2.232  ],\n",
      "       [ 2.688  , -0.1019 , -2.475  ],\n",
      "       [ 3.613  , -0.986  , -2.441  ],\n",
      "       [ 2.627  , -0.9443 , -1.585  ],\n",
      "       [ 2.902  , -0.2218 , -2.521  ],\n",
      "       [ 0.559  ,  1.33   , -2.148  ],\n",
      "       [ 2.951  , -0.8047 , -2.057  ],\n",
      "       [ 1.092  ,  0.4634 , -1.654  ],\n",
      "       [-0.9253 ,  1.737  , -0.86   ],\n",
      "       [ 3.525  , -0.906  , -2.451  ],\n",
      "       [ 2.162  , -0.448  , -1.718  ],\n",
      "       [ 1.038  ,  1.0205 , -2.266  ],\n",
      "       [ 0.965  ,  0.7246 , -1.8125 ],\n",
      "       [-0.3875 ,  1.085  , -0.6763 ],\n",
      "       [ 2.557  ,  0.795  , -3.44   ],\n",
      "       [-1.734  ,  1.5205 ,  0.4314 ],\n",
      "       [ 1.649  ,  0.1595 , -1.907  ],\n",
      "       [-0.718  ,  2.154  , -1.515  ],\n",
      "       [ 2.451  , -0.914  , -1.522  ],\n",
      "       [-0.9004 ,  1.382  , -0.4695 ],\n",
      "       [-0.783  ,  2.334  , -1.796  ],\n",
      "       [ 1.905  ,  0.5825 , -2.64   ],\n",
      "       [ 2.135  , -0.05466, -2.059  ],\n",
      "       [ 1.442  ,  0.9863 , -2.502  ],\n",
      "       [ 2.93   , -0.7505 , -2.094  ],\n",
      "       [ 4.2    , -1.648  , -2.365  ],\n",
      "       [ 1.616  , -0.659  , -0.99   ],\n",
      "       [ 0.787  ,  0.1636 , -1.047  ],\n",
      "       [ 0.396  ,  1.364  , -1.927  ],\n",
      "       [ 0.0451 ,  0.508  , -0.557  ],\n",
      "       [ 1.876  ,  0.378  , -2.336  ],\n",
      "       [ 0.675  ,  0.542  , -1.314  ],\n",
      "       [-1.271  ,  2.484  , -1.339  ],\n",
      "       [ 2.701  , -1.057  , -1.598  ],\n",
      "       [ 3.367  , -0.6226 , -2.611  ],\n",
      "       [ 2.402  , -0.427  , -1.924  ],\n",
      "       [ 2.76   ,  0.1666 , -2.883  ],\n",
      "       [ 4.13   , -1.614  , -2.34   ],\n",
      "       [ 2.197  , -0.7764 , -1.429  ],\n",
      "       [-0.668  ,  2.287  , -1.723  ],\n",
      "       [ 1.157  , -0.09576, -1.119  ],\n",
      "       [-1.266  ,  1.352  ,  0.2373 ],\n",
      "       [-1.967  , -0.1797 ,  2.234  ],\n",
      "       [-1.406  , -1.184  ,  2.582  ],\n",
      "       [ 4.06   , -1.41   , -2.447  ],\n",
      "       [-1.1045 , -0.05273,  1.203  ],\n",
      "       [ 0.62   , -0.3467 , -0.301  ],\n",
      "       [ 2.062  ,  0.548  , -2.719  ],\n",
      "       [ 2.197  ,  0.1329 , -2.322  ],\n",
      "       [-1.646  ,  1.984  , -0.2311 ],\n",
      "       [-1.48   ,  0.2404 ,  1.357  ],\n",
      "       [-0.0903 , -1.501  ,  1.305  ],\n",
      "       [-2.127  , -0.8076 ,  2.963  ],\n",
      "       [ 1.689  , -0.3481 , -1.37   ],\n",
      "       [-0.4062 ,  1.408  , -1.052  ],\n",
      "       [ 3.355  , -1.004  , -2.22   ],\n",
      "       [ 2.93   , -0.5083 , -2.309  ],\n",
      "       [-0.1769 ,  1.144  , -0.941  ],\n",
      "       [ 3.445  , -1.106  , -2.139  ],\n",
      "       [-0.1934 , -0.712  ,  0.797  ],\n",
      "       [ 2.307  , -0.2272 , -2.021  ],\n",
      "       [ 0.2678 , -0.524  ,  0.1357 ],\n",
      "       [-0.705  ,  1.186  , -0.412  ],\n",
      "       [ 0.008  ,  0.1177 , -0.1848 ],\n",
      "       [-0.829  ,  0.6636 ,  0.2913 ],\n",
      "       [ 0.589  ,  2.719  , -3.588  ],\n",
      "       [-0.4927 ,  1.6875 , -1.306  ],\n",
      "       [ 4.062  , -1.424  , -2.459  ],\n",
      "       [ 2.152  , -0.3691 , -1.755  ],\n",
      "       [ 2.076  ,  1.022  , -3.25   ],\n",
      "       [ 1.787  ,  0.691  , -2.559  ],\n",
      "       [ 3.572  , -1.089  , -2.324  ],\n",
      "       [-0.637  ,  1.38   , -0.717  ],\n",
      "       [ 1.194  ,  1.301  , -2.719  ],\n",
      "       [ 1.587  ,  0.4321 , -2.146  ],\n",
      "       [ 0.7925 ,  0.1913 , -1.112  ],\n",
      "       [-1.3125 , -0.3005 ,  1.649  ],\n",
      "       [ 4.04   , -1.334  , -2.533  ],\n",
      "       [ 3.541  , -0.8296 , -2.533  ],\n",
      "       [ 2.723  , -0.2573 , -2.398  ],\n",
      "       [ 2.469  , -0.4192 , -2.012  ],\n",
      "       [-0.145  ,  1.558  , -1.496  ],\n",
      "       [ 3.354  , -1.125  , -2.105  ],\n",
      "       [ 2.94   , -0.03653, -2.834  ],\n",
      "       [ 2.059  ,  1.194  , -3.416  ],\n",
      "       [ 2.201  ,  0.1034 , -2.354  ],\n",
      "       [-1.366  ,  0.8247 ,  0.7153 ],\n",
      "       [-0.7725 ,  1.865  , -1.174  ],\n",
      "       [ 3.11   , -0.5845 , -2.46   ],\n",
      "       [ 2.46   , -0.4438 , -1.969  ],\n",
      "       [ 3.74   , -0.9614 , -2.572  ],\n",
      "       [ 1.168  ,  0.942  , -2.275  ],\n",
      "       [ 2.12   ,  0.2333 , -2.41   ],\n",
      "       [-0.2256 , -0.2423 ,  0.419  ],\n",
      "       [ 3.822  , -1.151  , -2.467  ],\n",
      "       [ 0.4282 ,  2.086  , -2.643  ],\n",
      "       [ 2.242  ,  0.079  , -2.324  ],\n",
      "       [-0.618  ,  1.692  , -1.171  ],\n",
      "       [-0.7456 ,  1.716  , -1.009  ],\n",
      "       [ 1.149  , -1.0205 , -0.2405 ],\n",
      "       [ 3.924  , -1.199  , -2.555  ],\n",
      "       [-0.587  , -0.6284 ,  1.155  ],\n",
      "       [ 3.926  , -1.359  , -2.412  ],\n",
      "       [ 3.02   , -0.658  , -2.256  ],\n",
      "       [ 3.36   , -1.106  , -2.111  ],\n",
      "       [ 2.998  , -0.7007 , -2.166  ],\n",
      "       [ 2.11   ,  0.146  , -2.23   ],\n",
      "       [ 3.803  , -0.7856 , -2.818  ],\n",
      "       [ 3.418  , -0.8384 , -2.426  ],\n",
      "       [-1.403  ,  1.778  , -0.3289 ],\n",
      "       [-0.5054 , -0.03021,  0.4846 ],\n",
      "       [ 2.963  , -0.6904 , -2.146  ],\n",
      "       [ 2.77   , -0.4934 , -2.205  ],\n",
      "       [ 3.582  , -0.745  , -2.598  ],\n",
      "       [ 2.207  ,  0.3171 , -2.553  ],\n",
      "       [ 1.8545 , -1.345  , -0.588  ]], dtype=float16), label_ids=array([1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 2, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n",
      "       1, 1, 1, 2, 0, 2, 1, 0, 0, 0, 0, 0, 1, 1, 2, 0, 2, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 2, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 2, 1, 0, 1, 0,\n",
      "       0, 0, 2, 1, 0, 1, 1, 1, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "       1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 2, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "       1, 0, 0, 0, 1, 0, 0, 0, 2, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
      "       0, 1, 0, 1, 0, 0, 1, 0, 2, 0, 0, 0, 1, 2, 1, 1, 0, 0, 1, 0, 1, 1,\n",
      "       0, 0, 0, 1, 0, 0, 2, 2, 0, 0, 0, 1, 0, 1, 1, 0, 2, 0, 1, 0, 0, 1,\n",
      "       0, 2, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1, 0, 2, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 2,\n",
      "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 2]), metrics={'test_loss': 0.8489922285079956, 'test_accuracy': 0.7094017094017094, 'test_precision': 0.7129185842953959, 'test_recall': 0.7094017094017094, 'test_f1': 0.702892528798569, 'test_runtime': 1.9552, 'test_samples_per_second': 119.682, 'test_steps_per_second': 4.092})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd70dbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f647b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = torch.softmax(torch.tensor(test_results.predictions).to(torch.float32), dim=-1)\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f215e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66aa90f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_save = []\n",
    "for idx in range(len(test_data)):\n",
    "    item = test_data.__getitem__(idx)\n",
    "    actual_label = item['label']\n",
    "    predicted_label = predictions[idx]\n",
    "    claim = item['claim'] \n",
    "    premise = item['premise'] \n",
    "    category = item['category']\n",
    "    \n",
    "    # Append the information as a dictionary to the list\n",
    "    data_to_save.append({\n",
    "        'Claim': claim,\n",
    "        'Premise': premise,\n",
    "        'Actual Label': actual_label,\n",
    "        'Predicted Label': predicted_label,\n",
    "        'Category' : category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_to_save)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/home/elson/results/2.1.1_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fba2eff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Claim</th>\n",
       "      <th>Premise</th>\n",
       "      <th>Actual Label</th>\n",
       "      <th>Predicted Label</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COVID-19 vaccines are safe &amp; were reviewed by ...</td>\n",
       "      <td>Although COVID-19 vaccines have been proven to...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>COVID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Blood clots can be prevented.</td>\n",
       "      <td>Prevent blood clots and improve survival.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Blood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A platelet transfusion is a procedure in which...</td>\n",
       "      <td>Platelet transfusion is a lifesaving procedure...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Blood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Osteoporosis is a condition that affects only ...</td>\n",
       "      <td>Improvements have been made in detection and m...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bone health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nearly 1 in 5 people experience some type of a...</td>\n",
       "      <td>reported that women suffer from anxiety disord...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Fitness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Claim  \\\n",
       "0  COVID-19 vaccines are safe & were reviewed by ...   \n",
       "1                      Blood clots can be prevented.   \n",
       "2  A platelet transfusion is a procedure in which...   \n",
       "3  Osteoporosis is a condition that affects only ...   \n",
       "4  Nearly 1 in 5 people experience some type of a...   \n",
       "\n",
       "                                             Premise  Actual Label  \\\n",
       "0  Although COVID-19 vaccines have been proven to...             1   \n",
       "1          Prevent blood clots and improve survival.             1   \n",
       "2  Platelet transfusion is a lifesaving procedure...             0   \n",
       "3  Improvements have been made in detection and m...             1   \n",
       "4  reported that women suffer from anxiety disord...             0   \n",
       "\n",
       "   Predicted Label     Category  \n",
       "0                1        COVID  \n",
       "1                0        Blood  \n",
       "2                0        Blood  \n",
       "3                1  Bone health  \n",
       "4                0      Fitness  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b6dbb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correctly classified instances\n",
    "correctly_classified = df[df['Actual Label'] == df['Predicted Label']]\n",
    "\n",
    "# Calculate misclassified instances\n",
    "misclassified = df[df['Actual Label'] != df['Predicted Label']]\n",
    "\n",
    "# Count the number of correctly classified and misclassified by category\n",
    "correct_classification_counts = correctly_classified['Category'].value_counts()\n",
    "misclassification_counts = misclassified['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a98b515c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           40\n",
       "Bone health              15\n",
       "Fitness                  13\n",
       "Cancer                   12\n",
       "Diabetes                 11\n",
       "Skin                     11\n",
       "Eye                       7\n",
       "Cardiovascular Health     7\n",
       "Neurological health       7\n",
       "Ear                       6\n",
       "COVID                     6\n",
       "Throat                    6\n",
       "Hair                      5\n",
       "Blood                     5\n",
       "Muscles                   4\n",
       "Men's health              4\n",
       "Mental Health             3\n",
       "Women' s Health           3\n",
       "Dental Health             1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5dfa8d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Skin                     13\n",
       "General Health           11\n",
       "Hair                      7\n",
       "Bone health               6\n",
       "Cardiovascular Health     5\n",
       "Blood                     4\n",
       "Vascular                  3\n",
       "Women' s Health           3\n",
       "Throat                    3\n",
       "Fitness                   2\n",
       "Muscles                   2\n",
       "Men's health              2\n",
       "Neurological health       2\n",
       "Dental Health             2\n",
       "Eye                       2\n",
       "Diabetes                  1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
