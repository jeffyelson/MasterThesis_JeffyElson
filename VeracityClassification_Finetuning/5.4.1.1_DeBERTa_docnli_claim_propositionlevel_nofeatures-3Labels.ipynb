{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45f1f111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Apr 12 15:56:52 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:61:00.0 Off |                    0 |\n",
      "| N/A   38C    P0    55W / 300W |   3333MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  Off  | 00000000:62:00.0 Off |                    0 |\n",
      "| N/A   39C    P0    68W / 300W |  14325MiB / 32768MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  Off  | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   37C    P0    58W / 300W |   3253MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  Off  | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   40C    P0    69W / 300W |   3269MiB / 32768MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     11098      C   ...A-AVD/venv_ava/bin/python     1665MiB |\n",
      "|    0   N/A  N/A     17092      C   ...A-AVD/venv_ava/bin/python     1665MiB |\n",
      "|    1   N/A  N/A     11098      C   ...A-AVD/venv_ava/bin/python     1711MiB |\n",
      "|    1   N/A  N/A     11099      C   ...A-AVD/venv_ava/bin/python     2027MiB |\n",
      "|    1   N/A  N/A     11102      C   ...A-AVD/venv_ava/bin/python     1711MiB |\n",
      "|    1   N/A  N/A     11110      C   ...A-AVD/venv_ava/bin/python     1711MiB |\n",
      "|    1   N/A  N/A     17092      C   ...A-AVD/venv_ava/bin/python     1711MiB |\n",
      "|    1   N/A  N/A     17093      C   ...A-AVD/venv_ava/bin/python     2027MiB |\n",
      "|    1   N/A  N/A     17096      C   ...A-AVD/venv_ava/bin/python     1711MiB |\n",
      "|    1   N/A  N/A     17099      C   ...A-AVD/venv_ava/bin/python     1711MiB |\n",
      "|    2   N/A  N/A     11102      C   ...A-AVD/venv_ava/bin/python     1625MiB |\n",
      "|    2   N/A  N/A     17096      C   ...A-AVD/venv_ava/bin/python     1625MiB |\n",
      "|    3   N/A  N/A     11110      C   ...A-AVD/venv_ava/bin/python     1633MiB |\n",
      "|    3   N/A  N/A     17099      C   ...A-AVD/venv_ava/bin/python     1633MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-b4d5af22bd5d34d0\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-b4d5af22bd5d34d0/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 198.81it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('csv',data_files='dataset_propositionattribution_nerfeatures.csv',delimiter=',',column_names=[\"claim\",\"premise\",\"label\",\"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\",\"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\",\"url\", \"entities\",\"entity_map\",\"entity_map_ev\",\"entity_ev\",\"gem_exp\",\"gem_label\",\"gpt_exp\",\"gpt_label\",\"gold_exp\",\"split\"],skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e2914c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'entity_map_ev', 'entity_ev', 'gem_exp', 'gem_label', 'gpt_exp', 'gpt_label', 'gold_exp', 'split'],\n",
       "        num_rows: 2322\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57d56e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'test',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['split']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ce96b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-b4d5af22bd5d34d0/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-c7bf70b7c4f0e941.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-b4d5af22bd5d34d0/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-ca379e6fc623397c.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-b4d5af22bd5d34d0/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-41ed9283338b515a.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'entity_map_ev', 'entity_ev', 'gem_exp', 'gem_label', 'gpt_exp', 'gpt_label', 'gold_exp', 'split'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'entity_map_ev', 'entity_ev', 'gem_exp', 'gem_label', 'gpt_exp', 'gpt_label', 'gold_exp', 'split'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'entity_map_ev', 'entity_ev', 'gem_exp', 'gem_label', 'gpt_exp', 'gpt_label', 'gold_exp', 'split'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41f1db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\"claim\", \"premise\", \"label\",\"category\"]\n",
    "all_columns = dataset[\"train\"].column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-b4d5af22bd5d34d0/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-c60e3ec6a423acc6.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-b4d5af22bd5d34d0/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-db497f37725fd7a9.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-b4d5af22bd5d34d0/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-d8f0c0f0e53f8b11.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 1, 'entailment': 0, 'neutral': 2}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 1,\n",
    "    \"entailment\": 0,\n",
    "    \"neutral\": 2\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='MoritzLaurer/DeBERTa-v3-base-mnli-fever-docnli-ling-2c'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "        # Extracting claim and evidence texts\n",
    "\n",
    "        claim = item['claim'].lower()\n",
    "        premise = item['premise'].lower().replace('\\n', '')\n",
    "        item['claim']=claim\n",
    "        item['premise']=premise\n",
    "        \n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "            premise,claim,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "        item['input_ids'] = inputs['input_ids'].squeeze()  # Remove batch dimension\n",
    "        item['attention_mask']= inputs['attention_mask'].squeeze() # Remove batch dimension\n",
    "        \n",
    "        if 'label' in item:\n",
    "            item['labels'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62421eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at MoritzLaurer/DeBERTa-v3-base-mnli-fever-docnli-ling-2c and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([3, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([2]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DebertaV2ForSequenceClassification(\n",
       "  (deberta): DebertaV2Model(\n",
       "    (embeddings): DebertaV2Embeddings(\n",
       "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaV2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (1): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (2): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (3): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (4): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (5): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (6): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (7): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (8): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (9): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (10): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (11): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (pooler): ContextPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): StableDropout()\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (dropout): StableDropout()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"MoritzLaurer/DeBERTa-v3-base-mnli-fever-docnli-ling-2c\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=3, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    bal_accuracy = balanced_accuracy_score(labels,preds)\n",
    "\n",
    "    return {\"accuracy\": acc, \"balanced_accuracy\":bal_accuracy, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17c5e0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'claim': 'myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.',\n",
       " 'premise': 'the essential oils of frankincense and myrrh increase the fluidity of the lipid bilayer in the cuticle and change the orderly and dense structure to increase the permeability of the skin and decrease the barrier effect.',\n",
       " 'label': 0,\n",
       " 'category': 'General Health',\n",
       " 'input_ids': tensor([    1,   262,  1830,  6725,   265, 88609,   263, 98237,   993,   262,\n",
       "         49462,   265,   262, 22003, 96579,   267,   262, 61462,   263,   575,\n",
       "           262, 26217,   263,  9854,  1730,   264,   993,   262, 39632,   265,\n",
       "           262,  1158,   263,  4843,   262,  7275,  1290,   260,     2, 98237,\n",
       "          1830,  1080,   269,  1359,   427,   267, 17847,   633,   264,   408,\n",
       "          1300,   262,  2658,   265,   262,  1158,   260,     2,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'labels': tensor(0)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1020\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1020' max='1020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1020/1020 15:25, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.985900</td>\n",
       "      <td>0.962449</td>\n",
       "      <td>0.565591</td>\n",
       "      <td>0.421573</td>\n",
       "      <td>0.633051</td>\n",
       "      <td>0.565591</td>\n",
       "      <td>0.571254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.831200</td>\n",
       "      <td>0.815232</td>\n",
       "      <td>0.690323</td>\n",
       "      <td>0.456453</td>\n",
       "      <td>0.662903</td>\n",
       "      <td>0.690323</td>\n",
       "      <td>0.675195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.675200</td>\n",
       "      <td>0.851263</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.461086</td>\n",
       "      <td>0.669774</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.668659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.367600</td>\n",
       "      <td>0.929626</td>\n",
       "      <td>0.698925</td>\n",
       "      <td>0.440690</td>\n",
       "      <td>0.654208</td>\n",
       "      <td>0.698925</td>\n",
       "      <td>0.675664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.342800</td>\n",
       "      <td>1.285405</td>\n",
       "      <td>0.688172</td>\n",
       "      <td>0.471710</td>\n",
       "      <td>0.678451</td>\n",
       "      <td>0.688172</td>\n",
       "      <td>0.678529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.294600</td>\n",
       "      <td>1.252583</td>\n",
       "      <td>0.653763</td>\n",
       "      <td>0.526080</td>\n",
       "      <td>0.697946</td>\n",
       "      <td>0.653763</td>\n",
       "      <td>0.672207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.200600</td>\n",
       "      <td>1.448584</td>\n",
       "      <td>0.617204</td>\n",
       "      <td>0.525610</td>\n",
       "      <td>0.702468</td>\n",
       "      <td>0.617204</td>\n",
       "      <td>0.650474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.116700</td>\n",
       "      <td>1.514788</td>\n",
       "      <td>0.703226</td>\n",
       "      <td>0.554952</td>\n",
       "      <td>0.714466</td>\n",
       "      <td>0.703226</td>\n",
       "      <td>0.707799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.159700</td>\n",
       "      <td>1.705195</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.525308</td>\n",
       "      <td>0.707351</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.688491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.160200</td>\n",
       "      <td>2.076644</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.530358</td>\n",
       "      <td>0.713044</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.670583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.153900</td>\n",
       "      <td>1.508333</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.500164</td>\n",
       "      <td>0.706529</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.708056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.178900</td>\n",
       "      <td>1.643998</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.502099</td>\n",
       "      <td>0.696313</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.684368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.101600</td>\n",
       "      <td>1.972291</td>\n",
       "      <td>0.640860</td>\n",
       "      <td>0.506732</td>\n",
       "      <td>0.688551</td>\n",
       "      <td>0.640860</td>\n",
       "      <td>0.661036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.084400</td>\n",
       "      <td>2.146285</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.519610</td>\n",
       "      <td>0.706385</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.674755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.027100</td>\n",
       "      <td>2.068783</td>\n",
       "      <td>0.683871</td>\n",
       "      <td>0.520737</td>\n",
       "      <td>0.714362</td>\n",
       "      <td>0.683871</td>\n",
       "      <td>0.695245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>2.097934</td>\n",
       "      <td>0.696774</td>\n",
       "      <td>0.518359</td>\n",
       "      <td>0.704874</td>\n",
       "      <td>0.696774</td>\n",
       "      <td>0.700657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>2.268537</td>\n",
       "      <td>0.686022</td>\n",
       "      <td>0.524030</td>\n",
       "      <td>0.712441</td>\n",
       "      <td>0.686022</td>\n",
       "      <td>0.697447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.030900</td>\n",
       "      <td>2.225093</td>\n",
       "      <td>0.703226</td>\n",
       "      <td>0.528716</td>\n",
       "      <td>0.709701</td>\n",
       "      <td>0.703226</td>\n",
       "      <td>0.705963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>2.305823</td>\n",
       "      <td>0.694624</td>\n",
       "      <td>0.526373</td>\n",
       "      <td>0.707061</td>\n",
       "      <td>0.694624</td>\n",
       "      <td>0.699919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>2.371146</td>\n",
       "      <td>0.688172</td>\n",
       "      <td>0.521447</td>\n",
       "      <td>0.703552</td>\n",
       "      <td>0.688172</td>\n",
       "      <td>0.694802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to /home/elson/5.1.1.1_deberta_docnli/checkpoint-51\n",
      "Configuration saved in /home/elson/5.1.1.1_deberta_docnli/checkpoint-51/config.json\n",
      "Model weights saved in /home/elson/5.1.1.1_deberta_docnli/checkpoint-51/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to /home/elson/5.1.1.1_deberta_docnli/checkpoint-102\n",
      "Configuration saved in /home/elson/5.1.1.1_deberta_docnli/checkpoint-102/config.json\n",
      "Model weights saved in /home/elson/5.1.1.1_deberta_docnli/checkpoint-102/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.1.1_deberta_docnli/checkpoint-51] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to /home/elson/5.1.1.1_deberta_docnli/checkpoint-153\n",
      "Configuration saved in /home/elson/5.1.1.1_deberta_docnli/checkpoint-153/config.json\n",
      "Model weights saved in /home/elson/5.1.1.1_deberta_docnli/checkpoint-153/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to /home/elson/5.1.1.1_deberta_docnli/checkpoint-204\n",
      "Configuration saved in /home/elson/5.1.1.1_deberta_docnli/checkpoint-204/config.json\n",
      "Model weights saved in /home/elson/5.1.1.1_deberta_docnli/checkpoint-204/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.1.1_deberta_docnli/checkpoint-102] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/5.1.1.1_deberta_docnli/checkpoint-153] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.1.1_deberta_docnli/checkpoint-255\n",
      "Configuration saved in /home/elson/5.1.1.1_deberta_docnli/checkpoint-255/config.json\n",
      "Model weights saved in /home/elson/5.1.1.1_deberta_docnli/checkpoint-255/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.1.1_deberta_docnli/checkpoint-306\n",
      "Configuration saved in /home/elson/5.1.1.1_deberta_docnli/checkpoint-306/config.json\n",
      "Model weights saved in /home/elson/5.1.1.1_deberta_docnli/checkpoint-306/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.1.1_deberta_docnli/checkpoint-255] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.1.1_deberta_docnli/checkpoint-357\n",
      "Configuration saved in /home/elson/5.1.1.1_deberta_docnli/checkpoint-357/config.json\n",
      "Model weights saved in /home/elson/5.1.1.1_deberta_docnli/checkpoint-357/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.1.1_deberta_docnli/checkpoint-306] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.1.1_deberta_docnli/checkpoint-408\n",
      "Configuration saved in /home/elson/5.1.1.1_deberta_docnli/checkpoint-408/config.json\n",
      "Model weights saved in /home/elson/5.1.1.1_deberta_docnli/checkpoint-408/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.1.1_deberta_docnli/checkpoint-204] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/5.1.1.1_deberta_docnli/checkpoint-357] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.1.1_deberta_docnli/checkpoint-459\n",
      "Configuration saved in /home/elson/5.1.1.1_deberta_docnli/checkpoint-459/config.json\n",
      "Model weights saved in /home/elson/5.1.1.1_deberta_docnli/checkpoint-459/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.1.1_deberta_docnli/checkpoint-510\n",
      "Configuration saved in /home/elson/5.1.1.1_deberta_docnli/checkpoint-510/config.json\n",
      "Model weights saved in /home/elson/5.1.1.1_deberta_docnli/checkpoint-510/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.1.1_deberta_docnli/checkpoint-459] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.1.1_deberta_docnli/checkpoint-561\n",
      "Configuration saved in /home/elson/5.1.1.1_deberta_docnli/checkpoint-561/config.json\n",
      "Model weights saved in /home/elson/5.1.1.1_deberta_docnli/checkpoint-561/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.1.1_deberta_docnli/checkpoint-408] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/5.1.1.1_deberta_docnli/checkpoint-510] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.1.1_deberta_docnli/checkpoint-612\n",
      "Configuration saved in /home/elson/5.1.1.1_deberta_docnli/checkpoint-612/config.json\n",
      "Model weights saved in /home/elson/5.1.1.1_deberta_docnli/checkpoint-612/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.1.1_deberta_docnli/checkpoint-663\n",
      "Configuration saved in /home/elson/5.1.1.1_deberta_docnli/checkpoint-663/config.json\n",
      "Model weights saved in /home/elson/5.1.1.1_deberta_docnli/checkpoint-663/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.1.1_deberta_docnli/checkpoint-612] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.1.1_deberta_docnli/checkpoint-714\n",
      "Configuration saved in /home/elson/5.1.1.1_deberta_docnli/checkpoint-714/config.json\n",
      "Model weights saved in /home/elson/5.1.1.1_deberta_docnli/checkpoint-714/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.1.1_deberta_docnli/checkpoint-663] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.1.1_deberta_docnli/checkpoint-765\n",
      "Configuration saved in /home/elson/5.1.1.1_deberta_docnli/checkpoint-765/config.json\n",
      "Model weights saved in /home/elson/5.1.1.1_deberta_docnli/checkpoint-765/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.1.1_deberta_docnli/checkpoint-714] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.1.1_deberta_docnli/checkpoint-816\n",
      "Configuration saved in /home/elson/5.1.1.1_deberta_docnli/checkpoint-816/config.json\n",
      "Model weights saved in /home/elson/5.1.1.1_deberta_docnli/checkpoint-816/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.1.1_deberta_docnli/checkpoint-765] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.1.1_deberta_docnli/checkpoint-867\n",
      "Configuration saved in /home/elson/5.1.1.1_deberta_docnli/checkpoint-867/config.json\n",
      "Model weights saved in /home/elson/5.1.1.1_deberta_docnli/checkpoint-867/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [/home/elson/5.1.1.1_deberta_docnli/checkpoint-816] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.1.1_deberta_docnli/checkpoint-918\n",
      "Configuration saved in /home/elson/5.1.1.1_deberta_docnli/checkpoint-918/config.json\n",
      "Model weights saved in /home/elson/5.1.1.1_deberta_docnli/checkpoint-918/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.1.1_deberta_docnli/checkpoint-867] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.1.1_deberta_docnli/checkpoint-969\n",
      "Configuration saved in /home/elson/5.1.1.1_deberta_docnli/checkpoint-969/config.json\n",
      "Model weights saved in /home/elson/5.1.1.1_deberta_docnli/checkpoint-969/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.1.1_deberta_docnli/checkpoint-918] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.1.1_deberta_docnli/checkpoint-1020\n",
      "Configuration saved in /home/elson/5.1.1.1_deberta_docnli/checkpoint-1020/config.json\n",
      "Model weights saved in /home/elson/5.1.1.1_deberta_docnli/checkpoint-1020/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.1.1_deberta_docnli/checkpoint-969] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/elson/5.1.1.1_deberta_docnli/checkpoint-561 (score: 0.7096774193548387).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /home/elson/5.1.1.1_deberta_docnli/best_model/config.json\n",
      "Model weights saved in /home/elson/5.1.1.1_deberta_docnli/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/5.1.1.1_deberta_docnli/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/5.1.1.1_deberta_docnli/best_model/special_tokens_map.json\n",
      "added tokens file saved in /home/elson/5.1.1.1_deberta_docnli/best_model/added_tokens.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/5.1.1.1_deberta_docnli/best_model/tokenizer_config.json',\n",
       " '/home/elson/5.1.1.1_deberta_docnli/best_model/special_tokens_map.json',\n",
       " '/home/elson/5.1.1.1_deberta_docnli/best_model/spm.model',\n",
       " '/home/elson/5.1.1.1_deberta_docnli/best_model/added_tokens.json')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/5.1.1.1_deberta_docnli/',\n",
    "    num_train_epochs=20,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.6,\n",
    "    weight_decay=0.1,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/5.1.1.1_deberta_docnli/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/5.1.1.1_deberta_docnli/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63deaea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/5.1.1.1_deberta_docnli/best_model/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"/home/elson/5.1.1.1_deberta_docnli/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file /home/elson/5.1.1.1_deberta_docnli/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at /home/elson/5.1.1.1_deberta_docnli/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 32\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/5.1.1.1_deberta_docnli/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[ 5.4961e+00, -1.8838e+00, -1.9951e+00],\n",
      "       [-3.1470e-01, -2.8247e-01,  7.5293e-01],\n",
      "       [ 5.2070e+00, -1.6758e+00, -2.0371e+00],\n",
      "       [-1.3096e+00,  3.3145e+00, -3.3569e-01],\n",
      "       [ 2.2168e+00,  8.0811e-01, -1.1074e+00],\n",
      "       [ 5.1055e+00, -1.6631e+00, -1.9922e+00],\n",
      "       [ 3.8184e+00, -1.1924e+00, -1.6152e+00],\n",
      "       [ 5.3711e+00, -1.6299e+00, -1.9893e+00],\n",
      "       [ 4.5898e+00, -9.0723e-01, -1.7812e+00],\n",
      "       [ 5.1211e+00, -1.7334e+00, -1.9834e+00],\n",
      "       [ 5.3672e+00, -1.6211e+00, -2.0371e+00],\n",
      "       [ 3.0449e+00, -1.0742e+00, -1.1660e+00],\n",
      "       [ 2.5508e+00,  6.7920e-01, -1.2324e+00],\n",
      "       [ 5.3750e+00, -1.7236e+00, -2.0488e+00],\n",
      "       [-9.1553e-01, -2.8882e-01,  1.3555e+00],\n",
      "       [-3.1074e+00,  4.0352e+00,  1.8445e-01],\n",
      "       [ 4.4297e+00, -1.6982e+00, -1.4707e+00],\n",
      "       [ 2.8589e-01, -5.2100e-01,  4.4141e-01],\n",
      "       [-5.4688e-01, -5.5469e-01,  1.3418e+00],\n",
      "       [ 5.0938e+00, -1.6777e+00, -1.9990e+00],\n",
      "       [ 4.0283e-01,  2.0957e+00, -6.6309e-01],\n",
      "       [ 2.8906e+00, -1.3525e+00, -6.2012e-01],\n",
      "       [ 4.4883e+00, -1.6182e+00, -1.6514e+00],\n",
      "       [-3.1816e+00,  3.9766e+00,  2.5854e-01],\n",
      "       [ 4.6250e+00, -1.6592e+00, -1.7480e+00],\n",
      "       [-3.4883e+00,  4.0977e+00,  2.3547e-01],\n",
      "       [ 1.3025e-01, -4.3481e-01,  4.9902e-01],\n",
      "       [ 7.1533e-01, -4.4067e-01, -3.0365e-02],\n",
      "       [ 5.0742e+00, -1.6660e+00, -1.9961e+00],\n",
      "       [ 5.3750e+00, -1.6865e+00, -1.9893e+00],\n",
      "       [ 9.9072e-01,  1.5439e+00, -7.3096e-01],\n",
      "       [ 4.6133e+00, -1.4941e+00, -1.8682e+00],\n",
      "       [-8.7830e-02, -4.7583e-01,  6.9873e-01],\n",
      "       [ 5.3828e+00, -1.7119e+00, -2.0117e+00],\n",
      "       [ 1.2720e-01,  2.2754e+00, -6.3574e-01],\n",
      "       [ 5.4805e+00, -1.7266e+00, -1.8506e+00],\n",
      "       [ 4.5820e+00, -9.2676e-01, -1.6953e+00],\n",
      "       [ 5.3047e+00, -1.7119e+00, -2.0410e+00],\n",
      "       [-3.3965e+00,  4.1055e+00,  2.1130e-01],\n",
      "       [-2.2913e-01, -5.4395e-01,  1.2148e+00],\n",
      "       [-3.0137e+00,  4.0195e+00,  1.3794e-01],\n",
      "       [ 5.5273e+00, -1.8711e+00, -2.0469e+00],\n",
      "       [ 5.1914e+00, -1.5254e+00, -1.9443e+00],\n",
      "       [-3.0840e+00,  4.0859e+00,  1.1121e-01],\n",
      "       [-2.3340e+00,  3.7227e+00, -2.8625e-02],\n",
      "       [ 2.0703e+00, -7.7783e-01, -7.8564e-01],\n",
      "       [ 3.8047e+00, -2.7148e-01, -1.5439e+00],\n",
      "       [ 4.9492e+00, -1.7861e+00, -1.7900e+00],\n",
      "       [ 4.1641e+00, -1.4639e+00, -1.6133e+00],\n",
      "       [-1.3711e+00,  3.3262e+00, -3.2251e-01],\n",
      "       [ 6.2598e-01,  1.9639e+00, -7.2803e-01],\n",
      "       [ 5.4219e+00, -1.7676e+00, -2.0508e+00],\n",
      "       [ 5.0117e+00, -1.2686e+00, -1.8799e+00],\n",
      "       [ 3.6973e+00, -1.3682e+00, -1.3828e+00],\n",
      "       [-7.3584e-01,  2.9043e+00, -4.7266e-01],\n",
      "       [ 5.5273e+00, -1.7686e+00, -2.0527e+00],\n",
      "       [ 4.3398e+00, -1.4443e+00, -1.7480e+00],\n",
      "       [ 5.4336e+00, -1.8154e+00, -2.0508e+00],\n",
      "       [ 5.4766e+00, -1.8467e+00, -2.0059e+00],\n",
      "       [ 5.0039e+00, -1.2617e+00, -1.9014e+00],\n",
      "       [ 3.7637e+00, -1.2451e+00, -1.5518e+00],\n",
      "       [-2.3535e+00,  3.8398e+00, -8.7341e-02],\n",
      "       [ 4.6836e+00, -1.5811e+00, -1.8818e+00],\n",
      "       [ 4.6758e+00, -1.1289e+00, -1.7207e+00],\n",
      "       [ 5.4336e+00, -1.6289e+00, -1.9102e+00],\n",
      "       [ 4.8438e+00, -1.5312e+00, -1.9209e+00],\n",
      "       [ 5.2148e+00, -1.7109e+00, -2.0156e+00],\n",
      "       [ 5.2930e+00, -1.7080e+00, -2.0000e+00],\n",
      "       [ 5.2383e+00, -1.5166e+00, -1.9932e+00],\n",
      "       [ 4.2031e+00, -1.4180e+00, -1.6895e+00],\n",
      "       [ 5.5703e+00, -1.9580e+00, -1.9541e+00],\n",
      "       [ 4.9141e+00, -1.1797e+00, -1.7812e+00],\n",
      "       [ 4.9062e+00, -1.7324e+00, -1.8193e+00],\n",
      "       [ 1.1631e+00,  1.7002e+00, -9.3115e-01],\n",
      "       [ 5.1680e+00, -1.7197e+00, -1.9629e+00],\n",
      "       [ 5.1523e+00, -1.6143e+00, -1.9854e+00],\n",
      "       [ 5.3008e+00, -1.7549e+00, -1.9395e+00],\n",
      "       [ 4.4258e+00, -1.5332e+00, -1.7051e+00],\n",
      "       [ 5.3867e+00, -1.7139e+00, -2.0586e+00],\n",
      "       [ 5.3281e+00, -1.7461e+00, -2.0156e+00],\n",
      "       [ 5.3281e+00, -1.7461e+00, -2.0234e+00],\n",
      "       [ 4.3789e+00, -1.4482e+00, -1.7773e+00],\n",
      "       [ 4.8320e+00, -1.7432e+00, -1.8379e+00],\n",
      "       [ 5.1875e+00, -1.6172e+00, -2.0430e+00],\n",
      "       [ 5.4688e+00, -1.8262e+00, -2.0566e+00],\n",
      "       [ 5.8545e-01,  1.6055e+00, -5.1123e-01],\n",
      "       [ 5.0156e+00, -1.6523e+00, -1.9355e+00],\n",
      "       [ 4.0156e+00, -4.3506e-01, -1.6084e+00],\n",
      "       [ 1.7969e-01, -5.1123e-01,  5.3271e-01],\n",
      "       [ 3.5859e+00, -1.2715e+00, -1.4336e+00],\n",
      "       [ 5.0391e+00, -1.6592e+00, -1.9707e+00],\n",
      "       [ 5.1523e+00, -1.6953e+00, -2.0352e+00],\n",
      "       [-1.7138e-03,  2.4746e+00, -6.5088e-01],\n",
      "       [ 5.4375e+00, -1.8271e+00, -2.0234e+00],\n",
      "       [ 4.8984e+00, -1.3516e+00, -1.8223e+00],\n",
      "       [ 4.1758e+00, -6.4600e-01, -1.6289e+00],\n",
      "       [ 3.6289e+00, -1.1853e-01, -1.4541e+00],\n",
      "       [ 4.9219e+00, -1.4043e+00, -1.8760e+00],\n",
      "       [ 5.1953e+00, -1.6621e+00, -2.0352e+00],\n",
      "       [-1.6553e+00, -4.7290e-01,  2.5059e+00],\n",
      "       [-2.6484e+00,  3.9570e+00,  3.8177e-02],\n",
      "       [-6.0693e-01, -5.2588e-01,  1.3203e+00],\n",
      "       [ 5.3984e+00, -1.7402e+00, -2.0645e+00],\n",
      "       [ 4.6641e+00, -1.6855e+00, -1.7197e+00],\n",
      "       [ 5.4102e+00, -1.7314e+00, -2.0566e+00],\n",
      "       [ 5.1953e+00, -1.7432e+00, -2.0176e+00],\n",
      "       [ 5.1680e+00, -1.6152e+00, -2.0098e+00],\n",
      "       [ 4.9258e+00, -1.6670e+00, -1.9072e+00],\n",
      "       [ 5.3828e+00, -1.7549e+00, -2.0371e+00],\n",
      "       [ 4.7656e+00, -1.1875e+00, -1.7607e+00],\n",
      "       [ 5.2891e+00, -1.7168e+00, -2.0547e+00],\n",
      "       [ 5.4414e+00, -1.8008e+00, -2.0449e+00],\n",
      "       [ 3.5801e+00, -1.3564e+00, -1.3340e+00],\n",
      "       [ 5.0391e+00, -1.6143e+00, -1.9365e+00],\n",
      "       [ 4.9336e+00, -1.6885e+00, -1.9092e+00],\n",
      "       [ 4.7578e+00, -1.6680e+00, -1.8525e+00],\n",
      "       [ 5.2578e+00, -1.5996e+00, -1.9883e+00],\n",
      "       [ 5.2188e+00, -1.8984e+00, -1.6592e+00],\n",
      "       [ 5.2305e+00, -1.4717e+00, -1.9639e+00],\n",
      "       [ 4.9180e+00, -1.5625e+00, -1.9590e+00],\n",
      "       [ 2.3594e+00, -8.3887e-01, -9.6777e-01],\n",
      "       [ 5.2031e+00, -1.7207e+00, -2.0098e+00],\n",
      "       [ 5.3164e+00, -1.8213e+00, -1.9941e+00],\n",
      "       [ 5.0938e+00, -1.5293e+00, -1.9131e+00],\n",
      "       [ 5.0664e+00, -1.3408e+00, -1.8691e+00],\n",
      "       [ 5.1758e+00, -1.6260e+00, -1.9932e+00],\n",
      "       [ 1.3418e+00,  1.4912e+00, -9.5898e-01],\n",
      "       [ 5.2500e+00, -1.6787e+00, -2.0352e+00],\n",
      "       [ 5.5273e+00, -1.9043e+00, -1.8848e+00],\n",
      "       [ 5.1914e+00, -1.5098e+00, -1.9414e+00],\n",
      "       [ 4.4297e+00, -7.7197e-01, -1.7402e+00],\n",
      "       [ 4.7852e+00, -1.1025e+00, -1.8164e+00],\n",
      "       [ 5.2656e+00, -1.7178e+00, -2.0410e+00],\n",
      "       [-2.8809e-01,  2.6875e+00, -6.0303e-01],\n",
      "       [ 4.2852e+00, -6.8457e-01, -1.5957e+00],\n",
      "       [-1.6865e+00,  3.4492e+00, -2.0142e-01],\n",
      "       [ 5.3086e+00, -1.7881e+00, -1.9697e+00],\n",
      "       [-2.8828e+00,  4.0391e+00,  6.7810e-02],\n",
      "       [ 9.1162e-01,  1.7832e+00, -8.7451e-01],\n",
      "       [ 5.3008e+00, -1.7314e+00, -2.0430e+00],\n",
      "       [ 2.8906e+00, -1.0273e+00, -1.1494e+00],\n",
      "       [ 4.7930e+00, -1.1436e+00, -1.8193e+00],\n",
      "       [ 5.4414e+00, -1.6738e+00, -1.9961e+00],\n",
      "       [-7.2754e-01, -3.4644e-01,  1.2432e+00],\n",
      "       [ 5.3438e+00, -1.5908e+00, -2.0117e+00],\n",
      "       [ 3.9297e+00, -1.3984e+00, -1.4932e+00],\n",
      "       [-2.7930e+00,  3.9023e+00,  9.3994e-02],\n",
      "       [ 5.0625e+00, -1.5049e+00, -1.9238e+00],\n",
      "       [ 5.4688e+00, -1.7588e+00, -1.9336e+00],\n",
      "       [-2.3672e+00,  3.8066e+00, -3.6102e-02],\n",
      "       [ 1.7695e+00,  1.1807e+00, -1.0322e+00],\n",
      "       [ 5.1094e+00, -1.6816e+00, -1.9863e+00],\n",
      "       [ 4.0977e+00, -1.5176e+00, -1.4766e+00],\n",
      "       [ 4.5938e+00, -1.6758e+00, -1.7441e+00],\n",
      "       [ 5.3125e+00, -1.5068e+00, -1.9590e+00],\n",
      "       [ 5.2266e+00, -1.4668e+00, -1.9521e+00],\n",
      "       [ 5.2305e+00, -1.6025e+00, -2.0352e+00],\n",
      "       [-2.6738e+00,  3.9648e+00,  5.1331e-02],\n",
      "       [ 4.0938e+00, -1.6504e+00, -1.3154e+00],\n",
      "       [-3.2188e+00,  3.9941e+00,  2.0374e-01],\n",
      "       [-3.4062e+00,  4.1250e+00,  2.0142e-01],\n",
      "       [-3.3984e+00,  4.1328e+00,  1.6492e-01],\n",
      "       [ 5.2773e+00, -1.6934e+00, -1.9756e+00],\n",
      "       [ 4.4062e+00, -7.0264e-01, -1.6729e+00],\n",
      "       [ 3.4707e+00, -4.0894e-02, -1.4561e+00],\n",
      "       [ 2.1094e+00,  1.0020e+00, -1.1367e+00],\n",
      "       [ 5.5039e+00, -1.9248e+00, -1.9072e+00],\n",
      "       [-3.3555e+00,  4.0508e+00,  2.2583e-01],\n",
      "       [ 4.9453e+00, -1.3184e+00, -1.8613e+00],\n",
      "       [ 5.3594e+00, -1.6162e+00, -1.9873e+00],\n",
      "       [-3.4609e+00,  4.1289e+00,  2.0422e-01],\n",
      "       [ 5.1133e+00, -1.4629e+00, -1.9531e+00],\n",
      "       [ 5.0469e+00, -1.6201e+00, -1.9639e+00],\n",
      "       [ 5.3516e+00, -1.7363e+00, -2.0430e+00],\n",
      "       [ 5.4258e+00, -1.6855e+00, -2.0332e+00],\n",
      "       [-2.4792e-01,  2.2324e+00, -3.6963e-01],\n",
      "       [ 4.7539e+00, -1.5771e+00, -1.9199e+00],\n",
      "       [ 5.3633e+00, -1.8516e+00, -1.9277e+00],\n",
      "       [ 5.3164e+00, -1.5605e+00, -1.9873e+00],\n",
      "       [ 5.3438e+00, -1.5928e+00, -2.0176e+00],\n",
      "       [-3.3320e+00,  4.0234e+00,  2.5000e-01],\n",
      "       [ 5.1289e+00, -1.7090e+00, -1.9307e+00],\n",
      "       [-2.8867e+00,  4.0469e+00,  7.7881e-02],\n",
      "       [ 5.1953e+00, -1.6504e+00, -1.9482e+00],\n",
      "       [ 2.2305e+00, -8.4082e-01, -2.4548e-01],\n",
      "       [-5.0342e-01, -2.8442e-01,  9.1504e-01],\n",
      "       [ 4.1328e+00, -5.0195e-01, -1.6211e+00],\n",
      "       [ 5.2852e+00, -1.5342e+00, -1.9727e+00],\n",
      "       [ 2.0234e+00,  9.4873e-01, -1.0361e+00],\n",
      "       [-9.4971e-01, -3.5693e-01,  1.4336e+00],\n",
      "       [ 4.8789e+00, -1.3906e+00, -1.8105e+00],\n",
      "       [ 4.9492e+00, -1.1992e+00, -1.8721e+00],\n",
      "       [-1.5820e+00, -4.6704e-01,  2.5098e+00],\n",
      "       [ 3.4180e+00, -1.5430e+00, -8.7109e-01],\n",
      "       [-3.3809e+00,  4.1133e+00,  2.0508e-01],\n",
      "       [ 4.0234e+00, -1.3945e+00, -1.5518e+00],\n",
      "       [ 5.3867e+00, -1.8369e+00, -1.9932e+00],\n",
      "       [ 5.4375e+00, -1.7803e+00, -2.0605e+00],\n",
      "       [ 5.2500e+00, -1.6055e+00, -2.0332e+00],\n",
      "       [ 5.1875e+00, -1.5225e+00, -1.9600e+00],\n",
      "       [-9.8682e-01, -2.8589e-01,  1.5049e+00],\n",
      "       [ 5.2500e+00, -1.6865e+00, -2.0234e+00],\n",
      "       [ 5.0625e+00, -1.7490e+00, -1.9316e+00],\n",
      "       [ 5.3516e+00, -1.7158e+00, -2.0527e+00],\n",
      "       [-2.0059e+00,  3.5781e+00, -1.4685e-01],\n",
      "       [-2.5996e+00,  3.8340e+00,  1.2573e-01],\n",
      "       [ 5.2734e+00, -1.6270e+00, -2.0391e+00],\n",
      "       [ 5.1484e+00, -1.7773e+00, -1.9297e+00],\n",
      "       [ 5.5625e+00, -1.8311e+00, -2.0938e+00],\n",
      "       [ 4.4258e+00, -8.4229e-01, -1.7197e+00],\n",
      "       [ 5.2617e+00, -1.7500e+00, -1.9990e+00],\n",
      "       [ 5.2188e+00, -1.5537e+00, -1.9639e+00],\n",
      "       [ 5.3398e+00, -1.6963e+00, -1.9805e+00],\n",
      "       [ 4.9102e+00, -1.2109e+00, -1.8682e+00],\n",
      "       [ 5.4258e+00, -1.6689e+00, -2.0234e+00],\n",
      "       [-6.8506e-01,  2.9199e+00, -4.9585e-01],\n",
      "       [-2.1631e-01,  2.6270e+00, -6.2939e-01],\n",
      "       [ 5.4062e+00, -1.6768e+00, -2.0039e+00],\n",
      "       [ 4.7031e+00, -1.5205e+00, -1.8984e+00],\n",
      "       [ 5.2930e+00, -1.7305e+00, -2.0391e+00],\n",
      "       [ 3.1113e+00, -1.1895e+00, -1.0781e+00],\n",
      "       [ 1.4590e+00, -9.7607e-01,  3.9917e-02],\n",
      "       [ 3.7559e+00, -2.8345e-01, -1.4922e+00],\n",
      "       [ 5.3125e+00, -1.6992e+00, -2.0371e+00],\n",
      "       [ 5.3477e+00, -1.6377e+00, -1.9980e+00],\n",
      "       [ 4.9258e+00, -1.6348e+00, -1.9209e+00],\n",
      "       [ 5.5508e+00, -1.8311e+00, -2.0469e+00],\n",
      "       [-2.6426e+00,  3.8535e+00,  1.3770e-01],\n",
      "       [ 5.2109e+00, -1.7803e+00, -1.9307e+00],\n",
      "       [-1.2969e+00, -4.8413e-01,  1.9463e+00],\n",
      "       [ 2.8379e+00, -9.8877e-01, -1.1592e+00],\n",
      "       [ 4.0859e+00, -1.3945e+00, -1.6123e+00],\n",
      "       [ 5.0820e+00, -1.3535e+00, -1.9268e+00],\n",
      "       [ 5.2422e+00, -1.9004e+00, -1.7490e+00]], dtype=float16), label_ids=array([0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 2, 0, 0, 2, 0, 0, 2, 1,\n",
      "       0, 2, 1, 1, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 1, 2, 0, 0,\n",
      "       0, 1, 0, 0, 1, 1, 2, 0, 0, 2, 0, 0, 2, 2, 0, 0, 0, 1, 2, 0, 2, 1,\n",
      "       0, 0, 1, 1, 0, 0, 2, 2, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0,\n",
      "       1, 2, 0, 0, 1, 0, 0, 0, 1, 0, 0, 2, 1, 2, 0, 2, 0, 0, 0, 2, 0, 0,\n",
      "       2, 0, 2, 0, 2, 0, 0, 0, 1, 1, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "       0, 2, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 2, 2,\n",
      "       0, 0, 0, 2, 0, 1, 1, 1, 0, 0, 0, 2, 0, 0, 1, 0, 1, 0, 2, 0, 0, 0,\n",
      "       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 0, 2, 0, 0, 0, 0, 2, 2, 1, 0, 0,\n",
      "       0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 1]), metrics={'test_loss': 1.8915903568267822, 'test_accuracy': 0.6196581196581197, 'test_balanced_accuracy': 0.4365079365079365, 'test_precision': 0.5744575087537056, 'test_recall': 0.6196581196581197, 'test_f1': 0.5859017148909398, 'test_runtime': 1.9535, 'test_samples_per_second': 119.782, 'test_steps_per_second': 4.095})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73395d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "probabilities = torch.softmax(torch.tensor(test_results.predictions).to(torch.float32), dim=-1)\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)\n",
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb603377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_save = []\n",
    "for idx in range(len(test_data)):\n",
    "    item = dataset['test'][idx]\n",
    "    actual_label = item['label']\n",
    "    predicted_label = predictions[idx]\n",
    "    claim = item['claim'] \n",
    "    premise = item['premise'] \n",
    "    category = item['category']\n",
    "    \n",
    "    # Append the information as a dictionary to the list\n",
    "    data_to_save.append({\n",
    "        'Claim': claim,\n",
    "        'Premise': premise,\n",
    "        'Actual Label': actual_label,\n",
    "        'Predicted Label': predicted_label,\n",
    "        'Category' : category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_to_save)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/home/elson/results/5.1.1.1_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c23339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correctly classified instances\n",
    "correctly_classified = df[df['Actual Label'] == df['Predicted Label']]\n",
    "\n",
    "# Calculate misclassified instances\n",
    "misclassified = df[df['Actual Label'] != df['Predicted Label']]\n",
    "\n",
    "# Count the number of correctly classified and misclassified by category\n",
    "correct_classification_counts = correctly_classified['Category'].value_counts()\n",
    "misclassification_counts = misclassified['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca0def77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           32\n",
       "Fitness                  15\n",
       "Cancer                   12\n",
       "Bone health              11\n",
       "Neurological health       9\n",
       "Diabetes                  9\n",
       "Cardiovascular Health     9\n",
       "Hair                      8\n",
       "Throat                    7\n",
       "Ear                       6\n",
       "Blood                     5\n",
       "Skin                      5\n",
       "COVID                     5\n",
       "Women' s Health           3\n",
       "Eye                       3\n",
       "Dental Health             3\n",
       "Mental Health             3\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0fddd944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           19\n",
       "Skin                     19\n",
       "Bone health              10\n",
       "Men's health              6\n",
       "Eye                       6\n",
       "Muscles                   6\n",
       "Blood                     4\n",
       "Hair                      4\n",
       "Diabetes                  3\n",
       "Cardiovascular Health     3\n",
       "Vascular                  3\n",
       "Women' s Health           3\n",
       "Throat                    2\n",
       "COVID                     1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38b899b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_counts = df['Category'].value_counts()\n",
    "\n",
    "# Calculate ratios\n",
    "correct_classification_ratios = correct_classification_counts / total_counts\n",
    "misclassification_ratios = misclassification_counts / total_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3598b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blood                    0.555556\n",
      "Bone health              0.523810\n",
      "COVID                    0.833333\n",
      "Cancer                   1.000000\n",
      "Cardiovascular Health    0.750000\n",
      "Dental Health            1.000000\n",
      "Diabetes                 0.750000\n",
      "Ear                      1.000000\n",
      "Eye                      0.333333\n",
      "Fitness                  1.000000\n",
      "General Health           0.627451\n",
      "Hair                     0.666667\n",
      "Men's health                  NaN\n",
      "Mental Health            1.000000\n",
      "Muscles                       NaN\n",
      "Neurological health      1.000000\n",
      "Skin                     0.208333\n",
      "Throat                   0.777778\n",
      "Vascular                      NaN\n",
      "Women' s Health          0.500000\n",
      "Name: Category, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(correct_classification_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27602a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blood                    0.444444\n",
      "Bone health              0.476190\n",
      "COVID                    0.166667\n",
      "Cancer                        NaN\n",
      "Cardiovascular Health    0.250000\n",
      "Dental Health                 NaN\n",
      "Diabetes                 0.250000\n",
      "Ear                           NaN\n",
      "Eye                      0.666667\n",
      "Fitness                       NaN\n",
      "General Health           0.372549\n",
      "Hair                     0.333333\n",
      "Men's health             1.000000\n",
      "Mental Health                 NaN\n",
      "Muscles                  1.000000\n",
      "Neurological health           NaN\n",
      "Skin                     0.791667\n",
      "Throat                   0.222222\n",
      "Vascular                 1.000000\n",
      "Women' s Health          0.500000\n",
      "Name: Category, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(misclassification_ratios)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
