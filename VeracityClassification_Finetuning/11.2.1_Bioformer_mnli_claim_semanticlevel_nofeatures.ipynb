{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score,balanced_accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-31dfe7adddcf5ced\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 182.19it/s]\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-ad71be204b279b28.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-e7b6b615907c24ca.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-bee802838a3bfaea.arrow\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset from the CSV file\n",
    "dataset = load_dataset(\n",
    "    'csv',\n",
    "    data_files='dataset_semanticattribution_nerfeatures_split.csv',\n",
    "    delimiter=',',\n",
    "    column_names=[\n",
    "        \"claim\", \"premise\", \"label\", \"category\", \"count_bf\", \"count_ca\", \"count_dis\",\n",
    "        \"count_food\", \"count_lipid\", \"count_treat\", \"pres_bf\", \"pres_ca\", \"pres_dis\",\n",
    "        \"pres_food\", \"pres_lipid\", \"pres_treat\", \"counte_bf\", \"counte_ca\", \"counte_dis\",\n",
    "        \"counte_food\", \"counte_lipid\", \"counte_treat\", \"prese_bf\", \"prese_ca\", \"prese_dis\",\n",
    "        \"prese_food\", \"prese_lipid\", \"prese_treat\", \"url\", \"entities\", \"entity_map\",\n",
    "        \"gold_exp\", \"gemini_exp\", \"gemini_label\",\"entity_ev\",\"entity_map_ev\", \"split\"\n",
    "    ],\n",
    "    skiprows=1\n",
    ")\n",
    "\n",
    "\n",
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'gold_exp', 'gemini_exp', 'gemini_label', 'entity_ev', 'entity_map_ev', 'split'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'gold_exp', 'gemini_exp', 'gemini_label', 'entity_ev', 'entity_map_ev', 'split'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'gold_exp', 'gemini_exp', 'gemini_label', 'entity_ev', 'entity_map_ev', 'split'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41f1db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\"claim\", \"premise\", \"label\",\"category\"]\n",
    "all_columns = dataset[\"train\"].column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1623/1623 [00:00<00:00, 6747.00ex/s]\n",
      "100%|██████████| 465/465 [00:00<00:00, 7262.28ex/s]\n",
      "100%|██████████| 234/234 [00:00<00:00, 6987.32ex/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 0, 'entailment': 1, 'neutral': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 0,\n",
    "    \"entailment\": 1,\n",
    "    \"neutral\": 2\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='bioformers/bioformer-8L-mnli'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "        # Extracting claim and evidence texts\n",
    "\n",
    "        claim = item['claim']\n",
    "        premise = item['premise'].replace('\\n', '').replace('[','').replace(']','')\n",
    "        item['claim']=claim\n",
    "        item['premise']=premise\n",
    "        \n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "            claim, premise,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "        item['input_ids'] = inputs['input_ids'].squeeze()  # Remove batch dimension\n",
    "        item['attention_mask']= inputs['attention_mask'].squeeze() # Remove batch dimension\n",
    "        \n",
    "        if 'label' in item:\n",
    "            item['labels'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62421eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(32768, 512, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 512)\n",
       "      (token_type_embeddings): Embedding(2, 512)\n",
       "      (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=512, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"bioformers/bioformer-8L-mnli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=3, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    bal_accuracy = balanced_accuracy_score(labels,preds)\n",
    "\n",
    "    return {\"accuracy\": acc, \"balanced_accuracy\":bal_accuracy, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17c5e0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'claim': 'Myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.',\n",
       " 'premise': '; UnkoviÄ‡, N.; DimkiÄ‡, I.; JanaÄ‡koviÄ‡, P.; GavriloviÄ‡, M.; StanojeviÄ‡, O.; VukojeviÄ‡, J. Frankincense and myrrh essential oils and burn incense fume against micro-inhabitants of sacral ambients.Shameem, I. Phytochemical & therapeutic potentials of Murr makki (.Oxidative stress and immunotoxic effects of lead and their amelioration with myrrh (Commiphora molmol) emulsion.Essential Oils: Magical Ingredients for Skin Care.Chakravarty, N.; Kellogg, C.; Alvarez, J.; Equils, O.; Morgan, M. UV Protection by Natural Products: C. myrrha Oil Versus Sunscreen.Hamidpour, R.; Hamidpour, S.; Hamidpour, M.; Shahlari, M. Frankincense (ä¹³é¦™ RÇ” XiÄ\\x81ng;.species): From the selection of traditional applications to the novel phytotherapy for the prevention and treatment of serious diseases.Chemistry and immunomodulatory activity of frankincense oil.Compositions containing Boswellia extracts.; Cooper, E. Frankincense and myrrh as remedies in children.',\n",
       " 'label': 1,\n",
       " 'category': 'General Health',\n",
       " 'input_ids': tensor([  101, 31487,  4258,  3720,  6187,  1478,  8811,  1822,  1427,  3550,\n",
       "          5183,  4030,  1446,  3346,  2520,  1425,  6875,  1431,  1425,  3550,\n",
       "           119,   102,   132,   100,   336,   117,   151,   119,   132,   100,\n",
       "           336,   117,   146,   119,   132,   100,   336,   100,   336,   117,\n",
       "           153,   119,   132,   100,   336,   117,   150,   119,   132,   100,\n",
       "           336,   117,   152,   119,   132,   100,   336,   117,   147,   119,\n",
       "         26248,  2848,  9507,  1111,  1435,  2573,  1109,  4258,  3720, 15658,\n",
       "          1435,  8619,  1544,  3670, 13976,  1111,  2782,  2110,   118, 21901,\n",
       "          1431, 24417, 11643,  1113,   119, 26904,  4910,  1121,   117,   146,\n",
       "           119, 23293,  3919,   111,  3131,  8132,  1431, 24011,  1109,  2067,\n",
       "          1137, 14997,   113,   119, 21770,  2543,  1435, 10270,  5097, 30192,\n",
       "          1115,  1990,  1431,  2387,  1435,  1785, 28458,  1461,  2573,  1109,\n",
       "          4258,   113, 24383,  6169,  9565,  6814,  8952,   114, 18260,   119,\n",
       "         31651,   152,  4661,   131, 28447,  1527, 25714,  3062,  5642,  1471,\n",
       "         19601,  9248,   119, 23525, 26279, 17196,  1109,  2534,   117,   151,\n",
       "           119,   132, 11860,  3141,  1518,  1138,   117,   140,   119,   132,\n",
       "          1999, 23576, 14015,   117,   147,   119,   132, 11349,  4661,   117,\n",
       "           152,   119,   132,  9738,  2287,   117,   150,   119,  5959, 23114,\n",
       "          1520, 19077, 24358,  1481,   131,   140,   119,  2573,  1109,  4258,\n",
       "          1118,   152,  1473, 27495,  1463, 21906, 12695, 22906,   119, 31992,\n",
       "          1462, 12488,  1452,   117,   155,   119,   132, 31992,  1462, 12488,\n",
       "          1452,   117,   156,   119,   132, 31992,  1462, 12488,  1452,   117,\n",
       "           150,   119,   132, 25473, 22952,  1699,   117,   150,   119, 26248,\n",
       "          2848,  9507,  1111,   113,   100,   100,   333,   100,   132,   119,\n",
       "          2439,   114,   131,  5299,  1425,  4115,  1431,  5329,  4647,  1446,\n",
       "          1425,  3036, 20924, 17338,  1471,  1425,  4573,  1435,  1786,  1431,\n",
       "          5876,  3054,   119, 12459,  4503,  1435, 16228,  1950,  1431,  2132,\n",
       "          4765,  2848,  9507,  1111,  6187,   119,  6784,  3108,  1113,  3264,\n",
       "         27579, 15864,  1619,  6688,   119,   132,  3985,  2565,   117,   142,\n",
       "           119, 26248,  2848,  9507,  1111,  1435,  2573,  1109,  4258,  1475,\n",
       "         14868,  1559,  1427,  2409,   119,   102,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'labels': tensor(1)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 765\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='765' max='765' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [765/765 02:59, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.880300</td>\n",
       "      <td>0.818694</td>\n",
       "      <td>0.673118</td>\n",
       "      <td>0.338542</td>\n",
       "      <td>0.588802</td>\n",
       "      <td>0.673118</td>\n",
       "      <td>0.543776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.701300</td>\n",
       "      <td>0.858568</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.443502</td>\n",
       "      <td>0.637466</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.613322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.529500</td>\n",
       "      <td>0.882117</td>\n",
       "      <td>0.673118</td>\n",
       "      <td>0.519890</td>\n",
       "      <td>0.657715</td>\n",
       "      <td>0.673118</td>\n",
       "      <td>0.663985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.250800</td>\n",
       "      <td>1.181990</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.472135</td>\n",
       "      <td>0.643196</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.637534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.226000</td>\n",
       "      <td>1.329748</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.473106</td>\n",
       "      <td>0.634186</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.645418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.184100</td>\n",
       "      <td>1.452106</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.479947</td>\n",
       "      <td>0.635288</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.639683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.088500</td>\n",
       "      <td>1.699081</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>0.498346</td>\n",
       "      <td>0.655606</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>0.638274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.037700</td>\n",
       "      <td>1.730931</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.497460</td>\n",
       "      <td>0.648150</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.651097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.053300</td>\n",
       "      <td>1.744619</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.505241</td>\n",
       "      <td>0.651823</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.650900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.039900</td>\n",
       "      <td>1.924265</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.470848</td>\n",
       "      <td>0.626904</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.634287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.054400</td>\n",
       "      <td>1.966586</td>\n",
       "      <td>0.640860</td>\n",
       "      <td>0.484876</td>\n",
       "      <td>0.640860</td>\n",
       "      <td>0.640860</td>\n",
       "      <td>0.640860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.013800</td>\n",
       "      <td>2.025332</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.528660</td>\n",
       "      <td>0.665999</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.652900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>2.047329</td>\n",
       "      <td>0.647312</td>\n",
       "      <td>0.508034</td>\n",
       "      <td>0.654416</td>\n",
       "      <td>0.647312</td>\n",
       "      <td>0.649562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>2.035235</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.477416</td>\n",
       "      <td>0.630678</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.635199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>2.052542</td>\n",
       "      <td>0.640860</td>\n",
       "      <td>0.491195</td>\n",
       "      <td>0.638012</td>\n",
       "      <td>0.640860</td>\n",
       "      <td>0.637703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to /home/elson/11.2.1_bioformer/checkpoint-51\n",
      "Configuration saved in /home/elson/11.2.1_bioformer/checkpoint-51/config.json\n",
      "Model weights saved in /home/elson/11.2.1_bioformer/checkpoint-51/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.2.1_bioformer/checkpoint-102\n",
      "Configuration saved in /home/elson/11.2.1_bioformer/checkpoint-102/config.json\n",
      "Model weights saved in /home/elson/11.2.1_bioformer/checkpoint-102/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.2.1_bioformer/checkpoint-153\n",
      "Configuration saved in /home/elson/11.2.1_bioformer/checkpoint-153/config.json\n",
      "Model weights saved in /home/elson/11.2.1_bioformer/checkpoint-153/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.2.1_bioformer/checkpoint-102] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.2.1_bioformer/checkpoint-204\n",
      "Configuration saved in /home/elson/11.2.1_bioformer/checkpoint-204/config.json\n",
      "Model weights saved in /home/elson/11.2.1_bioformer/checkpoint-204/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.2.1_bioformer/checkpoint-153] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.2.1_bioformer/checkpoint-255\n",
      "Configuration saved in /home/elson/11.2.1_bioformer/checkpoint-255/config.json\n",
      "Model weights saved in /home/elson/11.2.1_bioformer/checkpoint-255/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.2.1_bioformer/checkpoint-204] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.2.1_bioformer/checkpoint-306\n",
      "Configuration saved in /home/elson/11.2.1_bioformer/checkpoint-306/config.json\n",
      "Model weights saved in /home/elson/11.2.1_bioformer/checkpoint-306/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.2.1_bioformer/checkpoint-255] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.2.1_bioformer/checkpoint-357\n",
      "Configuration saved in /home/elson/11.2.1_bioformer/checkpoint-357/config.json\n",
      "Model weights saved in /home/elson/11.2.1_bioformer/checkpoint-357/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.2.1_bioformer/checkpoint-306] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.2.1_bioformer/checkpoint-408\n",
      "Configuration saved in /home/elson/11.2.1_bioformer/checkpoint-408/config.json\n",
      "Model weights saved in /home/elson/11.2.1_bioformer/checkpoint-408/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.2.1_bioformer/checkpoint-357] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.2.1_bioformer/checkpoint-459\n",
      "Configuration saved in /home/elson/11.2.1_bioformer/checkpoint-459/config.json\n",
      "Model weights saved in /home/elson/11.2.1_bioformer/checkpoint-459/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.2.1_bioformer/checkpoint-408] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.2.1_bioformer/checkpoint-510\n",
      "Configuration saved in /home/elson/11.2.1_bioformer/checkpoint-510/config.json\n",
      "Model weights saved in /home/elson/11.2.1_bioformer/checkpoint-510/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.2.1_bioformer/checkpoint-459] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.2.1_bioformer/checkpoint-561\n",
      "Configuration saved in /home/elson/11.2.1_bioformer/checkpoint-561/config.json\n",
      "Model weights saved in /home/elson/11.2.1_bioformer/checkpoint-561/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.2.1_bioformer/checkpoint-510] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.2.1_bioformer/checkpoint-612\n",
      "Configuration saved in /home/elson/11.2.1_bioformer/checkpoint-612/config.json\n",
      "Model weights saved in /home/elson/11.2.1_bioformer/checkpoint-612/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.2.1_bioformer/checkpoint-561] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.2.1_bioformer/checkpoint-663\n",
      "Configuration saved in /home/elson/11.2.1_bioformer/checkpoint-663/config.json\n",
      "Model weights saved in /home/elson/11.2.1_bioformer/checkpoint-663/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.2.1_bioformer/checkpoint-612] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.2.1_bioformer/checkpoint-714\n",
      "Configuration saved in /home/elson/11.2.1_bioformer/checkpoint-714/config.json\n",
      "Model weights saved in /home/elson/11.2.1_bioformer/checkpoint-714/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.2.1_bioformer/checkpoint-663] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.2.1_bioformer/checkpoint-765\n",
      "Configuration saved in /home/elson/11.2.1_bioformer/checkpoint-765/config.json\n",
      "Model weights saved in /home/elson/11.2.1_bioformer/checkpoint-765/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.2.1_bioformer/checkpoint-714] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/elson/11.2.1_bioformer/checkpoint-51 (score: 0.6731182795698925).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Configuration saved in /home/elson/11.2.1_bioformer/best_model/config.json\n",
      "Model weights saved in /home/elson/11.2.1_bioformer/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/11.2.1_bioformer/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/11.2.1_bioformer/best_model/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/11.2.1_bioformer/best_model/tokenizer_config.json',\n",
       " '/home/elson/11.2.1_bioformer/best_model/special_tokens_map.json',\n",
       " '/home/elson/11.2.1_bioformer/best_model/vocab.txt',\n",
       " '/home/elson/11.2.1_bioformer/best_model/added_tokens.json',\n",
       " '/home/elson/11.2.1_bioformer/best_model/tokenizer.json')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/11.2.1_bioformer/',\n",
    "    num_train_epochs=15,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.06,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/11.2.1_bioformer/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/11.2.1_bioformer/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63deaea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/11.2.1_bioformer/best_model/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"/home/elson/11.2.1_bioformer/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"finetuning_task\": \"mnli\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 512,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"entailment\",\n",
      "    \"1\": \"neutral\",\n",
      "    \"2\": \"contradiction\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2048,\n",
      "  \"label2id\": {\n",
      "    \"contradiction\": 2,\n",
      "    \"entailment\": 0,\n",
      "    \"neutral\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 8,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32768\n",
      "}\n",
      "\n",
      "loading weights file /home/elson/11.2.1_bioformer/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at /home/elson/11.2.1_bioformer/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 32\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/11.2.1_bioformer/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[-0.5107,  0.723 , -0.7524],\n",
      "       [-0.7485,  1.302 , -1.062 ],\n",
      "       [-0.8477,  1.061 , -0.808 ],\n",
      "       [-0.712 ,  1.047 , -0.841 ],\n",
      "       [-0.6055,  1.003 , -0.9507],\n",
      "       [-0.921 ,  1.415 , -0.979 ],\n",
      "       [-0.518 ,  0.671 , -0.478 ],\n",
      "       [-0.7983,  0.974 , -0.6445],\n",
      "       [-0.466 ,  0.9956, -1.0625],\n",
      "       [-0.465 ,  0.739 , -0.7114],\n",
      "       [-0.821 ,  1.303 , -0.9985],\n",
      "       [-0.518 ,  0.869 , -0.9604],\n",
      "       [-0.6743,  0.9614, -0.8525],\n",
      "       [-0.56  ,  0.6743, -0.5576],\n",
      "       [-0.8745,  1.17  , -0.6797],\n",
      "       [-0.613 ,  0.875 , -0.834 ],\n",
      "       [-0.764 ,  1.048 , -0.627 ],\n",
      "       [-0.6045,  0.711 , -0.6963],\n",
      "       [-0.4458,  0.854 , -0.9375],\n",
      "       [-0.4253,  0.8438, -1.    ],\n",
      "       [-0.7344,  0.76  , -0.4885],\n",
      "       [-0.5654,  0.7397, -0.693 ],\n",
      "       [-0.769 ,  1.007 , -0.6914],\n",
      "       [-0.3547,  0.5923, -0.749 ],\n",
      "       [-0.5435,  0.7065, -0.6885],\n",
      "       [-0.4517,  0.71  , -0.8086],\n",
      "       [-0.549 ,  0.8286, -0.7544],\n",
      "       [-0.53  ,  0.7407, -0.839 ],\n",
      "       [-0.843 ,  0.883 , -0.5156],\n",
      "       [-0.753 ,  0.9844, -0.8765],\n",
      "       [-0.2345,  0.449 , -0.7236],\n",
      "       [-0.6333,  1.302 , -1.068 ],\n",
      "       [-0.639 ,  0.6685, -0.5635],\n",
      "       [-0.4172,  0.724 , -0.775 ],\n",
      "       [-0.71  ,  0.686 , -0.4785],\n",
      "       [-0.87  ,  0.9224, -0.6396],\n",
      "       [-0.4182,  0.889 , -0.9575],\n",
      "       [-0.581 ,  0.8286, -0.818 ],\n",
      "       [-0.4336,  0.748 , -0.8867],\n",
      "       [-0.9414,  1.224 , -0.7544],\n",
      "       [-0.4949,  0.7583, -0.721 ],\n",
      "       [-0.8047,  1.084 , -0.847 ],\n",
      "       [-0.3716,  0.745 , -0.8813],\n",
      "       [-0.479 ,  0.674 , -0.716 ],\n",
      "       [-0.755 ,  0.9263, -0.635 ],\n",
      "       [-0.762 ,  0.815 , -0.5195],\n",
      "       [-1.12  ,  1.3125, -0.589 ],\n",
      "       [-0.3582,  0.4807, -0.6133],\n",
      "       [-0.6025,  0.7817, -0.694 ],\n",
      "       [-0.2443,  0.5317, -0.802 ],\n",
      "       [-0.5337,  0.606 , -0.7305],\n",
      "       [-0.2366,  0.539 , -0.809 ],\n",
      "       [-0.473 ,  0.7207, -0.7383],\n",
      "       [-1.13  ,  1.223 , -0.4717],\n",
      "       [-0.3948,  0.6353, -0.8677],\n",
      "       [-0.399 ,  0.821 , -0.926 ],\n",
      "       [-0.566 ,  0.6226, -0.6396],\n",
      "       [-1.041 ,  1.334 , -0.677 ],\n",
      "       [-0.4146,  0.74  , -0.8994],\n",
      "       [-0.4785,  0.8   , -0.8657],\n",
      "       [-0.7524,  0.9253, -0.5996],\n",
      "       [-0.473 ,  0.7485, -0.797 ],\n",
      "       [-0.745 ,  0.979 , -0.5713],\n",
      "       [-0.5894,  0.9795, -0.955 ],\n",
      "       [-0.8784,  1.129 , -0.838 ],\n",
      "       [-0.6963,  0.696 , -0.487 ],\n",
      "       [-0.772 ,  1.134 , -0.9116],\n",
      "       [-0.5845,  0.79  , -0.7676],\n",
      "       [-0.829 ,  1.417 , -1.008 ],\n",
      "       [-0.3545,  0.3062, -0.405 ],\n",
      "       [-0.8604,  1.26  , -0.877 ],\n",
      "       [-1.143 ,  1.256 , -0.4434],\n",
      "       [-0.7417,  0.99  , -0.58  ],\n",
      "       [-0.5723,  0.814 , -0.7446],\n",
      "       [-0.628 ,  0.7   , -0.619 ],\n",
      "       [-0.5396,  0.594 , -0.5986],\n",
      "       [-0.4355,  0.66  , -0.6973],\n",
      "       [-0.552 ,  0.7744, -0.727 ],\n",
      "       [-0.863 ,  0.958 , -0.5127],\n",
      "       [-0.465 ,  0.7188, -0.7266],\n",
      "       [-0.5737,  0.809 , -0.725 ],\n",
      "       [-0.5586,  0.9697, -0.965 ],\n",
      "       [-0.595 ,  0.718 , -0.646 ],\n",
      "       [-0.65  ,  1.058 , -1.002 ],\n",
      "       [-0.4893,  0.7993, -0.756 ],\n",
      "       [-0.1683,  0.2573, -0.546 ],\n",
      "       [-0.5464,  0.6406, -0.7056],\n",
      "       [-0.675 ,  0.815 , -0.6973],\n",
      "       [-0.5054,  0.5967, -0.6484],\n",
      "       [-0.914 ,  1.158 , -0.72  ],\n",
      "       [-0.7705,  1.138 , -0.9004],\n",
      "       [-0.8867,  1.064 , -0.618 ],\n",
      "       [-0.863 ,  0.742 , -0.3298],\n",
      "       [-0.6006,  0.823 , -0.7227],\n",
      "       [-0.3293,  0.4844, -0.779 ],\n",
      "       [-0.845 ,  0.839 , -0.5435],\n",
      "       [-0.4202,  0.6226, -0.706 ],\n",
      "       [-0.3582,  0.642 , -0.8926],\n",
      "       [-0.918 ,  1.455 , -0.8965],\n",
      "       [-0.4841,  0.712 , -0.705 ],\n",
      "       [-0.2192,  0.652 , -0.9478],\n",
      "       [-0.968 ,  1.257 , -0.697 ],\n",
      "       [-0.5923,  0.9414, -0.8413],\n",
      "       [-0.863 ,  0.9004, -0.624 ],\n",
      "       [-0.41  ,  0.571 , -0.7183],\n",
      "       [-0.808 ,  1.13  , -0.8975],\n",
      "       [-0.723 ,  0.8076, -0.624 ],\n",
      "       [-0.6436,  0.992 , -0.7954],\n",
      "       [-0.817 ,  0.9604, -0.6553],\n",
      "       [-0.9907,  1.25  , -0.71  ],\n",
      "       [-0.9004,  0.993 , -0.5605],\n",
      "       [-0.6094,  0.736 , -0.587 ],\n",
      "       [-0.59  ,  0.564 , -0.4316],\n",
      "       [-0.59  ,  0.657 , -0.6367],\n",
      "       [-0.8623,  1.247 , -0.7114],\n",
      "       [-0.569 ,  0.989 , -0.995 ],\n",
      "       [-0.4207,  0.824 , -0.856 ],\n",
      "       [-0.4373,  0.52  , -0.476 ],\n",
      "       [-0.701 ,  1.186 , -1.068 ],\n",
      "       [-0.6143,  0.698 , -0.6387],\n",
      "       [-1.    ,  1.569 , -0.9873],\n",
      "       [-0.839 ,  0.951 , -0.74  ],\n",
      "       [-0.9536,  1.27  , -0.7637],\n",
      "       [-0.8047,  1.036 , -0.7256],\n",
      "       [-0.761 ,  1.092 , -0.9375],\n",
      "       [-0.5063,  1.272 , -1.13  ],\n",
      "       [-0.539 ,  0.7017, -0.7817],\n",
      "       [-0.7407,  1.183 , -0.9346],\n",
      "       [-0.6084,  0.8105, -0.6777],\n",
      "       [-0.8125,  1.066 , -0.825 ],\n",
      "       [-0.4907,  0.695 , -0.7124],\n",
      "       [-0.724 ,  0.7183, -0.543 ],\n",
      "       [-0.7036,  0.83  , -0.751 ],\n",
      "       [-0.4133,  0.4612, -0.6367],\n",
      "       [-0.8345,  1.312 , -0.9727],\n",
      "       [-0.545 ,  0.8364, -0.7188],\n",
      "       [-0.578 ,  0.8413, -0.8315],\n",
      "       [-0.3484,  0.6504, -0.8145],\n",
      "       [-0.2732,  0.589 , -0.92  ],\n",
      "       [-0.507 ,  0.7397, -0.758 ],\n",
      "       [-0.574 ,  0.788 , -0.772 ],\n",
      "       [-0.8135,  0.9336, -0.5635],\n",
      "       [-0.4746,  0.849 , -0.9014],\n",
      "       [-0.9   ,  1.314 , -0.859 ],\n",
      "       [-0.4993,  0.863 , -0.841 ],\n",
      "       [-0.6797,  0.7495, -0.684 ],\n",
      "       [-0.4678,  0.6084, -0.7344],\n",
      "       [-0.6255,  0.464 , -0.3835],\n",
      "       [-0.8096,  1.04  , -0.783 ],\n",
      "       [-0.2532,  0.3618, -0.5977],\n",
      "       [-0.927 ,  1.434 , -0.835 ],\n",
      "       [-0.7505,  0.828 , -0.71  ],\n",
      "       [-0.79  ,  0.9688, -0.6846],\n",
      "       [-0.5947,  0.7295, -0.601 ],\n",
      "       [-0.54  ,  0.6855, -0.7065],\n",
      "       [-0.7485,  1.066 , -0.7227],\n",
      "       [-0.808 ,  1.458 , -1.137 ],\n",
      "       [-0.4355,  0.698 , -0.764 ],\n",
      "       [-0.6436,  0.3984, -0.2495],\n",
      "       [-0.4883,  0.706 , -0.7417],\n",
      "       [-0.5166,  0.596 , -0.667 ],\n",
      "       [-0.6167,  0.9272, -0.8423],\n",
      "       [-0.4473,  0.8022, -0.895 ],\n",
      "       [-0.4714,  0.5566, -0.687 ],\n",
      "       [-0.2205,  0.4834, -0.7993],\n",
      "       [-0.5664,  0.7793, -0.8267],\n",
      "       [-0.593 ,  0.9434, -0.8853],\n",
      "       [-0.5933,  0.635 , -0.63  ],\n",
      "       [-0.589 ,  0.664 , -0.6465],\n",
      "       [-0.5166,  0.9795, -0.9717],\n",
      "       [-0.4556,  0.5957, -0.663 ],\n",
      "       [-0.4912,  1.023 , -1.021 ],\n",
      "       [-0.45  ,  0.763 , -0.775 ],\n",
      "       [-0.7793,  1.377 , -1.09  ],\n",
      "       [-0.6426,  0.943 , -0.773 ],\n",
      "       [-0.4602,  0.634 , -0.668 ],\n",
      "       [-0.698 ,  0.9917, -0.888 ],\n",
      "       [-0.3145,  0.374 , -0.565 ],\n",
      "       [-0.516 ,  0.6367, -0.6206],\n",
      "       [-0.4507,  0.5903, -0.624 ],\n",
      "       [-0.4255,  0.595 , -0.709 ],\n",
      "       [-0.4465,  0.265 , -0.354 ],\n",
      "       [-0.657 ,  0.7207, -0.537 ],\n",
      "       [-0.698 ,  1.027 , -0.827 ],\n",
      "       [-0.7593,  0.9634, -0.6675],\n",
      "       [-0.6997,  1.216 , -0.932 ],\n",
      "       [-0.7603,  0.8335, -0.659 ],\n",
      "       [-0.72  ,  1.173 , -0.8833],\n",
      "       [-0.55  ,  0.718 , -0.7964],\n",
      "       [-0.5854,  0.81  , -0.7188],\n",
      "       [-0.748 ,  1.133 , -0.798 ],\n",
      "       [-0.738 ,  1.003 , -0.862 ],\n",
      "       [-0.4922,  0.9165, -0.904 ],\n",
      "       [-0.5864,  0.711 , -0.593 ],\n",
      "       [-0.54  ,  0.88  , -0.841 ],\n",
      "       [-0.522 ,  0.8574, -0.868 ],\n",
      "       [-0.743 ,  0.967 , -0.734 ],\n",
      "       [-0.699 ,  1.177 , -1.019 ],\n",
      "       [-1.049 ,  1.347 , -0.705 ],\n",
      "       [-0.872 ,  1.005 , -0.4607],\n",
      "       [-0.723 ,  1.307 , -1.016 ],\n",
      "       [-0.7944,  1.045 , -0.7065],\n",
      "       [-0.7334,  0.6714, -0.4421],\n",
      "       [-0.871 ,  1.246 , -0.7485],\n",
      "       [-0.738 ,  1.064 , -0.755 ],\n",
      "       [-0.54  ,  0.799 , -0.8013],\n",
      "       [-0.4941,  0.8247, -0.929 ],\n",
      "       [-0.5415,  0.6763, -0.6055],\n",
      "       [-0.7974,  1.33  , -0.9917],\n",
      "       [-0.329 ,  0.5796, -0.859 ],\n",
      "       [-0.8213,  1.207 , -0.839 ],\n",
      "       [-1.126 ,  1.427 , -0.6245],\n",
      "       [-0.6626,  0.9097, -0.763 ],\n",
      "       [-0.5825,  1.066 , -1.02  ],\n",
      "       [-0.503 ,  0.939 , -1.084 ],\n",
      "       [-0.711 ,  0.8867, -0.7236],\n",
      "       [-0.6606,  1.045 , -0.8813],\n",
      "       [-0.6094,  0.766 , -0.7056],\n",
      "       [-0.6016,  1.082 , -0.935 ],\n",
      "       [-0.362 ,  0.6226, -0.752 ],\n",
      "       [-0.8125,  1.099 , -0.8477],\n",
      "       [-0.618 ,  0.8877, -0.7153],\n",
      "       [-0.5923,  0.9556, -0.805 ],\n",
      "       [-1.037 ,  1.756 , -1.04  ],\n",
      "       [-0.6895,  0.9453, -0.808 ],\n",
      "       [-0.5703,  0.7197, -0.737 ],\n",
      "       [-0.495 ,  0.677 , -0.7183],\n",
      "       [-0.55  ,  0.908 , -0.91  ],\n",
      "       [-0.5435,  0.663 , -0.6675],\n",
      "       [-0.647 ,  0.691 , -0.5737],\n",
      "       [-0.839 ,  1.008 , -0.7334],\n",
      "       [-0.3738,  0.4688, -0.6577],\n",
      "       [-0.5967,  0.7495, -0.682 ],\n",
      "       [-0.4182,  0.683 , -0.8145]], dtype=float16), label_ids=array([1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 2, 2, 1, 2, 1, 1, 2, 2,\n",
      "       1, 2, 0, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 0, 2, 1, 1,\n",
      "       1, 2, 1, 1, 1, 0, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 0, 2, 1, 2, 0,\n",
      "       1, 1, 0, 0, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       0, 2, 1, 2, 0, 1, 1, 1, 1, 1, 1, 2, 0, 2, 1, 2, 1, 1, 1, 2, 1, 1,\n",
      "       2, 1, 2, 1, 2, 1, 1, 1, 0, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 2, 1, 2, 1, 1, 1, 2, 0, 2, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2,\n",
      "       1, 1, 1, 2, 1, 0, 0, 0, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1,\n",
      "       1, 0, 1, 1, 1, 1, 0, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 0, 2, 1, 1, 1,\n",
      "       1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 0, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 0]), metrics={'test_loss': 0.9064732789993286, 'test_accuracy': 0.6452991452991453, 'test_balanced_accuracy': 0.3333333333333333, 'test_precision': 0.41641098692380746, 'test_recall': 0.6452991452991453, 'test_f1': 0.5061827061827062, 'test_runtime': 0.6339, 'test_samples_per_second': 369.15, 'test_steps_per_second': 12.621})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1cd75bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "probabilities = torch.softmax(torch.tensor(test_results.predictions).to(torch.float32), dim=-1)\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)\n",
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "766c4460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_save = []\n",
    "for idx in range(len(test_data)):\n",
    "    item = dataset['test'][idx]\n",
    "    actual_label = item['label']\n",
    "    predicted_label = predictions[idx]\n",
    "    claim = item['claim'] \n",
    "    premise = item['premise'] \n",
    "    category = item['category']\n",
    "    \n",
    "    # Append the information as a dictionary to the list\n",
    "    data_to_save.append({\n",
    "        'Claim': claim,\n",
    "        'Premise': premise,\n",
    "        'Actual Label': actual_label,\n",
    "        'Predicted Label': predicted_label,\n",
    "        'Category' : category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_to_save)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/home/elson/results/11.2.1_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3e1cc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correctly classified instances\n",
    "correctly_classified = df[df['Actual Label'] == df['Predicted Label']]\n",
    "\n",
    "# Calculate misclassified instances\n",
    "misclassified = df[df['Actual Label'] != df['Predicted Label']]\n",
    "\n",
    "# Count the number of correctly classified and misclassified by category\n",
    "correct_classification_counts = correctly_classified['Category'].value_counts()\n",
    "misclassification_counts = misclassified['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "afd884e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           35\n",
       "Fitness                  13\n",
       "Cancer                   12\n",
       "Bone health              11\n",
       "Skin                     10\n",
       "Diabetes                  9\n",
       "Throat                    9\n",
       "Hair                      9\n",
       "Neurological health       9\n",
       "Cardiovascular Health     6\n",
       "Ear                       6\n",
       "COVID                     6\n",
       "Eye                       5\n",
       "Blood                     4\n",
       "Women' s Health           2\n",
       "Mental Health             2\n",
       "Muscles                   2\n",
       "Vascular                  1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6477f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           16\n",
       "Skin                     14\n",
       "Bone health              10\n",
       "Men's health              6\n",
       "Cardiovascular Health     6\n",
       "Blood                     5\n",
       "Eye                       4\n",
       "Women' s Health           4\n",
       "Muscles                   4\n",
       "Dental Health             3\n",
       "Hair                      3\n",
       "Diabetes                  3\n",
       "Fitness                   2\n",
       "Vascular                  2\n",
       "Mental Health             1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
