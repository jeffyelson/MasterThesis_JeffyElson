{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-056e0caec74e8696\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-056e0caec74e8696/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 213.29it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('csv',data_files='dataset_semanticattribution_nerfeatures_split.csv',delimiter=',',column_names=[\"claim\",\"premise\",\"label\",\"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\",\"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\",\"url\", \"entities\",\"entity_map\",\"gold_exp\",\"gem_exp\",\"gem_label\",\"entity_map_ev\",\"entity_ev\",\"split\"],skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e2914c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'gold_exp', 'gem_exp', 'gem_label', 'entity_map_ev', 'entity_ev', 'split'],\n",
       "        num_rows: 2322\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57d56e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'test',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['split']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ce96b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-056e0caec74e8696/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-2a2c42dfce2e5962.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-056e0caec74e8696/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-30c3c2aed9ee6058.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-056e0caec74e8696/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-2aa654a7b533269e.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'gold_exp', 'gem_exp', 'gem_label', 'entity_map_ev', 'entity_ev', 'split'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'gold_exp', 'gem_exp', 'gem_label', 'entity_map_ev', 'entity_ev', 'split'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'gold_exp', 'gem_exp', 'gem_label', 'entity_map_ev', 'entity_ev', 'split'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41f1db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['claim', 'premise', 'label','category','count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat']\n",
    "all_columns = train_dataset.column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1623/1623 [00:00<00:00, 5815.54ex/s]\n",
      "100%|██████████| 465/465 [00:00<00:00, 5111.40ex/s]\n",
      "100%|██████████| 234/234 [00:00<00:00, 3965.36ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 1, 'entailment': 0, 'neutral': 1}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 1,\n",
    "    \"entailment\": 0,\n",
    "    \"neutral\": 1\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='MoritzLaurer/DeBERTa-v3-base-mnli-fever-docnli-ling-2c'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "\n",
    "        claim = item['claim']\n",
    "        premise = item['premise'].replace('\\n', '').replace('[','').replace(']','')\n",
    "        additional_features = [\n",
    "            \"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\"]\n",
    "    \n",
    "        for feature in additional_features:\n",
    "            if feature in item:\n",
    "                claim += \"[SEP]\" + str(item[feature])\n",
    "        item['claim']=claim\n",
    "        item['premise']=premise        \n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "             premise, claim,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "        item['input_ids'] = inputs['input_ids'].squeeze()  # Remove batch dimension\n",
    "        item['attention_mask']= inputs['attention_mask'].squeeze() # Remove batch dimension\n",
    "        \n",
    "        output_item = {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),  # Remove batch dimension\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),  # Remove batch dimension\n",
    "            'claim': claim,  # Include augmented claim text\n",
    "            'evidences': premise  # Include original evidence text\n",
    "        }\n",
    "        \n",
    "        if 'label' in item:\n",
    "            output_item['label'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return output_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62421eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DebertaV2ForSequenceClassification(\n",
       "  (deberta): DebertaV2Model(\n",
       "    (embeddings): DebertaV2Embeddings(\n",
       "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaV2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (1): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (2): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (3): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (4): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (5): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (6): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (7): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (8): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (9): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (10): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (11): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (pooler): ContextPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): StableDropout()\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): StableDropout()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"MoritzLaurer/DeBERTa-v3-base-mnli-fever-docnli-ling-2c\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=2, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    bal_accuracy = balanced_accuracy_score(labels,preds)\n",
    "\n",
    "    return {\"accuracy\": acc, \"balanced_accuracy\":bal_accuracy, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17c5e0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([     1,   2600,   3405,  16876,    667,  37198,  61593,    261,   1149,\n",
       "            260,    346,  29597,   6848,  37198,  61593,    261,    273,    260,\n",
       "            346,  37741,  37198,  61593,  16876,    667,  37198,  61593,    261,\n",
       "            916,    260,    346, 117259,  34984,  37198,  61593,    261,    749,\n",
       "            260,    346,  10490,  73907,   8007,  37198,  61593,    261,   1130,\n",
       "            260,    346,   1407,   3359,  73907,   8007,  37198,  61593,    261,\n",
       "            851,    260, 100066,    263,  98237,   1830,   6725,    263,   5134,\n",
       "          30055,  77487,    532,   4014,    271,    547,  52263,  16224,    265,\n",
       "          86207,  14178,    268,    260,  97818,   4379,    261,    273,    260,\n",
       "          43923,  23399,    429,   8068,   1068,    268,    265,  88327,   1917,\n",
       "         110269,    287,    260,  57909,   4765,  12100,   2148,    263,  25348,\n",
       "          20413,   1563,    265,    917,    263,    308,    266,  84530,  62542,\n",
       "            275,  98237,    287,  41462,    667,  65073,  44845,  22317,    285,\n",
       "          36774,    260,  70298,  40149,    294,  32799,  22280,    270,   9560,\n",
       "           2926,    260,  29466,  32531,  11238,   5750,    261,   1149,    260,\n",
       "            346,  35339,    261,    716,    260,    346,  29700,    261,    851,\n",
       "            260,    346,  43713,  15150,    261,   1130,    260,    346,   5794,\n",
       "            261,    749,    260,   9048,   5341,    293,   4613,   4950,    294,\n",
       "            716,    260,  98237,    452,   4366,  52114,  72408,    260,  44233,\n",
       "           4765,  39151,    261,    909,    260,    346,  42595,  39151,    261,\n",
       "            662,    260,    346,  42595,  39151,    261,    749,    260,    346,\n",
       "          11209,  60641,    261,    749,    260, 100066,    287,  15726,   2209,\n",
       "           5858,  25499,   3004,    909,  74742,    318,  13238,  37198,    198,\n",
       "            133,   5900,    346,    260,  43427,    285,    294,   1007,    262,\n",
       "           1857,    265,   1471,   1567,    264,    262,   2626,  41529,  28479,\n",
       "            270,    262,   5937,    263,   1035,    265,   1721,   4253,    260,\n",
       "          95126,    263, 121470,   1506,    265,  88609,   1080,    260,  12768,\n",
       "          19573,    268,   4086,  60761,   2767,  15808,    260,    346,   7413,\n",
       "            261,    829,    260, 100066,    263,  98237,    283,  11882,    267,\n",
       "            572,    260,      2,    573,  52341,   1830,   1080,    269,   1359,\n",
       "            427,    267,  17847,    633,    264,    408,   1300,    262,   2658,\n",
       "            265,    262,   1158,    260,      2,    767,      2,    767,      2,\n",
       "            767,      2,    767,      2,    767,      2,    767,      2,    767,\n",
       "              2,    767,      2,    767,      2,    767,      2,    767,      2,\n",
       "            767,      2,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'claim': 'Myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0',\n",
       " 'evidences': '; UnkoviÄ‡, N.; DimkiÄ‡, I.; JanaÄ‡koviÄ‡, P.; GavriloviÄ‡, M.; StanojeviÄ‡, O.; VukojeviÄ‡, J. Frankincense and myrrh essential oils and burn incense fume against micro-inhabitants of sacral ambients.Shameem, I. Phytochemical & therapeutic potentials of Murr makki (.Oxidative stress and immunotoxic effects of lead and their amelioration with myrrh (Commiphora molmol) emulsion.Essential Oils: Magical Ingredients for Skin Care.Chakravarty, N.; Kellogg, C.; Alvarez, J.; Equils, O.; Morgan, M. UV Protection by Natural Products: C. myrrha Oil Versus Sunscreen.Hamidpour, R.; Hamidpour, S.; Hamidpour, M.; Shahlari, M. Frankincense (ä¹³é¦™ RÇ” XiÄ\\x81ng;.species): From the selection of traditional applications to the novel phytotherapy for the prevention and treatment of serious diseases.Chemistry and immunomodulatory activity of frankincense oil.Compositions containing Boswellia extracts.; Cooper, E. Frankincense and myrrh as remedies in children.',\n",
       " 'label': tensor(0)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1530\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1530' max='1530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1530/1530 12:38, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.469400</td>\n",
       "      <td>0.699027</td>\n",
       "      <td>0.696774</td>\n",
       "      <td>0.725742</td>\n",
       "      <td>0.758879</td>\n",
       "      <td>0.696774</td>\n",
       "      <td>0.705863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.325800</td>\n",
       "      <td>0.628254</td>\n",
       "      <td>0.729032</td>\n",
       "      <td>0.739788</td>\n",
       "      <td>0.765003</td>\n",
       "      <td>0.729032</td>\n",
       "      <td>0.736634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.314500</td>\n",
       "      <td>0.690958</td>\n",
       "      <td>0.744086</td>\n",
       "      <td>0.749340</td>\n",
       "      <td>0.772301</td>\n",
       "      <td>0.744086</td>\n",
       "      <td>0.750700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.092500</td>\n",
       "      <td>1.223565</td>\n",
       "      <td>0.763441</td>\n",
       "      <td>0.747109</td>\n",
       "      <td>0.771872</td>\n",
       "      <td>0.763441</td>\n",
       "      <td>0.766499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.086600</td>\n",
       "      <td>1.239632</td>\n",
       "      <td>0.759140</td>\n",
       "      <td>0.745569</td>\n",
       "      <td>0.769912</td>\n",
       "      <td>0.759140</td>\n",
       "      <td>0.762816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.091900</td>\n",
       "      <td>1.107828</td>\n",
       "      <td>0.759140</td>\n",
       "      <td>0.750566</td>\n",
       "      <td>0.773522</td>\n",
       "      <td>0.759140</td>\n",
       "      <td>0.763578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.763710</td>\n",
       "      <td>0.737634</td>\n",
       "      <td>0.734540</td>\n",
       "      <td>0.759336</td>\n",
       "      <td>0.737634</td>\n",
       "      <td>0.743619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.811361</td>\n",
       "      <td>0.767742</td>\n",
       "      <td>0.765303</td>\n",
       "      <td>0.785772</td>\n",
       "      <td>0.767742</td>\n",
       "      <td>0.772663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.888788</td>\n",
       "      <td>0.767742</td>\n",
       "      <td>0.761972</td>\n",
       "      <td>0.783145</td>\n",
       "      <td>0.767742</td>\n",
       "      <td>0.772245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.888015</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.765114</td>\n",
       "      <td>0.786333</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.778009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.972135</td>\n",
       "      <td>0.769892</td>\n",
       "      <td>0.760244</td>\n",
       "      <td>0.782147</td>\n",
       "      <td>0.769892</td>\n",
       "      <td>0.773780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.021427</td>\n",
       "      <td>0.767742</td>\n",
       "      <td>0.756976</td>\n",
       "      <td>0.779461</td>\n",
       "      <td>0.767742</td>\n",
       "      <td>0.771543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.067059</td>\n",
       "      <td>0.767742</td>\n",
       "      <td>0.756976</td>\n",
       "      <td>0.779461</td>\n",
       "      <td>0.767742</td>\n",
       "      <td>0.771543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.082721</td>\n",
       "      <td>0.767742</td>\n",
       "      <td>0.756976</td>\n",
       "      <td>0.779461</td>\n",
       "      <td>0.767742</td>\n",
       "      <td>0.771543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.089456</td>\n",
       "      <td>0.767742</td>\n",
       "      <td>0.756976</td>\n",
       "      <td>0.779461</td>\n",
       "      <td>0.767742</td>\n",
       "      <td>0.771543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.3_deberta_docnli/checkpoint-102\n",
      "Configuration saved in /home/elson/5.2.3_deberta_docnli/checkpoint-102/config.json\n",
      "Model weights saved in /home/elson/5.2.3_deberta_docnli/checkpoint-102/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.3_deberta_docnli/checkpoint-204\n",
      "Configuration saved in /home/elson/5.2.3_deberta_docnli/checkpoint-204/config.json\n",
      "Model weights saved in /home/elson/5.2.3_deberta_docnli/checkpoint-204/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.2.3_deberta_docnli/checkpoint-102] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.3_deberta_docnli/checkpoint-306\n",
      "Configuration saved in /home/elson/5.2.3_deberta_docnli/checkpoint-306/config.json\n",
      "Model weights saved in /home/elson/5.2.3_deberta_docnli/checkpoint-306/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.2.3_deberta_docnli/checkpoint-204] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.3_deberta_docnli/checkpoint-408\n",
      "Configuration saved in /home/elson/5.2.3_deberta_docnli/checkpoint-408/config.json\n",
      "Model weights saved in /home/elson/5.2.3_deberta_docnli/checkpoint-408/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.2.3_deberta_docnli/checkpoint-306] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.3_deberta_docnli/checkpoint-510\n",
      "Configuration saved in /home/elson/5.2.3_deberta_docnli/checkpoint-510/config.json\n",
      "Model weights saved in /home/elson/5.2.3_deberta_docnli/checkpoint-510/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.3_deberta_docnli/checkpoint-612\n",
      "Configuration saved in /home/elson/5.2.3_deberta_docnli/checkpoint-612/config.json\n",
      "Model weights saved in /home/elson/5.2.3_deberta_docnli/checkpoint-612/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.2.3_deberta_docnli/checkpoint-510] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.3_deberta_docnli/checkpoint-714\n",
      "Configuration saved in /home/elson/5.2.3_deberta_docnli/checkpoint-714/config.json\n",
      "Model weights saved in /home/elson/5.2.3_deberta_docnli/checkpoint-714/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.2.3_deberta_docnli/checkpoint-612] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.3_deberta_docnli/checkpoint-816\n",
      "Configuration saved in /home/elson/5.2.3_deberta_docnli/checkpoint-816/config.json\n",
      "Model weights saved in /home/elson/5.2.3_deberta_docnli/checkpoint-816/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.2.3_deberta_docnli/checkpoint-408] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/5.2.3_deberta_docnli/checkpoint-714] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.3_deberta_docnli/checkpoint-918\n",
      "Configuration saved in /home/elson/5.2.3_deberta_docnli/checkpoint-918/config.json\n",
      "Model weights saved in /home/elson/5.2.3_deberta_docnli/checkpoint-918/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.3_deberta_docnli/checkpoint-1020\n",
      "Configuration saved in /home/elson/5.2.3_deberta_docnli/checkpoint-1020/config.json\n",
      "Model weights saved in /home/elson/5.2.3_deberta_docnli/checkpoint-1020/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.2.3_deberta_docnli/checkpoint-816] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/5.2.3_deberta_docnli/checkpoint-918] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.3_deberta_docnli/checkpoint-1122\n",
      "Configuration saved in /home/elson/5.2.3_deberta_docnli/checkpoint-1122/config.json\n",
      "Model weights saved in /home/elson/5.2.3_deberta_docnli/checkpoint-1122/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.3_deberta_docnli/checkpoint-1224\n",
      "Configuration saved in /home/elson/5.2.3_deberta_docnli/checkpoint-1224/config.json\n",
      "Model weights saved in /home/elson/5.2.3_deberta_docnli/checkpoint-1224/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.2.3_deberta_docnli/checkpoint-1122] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.3_deberta_docnli/checkpoint-1326\n",
      "Configuration saved in /home/elson/5.2.3_deberta_docnli/checkpoint-1326/config.json\n",
      "Model weights saved in /home/elson/5.2.3_deberta_docnli/checkpoint-1326/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.2.3_deberta_docnli/checkpoint-1224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.3_deberta_docnli/checkpoint-1428\n",
      "Configuration saved in /home/elson/5.2.3_deberta_docnli/checkpoint-1428/config.json\n",
      "Model weights saved in /home/elson/5.2.3_deberta_docnli/checkpoint-1428/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.2.3_deberta_docnli/checkpoint-1326] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.3_deberta_docnli/checkpoint-1530\n",
      "Configuration saved in /home/elson/5.2.3_deberta_docnli/checkpoint-1530/config.json\n",
      "Model weights saved in /home/elson/5.2.3_deberta_docnli/checkpoint-1530/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.2.3_deberta_docnli/checkpoint-1428] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/elson/5.2.3_deberta_docnli/checkpoint-1020 (score: 0.7741935483870968).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /home/elson/5.2.3_deberta_docnli/best_model/config.json\n",
      "Model weights saved in /home/elson/5.2.3_deberta_docnli/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/5.2.3_deberta_docnli/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/5.2.3_deberta_docnli/best_model/special_tokens_map.json\n",
      "added tokens file saved in /home/elson/5.2.3_deberta_docnli/best_model/added_tokens.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/5.2.3_deberta_docnli/best_model/tokenizer_config.json',\n",
       " '/home/elson/5.2.3_deberta_docnli/best_model/special_tokens_map.json',\n",
       " '/home/elson/5.2.3_deberta_docnli/best_model/spm.model',\n",
       " '/home/elson/5.2.3_deberta_docnli/best_model/added_tokens.json')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/5.2.3_deberta_docnli/',\n",
    "    num_train_epochs=15,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.06,\n",
    "    weight_decay=0.1,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/5.2.3_deberta_docnli/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/5.2.3_deberta_docnli/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63deaea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/5.2.3_deberta_docnli/best_model/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"/home/elson/5.2.3_deberta_docnli/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"entailment\",\n",
      "    \"1\": \"not_entailment\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"entailment\": 0,\n",
      "    \"not_entailment\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file /home/elson/5.2.3_deberta_docnli/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at /home/elson/5.2.3_deberta_docnli/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 16\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/5.2.3_deberta_docnli/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[ 2.178e+00, -2.068e+00],\n",
      "       [ 1.878e+00, -1.773e+00],\n",
      "       [ 4.137e+00, -3.918e+00],\n",
      "       [-4.887e+00,  5.230e+00],\n",
      "       [-1.883e+00,  1.997e+00],\n",
      "       [ 4.703e+00, -4.445e+00],\n",
      "       [ 5.086e+00, -4.789e+00],\n",
      "       [ 5.152e+00, -4.840e+00],\n",
      "       [ 4.086e+00, -3.877e+00],\n",
      "       [ 4.582e+00, -4.340e+00],\n",
      "       [ 5.484e+00, -5.137e+00],\n",
      "       [ 5.605e+00, -5.246e+00],\n",
      "       [-5.879e+00,  6.145e+00],\n",
      "       [ 5.359e+00, -5.020e+00],\n",
      "       [ 1.952e-01, -1.093e-01],\n",
      "       [-5.582e+00,  5.891e+00],\n",
      "       [ 2.301e+00, -2.227e+00],\n",
      "       [ 3.551e+00, -3.355e+00],\n",
      "       [ 5.668e+00, -5.305e+00],\n",
      "       [ 5.211e+00, -4.902e+00],\n",
      "       [-4.977e+00,  5.328e+00],\n",
      "       [-3.209e+00,  3.480e+00],\n",
      "       [ 5.527e+00, -5.180e+00],\n",
      "       [-5.629e+00,  5.945e+00],\n",
      "       [ 3.102e+00, -2.961e+00],\n",
      "       [-5.699e+00,  5.992e+00],\n",
      "       [ 5.043e+00, -4.734e+00],\n",
      "       [ 3.111e+00, -2.949e+00],\n",
      "       [ 5.180e+00, -4.859e+00],\n",
      "       [ 5.738e+00, -5.359e+00],\n",
      "       [-4.031e+00,  4.355e+00],\n",
      "       [ 1.692e+00, -1.647e+00],\n",
      "       [ 5.449e+00, -5.109e+00],\n",
      "       [ 4.051e+00, -3.850e+00],\n",
      "       [-3.887e+00,  4.176e+00],\n",
      "       [ 4.695e+00, -4.441e+00],\n",
      "       [ 2.758e+00, -2.639e+00],\n",
      "       [ 3.893e+00, -3.709e+00],\n",
      "       [-4.746e+00,  5.070e+00],\n",
      "       [ 3.275e+00, -3.135e+00],\n",
      "       [-5.488e+00,  5.809e+00],\n",
      "       [ 5.594e+00, -5.230e+00],\n",
      "       [-3.475e+00,  3.791e+00],\n",
      "       [-5.410e+00,  5.758e+00],\n",
      "       [-2.207e+00,  2.391e+00],\n",
      "       [ 5.340e+00, -5.012e+00],\n",
      "       [ 4.926e+00, -4.656e+00],\n",
      "       [ 4.629e+00, -4.340e+00],\n",
      "       [ 5.500e+00, -5.156e+00],\n",
      "       [-5.160e+00,  5.500e+00],\n",
      "       [-3.516e+00,  3.828e+00],\n",
      "       [ 3.508e+00, -3.352e+00],\n",
      "       [-4.879e+00,  5.234e+00],\n",
      "       [ 4.379e+00, -4.152e+00],\n",
      "       [ 3.561e+00, -3.400e+00],\n",
      "       [ 5.578e+00, -5.227e+00],\n",
      "       [-5.645e+00,  5.961e+00],\n",
      "       [ 5.238e+00, -4.922e+00],\n",
      "       [ 3.582e+00, -3.426e+00],\n",
      "       [ 5.477e+00, -5.129e+00],\n",
      "       [ 5.109e+00, -4.816e+00],\n",
      "       [-4.547e+00,  4.879e+00],\n",
      "       [ 4.816e+00, -4.559e+00],\n",
      "       [-3.713e+00,  3.975e+00],\n",
      "       [-3.979e+00,  4.320e+00],\n",
      "       [ 5.113e+00, -4.809e+00],\n",
      "       [ 3.529e+00, -3.383e+00],\n",
      "       [ 2.773e-01, -2.286e-01],\n",
      "       [ 5.242e+00, -4.926e+00],\n",
      "       [ 4.207e+00, -3.988e+00],\n",
      "       [ 4.457e+00, -4.223e+00],\n",
      "       [ 1.910e+00, -1.843e+00],\n",
      "       [ 2.541e+00, -2.445e+00],\n",
      "       [-2.178e+00,  2.346e+00],\n",
      "       [ 1.036e+00, -9.756e-01],\n",
      "       [ 3.053e+00, -2.898e+00],\n",
      "       [ 4.797e+00, -4.527e+00],\n",
      "       [ 4.941e+00, -4.668e+00],\n",
      "       [ 5.633e+00, -5.266e+00],\n",
      "       [ 3.281e+00, -3.135e+00],\n",
      "       [ 4.602e+00, -4.352e+00],\n",
      "       [ 5.617e+00, -5.258e+00],\n",
      "       [ 3.490e+00, -3.318e+00],\n",
      "       [ 4.930e+00, -4.645e+00],\n",
      "       [-2.908e+00,  3.182e+00],\n",
      "       [ 4.254e+00, -4.023e+00],\n",
      "       [ 5.090e+00, -4.793e+00],\n",
      "       [ 5.078e+00, -4.789e+00],\n",
      "       [ 2.900e+00, -2.777e+00],\n",
      "       [ 5.117e+00, -4.812e+00],\n",
      "       [ 3.426e+00, -3.268e+00],\n",
      "       [ 5.344e+00, -5.020e+00],\n",
      "       [-2.158e+00,  2.436e+00],\n",
      "       [ 3.105e+00, -2.945e+00],\n",
      "       [ 3.072e+00, -2.938e+00],\n",
      "       [ 1.235e+00, -1.167e+00],\n",
      "       [ 4.809e+00, -4.539e+00],\n",
      "       [ 3.525e+00, -3.359e+00],\n",
      "       [ 5.508e+00, -5.164e+00],\n",
      "       [ 5.734e+00, -5.352e+00],\n",
      "       [-5.305e+00,  5.629e+00],\n",
      "       [ 5.066e+00, -4.770e+00],\n",
      "       [ 3.588e+00, -3.422e+00],\n",
      "       [ 2.707e+00, -2.594e+00],\n",
      "       [ 4.352e+00, -4.117e+00],\n",
      "       [ 5.082e+00, -4.785e+00],\n",
      "       [ 4.809e+00, -4.539e+00],\n",
      "       [-5.934e+00,  6.203e+00],\n",
      "       [ 5.418e+00, -5.082e+00],\n",
      "       [ 5.129e+00, -4.824e+00],\n",
      "       [-4.430e+00,  4.750e+00],\n",
      "       [ 5.652e+00, -5.285e+00],\n",
      "       [ 5.320e+00, -4.996e+00],\n",
      "       [ 4.555e+00, -4.309e+00],\n",
      "       [ 4.016e+00, -3.816e+00],\n",
      "       [ 3.736e+00, -3.572e+00],\n",
      "       [ 5.883e+00, -5.496e+00],\n",
      "       [ 4.430e+00, -4.199e+00],\n",
      "       [ 5.680e+00, -5.309e+00],\n",
      "       [ 5.109e+00, -4.812e+00],\n",
      "       [ 5.613e+00, -5.254e+00],\n",
      "       [ 4.211e+00, -3.996e+00],\n",
      "       [ 4.691e+00, -4.441e+00],\n",
      "       [-3.391e+00,  3.723e+00],\n",
      "       [ 5.703e+00, -5.328e+00],\n",
      "       [ 5.328e+00, -5.012e+00],\n",
      "       [ 4.797e+00, -4.527e+00],\n",
      "       [ 5.281e+00, -4.957e+00],\n",
      "       [ 5.004e+00, -4.719e+00],\n",
      "       [ 2.951e+00, -2.840e+00],\n",
      "       [ 4.008e+00, -3.814e+00],\n",
      "       [ 1.110e+00, -1.045e+00],\n",
      "       [ 3.311e+00, -3.172e+00],\n",
      "       [-5.195e+00,  5.543e+00],\n",
      "       [ 3.580e+00, -3.418e+00],\n",
      "       [-3.703e+00,  4.016e+00],\n",
      "       [ 3.016e+00, -2.895e+00],\n",
      "       [-5.918e+00,  6.176e+00],\n",
      "       [-9.863e-01,  1.108e+00],\n",
      "       [-5.504e+00,  5.836e+00],\n",
      "       [ 5.133e+00, -4.828e+00],\n",
      "       [ 4.121e+00, -3.916e+00],\n",
      "       [ 3.586e+00, -3.422e+00],\n",
      "       [ 5.488e+00, -5.152e+00],\n",
      "       [ 4.496e+00, -4.250e+00],\n",
      "       [-5.594e+00,  5.934e+00],\n",
      "       [-5.746e+00,  6.043e+00],\n",
      "       [ 7.916e-02, -2.461e-02],\n",
      "       [ 5.852e+00, -5.465e+00],\n",
      "       [-5.027e+00,  5.379e+00],\n",
      "       [ 5.004e+00, -4.719e+00],\n",
      "       [ 4.301e+00, -4.051e+00],\n",
      "       [ 5.590e+00, -5.230e+00],\n",
      "       [ 4.773e+00, -4.496e+00],\n",
      "       [ 4.254e+00, -4.035e+00],\n",
      "       [ 5.930e+00, -5.527e+00],\n",
      "       [ 4.254e+00, -4.039e+00],\n",
      "       [-5.531e+00,  5.859e+00],\n",
      "       [ 4.914e+00, -4.641e+00],\n",
      "       [-5.656e+00,  5.969e+00],\n",
      "       [-5.840e+00,  6.109e+00],\n",
      "       [-5.543e+00,  5.848e+00],\n",
      "       [ 5.199e+00, -4.891e+00],\n",
      "       [-5.117e+00,  5.461e+00],\n",
      "       [-3.775e+00,  4.098e+00],\n",
      "       [-3.096e+00,  3.377e+00],\n",
      "       [ 4.773e+00, -4.512e+00],\n",
      "       [-2.480e+00,  2.713e+00],\n",
      "       [-6.445e-01,  7.480e-01],\n",
      "       [ 4.758e+00, -4.496e+00],\n",
      "       [-5.664e+00,  5.961e+00],\n",
      "       [ 3.771e+00, -3.604e+00],\n",
      "       [-5.844e+00,  6.129e+00],\n",
      "       [ 5.234e+00, -4.926e+00],\n",
      "       [ 4.910e+00, -4.609e+00],\n",
      "       [-4.559e+00,  4.875e+00],\n",
      "       [ 4.473e+00, -4.234e+00],\n",
      "       [ 3.900e+00, -3.691e+00],\n",
      "       [ 4.207e+00, -4.000e+00],\n",
      "       [ 3.363e+00, -3.209e+00],\n",
      "       [-5.125e+00,  5.469e+00],\n",
      "       [-3.781e+00,  4.098e+00],\n",
      "       [-5.141e+00,  5.469e+00],\n",
      "       [ 2.945e+00, -2.801e+00],\n",
      "       [-4.508e+00,  4.852e+00],\n",
      "       [ 6.035e+00, -5.621e+00],\n",
      "       [ 4.277e+00, -4.055e+00],\n",
      "       [ 1.738e+00, -1.676e+00],\n",
      "       [-5.277e+00,  5.582e+00],\n",
      "       [ 5.664e+00, -5.297e+00],\n",
      "       [-5.122e-01,  6.040e-01],\n",
      "       [ 5.078e+00, -4.781e+00],\n",
      "       [ 5.699e+00, -5.316e+00],\n",
      "       [-4.305e+00,  4.641e+00],\n",
      "       [-5.156e+00,  5.480e+00],\n",
      "       [ 5.359e+00, -5.031e+00],\n",
      "       [ 3.410e+00, -3.262e+00],\n",
      "       [ 4.152e+00, -3.945e+00],\n",
      "       [ 3.752e+00, -3.582e+00],\n",
      "       [ 3.697e+00, -3.537e+00],\n",
      "       [ 4.809e+00, -4.543e+00],\n",
      "       [ 4.996e+00, -4.711e+00],\n",
      "       [ 2.629e+00, -2.477e+00],\n",
      "       [ 4.469e+00, -4.242e+00],\n",
      "       [ 3.117e+00, -2.934e+00],\n",
      "       [-5.250e+00,  5.590e+00],\n",
      "       [ 5.070e+00, -4.770e+00],\n",
      "       [-4.957e+00,  5.297e+00],\n",
      "       [ 5.211e+00, -4.902e+00],\n",
      "       [ 4.418e+00, -4.184e+00],\n",
      "       [ 4.266e+00, -4.031e+00],\n",
      "       [-4.961e+00,  5.297e+00],\n",
      "       [ 5.648e+00, -5.289e+00],\n",
      "       [ 3.971e+00, -3.779e+00],\n",
      "       [-1.684e+00,  1.803e+00],\n",
      "       [ 8.667e-02,  4.555e-03],\n",
      "       [-3.609e+00,  3.930e+00],\n",
      "       [ 4.629e+00, -4.375e+00],\n",
      "       [ 5.105e+00, -4.805e+00],\n",
      "       [ 3.900e+00, -3.711e+00],\n",
      "       [ 5.531e+00, -5.191e+00],\n",
      "       [ 5.570e+00, -5.211e+00],\n",
      "       [ 3.166e+00, -3.014e+00],\n",
      "       [ 5.746e+00, -5.371e+00],\n",
      "       [ 2.992e+00, -2.850e+00],\n",
      "       [ 4.535e+00, -4.293e+00],\n",
      "       [ 2.188e+00, -2.115e+00],\n",
      "       [-5.789e+00,  6.078e+00],\n",
      "       [-4.438e+00,  4.781e+00],\n",
      "       [-2.109e+00,  2.320e+00],\n",
      "       [ 5.430e+00, -5.090e+00],\n",
      "       [ 4.625e+00, -4.375e+00],\n",
      "       [ 4.801e+00, -4.539e+00],\n",
      "       [ 4.156e+00, -3.941e+00]], dtype=float16), label_ids=array([0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
      "       0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
      "       0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1,\n",
      "       0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "       1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "       0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
      "       0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "       0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
      "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
      "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1]), metrics={'test_loss': 2.4169750213623047, 'test_accuracy': 0.6923076923076923, 'test_balanced_accuracy': 0.6395116891406686, 'test_precision': 0.6808375056895768, 'test_recall': 0.6923076923076923, 'test_f1': 0.6822505197505198, 'test_runtime': 2.3377, 'test_samples_per_second': 100.099, 'test_steps_per_second': 6.417})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73395d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "probabilities = torch.softmax(torch.tensor(test_results.predictions).to(torch.float32), dim=-1)\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)\n",
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb603377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_save = []\n",
    "for idx in range(len(test_data)):\n",
    "    item = dataset['test'][idx]\n",
    "    actual_label = item['label']\n",
    "    predicted_label = predictions[idx]\n",
    "    claim = item['claim'] \n",
    "    premise = item['premise'] \n",
    "    category = item['category']\n",
    "    \n",
    "    # Append the information as a dictionary to the list\n",
    "    data_to_save.append({\n",
    "        'Claim': claim,\n",
    "        'Premise': premise,\n",
    "        'Actual Label': actual_label,\n",
    "        'Predicted Label': predicted_label,\n",
    "        'Category' : category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_to_save)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/home/elson/results/5.2.3_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c23339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correctly classified instances\n",
    "correctly_classified = df[df['Actual Label'] == df['Predicted Label']]\n",
    "\n",
    "# Calculate misclassified instances\n",
    "misclassified = df[df['Actual Label'] != df['Predicted Label']]\n",
    "\n",
    "# Count the number of correctly classified and misclassified by category\n",
    "correct_classification_counts = correctly_classified['Category'].value_counts()\n",
    "misclassification_counts = misclassified['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca0def77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           41\n",
       "Bone health              15\n",
       "Cancer                   12\n",
       "Skin                     10\n",
       "Diabetes                 10\n",
       "Fitness                  10\n",
       "Throat                    9\n",
       "Cardiovascular Health     9\n",
       "Hair                      8\n",
       "Ear                       6\n",
       "Neurological health       5\n",
       "COVID                     5\n",
       "Women' s Health           5\n",
       "Blood                     4\n",
       "Muscles                   3\n",
       "Men's health              3\n",
       "Eye                       3\n",
       "Mental Health             2\n",
       "Vascular                  2\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0fddd944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Skin                     14\n",
       "General Health           10\n",
       "Bone health               6\n",
       "Eye                       6\n",
       "Blood                     5\n",
       "Fitness                   5\n",
       "Hair                      4\n",
       "Neurological health       4\n",
       "Men's health              3\n",
       "Cardiovascular Health     3\n",
       "Dental Health             3\n",
       "Muscles                   3\n",
       "Diabetes                  2\n",
       "COVID                     1\n",
       "Mental Health             1\n",
       "Vascular                  1\n",
       "Women' s Health           1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38b899b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_counts = df['Category'].value_counts()\n",
    "\n",
    "# Calculate ratios\n",
    "correct_classification_ratios = correct_classification_counts / total_counts\n",
    "misclassification_ratios = misclassification_counts / total_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c3598b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blood                    0.444444\n",
      "Bone health              0.714286\n",
      "COVID                    0.833333\n",
      "Cancer                   1.000000\n",
      "Cardiovascular Health    0.750000\n",
      "Dental Health                 NaN\n",
      "Diabetes                 0.833333\n",
      "Ear                      1.000000\n",
      "Eye                      0.333333\n",
      "Fitness                  0.666667\n",
      "General Health           0.803922\n",
      "Hair                     0.666667\n",
      "Men's health             0.500000\n",
      "Mental Health            0.666667\n",
      "Muscles                  0.500000\n",
      "Neurological health      0.555556\n",
      "Skin                     0.416667\n",
      "Throat                   1.000000\n",
      "Vascular                 0.666667\n",
      "Women' s Health          0.833333\n",
      "Name: Category, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(correct_classification_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27602a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blood                    0.555556\n",
      "Bone health              0.285714\n",
      "COVID                    0.166667\n",
      "Cancer                        NaN\n",
      "Cardiovascular Health    0.250000\n",
      "Dental Health            1.000000\n",
      "Diabetes                 0.166667\n",
      "Ear                           NaN\n",
      "Eye                      0.666667\n",
      "Fitness                  0.333333\n",
      "General Health           0.196078\n",
      "Hair                     0.333333\n",
      "Men's health             0.500000\n",
      "Mental Health            0.333333\n",
      "Muscles                  0.500000\n",
      "Neurological health      0.444444\n",
      "Skin                     0.583333\n",
      "Throat                        NaN\n",
      "Vascular                 0.333333\n",
      "Women' s Health          0.166667\n",
      "Name: Category, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(misclassification_ratios)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
