{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-022bc67e9c58e92d\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 374.56it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('csv',data_files='dataset_propositionattribution_nerfeatures.csv',delimiter=',',column_names=[\"claim\",\"premise\",\"label\",\"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\",\"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\",\"url\", \"entities\",\"entity_map\",\"entity_map_ev\",\"entities_ev\",\"gem_exp\",\"gem_label\",\"gpt_label\",\"gpt_exp\",\"gold_exp\",\"synonym\",\"voice\",\"split\"],skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "133f9357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-2b8e361375c0e153.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-0cc9bb699c2761fb.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-608a44ac65076739.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01252e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['claim', 'premise', 'label','category','counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat']\n",
    "all_columns = train_dataset.column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-79a498bd2ed80eb2.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-1d77a640a2b35599.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-a41ad8597b784971.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 0, 'entailment': 1, 'neutral': 2}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 0,\n",
    "    \"entailment\": 1,\n",
    "    \"neutral\": 2\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='pritamdeka/PubMedBERT-MNLI-MedNLI'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "        # Extracting claim and evidence texts\n",
    "        claim = item['claim'] \n",
    "        evidences = item['premise'].replace('\\n', '').replace('[','').replace(']','')\n",
    "        additional_features = [\n",
    "            'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat']\n",
    "    \n",
    "        for feature in additional_features:\n",
    "            if feature in item:\n",
    "                evidences += \"[SEP]\" + str(item[feature]) \n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "            evidences,claim,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "         # Construct the output item\n",
    "        output_item = {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),  # Remove batch dimension\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),  # Remove batch dimension\n",
    "            'claim': claim,  # Include augmented claim text\n",
    "            'evidences': evidences  # Include original evidence text\n",
    "        }\n",
    "        \n",
    "        if 'label' in item:\n",
    "            output_item['label'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return output_item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62421eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"pritamdeka/PubMedBERT-MNLI-MedNLI\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=512)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=3, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    return {\"accuracy\": acc, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f5cf584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([    2,  1920,  4415, 16984,  1927, 14542,  4006,  4480,  1930, 14227,\n",
       "          5004,  2760,  1920, 29555,  1927,  1920,  4486, 14269,  1922,  1920,\n",
       "         25420,  1930,  3185,  1920,  3238,  1954,  1930, 10472,  3170,  1942,\n",
       "          2760,  1920,  8828,  1927,  1920,  4407,  1930,  3714,  1920,  7104,\n",
       "          2495,    18,     3,    20,     3,    20,     3,    20,     3,    20,\n",
       "             3,    20,     3,    20,     3,    20,     3,    20,     3,    20,\n",
       "             3,    20,     3,    20,     3,    20,     3, 14227,  5004,  4415,\n",
       "          6691,  1977,  8929,  2251,  1922,  4407,  5715,  4461,  1942,  4087,\n",
       "          3326,  1920,  7818,  1927,  1920,  4407,    18,     3,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'claim': 'Myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.',\n",
       " 'evidences': 'The essential oils of frankincense and myrrh increase the fluidity of the lipid bilayer in the cuticle and change the orderly and dense structure to increase the permeability of the skin and decrease the barrier effect.[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0',\n",
       " 'label': tensor(1)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1020\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1020' max='1020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1020/1020 08:21, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.778900</td>\n",
       "      <td>0.832504</td>\n",
       "      <td>0.647312</td>\n",
       "      <td>0.560010</td>\n",
       "      <td>0.647312</td>\n",
       "      <td>0.585338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.693000</td>\n",
       "      <td>0.820781</td>\n",
       "      <td>0.632258</td>\n",
       "      <td>0.665594</td>\n",
       "      <td>0.632258</td>\n",
       "      <td>0.641984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.438000</td>\n",
       "      <td>1.120247</td>\n",
       "      <td>0.615054</td>\n",
       "      <td>0.627513</td>\n",
       "      <td>0.615054</td>\n",
       "      <td>0.615517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.251400</td>\n",
       "      <td>1.206538</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.688186</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.625971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>1.201577</td>\n",
       "      <td>0.630108</td>\n",
       "      <td>0.655859</td>\n",
       "      <td>0.630108</td>\n",
       "      <td>0.640652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>1.278016</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.629529</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.632384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.123000</td>\n",
       "      <td>1.947072</td>\n",
       "      <td>0.653763</td>\n",
       "      <td>0.641629</td>\n",
       "      <td>0.653763</td>\n",
       "      <td>0.646754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.141200</td>\n",
       "      <td>1.993280</td>\n",
       "      <td>0.615054</td>\n",
       "      <td>0.675445</td>\n",
       "      <td>0.615054</td>\n",
       "      <td>0.635900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.083500</td>\n",
       "      <td>1.985332</td>\n",
       "      <td>0.634409</td>\n",
       "      <td>0.640894</td>\n",
       "      <td>0.634409</td>\n",
       "      <td>0.625653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.067800</td>\n",
       "      <td>2.256844</td>\n",
       "      <td>0.627957</td>\n",
       "      <td>0.660138</td>\n",
       "      <td>0.627957</td>\n",
       "      <td>0.638618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.076900</td>\n",
       "      <td>2.035643</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.656928</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.648592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.050700</td>\n",
       "      <td>2.329192</td>\n",
       "      <td>0.653763</td>\n",
       "      <td>0.673861</td>\n",
       "      <td>0.653763</td>\n",
       "      <td>0.658770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>2.454726</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.661474</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.647156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>2.489712</td>\n",
       "      <td>0.664516</td>\n",
       "      <td>0.663485</td>\n",
       "      <td>0.664516</td>\n",
       "      <td>0.661446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>2.615305</td>\n",
       "      <td>0.636559</td>\n",
       "      <td>0.670592</td>\n",
       "      <td>0.636559</td>\n",
       "      <td>0.648905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>2.625428</td>\n",
       "      <td>0.653763</td>\n",
       "      <td>0.676637</td>\n",
       "      <td>0.653763</td>\n",
       "      <td>0.661874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>2.685555</td>\n",
       "      <td>0.636559</td>\n",
       "      <td>0.669086</td>\n",
       "      <td>0.636559</td>\n",
       "      <td>0.648958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>2.668338</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.669532</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.653426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>2.712143</td>\n",
       "      <td>0.636559</td>\n",
       "      <td>0.666447</td>\n",
       "      <td>0.636559</td>\n",
       "      <td>0.647863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>2.716293</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.667521</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.649684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.4_pubmedbert/checkpoint-51\n",
      "Configuration saved in /home/elson/1.4.4_pubmedbert/checkpoint-51/config.json\n",
      "Model weights saved in /home/elson/1.4.4_pubmedbert/checkpoint-51/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.4_pubmedbert/checkpoint-612] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/1.4.4_pubmedbert/checkpoint-1530] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.4_pubmedbert/checkpoint-102\n",
      "Configuration saved in /home/elson/1.4.4_pubmedbert/checkpoint-102/config.json\n",
      "Model weights saved in /home/elson/1.4.4_pubmedbert/checkpoint-102/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.4_pubmedbert/checkpoint-153\n",
      "Configuration saved in /home/elson/1.4.4_pubmedbert/checkpoint-153/config.json\n",
      "Model weights saved in /home/elson/1.4.4_pubmedbert/checkpoint-153/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.4_pubmedbert/checkpoint-102] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.4_pubmedbert/checkpoint-204\n",
      "Configuration saved in /home/elson/1.4.4_pubmedbert/checkpoint-204/config.json\n",
      "Model weights saved in /home/elson/1.4.4_pubmedbert/checkpoint-204/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.4_pubmedbert/checkpoint-153] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.4_pubmedbert/checkpoint-255\n",
      "Configuration saved in /home/elson/1.4.4_pubmedbert/checkpoint-255/config.json\n",
      "Model weights saved in /home/elson/1.4.4_pubmedbert/checkpoint-255/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.4_pubmedbert/checkpoint-204] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.4_pubmedbert/checkpoint-306\n",
      "Configuration saved in /home/elson/1.4.4_pubmedbert/checkpoint-306/config.json\n",
      "Model weights saved in /home/elson/1.4.4_pubmedbert/checkpoint-306/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.4_pubmedbert/checkpoint-255] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.4_pubmedbert/checkpoint-357\n",
      "Configuration saved in /home/elson/1.4.4_pubmedbert/checkpoint-357/config.json\n",
      "Model weights saved in /home/elson/1.4.4_pubmedbert/checkpoint-357/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.4_pubmedbert/checkpoint-51] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/1.4.4_pubmedbert/checkpoint-306] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.4_pubmedbert/checkpoint-408\n",
      "Configuration saved in /home/elson/1.4.4_pubmedbert/checkpoint-408/config.json\n",
      "Model weights saved in /home/elson/1.4.4_pubmedbert/checkpoint-408/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.4_pubmedbert/checkpoint-459\n",
      "Configuration saved in /home/elson/1.4.4_pubmedbert/checkpoint-459/config.json\n",
      "Model weights saved in /home/elson/1.4.4_pubmedbert/checkpoint-459/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.4_pubmedbert/checkpoint-408] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.4_pubmedbert/checkpoint-510\n",
      "Configuration saved in /home/elson/1.4.4_pubmedbert/checkpoint-510/config.json\n",
      "Model weights saved in /home/elson/1.4.4_pubmedbert/checkpoint-510/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.4_pubmedbert/checkpoint-459] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.4_pubmedbert/checkpoint-561\n",
      "Configuration saved in /home/elson/1.4.4_pubmedbert/checkpoint-561/config.json\n",
      "Model weights saved in /home/elson/1.4.4_pubmedbert/checkpoint-561/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.4_pubmedbert/checkpoint-510] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.4_pubmedbert/checkpoint-612\n",
      "Configuration saved in /home/elson/1.4.4_pubmedbert/checkpoint-612/config.json\n",
      "Model weights saved in /home/elson/1.4.4_pubmedbert/checkpoint-612/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.4_pubmedbert/checkpoint-561] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.4_pubmedbert/checkpoint-663\n",
      "Configuration saved in /home/elson/1.4.4_pubmedbert/checkpoint-663/config.json\n",
      "Model weights saved in /home/elson/1.4.4_pubmedbert/checkpoint-663/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.4_pubmedbert/checkpoint-612] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.4_pubmedbert/checkpoint-714\n",
      "Configuration saved in /home/elson/1.4.4_pubmedbert/checkpoint-714/config.json\n",
      "Model weights saved in /home/elson/1.4.4_pubmedbert/checkpoint-714/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.4_pubmedbert/checkpoint-357] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/1.4.4_pubmedbert/checkpoint-663] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.4_pubmedbert/checkpoint-765\n",
      "Configuration saved in /home/elson/1.4.4_pubmedbert/checkpoint-765/config.json\n",
      "Model weights saved in /home/elson/1.4.4_pubmedbert/checkpoint-765/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.4_pubmedbert/checkpoint-816\n",
      "Configuration saved in /home/elson/1.4.4_pubmedbert/checkpoint-816/config.json\n",
      "Model weights saved in /home/elson/1.4.4_pubmedbert/checkpoint-816/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.4_pubmedbert/checkpoint-765] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.4_pubmedbert/checkpoint-867\n",
      "Configuration saved in /home/elson/1.4.4_pubmedbert/checkpoint-867/config.json\n",
      "Model weights saved in /home/elson/1.4.4_pubmedbert/checkpoint-867/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.4_pubmedbert/checkpoint-816] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.4_pubmedbert/checkpoint-918\n",
      "Configuration saved in /home/elson/1.4.4_pubmedbert/checkpoint-918/config.json\n",
      "Model weights saved in /home/elson/1.4.4_pubmedbert/checkpoint-918/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.4_pubmedbert/checkpoint-867] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.4_pubmedbert/checkpoint-969\n",
      "Configuration saved in /home/elson/1.4.4_pubmedbert/checkpoint-969/config.json\n",
      "Model weights saved in /home/elson/1.4.4_pubmedbert/checkpoint-969/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.4_pubmedbert/checkpoint-918] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.4_pubmedbert/checkpoint-1020\n",
      "Configuration saved in /home/elson/1.4.4_pubmedbert/checkpoint-1020/config.json\n",
      "Model weights saved in /home/elson/1.4.4_pubmedbert/checkpoint-1020/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.4_pubmedbert/checkpoint-969] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading best model from /home/elson/1.4.4_pubmedbert/checkpoint-714 (score: 0.6645161290322581).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /home/elson/1.4.4_pubmedbert/best_model/config.json\n",
      "Model weights saved in /home/elson/1.4.4_pubmedbert/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/1.4.4_pubmedbert/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/1.4.4_pubmedbert/best_model/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/1.4.4_pubmedbert/best_model/tokenizer_config.json',\n",
       " '/home/elson/1.4.4_pubmedbert/best_model/special_tokens_map.json',\n",
       " '/home/elson/1.4.4_pubmedbert/best_model/vocab.txt',\n",
       " '/home/elson/1.4.4_pubmedbert/best_model/added_tokens.json',\n",
       " '/home/elson/1.4.4_pubmedbert/best_model/tokenizer.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/1.4.4_pubmedbert/',\n",
    "    num_train_epochs=20,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.1,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/1.4.4_pubmedbert/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/1.4.4_pubmedbert/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63deaea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/1.4.4_pubmedbert/best_model/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"/home/elson/1.4.4_pubmedbert/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"contradiction\",\n",
      "    \"1\": \"entailment\",\n",
      "    \"2\": \"neutral\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"contradiction\": 0,\n",
      "    \"entailment\": 1,\n",
      "    \"neutral\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file /home/elson/1.4.4_pubmedbert/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at /home/elson/1.4.4_pubmedbert/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 32\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/1.4.4_pubmedbert/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[-4.78  , -0.474 ,  4.56  ],\n",
      "       [-5.535 ,  4.77  , -0.3518],\n",
      "       [-4.01  ,  5.94  , -3.1   ],\n",
      "       [ 6.23  , -1.67  , -3.754 ],\n",
      "       [-3.764 ,  5.957 , -3.434 ],\n",
      "       [-3.281 ,  6.05  , -3.695 ],\n",
      "       [-4.367 ,  5.47  , -2.348 ],\n",
      "       [-5.51  ,  4.96  , -0.46  ],\n",
      "       [-4.234 ,  5.95  , -2.848 ],\n",
      "       [-3.055 ,  5.434 , -3.58  ],\n",
      "       [-3.098 ,  6.043 , -3.805 ],\n",
      "       [-3.578 ,  5.977 , -3.568 ],\n",
      "       [-3.947 ,  5.984 , -3.076 ],\n",
      "       [-3.867 ,  6.02  , -3.154 ],\n",
      "       [-3.924 ,  6.066 , -3.363 ],\n",
      "       [-2.395 ,  3.637 , -2.703 ],\n",
      "       [-3.764 ,  6.086 , -3.434 ],\n",
      "       [-3.455 ,  6.08  , -3.639 ],\n",
      "       [-4.12  ,  4.363 , -1.589 ],\n",
      "       [-3.902 ,  6.01  , -3.252 ],\n",
      "       [-4.457 ,  5.36  , -2.27  ],\n",
      "       [-2.113 ,  0.3237,  0.781 ],\n",
      "       [-3.635 ,  5.992 , -3.422 ],\n",
      "       [ 3.248 ,  1.553 , -5.188 ],\n",
      "       [ 6.004 , -2.924 , -1.908 ],\n",
      "       [ 6.324 , -2.352 , -2.975 ],\n",
      "       [-3.482 ,  6.08  , -3.576 ],\n",
      "       [-4.445 ,  5.887 , -2.654 ],\n",
      "       [-3.717 ,  6.07  , -3.365 ],\n",
      "       [-3.715 ,  5.996 , -3.377 ],\n",
      "       [-4.29  ,  4.4   , -1.617 ],\n",
      "       [-3.607 ,  5.902 , -3.463 ],\n",
      "       [-4.062 ,  6.062 , -3.152 ],\n",
      "       [-3.996 ,  3.793 , -0.8286],\n",
      "       [-1.144 , -1.806 ,  2.229 ],\n",
      "       [-3.28  ,  6.125 , -3.705 ],\n",
      "       [-3.54  ,  6.08  , -3.402 ],\n",
      "       [-4.348 ,  5.965 , -2.766 ],\n",
      "       [-0.8423,  4.234 , -4.633 ],\n",
      "       [-3.543 ,  6.137 , -3.508 ],\n",
      "       [ 3.227 ,  2.346 , -5.72  ],\n",
      "       [-4.56  ,  5.426 , -2.273 ],\n",
      "       [ 4.5   , -0.3499, -3.889 ],\n",
      "       [-2.395 , -1.38  ,  2.918 ],\n",
      "       [-3.475 , -2.197 ,  5.246 ],\n",
      "       [-3.18  ,  6.035 , -3.764 ],\n",
      "       [ 3.2   ,  0.8433, -3.738 ],\n",
      "       [-3.383 ,  6.086 , -3.703 ],\n",
      "       [-2.965 ,  6.023 , -3.953 ],\n",
      "       [ 0.464 ,  3.16  , -4.066 ],\n",
      "       [-4.95  ,  2.686 ,  0.7935],\n",
      "       [-4.77  ,  3.78  ,  0.0669],\n",
      "       [-3.688 ,  4.92  , -2.662 ],\n",
      "       [-4.38  ,  5.824 , -2.71  ],\n",
      "       [ 6.28  , -1.76  , -3.691 ],\n",
      "       [-3.547 ,  6.04  , -3.59  ],\n",
      "       [-3.633 , -2.506 ,  5.9   ],\n",
      "       [-3.902 ,  5.793 , -3.18  ],\n",
      "       [-3.732 ,  6.062 , -3.404 ],\n",
      "       [-3.678 ,  5.945 , -3.486 ],\n",
      "       [-3.658 ,  6.062 , -3.586 ],\n",
      "       [ 3.092 , -0.3335, -2.586 ],\n",
      "       [-0.931 , -3.479 ,  4.746 ],\n",
      "       [-3.73  ,  5.93  , -3.512 ],\n",
      "       [-4.203 , -0.9697,  4.875 ],\n",
      "       [-2.814 ,  5.906 , -4.168 ],\n",
      "       [-3.947 ,  6.08  , -3.285 ],\n",
      "       [-3.879 ,  6.06  , -3.365 ],\n",
      "       [-3.682 ,  5.695 , -2.904 ],\n",
      "       [ 6.273 , -1.839 , -3.459 ],\n",
      "       [-3.994 ,  5.49  , -2.96  ],\n",
      "       [-2.215 ,  3.908 , -2.414 ],\n",
      "       [-4.902 ,  4.67  , -1.269 ],\n",
      "       [-3.693 ,  6.117 , -3.418 ],\n",
      "       [-4.56  ,  5.707 , -2.447 ],\n",
      "       [-2.092 ,  5.555 , -4.445 ],\n",
      "       [-4.008 ,  5.945 , -3.104 ],\n",
      "       [-2.686 ,  5.414 , -3.842 ],\n",
      "       [-3.74  ,  6.1   , -3.418 ],\n",
      "       [-4.164 ,  5.676 , -2.938 ],\n",
      "       [-3.865 ,  5.996 , -3.385 ],\n",
      "       [-3.418 ,  6.05  , -3.715 ],\n",
      "       [-3.738 ,  6.035 , -3.484 ],\n",
      "       [-3.61  ,  6.023 , -3.469 ],\n",
      "       [-3.703 ,  6.06  , -3.457 ],\n",
      "       [-4.68  ,  5.03  , -1.529 ],\n",
      "       [-2.861 ,  5.773 , -3.947 ],\n",
      "       [ 2.838 ,  0.239 , -2.67  ],\n",
      "       [-4.062 ,  5.957 , -3.068 ],\n",
      "       [-2.58  ,  2.307 , -0.654 ],\n",
      "       [-4.14  ,  5.953 , -3.018 ],\n",
      "       [-3.535 ,  6.01  , -3.479 ],\n",
      "       [ 6.344 , -1.818 , -3.59  ],\n",
      "       [-3.346 ,  6.105 , -3.73  ],\n",
      "       [-3.934 ,  5.914 , -3.34  ],\n",
      "       [-2.07  , -3.527 ,  5.625 ],\n",
      "       [ 5.996 , -1.342 , -3.645 ],\n",
      "       [-3.781 ,  5.945 , -3.46  ],\n",
      "       [-3.842 ,  6.07  , -3.342 ],\n",
      "       [-3.406 ,  6.1   , -3.752 ],\n",
      "       [ 5.92  , -1.174 , -4.08  ],\n",
      "       [-3.285 ,  6.066 , -3.771 ],\n",
      "       [-3.79  ,  6.11  , -3.287 ],\n",
      "       [-4.445 , -0.652 ,  4.68  ],\n",
      "       [-4.008 ,  6.062 , -3.006 ],\n",
      "       [-3.594 ,  6.05  , -3.465 ],\n",
      "       [-0.9106,  4.906 , -5.25  ],\n",
      "       [-1.689 ,  5.04  , -4.504 ],\n",
      "       [-3.543 ,  6.035 , -3.432 ],\n",
      "       [-4.27  ,  5.215 , -2.018 ],\n",
      "       [-5.195 ,  3.941 ,  0.347 ],\n",
      "       [-4.008 ,  6.066 , -3.113 ],\n",
      "       [-4.008 ,  6.023 , -3.092 ],\n",
      "       [-3.613 ,  5.906 , -3.36  ],\n",
      "       [-4.996 ,  4.71  , -0.9043],\n",
      "       [-3.758 ,  5.9   , -3.348 ],\n",
      "       [-3.441 ,  6.055 , -3.64  ],\n",
      "       [-0.8184,  3.012 , -2.838 ],\n",
      "       [-4.152 ,  5.566 , -2.51  ],\n",
      "       [-3.094 ,  5.926 , -3.932 ],\n",
      "       [-2.402 , -2.879 ,  5.082 ],\n",
      "       [-4.652 ,  4.89  , -1.33  ],\n",
      "       [-4.29  ,  5.895 , -2.871 ],\n",
      "       [-5.105 ,  0.9785,  2.88  ],\n",
      "       [-3.148 , -2.936 ,  6.152 ],\n",
      "       [-3.59  ,  6.043 , -3.62  ],\n",
      "       [-4.375 ,  1.553 ,  1.762 ],\n",
      "       [-3.705 ,  5.996 , -3.463 ],\n",
      "       [-2.63  ,  5.7   , -4.12  ],\n",
      "       [-3.451 ,  5.965 , -3.697 ],\n",
      "       [-3.53  ,  5.887 , -3.486 ],\n",
      "       [ 6.35  , -2.254 , -2.797 ],\n",
      "       [-4.242 ,  5.992 , -2.89  ],\n",
      "       [ 0.558 , -4.44  ,  4.56  ],\n",
      "       [-1.093 ,  0.7837, -0.8184],\n",
      "       [-4.1   ,  5.92  , -2.979 ],\n",
      "       [-3.658 ,  5.953 , -3.494 ],\n",
      "       [-3.314 , -3.008 ,  6.14  ],\n",
      "       [-0.3167, -4.36  ,  5.2   ],\n",
      "       [-3.787 ,  6.098 , -3.252 ],\n",
      "       [-3.12  ,  6.    , -3.732 ],\n",
      "       [ 3.896 , -0.2291, -3.428 ],\n",
      "       [-4.33  ,  5.152 , -2.092 ],\n",
      "       [-3.273 ,  6.047 , -3.709 ],\n",
      "       [-3.875 ,  5.973 , -3.209 ],\n",
      "       [-4.492 ,  5.516 , -2.45  ],\n",
      "       [ 6.438 , -2.584 , -2.67  ],\n",
      "       [ 4.12  ,  0.4714, -4.137 ],\n",
      "       [-3.656 ,  6.09  , -3.516 ],\n",
      "       [-2.455 , -3.627 ,  6.06  ],\n",
      "       [-4.527 ,  3.818 , -0.5933],\n",
      "       [-4.168 ,  5.95  , -2.996 ],\n",
      "       [-4.59  , -0.604 ,  4.867 ],\n",
      "       [-3.83  ,  6.055 , -3.367 ],\n",
      "       [-4.02  ,  5.965 , -3.137 ],\n",
      "       [-3.549 ,  6.05  , -3.602 ],\n",
      "       [-3.498 ,  5.91  , -3.537 ],\n",
      "       [-3.672 ,  5.875 , -3.46  ],\n",
      "       [ 0.9453, -2.066 ,  1.417 ],\n",
      "       [ 6.42  , -2.479 , -2.854 ],\n",
      "       [ 6.39  , -2.227 , -3.203 ],\n",
      "       [ 6.348 , -2.662 , -2.547 ],\n",
      "       [-3.738 ,  5.973 , -3.49  ],\n",
      "       [ 6.18  , -1.825 , -3.658 ],\n",
      "       [ 3.527 , -2.566 , -0.4854],\n",
      "       [-5.086 ,  3.31  ,  0.4944],\n",
      "       [-2.49  ,  5.645 , -4.4   ],\n",
      "       [-3.465 ,  1.401 ,  1.387 ],\n",
      "       [-2.195 ,  4.52  , -3.438 ],\n",
      "       [ 1.204 ,  0.3547, -1.962 ],\n",
      "       [ 6.27  , -2.25  , -2.746 ],\n",
      "       [-1.274 ,  4.95  , -4.63  ],\n",
      "       [ 6.297 , -1.719 , -3.734 ],\n",
      "       [-3.94  ,  6.04  , -3.057 ],\n",
      "       [-3.418 ,  6.082 , -3.582 ],\n",
      "       [-4.957 ,  3.9   , -0.1725],\n",
      "       [-3.639 ,  6.145 , -3.45  ],\n",
      "       [ 6.316 , -2.21  , -3.008 ],\n",
      "       [-2.99  ,  5.773 , -4.082 ],\n",
      "       [-3.092 , -3.182 ,  6.06  ],\n",
      "       [-4.258 ,  0.748 ,  2.594 ],\n",
      "       [-2.867 ,  5.56  , -3.904 ],\n",
      "       [ 1.747 ,  3.18  , -5.65  ],\n",
      "       [-4.758 ,  0.392 ,  3.453 ],\n",
      "       [ 6.047 , -2.71  , -2.38  ],\n",
      "       [-3.916 ,  5.848 , -3.227 ],\n",
      "       [-3.516 ,  6.09  , -3.527 ],\n",
      "       [-3.613 ,  6.094 , -3.54  ],\n",
      "       [-4.18  ,  5.92  , -2.918 ],\n",
      "       [-3.605 ,  6.094 , -3.588 ],\n",
      "       [-3.936 ,  3.982 , -1.368 ],\n",
      "       [-3.773 ,  6.05  , -3.314 ],\n",
      "       [-4.16  ,  5.965 , -2.92  ],\n",
      "       [-4.117 ,  6.06  , -3.072 ],\n",
      "       [ 4.652 , -0.6084, -3.816 ],\n",
      "       [-3.416 ,  6.03  , -3.662 ],\n",
      "       [-3.768 ,  5.965 , -3.303 ],\n",
      "       [-3.865 ,  6.086 , -3.197 ],\n",
      "       [-3.996 ,  4.88  , -2.352 ],\n",
      "       [-4.54  ,  0.8384,  2.977 ],\n",
      "       [-4.13  ,  6.    , -3.023 ],\n",
      "       [-3.365 ,  5.96  , -3.71  ],\n",
      "       [-4.79  ,  2.543 ,  1.189 ],\n",
      "       [-4.08  ,  6.03  , -2.957 ],\n",
      "       [-2.564 , -2.396 ,  4.414 ],\n",
      "       [ 6.234 , -2.16  , -3.246 ],\n",
      "       [-3.926 ,  6.08  , -3.365 ],\n",
      "       [-5.29  ,  4.71  , -0.7275],\n",
      "       [-3.47  ,  6.047 , -3.537 ],\n",
      "       [-3.596 ,  6.05  , -3.65  ],\n",
      "       [-4.266 ,  5.902 , -2.72  ],\n",
      "       [-4.785 ,  1.206 ,  2.838 ],\n",
      "       [-4.066 ,  5.938 , -3.207 ],\n",
      "       [-3.719 ,  5.99  , -3.318 ],\n",
      "       [-3.791 ,  6.086 , -3.379 ],\n",
      "       [ 5.63  , -1.885 , -2.82  ],\n",
      "       [ 6.223 , -2.139 , -3.049 ],\n",
      "       [-3.576 ,  5.844 , -3.145 ],\n",
      "       [-3.84  ,  6.06  , -3.328 ],\n",
      "       [-3.928 ,  5.617 , -2.967 ],\n",
      "       [-3.646 ,  6.066 , -3.396 ],\n",
      "       [-3.424 ,  6.1   , -3.648 ],\n",
      "       [ 6.43  , -1.926 , -3.45  ],\n",
      "       [-3.676 ,  6.11  , -3.479 ],\n",
      "       [-3.04  ,  5.957 , -4.04  ],\n",
      "       [-3.438 ,  5.96  , -3.656 ],\n",
      "       [-3.465 ,  6.094 , -3.674 ],\n",
      "       [ 6.11  , -2.104 , -3.22  ],\n",
      "       [-4.65  ,  4.863 , -1.808 ],\n",
      "       [ 5.816 , -2.479 , -2.156 ],\n",
      "       [-3.158 ,  6.027 , -3.797 ],\n",
      "       [-3.943 ,  6.023 , -3.307 ],\n",
      "       [-2.484 ,  1.472 , -0.1447],\n",
      "       [ 3.752 , -0.2725, -2.895 ]], dtype=float16), label_ids=array([1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1,\n",
      "       1, 2, 0, 0, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 0, 1, 0, 2, 1, 1,\n",
      "       2, 0, 1, 1, 1, 0, 2, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 0, 2, 1, 2, 1,\n",
      "       1, 2, 0, 0, 1, 1, 2, 2, 2, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1,\n",
      "       1, 2, 1, 1, 2, 1, 2, 2, 0, 1, 1, 2, 0, 2, 1, 2, 1, 1, 1, 2, 1, 1,\n",
      "       2, 0, 1, 1, 2, 1, 1, 1, 2, 0, 2, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2,\n",
      "       1, 2, 1, 2, 1, 1, 2, 1, 0, 1, 1, 1, 2, 2, 0, 2, 1, 1, 1, 1, 2, 2,\n",
      "       0, 1, 1, 2, 1, 0, 0, 0, 2, 1, 1, 2, 1, 2, 0, 1, 0, 1, 2, 1, 1, 1,\n",
      "       1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 0, 0, 1, 2, 1,\n",
      "       1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 2, 0, 1, 1,\n",
      "       1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 0, 1, 1, 2]), metrics={'test_loss': 2.8010737895965576, 'test_accuracy': 0.6196581196581197, 'test_precision': 0.6048117058850512, 'test_recall': 0.6196581196581197, 'test_f1': 0.5833529232510557, 'test_runtime': 1.1287, 'test_samples_per_second': 207.322, 'test_steps_per_second': 7.088})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d4e861c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "probabilities = torch.softmax(torch.tensor(test_results.predictions).to(torch.float32), dim=-1)\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)\n",
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1747566",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_save = []\n",
    "for idx in range(len(test_data)):\n",
    "    item = dataset['test'][idx]\n",
    "    actual_label = item['label']\n",
    "    predicted_label = predictions[idx]\n",
    "    claim = item['claim'] \n",
    "    premise = item['premise'] \n",
    "    category = item['category']\n",
    "    \n",
    "    # Append the information as a dictionary to the list\n",
    "    data_to_save.append({\n",
    "        'Claim': claim,\n",
    "        'Premise': premise,\n",
    "        'Actual Label': actual_label,\n",
    "        'Predicted Label': predicted_label,\n",
    "        'Category' : category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_to_save)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/home/elson/results/1.4.4_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f40c56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correctly classified instances\n",
    "correctly_classified = df[df['Actual Label'] == df['Predicted Label']]\n",
    "\n",
    "# Calculate misclassified instances\n",
    "misclassified = df[df['Actual Label'] != df['Predicted Label']]\n",
    "\n",
    "# Count the number of correctly classified and misclassified by category\n",
    "correct_classification_counts = correctly_classified['Category'].value_counts()\n",
    "misclassification_counts = misclassified['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61d30750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           37\n",
       "Bone health              12\n",
       "Fitness                  12\n",
       "Skin                     12\n",
       "Diabetes                 11\n",
       "Cancer                    9\n",
       "Cardiovascular Health     9\n",
       "Throat                    7\n",
       "Ear                       6\n",
       "Neurological health       5\n",
       "Blood                     4\n",
       "Hair                      4\n",
       "Eye                       4\n",
       "Men's health              4\n",
       "Mental Health             3\n",
       "Women' s Health           3\n",
       "COVID                     2\n",
       "Muscles                   1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "670ffadf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           14\n",
       "Skin                     12\n",
       "Bone health               9\n",
       "Hair                      8\n",
       "Eye                       5\n",
       "Blood                     5\n",
       "Muscles                   5\n",
       "Neurological health       4\n",
       "COVID                     4\n",
       "Fitness                   3\n",
       "Vascular                  3\n",
       "Dental Health             3\n",
       "Women' s Health           3\n",
       "Cardiovascular Health     3\n",
       "Cancer                    3\n",
       "Throat                    2\n",
       "Men's health              2\n",
       "Diabetes                  1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
