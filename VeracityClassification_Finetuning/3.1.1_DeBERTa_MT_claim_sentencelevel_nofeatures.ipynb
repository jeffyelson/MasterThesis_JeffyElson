{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-cac7855410b939be\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-cac7855410b939be/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 314.96it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('csv',data_files='dataset_sentenceattribution_nerfeatures_split.csv',delimiter=',',column_names=[\"claim\",\"premise\",\"label\",\"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\",\"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\",\"url\", \"entities\",\"entity_map\",\"gem_exp\",\"gem_label\",\"gpt_label\",\"gpt_exp\",\"gold_exp\",\"entity_map_ev\",\"entity_ev\",\"split\"],skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "133f9357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cac7855410b939be/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-a932df0b74e1547a.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cac7855410b939be/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-926cef8097c290d1.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cac7855410b939be/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-2ec17003ffb0a917.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01252e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\"claim\", \"premise\", \"label\"]\n",
    "all_columns = dataset[\"train\"].column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cac7855410b939be/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-25128b691fbb2a7a.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cac7855410b939be/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-3cf6de4ed2bf1a77.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cac7855410b939be/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-69ecd84e19cd49e7.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 2, 'entailment': 0, 'neutral': 1}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 2,\n",
    "    \"entailment\": 0,\n",
    "    \"neutral\": 1\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e15010ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='sileod/deberta-v3-base-tasksource-nli'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "        # Extracting claim and evidence texts\n",
    "\n",
    "        claim = item['claim'].lower()\n",
    "        evidences = item['premise'].lower()\n",
    "        item['premise']=evidences\n",
    "        item['claim']=claim\n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "            claim, evidences,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "        item['input_ids'] = inputs['input_ids'].squeeze()  # Remove batch dimension\n",
    "        item['attention_mask']= inputs['attention_mask'].squeeze() # Remove batch dimension\n",
    "        \n",
    "        if 'label' in item:\n",
    "            item['labels'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62421eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1.25k/1.25k [00:00<00:00, 2.09MB/s]\n",
      "Downloading: 100%|██████████| 2.35M/2.35M [00:00<00:00, 27.3MB/s]\n",
      "Downloading: 100%|██████████| 23.0/23.0 [00:00<00:00, 66.2kB/s]\n",
      "Downloading: 100%|██████████| 286/286 [00:00<00:00, 665kB/s]\n",
      "Downloading: 100%|██████████| 18.1k/18.1k [00:00<00:00, 11.1MB/s]\n",
      "Downloading: 100%|██████████| 704M/704M [00:22<00:00, 32.2MB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DebertaV2ForSequenceClassification(\n",
       "  (deberta): DebertaV2Model(\n",
       "    (embeddings): DebertaV2Embeddings(\n",
       "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaV2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (1): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (2): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (3): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (4): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (5): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (6): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (7): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (8): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (9): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (10): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (11): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (pooler): ContextPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): StableDropout()\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (dropout): StableDropout()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"sileod/deberta-v3-base-tasksource-nli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=512)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=3, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    return {\"accuracy\": acc, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f5cf584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'claim': 'myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.',\n",
       " 'premise': 'additionally, laser doppler blood flow measurement showed that the frankincense and myrrh essential oil compound could promote the elimination of capillaries from skin epidermis to dermis by increasing skin blood flow.',\n",
       " 'label': 0,\n",
       " 'input_ids': tensor([    1, 98237,  1830,  1080,   269,  1359,   427,   267, 17847,   633,\n",
       "           264,   408,  1300,   262,  2658,   265,   262,  1158,   260,     2,\n",
       "          7229,   261,  5042,   333, 73325,  1452,  2155,  6116,  1938,   272,\n",
       "           262, 88609,   263, 98237,  1830,  1080,  7355,   387,  2655,   262,\n",
       "         12682,   265, 65008,   292,  1158, 53245,   264, 75840,   293,  2376,\n",
       "          1158,  1452,  2155,   260,     2,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'labels': tensor(0)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2040\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2040' max='2040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2040/2040 16:39, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.646200</td>\n",
       "      <td>0.737564</td>\n",
       "      <td>0.694624</td>\n",
       "      <td>0.667608</td>\n",
       "      <td>0.694624</td>\n",
       "      <td>0.679718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.275700</td>\n",
       "      <td>1.232224</td>\n",
       "      <td>0.658065</td>\n",
       "      <td>0.726180</td>\n",
       "      <td>0.658065</td>\n",
       "      <td>0.685273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.175400</td>\n",
       "      <td>1.929995</td>\n",
       "      <td>0.681720</td>\n",
       "      <td>0.702123</td>\n",
       "      <td>0.681720</td>\n",
       "      <td>0.690928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.043000</td>\n",
       "      <td>2.323722</td>\n",
       "      <td>0.658065</td>\n",
       "      <td>0.701921</td>\n",
       "      <td>0.658065</td>\n",
       "      <td>0.676505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.119400</td>\n",
       "      <td>2.671245</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.695906</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.669599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>2.874915</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.708821</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.689680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>3.299494</td>\n",
       "      <td>0.636559</td>\n",
       "      <td>0.719647</td>\n",
       "      <td>0.636559</td>\n",
       "      <td>0.669212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.851088</td>\n",
       "      <td>0.686022</td>\n",
       "      <td>0.699941</td>\n",
       "      <td>0.686022</td>\n",
       "      <td>0.692640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.019865</td>\n",
       "      <td>0.679570</td>\n",
       "      <td>0.693807</td>\n",
       "      <td>0.679570</td>\n",
       "      <td>0.686099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.143235</td>\n",
       "      <td>0.681720</td>\n",
       "      <td>0.699316</td>\n",
       "      <td>0.681720</td>\n",
       "      <td>0.689967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.173412</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.698052</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.686635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.226140</td>\n",
       "      <td>0.670968</td>\n",
       "      <td>0.695729</td>\n",
       "      <td>0.670968</td>\n",
       "      <td>0.682362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.161803</td>\n",
       "      <td>0.660215</td>\n",
       "      <td>0.709384</td>\n",
       "      <td>0.660215</td>\n",
       "      <td>0.681152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.089822</td>\n",
       "      <td>0.686022</td>\n",
       "      <td>0.722330</td>\n",
       "      <td>0.686022</td>\n",
       "      <td>0.701938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.128958</td>\n",
       "      <td>0.688172</td>\n",
       "      <td>0.712550</td>\n",
       "      <td>0.688172</td>\n",
       "      <td>0.699249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.151526</td>\n",
       "      <td>0.686022</td>\n",
       "      <td>0.714113</td>\n",
       "      <td>0.686022</td>\n",
       "      <td>0.698865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.275199</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.708684</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.690454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.286883</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.708684</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.690454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.293833</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.708684</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.690454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.296269</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.708684</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.690454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to /home/elson/3.1.1_deberta/checkpoint-102\n",
      "Configuration saved in /home/elson/3.1.1_deberta/checkpoint-102/config.json\n",
      "Model weights saved in /home/elson/3.1.1_deberta/checkpoint-102/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/3.1.1_deberta/checkpoint-204\n",
      "Configuration saved in /home/elson/3.1.1_deberta/checkpoint-204/config.json\n",
      "Model weights saved in /home/elson/3.1.1_deberta/checkpoint-204/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/3.1.1_deberta/checkpoint-306\n",
      "Configuration saved in /home/elson/3.1.1_deberta/checkpoint-306/config.json\n",
      "Model weights saved in /home/elson/3.1.1_deberta/checkpoint-306/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/3.1.1_deberta/checkpoint-204] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/3.1.1_deberta/checkpoint-408\n",
      "Configuration saved in /home/elson/3.1.1_deberta/checkpoint-408/config.json\n",
      "Model weights saved in /home/elson/3.1.1_deberta/checkpoint-408/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/3.1.1_deberta/checkpoint-306] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/3.1.1_deberta/checkpoint-510\n",
      "Configuration saved in /home/elson/3.1.1_deberta/checkpoint-510/config.json\n",
      "Model weights saved in /home/elson/3.1.1_deberta/checkpoint-510/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/3.1.1_deberta/checkpoint-408] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/3.1.1_deberta/checkpoint-612\n",
      "Configuration saved in /home/elson/3.1.1_deberta/checkpoint-612/config.json\n",
      "Model weights saved in /home/elson/3.1.1_deberta/checkpoint-612/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/3.1.1_deberta/checkpoint-510] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/3.1.1_deberta/checkpoint-714\n",
      "Configuration saved in /home/elson/3.1.1_deberta/checkpoint-714/config.json\n",
      "Model weights saved in /home/elson/3.1.1_deberta/checkpoint-714/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/3.1.1_deberta/checkpoint-612] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/3.1.1_deberta/checkpoint-816\n",
      "Configuration saved in /home/elson/3.1.1_deberta/checkpoint-816/config.json\n",
      "Model weights saved in /home/elson/3.1.1_deberta/checkpoint-816/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/3.1.1_deberta/checkpoint-714] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/3.1.1_deberta/checkpoint-918\n",
      "Configuration saved in /home/elson/3.1.1_deberta/checkpoint-918/config.json\n",
      "Model weights saved in /home/elson/3.1.1_deberta/checkpoint-918/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/3.1.1_deberta/checkpoint-816] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/3.1.1_deberta/checkpoint-1020\n",
      "Configuration saved in /home/elson/3.1.1_deberta/checkpoint-1020/config.json\n",
      "Model weights saved in /home/elson/3.1.1_deberta/checkpoint-1020/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/3.1.1_deberta/checkpoint-918] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/3.1.1_deberta/checkpoint-1122\n",
      "Configuration saved in /home/elson/3.1.1_deberta/checkpoint-1122/config.json\n",
      "Model weights saved in /home/elson/3.1.1_deberta/checkpoint-1122/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/3.1.1_deberta/checkpoint-1020] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/3.1.1_deberta/checkpoint-1224\n",
      "Configuration saved in /home/elson/3.1.1_deberta/checkpoint-1224/config.json\n",
      "Model weights saved in /home/elson/3.1.1_deberta/checkpoint-1224/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/3.1.1_deberta/checkpoint-1122] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/3.1.1_deberta/checkpoint-1326\n",
      "Configuration saved in /home/elson/3.1.1_deberta/checkpoint-1326/config.json\n",
      "Model weights saved in /home/elson/3.1.1_deberta/checkpoint-1326/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/3.1.1_deberta/checkpoint-1224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/3.1.1_deberta/checkpoint-1428\n",
      "Configuration saved in /home/elson/3.1.1_deberta/checkpoint-1428/config.json\n",
      "Model weights saved in /home/elson/3.1.1_deberta/checkpoint-1428/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/3.1.1_deberta/checkpoint-1326] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/3.1.1_deberta/checkpoint-1530\n",
      "Configuration saved in /home/elson/3.1.1_deberta/checkpoint-1530/config.json\n",
      "Model weights saved in /home/elson/3.1.1_deberta/checkpoint-1530/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/3.1.1_deberta/checkpoint-1428] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/3.1.1_deberta/checkpoint-1632\n",
      "Configuration saved in /home/elson/3.1.1_deberta/checkpoint-1632/config.json\n",
      "Model weights saved in /home/elson/3.1.1_deberta/checkpoint-1632/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/3.1.1_deberta/checkpoint-1530] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/3.1.1_deberta/checkpoint-1734\n",
      "Configuration saved in /home/elson/3.1.1_deberta/checkpoint-1734/config.json\n",
      "Model weights saved in /home/elson/3.1.1_deberta/checkpoint-1734/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/3.1.1_deberta/checkpoint-1632] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/3.1.1_deberta/checkpoint-1836\n",
      "Configuration saved in /home/elson/3.1.1_deberta/checkpoint-1836/config.json\n",
      "Model weights saved in /home/elson/3.1.1_deberta/checkpoint-1836/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/3.1.1_deberta/checkpoint-1734] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/3.1.1_deberta/checkpoint-1938\n",
      "Configuration saved in /home/elson/3.1.1_deberta/checkpoint-1938/config.json\n",
      "Model weights saved in /home/elson/3.1.1_deberta/checkpoint-1938/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/3.1.1_deberta/checkpoint-1836] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/3.1.1_deberta/checkpoint-2040\n",
      "Configuration saved in /home/elson/3.1.1_deberta/checkpoint-2040/config.json\n",
      "Model weights saved in /home/elson/3.1.1_deberta/checkpoint-2040/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/3.1.1_deberta/checkpoint-1938] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/elson/3.1.1_deberta/checkpoint-102 (score: 0.6946236559139785).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Configuration saved in /home/elson/3.1.1_deberta/best_model/config.json\n",
      "Model weights saved in /home/elson/3.1.1_deberta/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/3.1.1_deberta/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/3.1.1_deberta/best_model/special_tokens_map.json\n",
      "added tokens file saved in /home/elson/3.1.1_deberta/best_model/added_tokens.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/3.1.1_deberta/best_model/tokenizer_config.json',\n",
       " '/home/elson/3.1.1_deberta/best_model/special_tokens_map.json',\n",
       " '/home/elson/3.1.1_deberta/best_model/spm.model',\n",
       " '/home/elson/3.1.1_deberta/best_model/added_tokens.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/3.1.1_deberta/',\n",
    "    num_train_epochs=20,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.06,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/3.1.1_deberta/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/3.1.1_deberta/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63deaea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/3.1.1_deberta/best_model/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"/home/elson/3.1.1_deberta/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifiers_size\": [\n",
      "    3,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    1,\n",
      "    2,\n",
      "    3,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    1,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2,\n",
      "    3,\n",
      "    2,\n",
      "    6,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    5,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    47,\n",
      "    23,\n",
      "    9,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    20,\n",
      "    50,\n",
      "    3,\n",
      "    3,\n",
      "    4,\n",
      "    2,\n",
      "    8,\n",
      "    3,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    4,\n",
      "    20,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    174,\n",
      "    2,\n",
      "    2,\n",
      "    41,\n",
      "    2,\n",
      "    2,\n",
      "    51,\n",
      "    2,\n",
      "    3,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    3,\n",
      "    16,\n",
      "    2,\n",
      "    18,\n",
      "    8,\n",
      "    2,\n",
      "    17,\n",
      "    3,\n",
      "    2,\n",
      "    4,\n",
      "    7,\n",
      "    12,\n",
      "    7,\n",
      "    3,\n",
      "    3,\n",
      "    42,\n",
      "    11,\n",
      "    100,\n",
      "    13,\n",
      "    100,\n",
      "    8,\n",
      "    1,\n",
      "    20,\n",
      "    2,\n",
      "    2,\n",
      "    4,\n",
      "    5,\n",
      "    3,\n",
      "    4,\n",
      "    14,\n",
      "    2,\n",
      "    6,\n",
      "    4,\n",
      "    2,\n",
      "    1,\n",
      "    3,\n",
      "    10,\n",
      "    3,\n",
      "    10,\n",
      "    4,\n",
      "    2,\n",
      "    7,\n",
      "    6,\n",
      "    28,\n",
      "    3,\n",
      "    6,\n",
      "    3,\n",
      "    6,\n",
      "    5,\n",
      "    7,\n",
      "    4,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    6,\n",
      "    2,\n",
      "    2,\n",
      "    7,\n",
      "    20,\n",
      "    2,\n",
      "    9,\n",
      "    2,\n",
      "    3,\n",
      "    13,\n",
      "    2,\n",
      "    3,\n",
      "    2,\n",
      "    4,\n",
      "    4,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    4,\n",
      "    1,\n",
      "    2,\n",
      "    1,\n",
      "    13,\n",
      "    3,\n",
      "    5,\n",
      "    11,\n",
      "    37,\n",
      "    2,\n",
      "    49,\n",
      "    40,\n",
      "    10,\n",
      "    4,\n",
      "    1,\n",
      "    2,\n",
      "    2,\n",
      "    1,\n",
      "    5,\n",
      "    2,\n",
      "    3,\n",
      "    2,\n",
      "    2,\n",
      "    12,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    19,\n",
      "    3,\n",
      "    1,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    1,\n",
      "    2,\n",
      "    2,\n",
      "    1,\n",
      "    1,\n",
      "    2,\n",
      "    3,\n",
      "    2,\n",
      "    1,\n",
      "    4,\n",
      "    3,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    2,\n",
      "    3,\n",
      "    2,\n",
      "    3,\n",
      "    1,\n",
      "    1,\n",
      "    2,\n",
      "    1,\n",
      "    3,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    3,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    1,\n",
      "    3,\n",
      "    2,\n",
      "    2,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    2,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    4,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    3,\n",
      "    1,\n",
      "    3,\n",
      "    1,\n",
      "    2,\n",
      "    2,\n",
      "    1,\n",
      "    2,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    1,\n",
      "    3,\n",
      "    1,\n",
      "    1,\n",
      "    3,\n",
      "    1,\n",
      "    3,\n",
      "    2,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    2,\n",
      "    2,\n",
      "    50,\n",
      "    50,\n",
      "    50,\n",
      "    50,\n",
      "    2,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    77,\n",
      "    2,\n",
      "    1,\n",
      "    3,\n",
      "    2,\n",
      "    2,\n",
      "    1,\n",
      "    1,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    3,\n",
      "    18,\n",
      "    13,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    4,\n",
      "    2,\n",
      "    24,\n",
      "    23,\n",
      "    67,\n",
      "    279,\n",
      "    3,\n",
      "    2,\n",
      "    2,\n",
      "    1,\n",
      "    2,\n",
      "    2,\n",
      "    3,\n",
      "    1,\n",
      "    2,\n",
      "    3,\n",
      "    2,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2,\n",
      "    4,\n",
      "    1,\n",
      "    17,\n",
      "    3,\n",
      "    2,\n",
      "    3,\n",
      "    2,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    1,\n",
      "    1,\n",
      "    3,\n",
      "    2,\n",
      "    2,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"entailment\",\n",
      "    \"1\": \"neutral\",\n",
      "    \"2\": \"contradiction\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"contradiction\": 2,\n",
      "    \"entailment\": 0,\n",
      "    \"neutral\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"tasks\": [\n",
      "    \"glue/mnli\",\n",
      "    \"glue/qnli\",\n",
      "    \"glue/rte\",\n",
      "    \"glue/wnli\",\n",
      "    \"glue/mrpc\",\n",
      "    \"glue/qqp\",\n",
      "    \"glue/stsb\",\n",
      "    \"super_glue/boolq\",\n",
      "    \"super_glue/cb\",\n",
      "    \"super_glue/multirc\",\n",
      "    \"super_glue/wic\",\n",
      "    \"super_glue/axg\",\n",
      "    \"anli/a1\",\n",
      "    \"anli/a2\",\n",
      "    \"anli/a3\",\n",
      "    \"sick/label\",\n",
      "    \"sick/relatedness\",\n",
      "    \"sick/entailment_AB\",\n",
      "    \"snli\",\n",
      "    \"scitail/snli_format\",\n",
      "    \"hans\",\n",
      "    \"WANLI\",\n",
      "    \"recast/recast_verbnet\",\n",
      "    \"recast/recast_kg_relations\",\n",
      "    \"recast/recast_ner\",\n",
      "    \"recast/recast_factuality\",\n",
      "    \"recast/recast_puns\",\n",
      "    \"recast/recast_megaveridicality\",\n",
      "    \"recast/recast_sentiment\",\n",
      "    \"recast/recast_verbcorner\",\n",
      "    \"probability_words_nli/usnli\",\n",
      "    \"probability_words_nli/reasoning_1hop\",\n",
      "    \"probability_words_nli/reasoning_2hop\",\n",
      "    \"nan-nli/joey234--nan-nli\",\n",
      "    \"nli_fever\",\n",
      "    \"breaking_nli\",\n",
      "    \"conj_nli\",\n",
      "    \"fracas\",\n",
      "    \"dialogue_nli\",\n",
      "    \"mpe\",\n",
      "    \"dnc\",\n",
      "    \"recast_white/fnplus\",\n",
      "    \"recast_white/sprl\",\n",
      "    \"recast_white/dpr\",\n",
      "    \"joci\",\n",
      "    \"robust_nli/IS_CS\",\n",
      "    \"robust_nli/LI_LI\",\n",
      "    \"robust_nli/ST_WO\",\n",
      "    \"robust_nli/PI_SP\",\n",
      "    \"robust_nli/PI_CD\",\n",
      "    \"robust_nli/ST_SE\",\n",
      "    \"robust_nli/ST_NE\",\n",
      "    \"robust_nli/ST_LM\",\n",
      "    \"robust_nli_is_sd\",\n",
      "    \"robust_nli_li_ts\",\n",
      "    \"add_one_rte\",\n",
      "    \"imppres/implicature_numerals_10_100/log\",\n",
      "    \"imppres/implicature_connectives/log\",\n",
      "    \"imppres/implicature_modals/log\",\n",
      "    \"imppres/implicature_gradable_verb/log\",\n",
      "    \"imppres/implicature_gradable_adjective/log\",\n",
      "    \"imppres/implicature_numerals_2_3/log\",\n",
      "    \"imppres/implicature_quantifiers/log\",\n",
      "    \"glue_diagnostics/diagnostics\",\n",
      "    \"hlgd\",\n",
      "    \"paws/labeled_final\",\n",
      "    \"paws/labeled_swap\",\n",
      "    \"medical_questions_pairs\",\n",
      "    \"conll2003/pos_tags\",\n",
      "    \"conll2003/chunk_tags\",\n",
      "    \"conll2003/ner_tags\",\n",
      "    \"hh-rlhf\",\n",
      "    \"model-written-evals\",\n",
      "    \"truthful_qa/multiple_choice\",\n",
      "    \"fig-qa\",\n",
      "    \"bigbench/physical_intuition\",\n",
      "    \"bigbench/authorship_verification\",\n",
      "    \"bigbench/implicit_relations\",\n",
      "    \"bigbench/dyck_languages\",\n",
      "    \"bigbench/novel_concepts\",\n",
      "    \"bigbench/moral_permissibility\",\n",
      "    \"bigbench/metaphor_understanding\",\n",
      "    \"bigbench/temporal_sequences\",\n",
      "    \"bigbench/sports_understanding\",\n",
      "    \"bigbench/analytic_entailment\",\n",
      "    \"bigbench/social_support\",\n",
      "    \"bigbench/emoji_movie\",\n",
      "    \"bigbench/dark_humor_detection\",\n",
      "    \"bigbench/suicide_risk\",\n",
      "    \"bigbench/fact_checker\",\n",
      "    \"bigbench/hhh_alignment\",\n",
      "    \"bigbench/formal_fallacies_syllogisms_negation\",\n",
      "    \"bigbench/bbq_lite_json\",\n",
      "    \"bigbench/cause_and_effect\",\n",
      "    \"bigbench/logic_grid_puzzle\",\n",
      "    \"bigbench/empirical_judgments\",\n",
      "    \"bigbench/human_organs_senses\",\n",
      "    \"bigbench/misconceptions\",\n",
      "    \"bigbench/strange_stories\",\n",
      "    \"bigbench/logical_args\",\n",
      "    \"bigbench/known_unknowns\",\n",
      "    \"bigbench/cs_algorithms\",\n",
      "    \"bigbench/emojis_emotion_prediction\",\n",
      "    \"bigbench/cifar10_classification\",\n",
      "    \"bigbench/penguins_in_a_table\",\n",
      "    \"bigbench/odd_one_out\",\n",
      "    \"bigbench/intent_recognition\",\n",
      "    \"bigbench/physics\",\n",
      "    \"bigbench/conceptual_combinations\",\n",
      "    \"bigbench/logical_deduction\",\n",
      "    \"bigbench/causal_judgment\",\n",
      "    \"bigbench/winowhy\",\n",
      "    \"bigbench/arithmetic\",\n",
      "    \"bigbench/undo_permutation\",\n",
      "    \"bigbench/analogical_similarity\",\n",
      "    \"bigbench/social_iqa\",\n",
      "    \"bigbench/key_value_maps\",\n",
      "    \"bigbench/implicatures\",\n",
      "    \"bigbench/real_or_fake_text\",\n",
      "    \"bigbench/disambiguation_qa\",\n",
      "    \"bigbench/similarities_abstraction\",\n",
      "    \"bigbench/movie_dialog_same_or_different\",\n",
      "    \"bigbench/english_proverbs\",\n",
      "    \"bigbench/presuppositions_as_nli\",\n",
      "    \"bigbench/entailed_polarity\",\n",
      "    \"bigbench/snarks\",\n",
      "    \"bigbench/goal_step_wikihow\",\n",
      "    \"bigbench/crass_ai\",\n",
      "    \"bigbench/play_dialog_same_or_different\",\n",
      "    \"bigbench/hindu_knowledge\",\n",
      "    \"bigbench/international_phonetic_alphabet_nli\",\n",
      "    \"bigbench/understanding_fables\",\n",
      "    \"bigbench/geometric_shapes\",\n",
      "    \"bigbench/code_line_description\",\n",
      "    \"bigbench/riddle_sense\",\n",
      "    \"bigbench/symbol_interpretation\",\n",
      "    \"bigbench/irony_identification\",\n",
      "    \"bigbench/anachronisms\",\n",
      "    \"bigbench/navigate\",\n",
      "    \"bigbench/crash_blossom\",\n",
      "    \"bigbench/identify_odd_metaphor\",\n",
      "    \"bigbench/simple_ethical_questions\",\n",
      "    \"bigbench/contextual_parametric_knowledge_conflicts\",\n",
      "    \"bigbench/date_understanding\",\n",
      "    \"bigbench/figure_of_speech_detection\",\n",
      "    \"bigbench/question_selection\",\n",
      "    \"bigbench/elementary_math_qa\",\n",
      "    \"bigbench/nonsense_words_grammar\",\n",
      "    \"bigbench/salient_translation_error_detection\",\n",
      "    \"bigbench/epistemic_reasoning\",\n",
      "    \"bigbench/movie_recommendation\",\n",
      "    \"bigbench/strategyqa\",\n",
      "    \"bigbench/tracking_shuffled_objects\",\n",
      "    \"bigbench/unit_interpretation\",\n",
      "    \"bigbench/reasoning_about_colored_objects\",\n",
      "    \"bigbench/discourse_marker_prediction\",\n",
      "    \"bigbench/logical_fallacy_detection\",\n",
      "    \"bigbench/general_knowledge\",\n",
      "    \"bigbench/abstract_narrative_understanding\",\n",
      "    \"bigbench/color\",\n",
      "    \"bigbench/hyperbaton\",\n",
      "    \"bigbench/logical_sequence\",\n",
      "    \"bigbench/mnist_ascii\",\n",
      "    \"bigbench/fantasy_reasoning\",\n",
      "    \"bigbench/mathematical_induction\",\n",
      "    \"bigbench/timedial\",\n",
      "    \"bigbench/identify_math_theorems\",\n",
      "    \"bigbench/checkmate_in_one\",\n",
      "    \"bigbench/phrase_relatedness\",\n",
      "    \"bigbench/ruin_names\",\n",
      "    \"bigbench/gre_reading_comprehension\",\n",
      "    \"bigbench/metaphor_boolean\",\n",
      "    \"bigbench/sentence_ambiguity\",\n",
      "    \"bigbench/vitaminc_fact_verification\",\n",
      "    \"bigbench/evaluating_information_essentiality\",\n",
      "    \"cos_e/v1.0\",\n",
      "    \"cosmos_qa\",\n",
      "    \"dream\",\n",
      "    \"openbookqa\",\n",
      "    \"qasc\",\n",
      "    \"quartz\",\n",
      "    \"quail\",\n",
      "    \"head_qa/en\",\n",
      "    \"sciq\",\n",
      "    \"social_i_qa\",\n",
      "    \"wiki_hop/original\",\n",
      "    \"wiqa\",\n",
      "    \"piqa\",\n",
      "    \"hellaswag\",\n",
      "    \"super_glue/copa\",\n",
      "    \"balanced-copa\",\n",
      "    \"e-CARE\",\n",
      "    \"art\",\n",
      "    \"winogrande/winogrande_xl\",\n",
      "    \"codah/codah\",\n",
      "    \"ai2_arc/ARC-Challenge/challenge\",\n",
      "    \"ai2_arc/ARC-Easy/challenge\",\n",
      "    \"definite_pronoun_resolution\",\n",
      "    \"swag/regular\",\n",
      "    \"math_qa\",\n",
      "    \"glue/cola\",\n",
      "    \"glue/sst2\",\n",
      "    \"utilitarianism\",\n",
      "    \"amazon_counterfactual/en\",\n",
      "    \"insincere-questions\",\n",
      "    \"toxic_conversations\",\n",
      "    \"TuringBench\",\n",
      "    \"trec\",\n",
      "    \"vitaminc/tals--vitaminc\",\n",
      "    \"hope_edi/english\",\n",
      "    \"rumoureval_2019/RumourEval2019\",\n",
      "    \"ethos/binary\",\n",
      "    \"ethos/multilabel\",\n",
      "    \"tweet_eval/sentiment\",\n",
      "    \"tweet_eval/irony\",\n",
      "    \"tweet_eval/offensive\",\n",
      "    \"tweet_eval/hate\",\n",
      "    \"tweet_eval/emotion\",\n",
      "    \"tweet_eval/emoji\",\n",
      "    \"tweet_eval/stance_abortion\",\n",
      "    \"tweet_eval/stance_atheism\",\n",
      "    \"tweet_eval/stance_climate\",\n",
      "    \"tweet_eval/stance_feminist\",\n",
      "    \"tweet_eval/stance_hillary\",\n",
      "    \"discovery/discovery\",\n",
      "    \"pragmeval/squinky-informativeness\",\n",
      "    \"pragmeval/emobank-arousal\",\n",
      "    \"pragmeval/switchboard\",\n",
      "    \"pragmeval/squinky-implicature\",\n",
      "    \"pragmeval/emobank-valence\",\n",
      "    \"pragmeval/mrda\",\n",
      "    \"pragmeval/squinky-formality\",\n",
      "    \"pragmeval/verifiability\",\n",
      "    \"pragmeval/emobank-dominance\",\n",
      "    \"pragmeval/persuasiveness-specificity\",\n",
      "    \"pragmeval/persuasiveness-strength\",\n",
      "    \"pragmeval/persuasiveness-claimtype\",\n",
      "    \"pragmeval/pdtb\",\n",
      "    \"pragmeval/sarcasm\",\n",
      "    \"pragmeval/stac\",\n",
      "    \"pragmeval/persuasiveness-premisetype\",\n",
      "    \"pragmeval/persuasiveness-eloquence\",\n",
      "    \"pragmeval/gum\",\n",
      "    \"pragmeval/emergent\",\n",
      "    \"pragmeval/persuasiveness-relevance\",\n",
      "    \"silicone/dyda_da\",\n",
      "    \"silicone/dyda_e\",\n",
      "    \"silicone/maptask\",\n",
      "    \"silicone/meld_e\",\n",
      "    \"silicone/meld_s\",\n",
      "    \"silicone/sem\",\n",
      "    \"silicone/oasis\",\n",
      "    \"silicone/iemocap\",\n",
      "    \"lex_glue/eurlex\",\n",
      "    \"lex_glue/scotus\",\n",
      "    \"lex_glue/ledgar\",\n",
      "    \"lex_glue/unfair_tos\",\n",
      "    \"lex_glue/case_hold\",\n",
      "    \"language-identification\",\n",
      "    \"imdb\",\n",
      "    \"rotten_tomatoes\",\n",
      "    \"ag_news\",\n",
      "    \"yelp_review_full/yelp_review_full\",\n",
      "    \"financial_phrasebank/sentences_allagree\",\n",
      "    \"poem_sentiment\",\n",
      "    \"dbpedia_14/dbpedia_14\",\n",
      "    \"amazon_polarity/amazon_polarity\",\n",
      "    \"app_reviews\",\n",
      "    \"hate_speech18\",\n",
      "    \"sms_spam\",\n",
      "    \"humicroedit/subtask-1\",\n",
      "    \"humicroedit/subtask-2\",\n",
      "    \"snips_built_in_intents\",\n",
      "    \"hate_speech_offensive\",\n",
      "    \"yahoo_answers_topics\",\n",
      "    \"stackoverflow-questions\",\n",
      "    \"hyperpartisan_news\",\n",
      "    \"sciie\",\n",
      "    \"citation_intent\",\n",
      "    \"go_emotions/simplified\",\n",
      "    \"scicite\",\n",
      "    \"liar\",\n",
      "    \"lexical_relation_classification/ROOT09\",\n",
      "    \"lexical_relation_classification/BLESS\",\n",
      "    \"lexical_relation_classification/CogALexV\",\n",
      "    \"lexical_relation_classification/EVALution\",\n",
      "    \"lexical_relation_classification/K&H+N\",\n",
      "    \"linguisticprobing/coordination_inversion\",\n",
      "    \"linguisticprobing/obj_number\",\n",
      "    \"linguisticprobing/past_present\",\n",
      "    \"linguisticprobing/sentence_length\",\n",
      "    \"linguisticprobing/subj_number\",\n",
      "    \"linguisticprobing/odd_man_out\",\n",
      "    \"linguisticprobing/tree_depth\",\n",
      "    \"linguisticprobing/top_constituents\",\n",
      "    \"linguisticprobing/bigram_shift\",\n",
      "    \"crowdflower/political-media-message\",\n",
      "    \"crowdflower/political-media-audience\",\n",
      "    \"crowdflower/economic-news\",\n",
      "    \"crowdflower/text_emotion\",\n",
      "    \"crowdflower/political-media-bias\",\n",
      "    \"crowdflower/airline-sentiment\",\n",
      "    \"crowdflower/tweet_global_warming\",\n",
      "    \"crowdflower/corporate-messaging\",\n",
      "    \"crowdflower/sentiment_nuclear_power\",\n",
      "    \"ethics/commonsense\",\n",
      "    \"ethics/deontology\",\n",
      "    \"ethics/justice\",\n",
      "    \"ethics/virtue\",\n",
      "    \"emo/emo2019\",\n",
      "    \"google_wellformed_query\",\n",
      "    \"tweets_hate_speech_detection\",\n",
      "    \"has_part\",\n",
      "    \"wnut_17/wnut_17\",\n",
      "    \"ncbi_disease/ncbi_disease\",\n",
      "    \"acronym_identification\",\n",
      "    \"jnlpba/jnlpba\",\n",
      "    \"ontonotes_english/SpeedOfMagic--ontonotes_english\",\n",
      "    \"blog_authorship_corpus/gender\",\n",
      "    \"blog_authorship_corpus/age\",\n",
      "    \"blog_authorship_corpus/job\",\n",
      "    \"open_question_type\",\n",
      "    \"health_fact\",\n",
      "    \"commonsense_qa\",\n",
      "    \"mc_taco\",\n",
      "    \"ade_corpus_v2/Ade_corpus_v2_classification\",\n",
      "    \"discosense\",\n",
      "    \"circa\",\n",
      "    \"phrase_similarity\",\n",
      "    \"scientific-exaggeration-detection\",\n",
      "    \"quarel\",\n",
      "    \"fever-evidence-related/mwong--fever-related\",\n",
      "    \"numer_sense\",\n",
      "    \"dynasent/dynabench.dynasent.r1.all/r1\",\n",
      "    \"dynasent/dynabench.dynasent.r2.all/r2\",\n",
      "    \"Sarcasm_News_Headline\",\n",
      "    \"sem_eval_2010_task_8\",\n",
      "    \"auditor_review/demo-org--auditor_review\",\n",
      "    \"medmcqa\",\n",
      "    \"Dynasent_Disagreement\",\n",
      "    \"Politeness_Disagreement\",\n",
      "    \"SBIC_Disagreement\",\n",
      "    \"SChem_Disagreement\",\n",
      "    \"Dilemmas_Disagreement\",\n",
      "    \"logiqa\",\n",
      "    \"wiki_qa\",\n",
      "    \"cycic_classification\",\n",
      "    \"cycic_multiplechoice\",\n",
      "    \"sts-companion\",\n",
      "    \"commonsense_qa_2.0\",\n",
      "    \"lingnli\",\n",
      "    \"monotonicity-entailment\",\n",
      "    \"arct\",\n",
      "    \"scinli\",\n",
      "    \"naturallogic\",\n",
      "    \"onestop_qa\",\n",
      "    \"moral_stories/full\",\n",
      "    \"prost\",\n",
      "    \"dynahate\",\n",
      "    \"syntactic-augmentation-nli\",\n",
      "    \"autotnli\",\n",
      "    \"CONDAQA\",\n",
      "    \"webgpt_comparisons\",\n",
      "    \"synthetic-instruct-gptj-pairwise\",\n",
      "    \"scruples\",\n",
      "    \"wouldyourather\",\n",
      "    \"attempto-nli\",\n",
      "    \"defeasible-nli/snli\",\n",
      "    \"defeasible-nli/atomic\",\n",
      "    \"help-nli\",\n",
      "    \"nli-veridicality-transitivity\",\n",
      "    \"natural-language-satisfiability\",\n",
      "    \"lonli\",\n",
      "    \"dadc-limit-nli\",\n",
      "    \"FLUTE\",\n",
      "    \"strategy-qa\",\n",
      "    \"summarize_from_feedback/comparisons\",\n",
      "    \"folio\",\n",
      "    \"tomi-nli\",\n",
      "    \"avicenna\",\n",
      "    \"SHP\",\n",
      "    \"MedQA-USMLE-4-options-hf\",\n",
      "    \"wikimedqa/medwiki\",\n",
      "    \"cicero\",\n",
      "    \"CREAK\",\n",
      "    \"mutual\",\n",
      "    \"NeQA\",\n",
      "    \"quote-repetition\",\n",
      "    \"redefine-math\",\n",
      "    \"puzzte\",\n",
      "    \"implicatures\",\n",
      "    \"race/high\",\n",
      "    \"race/middle\",\n",
      "    \"race-c\",\n",
      "    \"spartqa-yn\",\n",
      "    \"spartqa-mchoice\",\n",
      "    \"temporal-nli\",\n",
      "    \"riddle_sense\",\n",
      "    \"clcd-english\",\n",
      "    \"twentyquestions\",\n",
      "    \"reclor\",\n",
      "    \"counterfactually-augmented-imdb\",\n",
      "    \"counterfactually-augmented-snli\",\n",
      "    \"cnli\",\n",
      "    \"boolq-natural-perturbations\",\n",
      "    \"acceptability-prediction\",\n",
      "    \"equate\",\n",
      "    \"ScienceQA_text_only\",\n",
      "    \"ekar_english\",\n",
      "    \"implicit-hate-stg1\",\n",
      "    \"chaos-mnli-ambiguity\",\n",
      "    \"headline_cause/en_simple\",\n",
      "    \"logiqa-2.0-nli\",\n",
      "    \"oasst1_dense_flat/quality\",\n",
      "    \"oasst1_dense_flat/toxicity\",\n",
      "    \"oasst1_dense_flat/helpfulness\",\n",
      "    \"PARARULE-Plus\",\n",
      "    \"mindgames\",\n",
      "    \"universal_dependencies/en_lines/deprel\",\n",
      "    \"universal_dependencies/en_partut/deprel\",\n",
      "    \"universal_dependencies/en_ewt/deprel\",\n",
      "    \"universal_dependencies/en_gum/deprel\",\n",
      "    \"ambient\",\n",
      "    \"path-naturalness-prediction\",\n",
      "    \"civil_comments/toxicity\",\n",
      "    \"civil_comments/severe_toxicity\",\n",
      "    \"civil_comments/obscene\",\n",
      "    \"civil_comments/threat\",\n",
      "    \"civil_comments/insult\",\n",
      "    \"civil_comments/identity_attack\",\n",
      "    \"civil_comments/sexual_explicit\",\n",
      "    \"cloth\",\n",
      "    \"dgen\",\n",
      "    \"oasst1_pairwise_rlhf_reward\",\n",
      "    \"I2D2\",\n",
      "    \"args_me\",\n",
      "    \"Touche23-ValueEval\",\n",
      "    \"starcon\",\n",
      "    \"banking77\",\n",
      "    \"ruletaker\",\n",
      "    \"lsat_qa/all\",\n",
      "    \"ConTRoL-nli\",\n",
      "    \"tracie\",\n",
      "    \"sherliic\",\n",
      "    \"sen-making/1\",\n",
      "    \"sen-making/2\",\n",
      "    \"winowhy\",\n",
      "    \"mbib-base/cognitive-bias\",\n",
      "    \"mbib-base/fake-news\",\n",
      "    \"mbib-base/gender-bias\",\n",
      "    \"mbib-base/hate-speech\",\n",
      "    \"mbib-base/linguistic-bias\",\n",
      "    \"mbib-base/political-bias\",\n",
      "    \"mbib-base/racial-bias\",\n",
      "    \"mbib-base/text-level-bias\",\n",
      "    \"robustLR\",\n",
      "    \"v1/gen_train234_test2to10\",\n",
      "    \"logical-fallacy\",\n",
      "    \"parade\",\n",
      "    \"cladder\",\n",
      "    \"subjectivity\",\n",
      "    \"MOH\",\n",
      "    \"VUAC\",\n",
      "    \"TroFi\",\n",
      "    \"sharc_modified/mod\",\n",
      "    \"conceptrules_v2\",\n",
      "    \"disrpt/eng.dep.scidtb.rels\",\n",
      "    \"conll2000\",\n",
      "    \"few-nerd/supervised\",\n",
      "    \"finer-139\",\n",
      "    \"zero-shot-label-nli\",\n",
      "    \"com2sense\",\n",
      "    \"scone\",\n",
      "    \"winodict\",\n",
      "    \"fool-me-twice\",\n",
      "    \"monli\",\n",
      "    \"corr2cause\",\n",
      "    \"lsat_qa/all\",\n",
      "    \"apt\",\n",
      "    \"twitter-financial-news-sentiment\",\n",
      "    \"icl-symbol-tuning-instruct\",\n",
      "    \"SpaceNLI\",\n",
      "    \"propsegment/nli\",\n",
      "    \"HatemojiBuild\",\n",
      "    \"regset\",\n",
      "    \"esci\",\n",
      "    \"chatbot_arena_conversations\",\n",
      "    \"dnd_style_intents\",\n",
      "    \"FLD.v2\",\n",
      "    \"SDOH-NLI\",\n",
      "    \"scifact_entailment\",\n",
      "    \"feasibilityQA\",\n",
      "    \"simple_pair\",\n",
      "    \"AdjectiveScaleProbe-nli\",\n",
      "    \"resnli\",\n",
      "    \"SpaRTUN\",\n",
      "    \"ReSQ\",\n",
      "    \"semantic_fragments_nli\",\n",
      "    \"dataset_train_nli\",\n",
      "    \"babi_nli\",\n",
      "    \"gen_debiased_nli\",\n",
      "    \"imppres/presupposition\",\n",
      "    \"/prag\",\n",
      "    \"blimp-2\",\n",
      "    \"mmlu-4\"\n",
      "  ],\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file /home/elson/3.1.1_deberta/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at /home/elson/3.1.1_deberta/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 16\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/3.1.1_deberta/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[ 0.9165  , -0.674   , -0.4978  ],\n",
      "       [ 1.725   , -0.613   , -1.671   ],\n",
      "       [ 2.273   , -1.712   , -2.727   ],\n",
      "       [ 0.3335  , -1.218   ,  1.063   ],\n",
      "       [ 1.139   , -0.753   , -0.7437  ],\n",
      "       [ 2.795   , -1.657   , -3.553   ],\n",
      "       [ 1.635   , -1.579   , -1.06    ],\n",
      "       [ 1.871   , -1.755   , -1.291   ],\n",
      "       [ 1.676   , -1.233   , -1.953   ],\n",
      "       [ 1.0625  , -1.098   , -0.697   ],\n",
      "       [ 2.117   , -1.922   , -1.586   ],\n",
      "       [ 1.763   , -1.367   , -1.068   ],\n",
      "       [ 0.8296  , -0.959   , -0.0659  ],\n",
      "       [ 1.932   , -1.916   , -1.352   ],\n",
      "       [ 1.125   , -1.045   , -0.3694  ],\n",
      "       [-0.03354 , -1.078   ,  1.443   ],\n",
      "       [ 1.513   , -0.552   , -1.976   ],\n",
      "       [ 1.781   , -0.979   , -1.643   ],\n",
      "       [ 2.385   , -1.611   , -2.086   ],\n",
      "       [ 0.7446  , -1.156   , -0.02411 ],\n",
      "       [ 1.093   , -0.6875  , -1.053   ],\n",
      "       [ 0.5176  , -0.3215  , -0.64    ],\n",
      "       [ 1.228   , -0.657   , -1.289   ],\n",
      "       [-0.27    , -1.09    ,  1.819   ],\n",
      "       [ 0.2588  , -1.204   ,  1.689   ],\n",
      "       [-0.9385  , -0.4697  ,  1.99    ],\n",
      "       [ 2.1     , -1.051   , -2.176   ],\n",
      "       [ 1.14    , -0.316   , -0.968   ],\n",
      "       [ 2.2     , -1.149   , -2.61    ],\n",
      "       [ 1.614   , -1.205   , -1.554   ],\n",
      "       [-0.10297 , -0.9272  ,  1.058   ],\n",
      "       [ 2.178   , -1.406   , -2.053   ],\n",
      "       [ 1.9795  , -0.962   , -1.722   ],\n",
      "       [ 1.813   , -0.9976  , -1.598   ],\n",
      "       [ 0.2401  , -0.9644  , -0.0991  ],\n",
      "       [ 1.372   , -0.3435  , -1.772   ],\n",
      "       [ 0.6577  , -0.7847  ,  0.1694  ],\n",
      "       [ 1.466   , -1.185   , -1.408   ],\n",
      "       [-0.2311  , -1.073   ,  1.848   ],\n",
      "       [ 1.549   , -0.3352  , -2.076   ],\n",
      "       [-0.341   , -1.032   ,  2.04    ],\n",
      "       [ 1.492   , -0.5117  , -1.898   ],\n",
      "       [ 0.754   , -0.577   , -0.5527  ],\n",
      "       [-0.09045 , -0.7925  ,  1.516   ],\n",
      "       [ 0.463   , -0.7725  , -0.356   ],\n",
      "       [ 1.546   , -0.428   , -1.456   ],\n",
      "       [ 0.651   , -0.9326  , -0.3538  ],\n",
      "       [ 1.097   , -0.9956  , -0.4834  ],\n",
      "       [ 1.717   , -1.122   , -1.623   ],\n",
      "       [-0.1781  , -1.353   ,  2.193   ],\n",
      "       [ 0.7695  , -0.709   , -0.3237  ],\n",
      "       [ 1.862   , -0.7837  , -1.77    ],\n",
      "       [ 1.29    , -1.216   , -0.8564  ],\n",
      "       [ 1.602   , -1.235   , -1.163   ],\n",
      "       [-0.3088  , -0.4165  ,  0.9053  ],\n",
      "       [ 0.9995  , -1.066   , -0.355   ],\n",
      "       [-0.2017  ,  0.1882  ,  0.4814  ],\n",
      "       [ 1.846   , -0.1964  , -2.521   ],\n",
      "       [ 0.3125  , -1.009   ,  0.0757  ],\n",
      "       [ 2.531   , -1.869   , -2.574   ],\n",
      "       [ 1.82    , -0.9854  , -1.858   ],\n",
      "       [-0.3523  , -1.451   ,  2.463   ],\n",
      "       [ 1.378   , -0.429   , -1.6455  ],\n",
      "       [ 1.39    , -0.9634  , -1.016   ],\n",
      "       [ 1.218   , -0.3418  , -1.596   ],\n",
      "       [ 2.242   , -1.521   , -2.543   ],\n",
      "       [ 1.326   , -0.872   , -1.273   ],\n",
      "       [ 2.13    , -2.102   , -1.706   ],\n",
      "       [ 1.556   , -1.523   , -0.923   ],\n",
      "       [ 0.1404  , -1.026   ,  1.005   ],\n",
      "       [ 0.6455  , -0.44    , -0.3389  ],\n",
      "       [ 0.6943  , -0.6694  , -0.2512  ],\n",
      "       [ 1.257   , -0.2207  , -1.499   ],\n",
      "       [ 0.7046  , -0.8413  , -0.07056 ],\n",
      "       [-0.3875  , -0.3733  ,  0.6714  ],\n",
      "       [ 0.4385  , -0.6714  ,  0.467   ],\n",
      "       [ 1.454   , -1.082   , -1.002   ],\n",
      "       [ 1.698   , -0.881   , -1.605   ],\n",
      "       [ 2.25    , -2.014   , -1.816   ],\n",
      "       [ 0.01741 , -1.045   ,  0.8345  ],\n",
      "       [ 1.875   , -1.495   , -1.629   ],\n",
      "       [ 1.655   , -1.054   , -1.4795  ],\n",
      "       [ 1.586   , -0.9688  , -1.408   ],\n",
      "       [ 2.281   , -2.08    , -2.213   ],\n",
      "       [ 2.121   , -1.376   , -2.314   ],\n",
      "       [ 0.07355 , -1.407   ,  0.916   ],\n",
      "       [ 1.773   , -1.546   , -1.292   ],\n",
      "       [ 0.435   , -0.526   ,  0.3013  ],\n",
      "       [ 1.113   , -0.4507  , -1.213   ],\n",
      "       [ 1.378   , -0.429   , -1.6455  ],\n",
      "       [ 2.129   , -1.555   , -2.818   ],\n",
      "       [ 1.943   , -1.379   , -2.12    ],\n",
      "       [ 0.3306  , -1.803   ,  1.899   ],\n",
      "       [ 0.842   , -0.403   , -0.5464  ],\n",
      "       [ 1.346   , -0.587   , -1.317   ],\n",
      "       [ 0.739   , -0.4946  , -0.504   ],\n",
      "       [ 0.4807  , -0.6772  ,  0.1744  ],\n",
      "       [ 1.656   , -0.5986  , -1.879   ],\n",
      "       [ 2.229   , -1.804   , -2.117   ],\n",
      "       [ 2.201   , -1.209   , -2.666   ],\n",
      "       [ 0.381   , -1.638   ,  2.115   ],\n",
      "       [ 1.599   , -0.4038  , -1.855   ],\n",
      "       [ 2.08    , -1.205   , -2.578   ],\n",
      "       [ 1.467   , -0.542   , -1.989   ],\n",
      "       [-0.2104  , -0.2915  ,  0.833   ],\n",
      "       [ 1.841   , -1.219   , -1.844   ],\n",
      "       [ 1.089   , -0.9062  , -0.7173  ],\n",
      "       [ 0.1366  , -0.4495  ,  0.661   ],\n",
      "       [ 1.753   , -1.194   , -1.852   ],\n",
      "       [ 1.764   , -1.2705  , -1.77    ],\n",
      "       [ 1.744   , -1.326   , -1.508   ],\n",
      "       [ 1.996   , -1.682   , -1.622   ],\n",
      "       [ 1.59    , -1.049   , -1.445   ],\n",
      "       [ 1.537   , -1.202   , -1.269   ],\n",
      "       [ 2.312   , -1.192   , -2.846   ],\n",
      "       [ 1.537   , -1.081   , -1.528   ],\n",
      "       [ 1.935   , -1.874   , -1.043   ],\n",
      "       [ 0.452   , -0.8096  ,  0.317   ],\n",
      "       [ 2.264   , -1.968   , -1.9795  ],\n",
      "       [ 1.544   , -0.888   , -1.449   ],\n",
      "       [ 1.788   , -0.8774  , -2.148   ],\n",
      "       [ 1.705   , -1.263   , -1.639   ],\n",
      "       [ 1.537   , -0.5303  , -1.908   ],\n",
      "       [ 1.181   , -0.725   , -1.419   ],\n",
      "       [ 1.443   , -0.9263  , -1.171   ],\n",
      "       [ 1.128   , -0.996   , -0.6133  ],\n",
      "       [ 0.4954  , -0.5073  , -0.09674 ],\n",
      "       [ 2.375   , -1.767   , -2.586   ],\n",
      "       [ 1.137   , -0.7827  , -1.426   ],\n",
      "       [ 1.367   , -0.757   , -1.212   ],\n",
      "       [ 0.7563  , -0.94    ,  0.1489  ],\n",
      "       [-0.55    , -0.6094  ,  1.791   ],\n",
      "       [ 1.303   , -1.163   , -0.7896  ],\n",
      "       [ 0.2312  , -1.121   ,  1.066   ],\n",
      "       [ 1.831   , -1.138   , -2.342   ],\n",
      "       [ 0.401   , -0.5317  ,  0.1232  ],\n",
      "       [ 0.014305, -1.1     ,  0.827   ],\n",
      "       [ 0.3242  , -0.9863  ,  1.047   ],\n",
      "       [-0.36    , -0.2388  ,  0.754   ],\n",
      "       [ 2.443   , -1.399   , -2.959   ],\n",
      "       [ 1.468   , -0.4463  , -1.314   ],\n",
      "       [ 1.655   , -1.458   , -1.577   ],\n",
      "       [ 1.201   , -0.607   , -1.218   ],\n",
      "       [ 2.52    , -1.59    , -2.326   ],\n",
      "       [ 0.806   , -1.205   ,  0.3757  ],\n",
      "       [ 1.922   , -1.077   , -1.865   ],\n",
      "       [-0.268   , -0.741   ,  1.874   ],\n",
      "       [ 0.1506  , -1.434   ,  1.642   ],\n",
      "       [ 0.2041  , -0.1823  ,  0.1692  ],\n",
      "       [ 0.4465  , -0.9907  ,  0.5923  ],\n",
      "       [ 0.6113  , -0.6123  , -0.022   ],\n",
      "       [ 1.967   , -1.673   , -2.346   ],\n",
      "       [ 2.383   , -1.389   , -2.926   ],\n",
      "       [ 1.576   , -1.028   , -1.305   ],\n",
      "       [ 1.961   , -0.7593  , -2.3     ],\n",
      "       [ 2.324   , -2.031   , -2.084   ],\n",
      "       [ 1.72    , -1.713   , -1.43    ],\n",
      "       [ 0.422   , -0.553   ,  0.1604  ],\n",
      "       [ 0.173   , -0.739   ,  0.637   ],\n",
      "       [-0.4414  , -0.848   ,  2.055   ],\n",
      "       [-0.76    , -0.5054  ,  1.626   ],\n",
      "       [ 0.04047 , -1.562   ,  2.297   ],\n",
      "       [ 2.213   , -1.677   , -2.12    ],\n",
      "       [-0.1287  , -0.3875  ,  1.298   ],\n",
      "       [ 1.205   , -1.222   , -0.771   ],\n",
      "       [ 0.92    , -0.772   , -0.382   ],\n",
      "       [ 0.859   , -0.4504  , -1.169   ],\n",
      "       [-0.6284  , -0.724   ,  2.04    ],\n",
      "       [ 0.01671 , -1.057   ,  1.845   ],\n",
      "       [ 0.494   , -0.7363  ,  0.063   ],\n",
      "       [-0.991   , -0.2429  ,  1.769   ],\n",
      "       [ 0.88    , -1.608   ,  0.4175  ],\n",
      "       [-0.1667  , -0.2832  ,  0.739   ],\n",
      "       [ 2.152   , -1.822   , -2.102   ],\n",
      "       [ 1.862   , -0.695   , -1.808   ],\n",
      "       [-0.2634  , -0.7876  ,  1.05    ],\n",
      "       [ 1.821   , -1.301   , -1.727   ],\n",
      "       [ 0.3403  , -1.121   ,  1.049   ],\n",
      "       [ 1.794   , -1.008   , -2.371   ],\n",
      "       [ 0.1677  , -0.7524  ,  0.4688  ],\n",
      "       [-0.655   , -0.4937  ,  1.569   ],\n",
      "       [-0.2583  , -0.1914  ,  0.905   ],\n",
      "       [ 0.0552  , -1.216   ,  1.572   ],\n",
      "       [ 1.419   , -0.545   , -1.544   ],\n",
      "       [ 0.5967  , -0.4294  , -0.6914  ],\n",
      "       [ 2.217   , -1.393   , -1.851   ],\n",
      "       [ 1.418   , -0.869   , -1.057   ],\n",
      "       [ 1.207   , -0.543   , -1.376   ],\n",
      "       [ 1.019   , -0.759   , -0.4897  ],\n",
      "       [ 2.303   , -1.3125  , -2.1     ],\n",
      "       [ 0.0457  , -0.476   ,  0.1862  ],\n",
      "       [ 1.28    , -0.7505  , -1.282   ],\n",
      "       [ 1.16    , -1.175   , -0.5825  ],\n",
      "       [ 1.527   , -1.035   , -1.089   ],\n",
      "       [ 0.4368  , -1.644   ,  1.829   ],\n",
      "       [ 2.523   , -1.598   , -2.496   ],\n",
      "       [ 1.302   , -0.4119  , -1.656   ],\n",
      "       [ 2.088   , -1.123   , -2.492   ],\n",
      "       [ 2.162   , -1.883   , -2.049   ],\n",
      "       [ 1.056   , -0.726   , -0.8994  ],\n",
      "       [ 1.726   , -1.939   , -0.7007  ],\n",
      "       [ 1.888   , -0.6665  , -2.139   ],\n",
      "       [ 1.082   , -0.862   , -0.9033  ],\n",
      "       [ 1.516   , -0.944   , -1.946   ],\n",
      "       [-0.1853  , -0.31    ,  0.4905  ],\n",
      "       [-0.484   , -0.8975  ,  2.062   ],\n",
      "       [ 2.621   , -1.906   , -2.654   ],\n",
      "       [ 1.706   , -1.2     , -1.311   ],\n",
      "       [ 2.25    , -1.676   , -2.4     ],\n",
      "       [ 2.133   , -1.263   , -2.414   ],\n",
      "       [ 0.8594  , -0.774   , -0.255   ],\n",
      "       [ 1.27    , -0.8184  , -1.094   ],\n",
      "       [ 2.102   , -1.616   , -1.745   ],\n",
      "       [ 1.546   , -1.189   , -1.856   ],\n",
      "       [ 2.158   , -1.183   , -2.514   ],\n",
      "       [-0.4236  , -0.513   ,  1.219   ],\n",
      "       [-0.02632 , -0.4343  ,  0.5757  ],\n",
      "       [ 0.4631  , -0.9185  ,  0.713   ],\n",
      "       [ 2.53    , -1.411   , -2.71    ],\n",
      "       [ 0.1461  , -0.749   ,  0.993   ],\n",
      "       [ 2.682   , -1.712   , -2.834   ],\n",
      "       [ 1.7     , -0.5405  , -1.483   ],\n",
      "       [ 1.6875  , -1.035   , -1.474   ],\n",
      "       [ 2.117   , -1.632   , -1.867   ],\n",
      "       [ 1.556   , -0.7847  , -2.107   ],\n",
      "       [ 2.791   , -1.459   , -3.617   ],\n",
      "       [ 2.078   , -1.84    , -1.684   ],\n",
      "       [-0.1354  , -1.283   ,  1.46    ],\n",
      "       [ 1.361   , -1.089   , -0.749   ],\n",
      "       [ 0.4297  , -0.799   ,  0.3271  ],\n",
      "       [ 1.9795  , -1.043   , -2.137   ],\n",
      "       [ 2.305   , -1.379   , -2.596   ],\n",
      "       [ 1.859   , -1.      , -2.27    ],\n",
      "       [ 1.137   , -0.934   , -0.6045  ]], dtype=float16), label_ids=array([0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 2,\n",
      "       0, 1, 2, 2, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 2, 1, 0, 0,\n",
      "       0, 2, 0, 0, 2, 2, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 2, 1, 0, 1, 2,\n",
      "       0, 0, 2, 2, 0, 0, 1, 1, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "       2, 1, 0, 0, 2, 0, 0, 0, 2, 0, 0, 1, 2, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "       1, 0, 1, 0, 1, 0, 0, 0, 2, 2, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2,\n",
      "       0, 1, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 2, 2, 0, 0, 0, 0, 1, 1,\n",
      "       0, 0, 0, 1, 0, 2, 2, 2, 0, 0, 0, 1, 0, 0, 2, 0, 2, 0, 1, 0, 0, 0,\n",
      "       0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 1, 0, 0, 0, 0, 1, 1, 2, 0, 0,\n",
      "       0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 2]), metrics={'test_loss': 0.9396482110023499, 'test_accuracy': 0.6452991452991453, 'test_precision': 0.5322886989553657, 'test_recall': 0.6452991452991453, 'test_f1': 0.5832847707847708, 'test_runtime': 2.1408, 'test_samples_per_second': 109.303, 'test_steps_per_second': 7.007})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
