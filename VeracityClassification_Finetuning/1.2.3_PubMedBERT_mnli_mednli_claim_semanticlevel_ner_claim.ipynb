{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score,balanced_accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82806f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jul 29 18:07:37 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:61:00.0 Off |                    0 |\n",
      "| N/A   45C    P0    57W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  Off  | 00000000:62:00.0 Off |                    0 |\n",
      "| N/A   46C    P0    58W / 300W |  23156MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  Off  | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   45C    P0    61W / 300W |      0MiB / 32768MiB |      2%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  Off  | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   48C    P0    61W / 300W |  23156MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    1   N/A  N/A      7950      C   ...son/factcheck/bin/python3    23153MiB |\n",
      "|    3   N/A  N/A     16579      C   ...son/factcheck/bin/python3    23153MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-31dfe7adddcf5ced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 2457.12it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 473.13it/s]\n",
      "                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 205.65it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 20.33ba/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 21.01ba/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 20.98ba/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset from the CSV file\n",
    "dataset = load_dataset(\n",
    "    'csv',\n",
    "    data_files='dataset_semanticattribution_nerfeatures_split.csv',\n",
    "    delimiter=',',\n",
    "    column_names=[\n",
    "        \"claim\", \"premise\", \"label\", \"category\", \"count_bf\", \"count_ca\", \"count_dis\",\n",
    "        \"count_food\", \"count_lipid\", \"count_treat\", \"pres_bf\", \"pres_ca\", \"pres_dis\",\n",
    "        \"pres_food\", \"pres_lipid\", \"pres_treat\", \"counte_bf\", \"counte_ca\", \"counte_dis\",\n",
    "        \"counte_food\", \"counte_lipid\", \"counte_treat\", \"prese_bf\", \"prese_ca\", \"prese_dis\",\n",
    "        \"prese_food\", \"prese_lipid\", \"prese_treat\", \"url\", \"entities\", \"entity_map\",\n",
    "        \"gold_exp\", \"gemini_exp\", \"gemini_label\",\"entity_ev\",\"entity_map_ev\", \"split\"\n",
    "    ],\n",
    "    skiprows=1\n",
    ")\n",
    "\n",
    "# Assuming 'split' column contains strings 'train', 'validation', 'test'\n",
    "# Filter the loaded dataset into subsets\n",
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'gold_exp', 'gemini_exp', 'gemini_label', 'entity_ev', 'entity_map_ev', 'split'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f3e71be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41f1db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['claim', 'premise', 'label','category','count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat']\n",
    "all_columns = train_dataset.column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1623/1623 [00:00<00:00, 4308.28ex/s]\n",
      "100%|██████████| 465/465 [00:00<00:00, 4560.66ex/s]\n",
      "100%|██████████| 234/234 [00:00<00:00, 4414.72ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 0, 'entailment': 1, 'neutral': 2}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 0,\n",
    "    \"entailment\": 1,\n",
    "    \"neutral\": 2\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b5bb17f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "465"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['val']['claim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='pritamdeka/PubMedBERT-MNLI-MedNLI'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "\n",
    "        claim = item['claim']\n",
    "        premise = item['premise'].replace('\\n', '').replace('[','').replace(']','')\n",
    "        additional_features = [\n",
    "            \"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\"]\n",
    "    \n",
    "        for feature in additional_features:\n",
    "            if feature in item:\n",
    "                claim += \"[SEP]\" + str(item[feature])\n",
    "        item['claim']=claim\n",
    "        item['premise']=premise        \n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "             premise, claim,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "        item['input_ids'] = inputs['input_ids'].squeeze()  # Remove batch dimension\n",
    "        item['attention_mask']= inputs['attention_mask'].squeeze() # Remove batch dimension\n",
    "        \n",
    "        output_item = {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),  # Remove batch dimension\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),  # Remove batch dimension\n",
    "            'claim': claim,  # Include augmented claim text\n",
    "            'evidences': premise  # Include original evidence text\n",
    "        }\n",
    "        \n",
    "        if 'label' in item:\n",
    "            output_item['label'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return output_item\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62421eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"pritamdeka/PubMedBERT-MNLI-MedNLI\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=3, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f72c5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model is on device: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    bal_accuracy = balanced_accuracy_score(labels,preds)\n",
    "\n",
    "    return {\"accuracy\": acc, \"balanced_accuracy\":bal_accuracy, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17c5e0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([    2,    31,  2067, 29949,  2126,   240,    16,    56,    18,    31,\n",
       "          3363,  7369,  1019,   240,    16,    51,    18,    31,  7626,  5025,\n",
       "           240,  6235,  2165,  1019,   240,    16,    58,    18,    31,  4357,\n",
       "         23663,  1970, 25210,  1019,   240,    16,    55,    18,    31, 17725,\n",
       "          1037, 12518,  2165,  1019,   240,    16,    57,    18,    31, 28193,\n",
       "          8323, 12518,  2165,  1019,   240,    16,    52,    18, 14542,  4006,\n",
       "          4480,  1930, 14227,  5004,  4415, 16984,  1930, 10659,  2043,  4480,\n",
       "         13203,  1021,  3316,  2703,    17, 22248,  1927, 27041, 11638,  1036,\n",
       "            18,  8236,  5182,  1035,    16,    51,    18, 22719,    10,  4272,\n",
       "          9322,  1927, 26503,  4340,  7369,    12,    18,  5163,  3071,  1930,\n",
       "          6595,  4575, 18068,  1030,  2564,  1927,  2949,  1930,  2310, 11963,\n",
       "          1943,  1956, 14227,  5004,    12,  2689,  6285,  8846,  2629, 12492,\n",
       "          1024,    13, 19490,    18,  4415, 16984,    30,  9624,  2046, 18056,\n",
       "          1958,  4407,  2859,    18, 13297, 21783, 15777,  7446,  1012,    16,\n",
       "            56,    18,    31, 16080, 22284,  1029,    16,    45,    18,    31,\n",
       "         28374, 29834,    16,    52,    18,    31,  3009,  5002,    16,    57,\n",
       "            18,    31, 28098,    16,    55,    18,  5819,  6202,  2007,  4613,\n",
       "          4461,    30,    45,    18, 14227,  5004,  1019,  6691,  4072,  8147,\n",
       "         12709, 16527,    18,  8616,  1960,  7056,  1949,    16,    60,    18,\n",
       "            31,  8616,  1960,  7056,  1949,    16,    61,    18,    31,  8616,\n",
       "          1960,  7056,  1949,    16,    55,    18,    31, 26043,  5148,  3027,\n",
       "            16,    55,    18, 14542,  4006,  4480,    12,    43,  1574,  1216,\n",
       "          1021,  1793,  1062,  7399,   237, 27645,  2029,    31,    18,  3038,\n",
       "            13,    30,  2037,  1920,  4367,  1927,  6378,  5990,  1942,  1920,\n",
       "          4008, 25512, 20512,  1958,  1920,  5455,  1930,  2311,  1927,  7433,\n",
       "          3902,    18, 10021,  1930, 18659,  2455,  1927, 14542,  4006,  4480,\n",
       "          6691,    18, 15926,  3165, 16159, 11324,  2126,  6391,    18,    31,\n",
       "          9108,    16,    47,    18, 14542,  4006,  4480,  1930, 14227,  5004,\n",
       "          1966, 17186,  2062,  1922,  3069,    18,     3, 14227,  5004,  4415,\n",
       "          6691,  1977,  8929,  2251,  1922,  4407,  5715,  4461,  1942,  4087,\n",
       "          3326,  1920,  7818,  1927,  1920,  4407,    18,     3,    20,     3,\n",
       "            20,     3,    20,     3,    20,     3,    20,     3,    20,     3,\n",
       "            20,     3,    20,     3,    20,     3,    20,     3,    20,     3,\n",
       "            20,     3,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'claim': 'Myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0',\n",
       " 'evidences': '; UnkoviÄ‡, N.; DimkiÄ‡, I.; JanaÄ‡koviÄ‡, P.; GavriloviÄ‡, M.; StanojeviÄ‡, O.; VukojeviÄ‡, J. Frankincense and myrrh essential oils and burn incense fume against micro-inhabitants of sacral ambients.Shameem, I. Phytochemical & therapeutic potentials of Murr makki (.Oxidative stress and immunotoxic effects of lead and their amelioration with myrrh (Commiphora molmol) emulsion.Essential Oils: Magical Ingredients for Skin Care.Chakravarty, N.; Kellogg, C.; Alvarez, J.; Equils, O.; Morgan, M. UV Protection by Natural Products: C. myrrha Oil Versus Sunscreen.Hamidpour, R.; Hamidpour, S.; Hamidpour, M.; Shahlari, M. Frankincense (ä¹³é¦™ RÇ” XiÄ\\x81ng;.species): From the selection of traditional applications to the novel phytotherapy for the prevention and treatment of serious diseases.Chemistry and immunomodulatory activity of frankincense oil.Compositions containing Boswellia extracts.; Cooper, E. Frankincense and myrrh as remedies in children.',\n",
       " 'label': tensor(1)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on device: cuda:0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='765' max='765' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [765/765 06:21, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.832700</td>\n",
       "      <td>0.864127</td>\n",
       "      <td>0.610753</td>\n",
       "      <td>0.506214</td>\n",
       "      <td>0.664907</td>\n",
       "      <td>0.610753</td>\n",
       "      <td>0.631466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.575400</td>\n",
       "      <td>0.968432</td>\n",
       "      <td>0.589247</td>\n",
       "      <td>0.475546</td>\n",
       "      <td>0.659441</td>\n",
       "      <td>0.589247</td>\n",
       "      <td>0.617875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.358400</td>\n",
       "      <td>1.145763</td>\n",
       "      <td>0.604301</td>\n",
       "      <td>0.467959</td>\n",
       "      <td>0.634273</td>\n",
       "      <td>0.604301</td>\n",
       "      <td>0.615167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.150600</td>\n",
       "      <td>1.666675</td>\n",
       "      <td>0.587097</td>\n",
       "      <td>0.497854</td>\n",
       "      <td>0.670397</td>\n",
       "      <td>0.587097</td>\n",
       "      <td>0.617826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.191000</td>\n",
       "      <td>1.978906</td>\n",
       "      <td>0.632258</td>\n",
       "      <td>0.513442</td>\n",
       "      <td>0.659835</td>\n",
       "      <td>0.632258</td>\n",
       "      <td>0.632914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.098300</td>\n",
       "      <td>1.840359</td>\n",
       "      <td>0.632258</td>\n",
       "      <td>0.515154</td>\n",
       "      <td>0.659609</td>\n",
       "      <td>0.632258</td>\n",
       "      <td>0.636071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.060400</td>\n",
       "      <td>2.329692</td>\n",
       "      <td>0.591398</td>\n",
       "      <td>0.482965</td>\n",
       "      <td>0.649676</td>\n",
       "      <td>0.591398</td>\n",
       "      <td>0.614020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.060400</td>\n",
       "      <td>2.528706</td>\n",
       "      <td>0.597849</td>\n",
       "      <td>0.494418</td>\n",
       "      <td>0.664559</td>\n",
       "      <td>0.597849</td>\n",
       "      <td>0.621250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.057300</td>\n",
       "      <td>2.366485</td>\n",
       "      <td>0.640860</td>\n",
       "      <td>0.496549</td>\n",
       "      <td>0.650910</td>\n",
       "      <td>0.640860</td>\n",
       "      <td>0.643224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.016300</td>\n",
       "      <td>2.580070</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>0.503202</td>\n",
       "      <td>0.650629</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>0.636426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>2.856714</td>\n",
       "      <td>0.608602</td>\n",
       "      <td>0.509005</td>\n",
       "      <td>0.662737</td>\n",
       "      <td>0.608602</td>\n",
       "      <td>0.625674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>2.861682</td>\n",
       "      <td>0.623656</td>\n",
       "      <td>0.516732</td>\n",
       "      <td>0.657273</td>\n",
       "      <td>0.623656</td>\n",
       "      <td>0.635756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>2.898526</td>\n",
       "      <td>0.630108</td>\n",
       "      <td>0.519938</td>\n",
       "      <td>0.660604</td>\n",
       "      <td>0.630108</td>\n",
       "      <td>0.641310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>2.951333</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.509927</td>\n",
       "      <td>0.662637</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.630541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>2.917884</td>\n",
       "      <td>0.623656</td>\n",
       "      <td>0.512592</td>\n",
       "      <td>0.659038</td>\n",
       "      <td>0.623656</td>\n",
       "      <td>0.636389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.3_pubmedbert/checkpoint-51\n",
      "Configuration saved in /home/elson/1.2.3_pubmedbert/checkpoint-51/config.json\n",
      "Model weights saved in /home/elson/1.2.3_pubmedbert/checkpoint-51/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.3_pubmedbert/checkpoint-102\n",
      "Configuration saved in /home/elson/1.2.3_pubmedbert/checkpoint-102/config.json\n",
      "Model weights saved in /home/elson/1.2.3_pubmedbert/checkpoint-102/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.3_pubmedbert/checkpoint-153\n",
      "Configuration saved in /home/elson/1.2.3_pubmedbert/checkpoint-153/config.json\n",
      "Model weights saved in /home/elson/1.2.3_pubmedbert/checkpoint-153/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.2.3_pubmedbert/checkpoint-102] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.3_pubmedbert/checkpoint-204\n",
      "Configuration saved in /home/elson/1.2.3_pubmedbert/checkpoint-204/config.json\n",
      "Model weights saved in /home/elson/1.2.3_pubmedbert/checkpoint-204/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.2.3_pubmedbert/checkpoint-153] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.3_pubmedbert/checkpoint-255\n",
      "Configuration saved in /home/elson/1.2.3_pubmedbert/checkpoint-255/config.json\n",
      "Model weights saved in /home/elson/1.2.3_pubmedbert/checkpoint-255/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.2.3_pubmedbert/checkpoint-51] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/1.2.3_pubmedbert/checkpoint-204] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.3_pubmedbert/checkpoint-306\n",
      "Configuration saved in /home/elson/1.2.3_pubmedbert/checkpoint-306/config.json\n",
      "Model weights saved in /home/elson/1.2.3_pubmedbert/checkpoint-306/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.3_pubmedbert/checkpoint-357\n",
      "Configuration saved in /home/elson/1.2.3_pubmedbert/checkpoint-357/config.json\n",
      "Model weights saved in /home/elson/1.2.3_pubmedbert/checkpoint-357/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.2.3_pubmedbert/checkpoint-306] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.3_pubmedbert/checkpoint-408\n",
      "Configuration saved in /home/elson/1.2.3_pubmedbert/checkpoint-408/config.json\n",
      "Model weights saved in /home/elson/1.2.3_pubmedbert/checkpoint-408/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.2.3_pubmedbert/checkpoint-357] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.3_pubmedbert/checkpoint-459\n",
      "Configuration saved in /home/elson/1.2.3_pubmedbert/checkpoint-459/config.json\n",
      "Model weights saved in /home/elson/1.2.3_pubmedbert/checkpoint-459/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.2.3_pubmedbert/checkpoint-255] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/1.2.3_pubmedbert/checkpoint-408] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.3_pubmedbert/checkpoint-510\n",
      "Configuration saved in /home/elson/1.2.3_pubmedbert/checkpoint-510/config.json\n",
      "Model weights saved in /home/elson/1.2.3_pubmedbert/checkpoint-510/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.3_pubmedbert/checkpoint-561\n",
      "Configuration saved in /home/elson/1.2.3_pubmedbert/checkpoint-561/config.json\n",
      "Model weights saved in /home/elson/1.2.3_pubmedbert/checkpoint-561/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.2.3_pubmedbert/checkpoint-510] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.3_pubmedbert/checkpoint-612\n",
      "Configuration saved in /home/elson/1.2.3_pubmedbert/checkpoint-612/config.json\n",
      "Model weights saved in /home/elson/1.2.3_pubmedbert/checkpoint-612/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.2.3_pubmedbert/checkpoint-561] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.3_pubmedbert/checkpoint-663\n",
      "Configuration saved in /home/elson/1.2.3_pubmedbert/checkpoint-663/config.json\n",
      "Model weights saved in /home/elson/1.2.3_pubmedbert/checkpoint-663/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.2.3_pubmedbert/checkpoint-612] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.3_pubmedbert/checkpoint-714\n",
      "Configuration saved in /home/elson/1.2.3_pubmedbert/checkpoint-714/config.json\n",
      "Model weights saved in /home/elson/1.2.3_pubmedbert/checkpoint-714/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.2.3_pubmedbert/checkpoint-663] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.3_pubmedbert/checkpoint-765\n",
      "Configuration saved in /home/elson/1.2.3_pubmedbert/checkpoint-765/config.json\n",
      "Model weights saved in /home/elson/1.2.3_pubmedbert/checkpoint-765/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.2.3_pubmedbert/checkpoint-714] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/elson/1.2.3_pubmedbert/checkpoint-459 (score: 0.6408602150537634).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /home/elson/1.2.3_pubmedbert/best_model/config.json\n",
      "Model weights saved in /home/elson/1.2.3_pubmedbert/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/1.2.3_pubmedbert/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/1.2.3_pubmedbert/best_model/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/1.2.3_pubmedbert/best_model/tokenizer_config.json',\n",
       " '/home/elson/1.2.3_pubmedbert/best_model/special_tokens_map.json',\n",
       " '/home/elson/1.2.3_pubmedbert/best_model/vocab.txt',\n",
       " '/home/elson/1.2.3_pubmedbert/best_model/added_tokens.json',\n",
       " '/home/elson/1.2.3_pubmedbert/best_model/tokenizer.json')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/1.2.3_pubmedbert/',\n",
    "    num_train_epochs=15,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.1,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(\"cuda:0\"),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "print(f\"Model is on device: {next(model.parameters()).device}\")\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/1.2.3_pubmedbert/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/1.2.3_pubmedbert/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cdee1665",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/1.2.3_pubmedbert/best_model/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"/home/elson/1.2.3_pubmedbert/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"contradiction\",\n",
      "    \"1\": \"entailment\",\n",
      "    \"2\": \"neutral\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"contradiction\": 0,\n",
      "    \"entailment\": 1,\n",
      "    \"neutral\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file /home/elson/1.2.3_pubmedbert/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at /home/elson/1.2.3_pubmedbert/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 32\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/1.2.3_pubmedbert/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[-0.3381 ,  1.906  , -2.553  ],\n",
      "       [-3.959  ,  5.715  , -3.041  ],\n",
      "       [-4.11   ,  6.023  , -3.246  ],\n",
      "       [ 3.684  ,  1.467  , -5.113  ],\n",
      "       [ 1.231  ,  1.856  , -3.617  ],\n",
      "       [-3.994  ,  6.145  , -3.367  ],\n",
      "       [-4.477  ,  6.043  , -2.69   ],\n",
      "       [-3.807  ,  5.76   , -3.139  ],\n",
      "       [-4.434  ,  6.008  , -2.941  ],\n",
      "       [-1.673  ,  3.352  , -2.715  ],\n",
      "       [-3.307  ,  5.664  , -3.441  ],\n",
      "       [-3.695  ,  5.953  , -3.334  ],\n",
      "       [-4.082  ,  6.02   , -3.16   ],\n",
      "       [-3.658  ,  6.027  , -3.469  ],\n",
      "       [-4.99   ,  5.184  , -1.626  ],\n",
      "       [ 5.484  , -0.6646 , -4.227  ],\n",
      "       [-4.355  ,  6.105  , -3.086  ],\n",
      "       [-3.994  ,  6.195  , -3.385  ],\n",
      "       [-3.816  ,  6.04   , -3.307  ],\n",
      "       [-3.783  ,  6.223  , -3.531  ],\n",
      "       [-3.607  ,  6.004  , -3.658  ],\n",
      "       [-4.684  ,  5.562  , -2.38   ],\n",
      "       [-5.01   ,  3.066  ,  1.196  ],\n",
      "       [-1.524  , -3.338  ,  4.914  ],\n",
      "       [ 0.964  ,  3.436  , -4.832  ],\n",
      "       [ 3.422  , -1.751  , -1.295  ],\n",
      "       [-3.26   ,  6.09   , -3.785  ],\n",
      "       [-4.42   ,  5.824  , -2.79   ],\n",
      "       [-3.598  ,  4.793  , -2.566  ],\n",
      "       [-3.398  ,  6.145  , -3.756  ],\n",
      "       [-3.287  ,  2.656  ,  0.00702],\n",
      "       [-3.865  ,  6.168  , -3.445  ],\n",
      "       [-3.586  ,  6.11   , -3.586  ],\n",
      "       [-3.65   ,  2.156  ,  0.2129 ],\n",
      "       [-3.56   ,  4.67   , -2.535  ],\n",
      "       [-4.688  ,  5.887  , -2.633  ],\n",
      "       [-3.713  ,  6.137  , -3.586  ],\n",
      "       [-3.451  ,  6.066  , -3.643  ],\n",
      "       [ 3.71   ,  1.612  , -5.383  ],\n",
      "       [-4.02   ,  6.125  , -3.402  ],\n",
      "       [-0.3428 ,  4.21   , -5.008  ],\n",
      "       [-3.824  ,  6.176  , -3.482  ],\n",
      "       [-3.559  ,  6.023  , -3.613  ],\n",
      "       [ 1.662  ,  0.9604 , -2.865  ],\n",
      "       [-2.344  ,  1.61   , -0.0451 ],\n",
      "       [-3.809  ,  6.09   , -3.363  ],\n",
      "       [-1.88   ,  5.21   , -4.484  ],\n",
      "       [-3.602  ,  6.156  , -3.66   ],\n",
      "       [-3.291  ,  6.07   , -3.88   ],\n",
      "       [ 4.715  , -0.2886 , -3.586  ],\n",
      "       [-2.447  ,  5.406  , -4.     ],\n",
      "       [-4.13   ,  4.098  , -1.09   ],\n",
      "       [-0.4514 , -3.752  ,  4.547  ],\n",
      "       [-3.95   ,  6.2    , -3.422  ],\n",
      "       [-2.03   ,  4.613  , -3.777  ],\n",
      "       [-3.402  ,  6.156  , -3.773  ],\n",
      "       [-3.111  ,  2.88   , -0.4922 ],\n",
      "       [-4.88   ,  5.25   , -1.84   ],\n",
      "       [-2.72   ,  4.73   , -3.375  ],\n",
      "       [-3.707  ,  6.188  , -3.596  ],\n",
      "       [-4.027  ,  5.758  , -3.14   ],\n",
      "       [ 3.84   ,  0.837  , -4.22   ],\n",
      "       [-2.424  , -2.254  ,  4.75   ],\n",
      "       [ 2.494  ,  2.463  , -5.27   ],\n",
      "       [-3.88   ,  6.117  , -3.475  ],\n",
      "       [-3.287  ,  5.766  , -3.613  ],\n",
      "       [-3.262  ,  6.055  , -3.799  ],\n",
      "       [-3.1    ,  6.094  , -3.863  ],\n",
      "       [-3.654  ,  6.176  , -3.572  ],\n",
      "       [-2.117  ,  5.047  , -4.266  ],\n",
      "       [-4.406  ,  5.715  , -2.71   ],\n",
      "       [-4.11   ,  6.16   , -3.297  ],\n",
      "       [-4.855  ,  4.62   , -1.082  ],\n",
      "       [-2.787  ,  4.75   , -3.11   ],\n",
      "       [-4.09   ,  1.206  ,  1.55   ],\n",
      "       [-2.572  ,  5.605  , -4.105  ],\n",
      "       [-4.14   ,  6.043  , -3.066  ],\n",
      "       [-4.36   ,  5.88   , -2.953  ],\n",
      "       [-3.41   ,  6.13   , -3.732  ],\n",
      "       [-3.232  ,  5.73   , -3.65   ],\n",
      "       [-3.621  ,  6.13   , -3.637  ],\n",
      "       [-3.568  ,  6.004  , -3.63   ],\n",
      "       [-4.297  ,  6.04   , -3.018  ],\n",
      "       [-3.11   ,  5.95   , -3.846  ],\n",
      "       [-3.428  ,  5.938  , -3.625  ],\n",
      "       [-4.54   ,  3.988  , -0.658  ],\n",
      "       [-3.695  ,  5.95   , -3.465  ],\n",
      "       [-2.338  ,  5.55   , -4.383  ],\n",
      "       [-3.75   ,  4.89   , -2.943  ],\n",
      "       [-2.428  , -1.102  ,  3.314  ],\n",
      "       [-3.799  ,  6.047  , -3.562  ],\n",
      "       [-3.662  ,  6.113  , -3.578  ],\n",
      "       [ 1.907  ,  2.377  , -4.934  ],\n",
      "       [-3.654  ,  6.047  , -3.559  ],\n",
      "       [-1.454  ,  5.41   , -4.684  ],\n",
      "       [-3.553  ,  5.273  , -3.02   ],\n",
      "       [-2.83   ,  5.543  , -3.959  ],\n",
      "       [-2.762  ,  5.83   , -4.11   ],\n",
      "       [-3.71   ,  6.203  , -3.54   ],\n",
      "       [-3.676  ,  6.176  , -3.621  ],\n",
      "       [ 4.64   ,  0.6323 , -4.8    ],\n",
      "       [-4.023  ,  6.19   , -3.352  ],\n",
      "       [-3.81   ,  6.098  , -3.441  ],\n",
      "       [-4.547  ,  4.543  , -1.525  ],\n",
      "       [-4.188  ,  5.78   , -2.928  ],\n",
      "       [-3.52   ,  6.098  , -3.654  ],\n",
      "       [-3.338  ,  5.582  , -3.611  ],\n",
      "       [-4.453  ,  5.203  , -2.053  ],\n",
      "       [-3.303  ,  6.023  , -3.72   ],\n",
      "       [-3.705  ,  6.105  , -3.367  ],\n",
      "       [-1.57   ,  5.344  , -4.656  ],\n",
      "       [-4.074  ,  6.1    , -3.209  ],\n",
      "       [-3.98   ,  6.16   , -3.39   ],\n",
      "       [-4.062  ,  5.95   , -3.152  ],\n",
      "       [-3.639  ,  6.21   , -3.65   ],\n",
      "       [-3.807  ,  6.12   , -3.443  ],\n",
      "       [-3.85   ,  6.168  , -3.455  ],\n",
      "       [-2.803  , -2.021  ,  4.688  ],\n",
      "       [-2.96   ,  6.     , -4.035  ],\n",
      "       [-3.12   ,  5.83   , -4.02   ],\n",
      "       [-4.58   ,  5.324  , -2.072  ],\n",
      "       [-3.266  ,  4.996  , -2.727  ],\n",
      "       [-4.81   ,  4.383  , -1.058  ],\n",
      "       [-3.408  ,  5.637  , -3.475  ],\n",
      "       [-3.63   ,  6.164  , -3.633  ],\n",
      "       [-3.436  ,  6.12   , -3.77   ],\n",
      "       [-3.23   ,  5.797  , -3.637  ],\n",
      "       [-3.898  ,  6.184  , -3.482  ],\n",
      "       [-4.68   ,  5.707  , -2.559  ],\n",
      "       [-3.19   ,  5.78   , -3.475  ],\n",
      "       [-3.947  ,  4.355  , -1.743  ],\n",
      "       [ 2.883  ,  0.10974, -3.115  ],\n",
      "       [-3.729  ,  5.953  , -3.219  ],\n",
      "       [ 4.96   , -1.122  , -3.375  ],\n",
      "       [-3.701  ,  6.11   , -3.53   ],\n",
      "       [-4.19   ,  5.816  , -3.06   ],\n",
      "       [-2.332  ,  4.48   , -3.281  ],\n",
      "       [ 5.38   , -0.5127 , -4.41   ],\n",
      "       [ 0.849  ,  2.064  , -3.5    ],\n",
      "       [-2.725  , -2.498  ,  4.84   ],\n",
      "       [-3.45   ,  6.01   , -3.639  ],\n",
      "       [-3.977  ,  0.4792 ,  3.25   ],\n",
      "       [-3.479  ,  1.716  ,  0.6997 ],\n",
      "       [-3.365  ,  6.113  , -3.73   ],\n",
      "       [ 5.7    , -1.657  , -3.238  ],\n",
      "       [-4.332  ,  5.94   , -2.979  ],\n",
      "       [ 4.94   ,  0.12195, -4.742  ],\n",
      "       [-0.1492 ,  3.951  , -4.688  ],\n",
      "       [-3.068  ,  6.     , -3.986  ],\n",
      "       [-3.719  ,  3.611  , -1.179  ],\n",
      "       [-3.53   ,  6.043  , -3.623  ],\n",
      "       [-3.877  ,  6.113  , -3.477  ],\n",
      "       [-3.676  ,  6.18   , -3.568  ],\n",
      "       [-4.117  ,  6.113  , -3.236  ],\n",
      "       [-3.607  ,  5.918  , -3.488  ],\n",
      "       [-3.854  ,  6.168  , -3.506  ],\n",
      "       [-3.346  ,  5.875  , -3.668  ],\n",
      "       [-4.15   ,  5.844  , -3.043  ],\n",
      "       [-3.031  ,  2.596  , -0.1385 ],\n",
      "       [ 5.406  , -0.571  , -4.27   ],\n",
      "       [ 5.49   , -2.506  , -1.991  ],\n",
      "       [ 5.25   , -0.3362 , -4.49   ],\n",
      "       [-4.     ,  5.945  , -3.098  ],\n",
      "       [ 1.347  ,  2.61   , -4.594  ],\n",
      "       [-3.855  ,  6.062  , -3.4    ],\n",
      "       [-2.137  ,  5.188  , -4.26   ],\n",
      "       [-4.285  ,  5.82   , -3.074  ],\n",
      "       [-3.61   ,  5.816  , -3.531  ],\n",
      "       [-2.637  ,  4.723  , -3.49   ],\n",
      "       [-3.807  ,  5.977  , -3.412  ],\n",
      "       [ 5.51   , -2.127  , -2.543  ],\n",
      "       [-0.1326 , -3.812  ,  4.535  ],\n",
      "       [-4.215  ,  4.5    , -1.551  ],\n",
      "       [-4.082  ,  6.215  , -3.287  ],\n",
      "       [-3.31   ,  5.812  , -3.574  ],\n",
      "       [-1.427  , -1.246  ,  2.38   ],\n",
      "       [-3.768  ,  5.992  , -3.299  ],\n",
      "       [-0.58   ,  4.336  , -4.652  ],\n",
      "       [-2.568  ,  5.87   , -4.293  ],\n",
      "       [ 5.668  , -1.12   , -3.803  ],\n",
      "       [-0.749  ,  4.86   , -4.984  ],\n",
      "       [-3.443  ,  5.29   , -3.309  ],\n",
      "       [ 4.945  ,  0.1943 , -4.77   ],\n",
      "       [-1.811  , -1.165  ,  2.365  ],\n",
      "       [-2.227  , -1.022  ,  2.527  ],\n",
      "       [-3.236  ,  6.082  , -3.756  ],\n",
      "       [-2.96   ,  5.91   , -3.893  ],\n",
      "       [-3.834  ,  5.723  , -3.125  ],\n",
      "       [ 4.094  ,  0.1119 , -3.959  ],\n",
      "       [-3.758  ,  6.023  , -3.283  ],\n",
      "       [-2.58   ,  2.883  , -1.869  ],\n",
      "       [-4.156  ,  5.902  , -2.918  ],\n",
      "       [-3.361  ,  5.99   , -3.635  ],\n",
      "       [-3.936  ,  0.09625,  3.32   ],\n",
      "       [ 3.426  ,  1.784  , -5.35   ],\n",
      "       [-3.82   ,  6.086  , -3.434  ],\n",
      "       [-4.13   ,  5.645  , -3.06   ],\n",
      "       [-3.84   ,  6.137  , -3.395  ],\n",
      "       [-3.11   ,  5.63   , -3.752  ],\n",
      "       [-4.832  ,  5.234  , -1.932  ],\n",
      "       [-3.652  ,  6.027  , -3.389  ],\n",
      "       [-3.742  ,  6.082  , -3.49   ],\n",
      "       [-2.139  , -0.5605 ,  2.266  ],\n",
      "       [-3.998  ,  6.215  , -3.389  ],\n",
      "       [-4.55   ,  5.484  , -2.19   ],\n",
      "       [-1.642  ,  2.588  , -1.652  ],\n",
      "       [-4.008  ,  6.184  , -3.357  ],\n",
      "       [-4.33   ,  4.883  , -1.88   ],\n",
      "       [-3.89   ,  6.152  , -3.477  ],\n",
      "       [-3.553  ,  6.117  , -3.643  ],\n",
      "       [-3.92   ,  6.2    , -3.408  ],\n",
      "       [-4.785  ,  4.57   , -1.347  ],\n",
      "       [-3.111  ,  6.1    , -3.941  ],\n",
      "       [-5.176  ,  4.855  , -1.063  ],\n",
      "       [-3.467  ,  5.77   , -3.262  ],\n",
      "       [ 4.113  , -2.176  , -1.234  ],\n",
      "       [-0.9126 ,  3.951  , -3.826  ],\n",
      "       [-3.629  ,  5.695  , -3.371  ],\n",
      "       [-3.764  ,  6.15   , -3.535  ],\n",
      "       [-3.4    ,  5.668  , -3.541  ],\n",
      "       [-3.207  ,  6.05   , -3.78   ],\n",
      "       [-3.25   ,  5.773  , -3.436  ],\n",
      "       [-3.285  ,  5.875  , -3.785  ],\n",
      "       [-3.316  ,  6.152  , -3.818  ],\n",
      "       [-2.766  ,  5.887  , -4.01   ],\n",
      "       [-3.81   ,  6.008  , -3.455  ],\n",
      "       [-3.275  ,  6.156  , -3.773  ],\n",
      "       [ 4.113  , -1.22   , -2.361  ],\n",
      "       [-2.133  ,  3.438  , -2.512  ],\n",
      "       [-0.02057, -3.49   ,  3.996  ],\n",
      "       [-3.379  ,  6.03   , -3.67   ],\n",
      "       [-5.06   ,  3.158  ,  0.7563 ],\n",
      "       [-2.785  ,  5.98   , -4.12   ],\n",
      "       [ 5.9    , -1.492  , -3.611  ]], dtype=float16), label_ids=array([1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 2, 2, 1, 2, 1, 1, 2, 2,\n",
      "       1, 2, 0, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 0, 2, 1, 1,\n",
      "       1, 2, 1, 1, 1, 0, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 0, 2, 1, 2, 0,\n",
      "       1, 1, 0, 0, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       0, 2, 1, 2, 0, 1, 1, 1, 1, 1, 1, 2, 0, 2, 1, 2, 1, 1, 1, 2, 1, 1,\n",
      "       2, 1, 2, 1, 2, 1, 1, 1, 0, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 2, 1, 2, 1, 1, 1, 2, 0, 2, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2,\n",
      "       1, 1, 1, 2, 1, 0, 0, 0, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1,\n",
      "       1, 0, 1, 1, 1, 1, 0, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 0, 2, 1, 1, 1,\n",
      "       1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 0, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 0]), metrics={'test_loss': 2.4888010025024414, 'test_accuracy': 0.6666666666666666, 'test_balanced_accuracy': 0.4888905804639991, 'test_precision': 0.6124530795664817, 'test_recall': 0.6666666666666666, 'test_f1': 0.6123030127861044, 'test_runtime': 1.2635, 'test_samples_per_second': 185.207, 'test_steps_per_second': 6.332})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be81d0c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjQAAAG5CAYAAACZTa6YAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAnhElEQVR4nO3deZgcZbWA8fdMAgSEQEJICJuAIIjIIshl0YggCoIGEQEFRS4aEQRRryzKJoLbdQH1CkZAwiI7yCqLCCLIkrDKKsgaCDuELUiWc//oCk5iMpkM3dNdVe+Pp55UV1VXnR7n6Tme831VkZlIkiSVWVe7A5AkSXqrTGgkSVLpmdBIkqTSM6GRJEmlZ0IjSZJKz4RGkiSVngmNVBIRsXBEXBgRkyPirLdwnp0j4vJmxtYOEfHHiNi13XFI6gwmNFKTRcRnI2JCRLwSEZOKP7zvb8KptwdGAEtm5qf7epLMPDUzP9KEeGYREZtGREbEebNtX7vYfnUvz3NYRJwyr+Myc6vMHNfHcCVVjAmN1EQR8Q3gKOD7NJKPFYBfA6ObcPq3A//IzGlNOFerPANsFBFLdtu2K/CPZl0gGvzukjQLvxSkJomIxYHDgb0y89zMfDUzp2bmhZn5reKYhSLiqIh4oliOioiFin2bRsTEiPhmRDxdVHd2K/Z9FzgE2LGo/Ow+eyUjIlYsKiEDi9dfiIgHI+LliHgoInbutv3abu/bOCLGF62s8RGxcbd9V0fE9yLiuuI8l0fEsB5+DG8AfwB2Kt4/ANgROHW2n9XREfFYRLwUETdHxAeK7VsC3+72OW/vFseREXEd8BqwcrHti8X+YyLinG7n/1FEXBkR0dv//SSVmwmN1DwbAYOA83o45jvAhsA6wNrABsBB3fYvDSwOLAvsDvxfRAzJzENpVH3OyMxFM/P4ngKJiLcBvwC2yszFgI2B2+Zw3FDg4uLYJYGfARfPVmH5LLAbMBxYEPifnq4NnAR8vlj/KHAn8MRsx4yn8TMYCvweOCsiBmXmpbN9zrW7vedzwBhgMeCR2c73TeA9RbL2ARo/u13TZ7tItWFCIzXPksCz82gJ7QwcnplPZ+YzwHdp/KGeaWqxf2pmXgK8AqzWx3hmAGtGxMKZOSkz75rDMVsD92fmyZk5LTNPA+4FPt7tmN9l5j8ycwpwJo1EZK4y82/A0IhYjUZic9IcjjklM58rrvlTYCHm/TlPzMy7ivdMne18r9H4Of4MOAXYOzMnzuN8kirEhEZqnueAYTNbPnOxDLNWFx4ptr15jtkSoteARec3kMx8lUarZw9gUkRcHBGr9yKemTEt2+31k32I52Tgq8CHmEPFKiL+JyLuKdpcL9KoSvXUygJ4rKedmXkj8CAQNBIvSTViQiM1z/XAv4BtezjmCRqDe2dagf9sx/TWq8Ai3V4v3X1nZl6WmVsAI2lUXX7bi3hmxvR4H2Oa6WRgT+CSonrypqIltB+wAzAkM5cAJtNIRADm1ibqsX0UEXvRqPQ8UZxfUo2Y0EhNkpmTaQzc/b+I2DYiFomIBSJiq4j4cXHYacBBEbFUMbj2EBotkr64DRgVESsUA5IPnLkjIkZExOhiLM2/aLSuZszhHJcA7yymmg+MiB2BNYCL+hgTAJn5EPBBGmOGZrcYMI3GjKiBEXEIMLjb/qeAFednJlNEvBM4AtiFRutpv4hYp2/RSyojExqpiYrxIN+gMdD3GRptkq/SmPkDjT+6E4A7gL8DtxTb+nKtK4AzinPdzKxJSFcRxxPA8zSSi6/M4RzPAdvQGFT7HI3KxjaZ+WxfYprt3Ndm5pyqT5cBl9KYyv0I8DqztpNm3jTwuYi4ZV7XKVp8pwA/yszbM/N+GjOlTp45g0xS9YWTACRJUtlZoZEkSaVnQiNJkkrPhEaSJJWeCY0kSSq9nm4A1laTJr/haGU11fQZ/kqpeYYt5gQqNd+ggfTr88cWXverTftinHLrr9r67DQrNJIkqfQ6tkIjSZJarPf3r+x41fkkkiSptqzQSJJUV9HWYS9NZUIjSVJd2XKSJEnqHFZoJEmqK1tOkiSp9Gw5SZIkdQ4rNJIk1ZUtJ0mSVHq2nCRJkjqHFRpJkurKlpMkSSo9W06SJEmdwwqNJEl1ZctJkiSVni0nSZKkzmGFRpKkurLlJEmSSs+WkyRJUuewQiNJUl1VqEJjQiNJUl11VWcMTXVSM0mSVFtWaCRJqitbTpIkqfQqNG27OqmZJEmqLSs0kiTVlS0nSZJUeracJEmSOocVGkmS6sqWkyRJKr0KtZxMaCRJqqsKVWiq80kkSVJtWaGRJKmubDlJkqTSs+UkSZLUOazQSJJUV7acJElS6dlykiRJ6hxWaCRJqqsKVWhMaCRJqqsKjaGpTmomSZJqywqNJEl1VaGWU3U+iSRJmj8RzVvmeak4ISKejog7u23734i4NyLuiIjzImKJbvsOjIgHIuK+iPjovM5vQiNJkvrDicCWs227AlgzM9cC/gEcCBARawA7Ae8u3vPriBjQ08lNaCRJqqvoat4yD5l5DfD8bNsuz8xpxcsbgOWK9dHA6Zn5r8x8CHgA2KCn85vQSJJUV01sOUXEmIiY0G0ZM5/R/Dfwx2J9WeCxbvsmFtvmykHBkiTpLcvMscDYvrw3Ir4DTANO7ev1TWgkSaqp6ID70ETEF4BtgM0zM4vNjwPLdztsuWLbXNlykiSppqLRKmrK0sfrbwnsB3wiM1/rtusCYKeIWCgiVgJWBW7q6VxWaCRJUstFxGnApsCwiJgIHEpjVtNCwBVFUnRDZu6RmXdFxJnA3TRaUXtl5vSezm9CI0lSXfVjxykzPzOHzcf3cPyRwJG9Pb8JjSRJNdUJY2iaxTE0kiSp9KzQSJJUU1Wq0JjQSJJUU1VKaGw5SZKk0rNCI0lSTVWpQmNCUyI/+t7BXH/tNSwxZCgnnn4eAMcf+0uuu+YqIroYMnQoBxxyBMOWGt7mSFUW/3vEIdxw3V9YYshQjv9943dq3G9/zcUXnMsSSwwBYPev7MN/bfyBdoapkjrkoAO55i9XM3Tokpx7/kXtDkdzUp18xpZTmWy59Wh+fPQxs2zbaZfdOOH353L8qWez0fs/yLjjjm1TdCqjj279CX7w82P+Y/v2O+3C2JPPYuzJZ5nMqM9Gb7sdx/zmuHaHoZowoSmRtd+7PosNXnyWbW9bdNE311+fMqVS5UO13lrrrs/g2X6npGZZb/33MXhxf786WbsffdBMLWs5RcTqwGj+/bjvx4ELMvOeVl2zro779S+47JILeNuii3HUMXO96aLUa38463Quv+RCVnvXu9ljn/9hscGD2x2SpBbohESkWVpSoYmI/YHTaXTnbiqWAE6LiAN6eN+YiJgQERNOOdEyZW99cc99OOuiP7HFlltz3lmntTscldzHt9uRk8+5mLEnn8XQJYdx7C9+0u6QJGmeWtVy2h14X2b+MDNPKZYfAhsU++YoM8dm5vqZuf4uX/hii0Krrg9vuTV/+fOf2h2GSm7okksyYMAAurq62Hr0p7j37r+3OyRJLVKlllOrEpoZwDJz2D6y2KcmmfjoI2+uX/eXP7PCiiu1MRpVwXPPPvPm+rV/+TMrrrxqG6OR1EpVSmhaNYZmX+DKiLgfeKzYtgKwCvDVFl2z8g4/aD9uu3k8k198ke232ZzdvrQXN/7trzz6yMN0dQUjll6GbxxwcLvDVIkccfB+3H7LBCa/+CI7fvzD7PqlPbn9lgn88/57gWDpkcvw9QMOaXeYKqn9/+cbTBh/Ey+++AJbbDaKr+y1N9t96tPtDksVFZnZmhNHdNFoMXUfFDw+M6f35v2TJr/RmsBUW9Nn+Cul5hm22ELtDkEVNGhg/94ZZsldT2vaF+Nz4z7T1jJNy2Y5ZeYM4IZWnV+SJL01ndAqahbvQyNJkkrPRx9IklRTVarQmNBIklRTVUpobDlJkqTSs0IjSVJdVadAY0IjSVJd2XKSJEnqIFZoJEmqqSpVaExoJEmqqSolNLacJElS6VmhkSSppqpUoTGhkSSprqqTz9hykiRJ5WeFRpKkmrLlJEmSSq9KCY0tJ0mSVHpWaCRJqqkqVWhMaCRJqqvq5DMmNJIk1VWVKjSOoZEkSaVnhUaSpJqqUoXGhEaSpJqqUkJjy0mSJJWeFRpJkmqqShUaExpJkuqqOvmMLSdJklR+VmgkSaopW06SJKn0qpTQ2HKSJEmlZ4VGkqSaqlCBxoRGkqS6suUkSZI0HyLihIh4OiLu7LZtaERcERH3F/8OKbZHRPwiIh6IiDsi4r3zOr8JjSRJNRXRvKUXTgS2nG3bAcCVmbkqcGXxGmArYNViGQMcM6+Tm9BIklRTEdG0ZV4y8xrg+dk2jwbGFevjgG27bT8pG24AloiIkT2d34RGkiS9ZRExJiImdFvG9OJtIzJzUrH+JDCiWF8WeKzbcROLbXPloGBJkmqqmWOCM3MsMPYtvD8jIvv6fhMaSZJqqqur7bOcnoqIkZk5qWgpPV1sfxxYvttxyxXb5sqWkyRJapcLgF2L9V2B87tt/3wx22lDYHK31tQcWaGRJKmm+vM2NBFxGrApMCwiJgKHAj8EzoyI3YFHgB2Kwy8BPgY8ALwG7Dav85vQSJJUU/15Y73M/Mxcdm0+h2MT2Gt+zm/LSZIklZ4VGkmSaqpCTz4woZEkqa58lpMkSVIHsUIjSVJNValCY0IjSVJNVSifseUkSZLKzwqNJEk1ZctJkiSVXoXyGVtOkiSp/KzQSJJUU7acJElS6VUon7HlJEmSys8KjSRJNWXLSZIklV6F8hlbTpIkqfys0EiSVFO2nPrBIgt2bGgqqaU33qfdIahCHr/26HaHoAoaNHBAv16vQvmMLSdJklR+lkEkSaopW06SJKn0KpTP2HKSJEnlZ4VGkqSasuUkSZJKr0L5jC0nSZJUflZoJEmqKVtOkiSp9KqU0NhykiRJpWeFRpKkmqpQgcaERpKkurLlJEmS1EGs0EiSVFMVKtCY0EiSVFdVajmZ0EiSVFMVymccQyNJksrPCo0kSTXVVaESjQmNJEk1VaF8xpaTJEkqPys0kiTVlLOcJElS6XVVJ5+x5SRJksrPCo0kSTVly0mSJJVehfIZW06SJKn8rNBIklRTQXVKNCY0kiTVlLOcJEmSOogJjSRJNRURTVt6ca2vR8RdEXFnRJwWEYMiYqWIuDEiHoiIMyJiwb5+FhMaSZJqKqJ5S8/XiWWBfYD1M3NNYACwE/Aj4OeZuQrwArB7Xz+LCY0kSeoPA4GFI2IgsAgwCdgMOLvYPw7Ytq8nN6GRJKmmuiKatkTEmIiY0G0ZM/M6mfk48BPgURqJzGTgZuDFzJxWHDYRWLavn8VZTpIk1VQzb6yXmWOBsXO+TgwBRgMrAS8CZwFbNu/qPSQ0EfFLIOe2PzP3aWYgkiSpsj4MPJSZzwBExLnAJsASETGwqNIsBzze1wv0VKGZ0NeTSpKkztePz3J6FNgwIhYBpgCb08gzrgK2B04HdgXO7+sF5prQZOa47q8jYpHMfK2vF5IkSZ2lv/KZzLwxIs4GbgGmAbfSaE9dDJweEUcU247v6zXmOYYmIjYqLrAosEJErA18OTP37OtFJUlSvWTmocChs21+ENigGefvzaDgo4CPAhcUAd0eEaOacXFJktQ+XRV63HavZjll5mOz9dmmtyYcSZLUX6qTzvQuoXksIjYGMiIWAL4G3NPasCRJknqvNwnNHsDRNG528wRwGbBXK4OSJEmt14+znFpunglNZj4L7NwPsUiSpH7UVZ18Zt6PPoiIlSPiwoh4JiKejojzI2Ll/ghOkiSpN3rzLKffA2cCI4FlaNyu+LRWBiVJklovGs9gasrSbr1JaBbJzJMzc1qxnAIManVgkiSptSKat7RbT89yGlqs/jEiDqBxW+IEdgQu6YfYJEmSeqWnQcE300hgZuZdX+62L4EDWxWUJElqvU5oFTVLT89yWqk/A5EkSf2rSrOcenWn4IhYE1iDbmNnMvOkVgUlSZI0P3rzcMpDgU1pJDSXAFsB1wImNJIklViVWk69meW0PbA58GRm7gasDSze0qgkSVLLRROXdutNQjMlM2cA0yJiMPA0sHxrw5IkSeq93oyhmRARSwC/pTHz6RXg+lYGJUmSWq+rQi2n3jzLac9i9diIuBQYDDzb0qgkSVLLVSif6d0sp5ky82GAiHgUWKEVAUmSJM2v+UpouqlQTidJUj1VaZZTXxOabGoUkiSp31Uon+nxWU6/ZM6JSwBLtCog9d7LL73EkYcfzD8fuJ+I4KDDjmCttddtd1jqcMceujNbjVqTZ55/mfU//X0ADtlza7b54FrMyOSZ519mzKGnMOmZyXz985uz48feB8DAAV2svtLSLL/ZAbzw0mvt/AgqkdNOGceFfzibiOAdq7yT7xx2JAsttFC7w1IFReaciy0RsWtPb8zMcS2JqDB5ygyrQPNw2EEHsM5712Pb7T7N1Klv8PqU11ls8OB2h9Wxlt54n3aH0BE2ee87ePW1f3Hc9z7/ZkKz2NsG8fKrrwOw52c+yOorj2SfI0+f5X0fG7Ume+/8Ibb68i/7PeZO9Pi1R7c7hI739NNPscd/78Lvz76QQYMG8Z39v87Gm4xi6098st2hdayhbxvQrzWTr5xzd9P+1h7zqTXaWu/p6VlOLU1Y9Na88vLL3HrLBA793g8AWGCBBVlggQXbHJXK4Lpb/skKI4fOsm1mMgOwyMILMaf/o7PDlutz5qU3tzw+Vcv06dP5179eZ+DAgbw+5XWGLTW83SGpm1q0nNTZnnh8IkOGDOXwQ77N/f+4j9XXWINv7vdtFl54kXaHppI6bK+Ps/M2GzD5lSlsOeYXs+xbeNACbLHxu/j6D89sU3Qqo+HDR/DZz+3GJz+2OQstNIgNNtqY/9pok3aHpYrqzZ2C1YGmTZ/Offfezad22IlTzjiXhQctwrgTftvusFRih/3fhay61cGc/scJ7LHjqFn2bT3qPVx/24OOndF8eemlyfz16j9zzkVXcOFlV/P6lClcevEF7Q5L3URE05Z26/eEJiJ262HfmIiYEBETTjx+bH+GVTrDR4xg+PARrPmetQHYbIuPcN89d7c5KlXBGZeMZ9vN15ll26c/uh5n2W7SfBp/4/WMXHZZhgwZysAFFuCDm23B3++4rd1hqZuuJi7t1pdZTgBkZl9HWH4X+N1czjkWGAsOCp6XYcOWYvjSI3nk4Yd4+4orMf7GG1hp5VXaHZZK6h0rLMU/H30GgG02XYt/PPzUm/sGLzqI96+3Crt9x2F1mj9LLz2Su/5+O69PmcJCgwYx4aYbeNca7253WKqonsbQTOjrSSPijrntAkb09bya1bf2/w4Hf/tbTJs6lWWWXZ5DDj+y3SGpBMb94At8YL1VGbbEojxw6ff43rGXsOX7382qbx/OjBnJo5Oen2WG0yc+tDZX3nAvr73+RhujVhm9+z1r86HNP8KuO2/PwAEDeOdq72L0dju0Oyx10wmtomaZ67Ttt3TSiKeAjwIvzL4L+FtmLjOvc1ihUbM5bVvN5LRttUJ/T9ve9/x7m/a39qjRq3fmtO2ZImIpYH9gDWDQzO2ZuVkPb7sIWDQzb5vD+a6e7yglSVLTdVWnQNOrcTynAvcAK9EY//IwML6nN2Tm7pl57Vz2fXY+Y5QkSepRbxKaJTPzeGBqZv4lM/8b6Kk6I0mSSqBK07Z7c2O9qcW/kyJia+AJYGgPx0uSpBKoUsupNwnNERGxOPBN4JfAYODrLY1KkiRpPswzocnMi4rVycCHWhuOJEnqLx3QKWqa3sxy+h1zuMFeMZZGkiSVVFeFMpretJwu6rY+CPgkjXE0kiRJHaE3Ladzur+OiNOAOU7JliRJ5dEJz2Bqlt5UaGa3KjC82YFIkqT+VaGOU6/G0LzMrGNonqRx52BJkqSO0JuW02L9EYgkSepfVRoUPM/2WURc2ZttkiSpXCKat7TbXCs0ETEIWAQYFhFDaDwpGxo31lu2H2KTJEnqlZ5aTl8G9gWWAW7m3wnNS8CvWhuWJElqtVo8+iAzjwaOjoi9M/OX/RiTJEnqB7UaQwPMiIglZr6IiCERsWfrQpIkSZo/vUlovpSZL858kZkvAF9qWUSSJKlfVGlQcG8SmgER/w41IgYAC7YuJEmS1B+6onnLvETEEhFxdkTcGxH3RMRGETE0Iq6IiPuLf4f0+bP04phLgTMiYvOI2Bw4rdgmSZLUW0cDl2bm6sDawD3AAcCVmbkqcGXxuk968+iD/YExwFeK11cAv+3rBSVJUmcI+qdXFBGLA6OALwBk5hvAGxExGti0OGwccDV9fBrBPCs0mTkjM4/NzO0zc3vgbsBZT5IklVwzW04RMSYiJnRbxnS71ErAM8DvIuLWiDguIt4GjMjMScUxTwIj+vpZevVwyohYF/gMsAPwEHBuXy8oSZKqJzPHAmPnsnsg8F5g78y8MSKOZrb2UmZmROQc390LPd0p+J00kpjPAM8CZwCRmR/q68UkSVLn6Mcb600EJmbmjcXrs2kkNE9FxMjMnBQRI4Gn+3qBnlpO9wKbAdtk5vuLm+tN7+uFJElSZ4mIpi09ycwngcciYrVi0+Y0hrBcAOxabNsVOL+vn6WnltN2wE7AVRFxKXA69NPoIUmSVDV7A6dGxILAg8BuNAorZ0bE7sAjNIa29ElPjz74A/CHYtDOaBrPdRoeEccA52Xm5X29qCRJar/+fJZTZt4GrD+HXZs34/y9meX0amb+PjM/DiwH3Eofp1RJkqTOUbc7Bb8pM1/IzLGZ2ZRsSpIkqRl6NW1bkiRVT5Wetm1CI0lSTfXnGJpWm6+WkyRJUieyQiNJUk1VqONkQiNJUl11Vej2cracJElS6VmhkSSppmw5SZKk0nOWkyRJUgexQiNJUk15Yz1JklR6FcpnbDlJkqTys0IjSVJN2XKSJEmlV6F8xpaTJEkqPys0kiTVVJWqGiY0kiTVVFSo51Sl5EySJNWUFRpJkmqqOvUZExpJkmqrStO2bTlJkqTSs0IjSVJNVac+Y0IjSVJtVajjZMtJkiSVnxUaSZJqqkr3oTGhkSSppqrUpjGhkSSppqpUoalSciZJkmrKCo0kSTVVnfqMCY1q5JxTDml3CKqQAV1V+lOgurLlJEmS1EGs0EiSVFNVqmqY0EiSVFO2nCRJkjqIFRpJkmqqOvUZExpJkmqrQh0nW06SJKn8rNBIklRTXRVqOpnQSJJUU7acJEmSOogVGkmSaipsOUmSpLKz5SRJktRBrNBIklRTznKSJEmlZ8tJkiRpPkXEgIi4NSIuKl6vFBE3RsQDEXFGRCzY13Ob0EiSVFMRzVt66WvAPd1e/wj4eWauArwA7N7Xz2JCI0lSTUUT/5vntSKWA7YGjiteB7AZcHZxyDhg275+FhMaSZL0lkXEmIiY0G0ZM9shRwH7ATOK10sCL2bmtOL1RGDZvl7fQcGSJNVUVxMHBWfmWGDsnPZFxDbA05l5c0Rs2ryr/psJjSRJNdWPdwreBPhERHwMGAQMBo4GloiIgUWVZjng8b5ewJaTJElqqcw8MDOXy8wVgZ2AP2fmzsBVwPbFYbsC5/f1GiY0kiTVVBtmOc1uf+AbEfEAjTE1x/f1RLacJEmqqXY8nDIzrwauLtYfBDZoxnmt0EiSpNKzQiNJUk01c5ZTu5nQSJJUU+1oObWKLSdJklR6VmgkSaqpKj1t24RGkqSaqlA+Y8tJkiSVnxUaSZJqqqtCPScTGkmSaqo66YwtJ0mSVAFWaCRJqqsKlWhMaCRJqilvrCdJktRBrNBIklRTFZrkZEIjSVJdVSifseUkSZLKzwqNJEl1VaESjQmNJEk15SwnSZKkDmKFRpKkmnKWkyRJKr0K5TO2nCRJUvlZoZEkqa4qVKIxoZEkqaac5SRJktRBrNBIklRTznKSJEmlV6F8xoRGkqTaqlBG4xgaSZJUelZoJEmqqSrNcjKhkSSppqo0KNiWkyRJKj0rNJIk1VSFCjQmNJIk1VaFMhpbTpIkqfSs0JTYyy+9xJGHH8w/H7ifiOCgw45grbXXbXdYKqEZ06fzs/2+xOJDh/Gl7/yYk39+OI/9814GDBjICqu+ix32+BYDBvp1ofnn91Rnc5aTOsJPf/x9Ntz4/fzwJ0czdeobvD7l9XaHpJK65uKzGLHc23n9tVcBWG/UFuyy78EAnPzz73LDny5kky0/2c4QVVJ+T3U2Zzmp7V55+WVuvWUCoz+5PQALLLAgiw0e3OaoVEYvPvs0d998PRt+eJs3t62x3kZEBBHBCqu+ixefe6aNEaqs/J5Sf2pZQhMRq0fE5hGx6Gzbt2zVNevkiccnMmTIUA4/5NvssuN2HPHdg5gy5bV2h6USOu+EX/Dxz+9JxH9+HUyfNo0JV1/G6uv+VxsiU9n5PdX5oolLu7UkoYmIfYDzgb2BOyNidLfd3+/hfWMiYkJETDjx+LGtCK0ypk2fzn333s2ndtiJU844l4UHLcK4E37b7rBUMndNuI7FFh/C8u9YbY77zx77U96xxjq8Y421+zkyVYHfUyVQoYymVWNovgSsl5mvRMSKwNkRsWJmHk0PHzszxwJjASZPmZEtiq0Sho8YwfDhI1jzPY0/NJtt8RFO8otC8+mhe//OneOv4+5bbmDa1Dd4/bVXOeWow9ll30O49Izf8cpLL7Lbft9qd5gqKb+n1J9aldB0ZeYrAJn5cERsSiOpeTsdkceV37BhSzF86ZE88vBDvH3FlRh/4w2stPIq7Q5LJbPNLnuwzS57APDAnbdy1fmnscu+h3DDFRdy32038ZXDjqKry6F26hu/pzqfs5zm7amIWCczbwMoKjXbACcA72nRNWvnW/t/h4O//S2mTZ3KMssuzyGHH9nukFQRZ/3mpwxZagRHH9hIdtbacBQf3WG3NkelMvJ7qrNVaZZTZDa/sxMRywHTMvPJOezbJDOvm9c5bDmp2a578Nl2h6AK2WTlYe0OQRW0+MJd/Zpi3Pfka037W7va0ou0NT1qSYUmMyf2sG+eyYwkSWq9ChVovLGeJEm1VaGMxtF+kiSp9ExoJEmqqWjifz1eJ2L5iLgqIu6OiLsi4mvF9qERcUVE3F/8O6Svn8WERpKkmopo3jIP04BvZuYawIbAXhGxBnAAcGVmrgpcWbzuExMaSZLUUpk5KTNvKdZfBu4BlgVGA+OKw8YB2/b1GiY0kiTVVDOffND98UXFMmaO12w8QWBd4EZgRGZOKnY9CYzo62dxlpMkSXXVxFlO3R9fNNfLNR5YfQ6wb2a+FN16VZmZEdHn++JYoZEkSS0XEQvQSGZOzcxzi81PRcTIYv9I4Om+nt+ERpKkmurHWU4BHA/ck5k/67brAmDXYn1X4Py+fhZbTpIk1VQ/PstpE+BzwN8j4rZi27eBHwJnRsTuwCPADn29gAmNJElqqcy8lrmP2Nm8GdcwoZEkqaYq9OQDExpJkmqrQhmNg4IlSVLpWaGRJKmm5jU7qUxMaCRJqql+nOXUcracJElS6VmhkSSppipUoDGhkSSprmw5SZIkdRArNJIk1VZ1SjQmNJIk1ZQtJ0mSpA5ihUaSpJqqUIHGhEaSpLqy5SRJktRBrNBIklRTPstJkiSVX3XyGVtOkiSp/KzQSJJUUxUq0JjQSJJUV85ykiRJ6iBWaCRJqilnOUmSpPKrTj5jy0mSJJWfFRpJkmqqQgUaExpJkuqqSrOcTGgkSaqpKg0KdgyNJEkqPSs0kiTVVJVaTlZoJElS6ZnQSJKk0rPlJElSTVWp5WRCI0lSTTnLSZIkqYNYoZEkqaZsOUmSpNKrUD5jy0mSJJWfFRpJkuqqQiUaExpJkmrKWU6SJEkdxAqNJEk15SwnSZJUehXKZ2w5SZKk8rNCI0lSXVWoRGNCI0lSTTnLSZIkqYNYoZEkqaaqNMspMrPdMegtiogxmTm23XGoGvx9UrP5O6X+YMupGsa0OwBVir9PajZ/p9RyJjSSJKn0TGgkSVLpmdBUg71pNZO/T2o2f6fUcg4KliRJpWeFRpIklZ4JjSRJKj0TmhKLiC0j4r6IeCAiDmh3PCq3iDghIp6OiDvbHYuqISKWj4irIuLuiLgrIr7W7phUXY6hKamIGAD8A9gCmAiMBz6TmXe3NTCVVkSMAl4BTsrMNdsdj8ovIkYCIzPzlohYDLgZ2NbvKbWCFZry2gB4IDMfzMw3gNOB0W2OSSWWmdcAz7c7DlVHZk7KzFuK9ZeBe4Bl2xuVqsqEpryWBR7r9noiflFI6lARsSKwLnBjm0NRRZnQSJJaKiIWBc4B9s3Ml9odj6rJhKa8HgeW7/Z6uWKbJHWMiFiARjJzamae2+54VF0mNOU1Hlg1IlaKiAWBnYAL2hyTJL0pIgI4HrgnM3/W7nhUbSY0JZWZ04CvApfRGGh3Zmbe1d6oVGYRcRpwPbBaREyMiN3bHZNKbxPgc8BmEXFbsXys3UGpmpy2LUmSSs8KjSRJKj0TGkmSVHomNJIkqfRMaCRJUumZ0EiSpNIzoZHaKCKmF1NZ74yIsyJikbdwrhMjYvti/biIWKOHYzeNiI37cI2HI2JYb7fP5RxfiIhfNeO6kjSTCY3UXlMyc53i6dZvAHt03xkRA/ty0sz84jyeaLwpMN8JjSR1KhMaqXP8FVilqJ78NSIuAO6OiAER8b8RMT4i7oiIL0PjLqwR8auIuC8i/gQMn3miiLg6ItYv1reMiFsi4vaIuLJ4SOAewNeL6tAHImKpiDinuMb4iNikeO+SEXF5RNwVEccB0dsPExEbRMT1EXFrRPwtIlbrtnv5Isb7I+LQbu/ZJSJuKuL6TUQM6PuPU1Kd9On//UlqrqISsxVwabHpvcCamflQRIwBJmfm+yJiIeC6iLicxpOLVwPWAEYAdwMnzHbepYDfAqOKcw3NzOcj4ljglcz8SXHc74GfZ+a1EbECjTtQvws4FLg2Mw+PiK2B+bl78L3ABzJzWkR8GPg+8Kli3wbAmsBrwPiIuBh4FdgR2CQzp0bEr4GdgZPm45qSasqERmqvhSPitmL9rzSee7MxcFNmPlRs/wiw1szxMcDiwKrAKOC0zJwOPBERf57D+TcErpl5rsx8fi5xfBhYo/HoHQAGF09IHgVsV7z34oh4YT4+2+LAuIhYFUhggW77rsjM5wAi4lzg/cA0YD0aCQ7AwsDT83E9STVmQiO115TMXKf7huKP+avdNwF7Z+Zlsx3XzGfidAEbZubrc4ilr74HXJWZnyzaXFd32zf7M1eSxuccl5kHvpWLSqonx9BIne8y4CsRsQBARLwzIt4GXAPsWIyxGQl8aA7vvQEYFRErFe8dWmx/GVis23GXA3vPfBER6xSr1wCfLbZtBQyZj7gXBx4v1r8w274tImJoRCwMbAtcB1wJbB8Rw2fGGhFvn4/rSaoxExqp8x1HY3zMLRFxJ/AbGtXV84D7i30n0XhS9iwy8xlgDHBuRNwOnFHsuhD45MxBwcA+wPrFoOO7+fdsq+/SSIjuotF6erSHOO8ontI9MSJ+BvwY+EFE3Mp/VoNvAs4B7gDOycwJxaysg4DLI+IO4ApgZC9/RpJqzqdtS5Kk0rNCI0mSSs+ERpIklZ4JjSRJKj0TGkmSVHomNJIkqfRMaCRJUumZ0EiSpNL7f9vkDNpxhSyUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "probabilities = torch.softmax(torch.tensor(test_results.predictions).to(torch.float32), dim=-1)\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)\n",
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef4c67fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_save = []\n",
    "for idx in range(len(test_data)):\n",
    "    item = dataset['test'][idx]\n",
    "    actual_label = item['label']\n",
    "    predicted_label = predictions[idx]\n",
    "    claim = item['claim'] \n",
    "    premise = item['premise'] \n",
    "    category = item['category']\n",
    "    \n",
    "    # Append the information as a dictionary to the list\n",
    "    data_to_save.append({\n",
    "        'Claim': claim,\n",
    "        'Premise': premise,\n",
    "        'Actual Label': actual_label,\n",
    "        'Predicted Label': predicted_label,\n",
    "        'Category' : category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_to_save)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/home/elson/results/1.2.3_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a1a63a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correctly classified instances\n",
    "correctly_classified = df[df['Actual Label'] == df['Predicted Label']]\n",
    "\n",
    "# Calculate misclassified instances\n",
    "misclassified = df[df['Actual Label'] != df['Predicted Label']]\n",
    "\n",
    "# Count the number of correctly classified and misclassified by category\n",
    "correct_classification_counts = correctly_classified['Category'].value_counts()\n",
    "misclassification_counts = misclassified['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c4055e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           36\n",
       "Cancer                   12\n",
       "Bone health              12\n",
       "Fitness                  12\n",
       "Diabetes                 11\n",
       "Cardiovascular Health    10\n",
       "Skin                     10\n",
       "Throat                    9\n",
       "Hair                      8\n",
       "Neurological health       8\n",
       "Eye                       7\n",
       "Ear                       6\n",
       "Blood                     4\n",
       "Women' s Health           4\n",
       "Muscles                   2\n",
       "Mental Health             2\n",
       "COVID                     2\n",
       "Vascular                  1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "117a1d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           15\n",
       "Skin                     14\n",
       "Bone health               9\n",
       "Men's health              6\n",
       "Blood                     5\n",
       "COVID                     4\n",
       "Hair                      4\n",
       "Muscles                   4\n",
       "Dental Health             3\n",
       "Fitness                   3\n",
       "Eye                       2\n",
       "Women' s Health           2\n",
       "Vascular                  2\n",
       "Cardiovascular Health     2\n",
       "Mental Health             1\n",
       "Diabetes                  1\n",
       "Neurological health       1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838e2165",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
