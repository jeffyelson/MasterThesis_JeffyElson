{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score,balanced_accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-31dfe7adddcf5ced\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 333.60it/s]\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-ad71be204b279b28.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-e7b6b615907c24ca.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-bee802838a3bfaea.arrow\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset from the CSV file\n",
    "dataset = load_dataset(\n",
    "    'csv',\n",
    "    data_files='dataset_semanticattribution_nerfeatures_split.csv',\n",
    "    delimiter=',',\n",
    "    column_names=[\n",
    "        \"claim\", \"premise\", \"label\", \"category\", \"count_bf\", \"count_ca\", \"count_dis\",\n",
    "        \"count_food\", \"count_lipid\", \"count_treat\", \"pres_bf\", \"pres_ca\", \"pres_dis\",\n",
    "        \"pres_food\", \"pres_lipid\", \"pres_treat\", \"counte_bf\", \"counte_ca\", \"counte_dis\",\n",
    "        \"counte_food\", \"counte_lipid\", \"counte_treat\", \"prese_bf\", \"prese_ca\", \"prese_dis\",\n",
    "        \"prese_food\", \"prese_lipid\", \"prese_treat\", \"url\", \"entities\", \"entity_map\",\n",
    "        \"gold_exp\", \"gemini_exp\", \"gemini_label\",\"entity_ev\",\"entity_map_ev\", \"split\"\n",
    "    ],\n",
    "    skiprows=1\n",
    ")\n",
    "\n",
    "\n",
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'gold_exp', 'gemini_exp', 'gemini_label', 'entity_ev', 'entity_map_ev', 'split'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'gold_exp', 'gemini_exp', 'gemini_label', 'entity_ev', 'entity_map_ev', 'split'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'gold_exp', 'gemini_exp', 'gemini_label', 'entity_ev', 'entity_map_ev', 'split'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41f1db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\"claim\", \"premise\", \"label\",\"category\"]\n",
    "all_columns = dataset[\"train\"].column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-fd677073a7d68d5a.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-1a68850df07b3513.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-de2cb4ce7db32b5e.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 0, 'entailment': 1, 'neutral': 2}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 0,\n",
    "    \"entailment\": 1,\n",
    "    \"neutral\": 2\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='TehranNLP-org/electra-base-mnli'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "        # Extracting claim and evidence texts\n",
    "\n",
    "        claim = item['claim']\n",
    "        premise = item['premise'].replace('\\n', '').replace('[','').replace(']','')\n",
    "        item['claim']=claim\n",
    "        item['premise']=premise\n",
    "        \n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "            claim, premise,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "        item['input_ids'] = inputs['input_ids'].squeeze()  # Remove batch dimension\n",
    "        item['attention_mask']= inputs['attention_mask'].squeeze() # Remove batch dimension\n",
    "        \n",
    "        if 'label' in item:\n",
    "            item['labels'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62421eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElectraForSequenceClassification(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): ElectraClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"TehranNLP-org/electra-base-mnli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=3, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    bal_accuracy = balanced_accuracy_score(labels,preds)\n",
    "\n",
    "    return {\"accuracy\": acc, \"balanced_accuracy\":bal_accuracy, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17c5e0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'claim': 'Myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.',\n",
       " 'premise': '; UnkoviÄ‡, N.; DimkiÄ‡, I.; JanaÄ‡koviÄ‡, P.; GavriloviÄ‡, M.; StanojeviÄ‡, O.; VukojeviÄ‡, J. Frankincense and myrrh essential oils and burn incense fume against micro-inhabitants of sacral ambients.Shameem, I. Phytochemical & therapeutic potentials of Murr makki (.Oxidative stress and immunotoxic effects of lead and their amelioration with myrrh (Commiphora molmol) emulsion.Essential Oils: Magical Ingredients for Skin Care.Chakravarty, N.; Kellogg, C.; Alvarez, J.; Equils, O.; Morgan, M. UV Protection by Natural Products: C. myrrha Oil Versus Sunscreen.Hamidpour, R.; Hamidpour, S.; Hamidpour, M.; Shahlari, M. Frankincense (ä¹³é¦™ RÇ” XiÄ\\x81ng;.species): From the selection of traditional applications to the novel phytotherapy for the prevention and treatment of serious diseases.Chemistry and immunomodulatory activity of frankincense oil.Compositions containing Boswellia extracts.; Cooper, E. Frankincense and myrrh as remedies in children.',\n",
       " 'label': 1,\n",
       " 'category': 'General Health',\n",
       " 'input_ids': tensor([  101,  2026, 12171,  2232,  6827,  3514,  2003,  2823,  2109,  1999,\n",
       "          3096, 16302,  3688,  2000,  2393,  5335,  1996,  3311,  1997,  1996,\n",
       "          3096,  1012,   102,  1025,  4895,  7724,  2401,  1527,  1010,  1050,\n",
       "          1012,  1025, 11737, 21128,  1527,  1010,  1045,  1012,  1025, 23341,\n",
       "          2050,  1527, 12849,  9035,  1527,  1010,  1052,  1012,  1025, 11721,\n",
       "         19716, 22360,  9035,  1527,  1010,  1049,  1012,  1025,  9761, 29147,\n",
       "          6777,  2401,  1527,  1010,  1051,  1012,  1025, 24728,  3683,  6460,\n",
       "          9035,  1527,  1010,  1046,  1012,  3581,  2378, 19023,  2063,  1998,\n",
       "          2026, 12171,  2232,  6827, 20631,  1998,  6402, 28647, 11865,  4168,\n",
       "          2114, 12702,  1011,  4864,  1997, 17266,  7941, 17093,  2015,  1012,\n",
       "          9467,  6633,  1010,  1045,  1012,  6887, 22123, 23555,  7712,  2389,\n",
       "          1004, 17261,  4022,  2015,  1997, 14163, 12171,  5003, 24103,  1006,\n",
       "          1012, 23060,  8524,  6024,  6911,  1998, 10047, 23041, 11439,  9048,\n",
       "          2278,  3896,  1997,  2599,  1998,  2037,  2572, 20806, 21223,  2007,\n",
       "          2026, 12171,  2232,  1006,  4012,  4328,  8458,  6525,  9587, 13728,\n",
       "          4747,  1007,  7861, 23316,  1012,  6827, 20631,  1024,  8687, 12760,\n",
       "          2005,  3096,  2729,  1012, 15775, 22272, 10755,  3723,  1010,  1050,\n",
       "          1012,  1025, 26129,  1010,  1039,  1012,  1025, 16309,  1010,  1046,\n",
       "          1012,  1025,  1041, 26147,  2015,  1010,  1051,  1012,  1025,  5253,\n",
       "          1010,  1049,  1012, 23068,  3860,  2011,  3019,  3688,  1024,  1039,\n",
       "          1012,  2026, 12171,  3270,  3514,  6431, 19352, 24410,  1012, 24811,\n",
       "         27757,  1010,  1054,  1012,  1025, 24811, 27757,  1010,  1055,  1012,\n",
       "          1025, 24811, 27757,  1010,  1049,  1012,  1025,  7890,  8017,  2072,\n",
       "          1010,  1049,  1012,  3581,  2378, 19023,  2063,  1006,  1037, 27904,\n",
       "         18107,  2063, 29649, 30108, 22110,  1524, 27735,  1025,  1012,  2427,\n",
       "          1007,  1024,  2013,  1996,  4989,  1997,  3151,  5097,  2000,  1996,\n",
       "          3117,  6887, 22123, 14573,  6906,  7685,  2005,  1996,  9740,  1998,\n",
       "          3949,  1997,  3809,  7870,  1012,  6370,  1998, 10047, 23041, 19506,\n",
       "          8566, 20051, 10253,  4023,  1997,  3581,  2378, 19023,  2063,  3514,\n",
       "          1012,  9265,  4820,  8945, 19228,  2401, 27059,  1012,  1025,  6201,\n",
       "          1010,  1041,  1012,  3581,  2378, 19023,  2063,  1998,  2026, 12171,\n",
       "          2232,  2004,  2128,  7583,  3111,  1999,  2336,  1012,   102,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'labels': tensor(1)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 765\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='765' max='765' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [765/765 06:23, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.855600</td>\n",
       "      <td>0.792437</td>\n",
       "      <td>0.673118</td>\n",
       "      <td>0.364595</td>\n",
       "      <td>0.620296</td>\n",
       "      <td>0.673118</td>\n",
       "      <td>0.567796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.660700</td>\n",
       "      <td>0.789359</td>\n",
       "      <td>0.664516</td>\n",
       "      <td>0.474497</td>\n",
       "      <td>0.658049</td>\n",
       "      <td>0.664516</td>\n",
       "      <td>0.653681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.427700</td>\n",
       "      <td>1.010043</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.479092</td>\n",
       "      <td>0.646263</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.654956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.196200</td>\n",
       "      <td>1.350620</td>\n",
       "      <td>0.623656</td>\n",
       "      <td>0.514087</td>\n",
       "      <td>0.668232</td>\n",
       "      <td>0.623656</td>\n",
       "      <td>0.640090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.196800</td>\n",
       "      <td>1.617076</td>\n",
       "      <td>0.673118</td>\n",
       "      <td>0.498972</td>\n",
       "      <td>0.658647</td>\n",
       "      <td>0.673118</td>\n",
       "      <td>0.662101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.163100</td>\n",
       "      <td>1.713909</td>\n",
       "      <td>0.634409</td>\n",
       "      <td>0.499694</td>\n",
       "      <td>0.640147</td>\n",
       "      <td>0.634409</td>\n",
       "      <td>0.637099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.070600</td>\n",
       "      <td>1.898198</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.524382</td>\n",
       "      <td>0.667921</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.670675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.063700</td>\n",
       "      <td>1.972273</td>\n",
       "      <td>0.694624</td>\n",
       "      <td>0.538853</td>\n",
       "      <td>0.680255</td>\n",
       "      <td>0.694624</td>\n",
       "      <td>0.686212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.042300</td>\n",
       "      <td>2.056435</td>\n",
       "      <td>0.690323</td>\n",
       "      <td>0.524795</td>\n",
       "      <td>0.673705</td>\n",
       "      <td>0.690323</td>\n",
       "      <td>0.680724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.054400</td>\n",
       "      <td>2.223112</td>\n",
       "      <td>0.681720</td>\n",
       "      <td>0.525159</td>\n",
       "      <td>0.679662</td>\n",
       "      <td>0.681720</td>\n",
       "      <td>0.677070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>2.293203</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.543224</td>\n",
       "      <td>0.677827</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.677135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>2.326432</td>\n",
       "      <td>0.681720</td>\n",
       "      <td>0.527587</td>\n",
       "      <td>0.671851</td>\n",
       "      <td>0.681720</td>\n",
       "      <td>0.675923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>2.385406</td>\n",
       "      <td>0.686022</td>\n",
       "      <td>0.541646</td>\n",
       "      <td>0.677107</td>\n",
       "      <td>0.686022</td>\n",
       "      <td>0.681150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>2.415417</td>\n",
       "      <td>0.686022</td>\n",
       "      <td>0.541646</td>\n",
       "      <td>0.677036</td>\n",
       "      <td>0.686022</td>\n",
       "      <td>0.680992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>2.424816</td>\n",
       "      <td>0.681720</td>\n",
       "      <td>0.530015</td>\n",
       "      <td>0.670500</td>\n",
       "      <td>0.681720</td>\n",
       "      <td>0.675529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/12.2.1_electra/checkpoint-51\n",
      "Configuration saved in /home/elson/12.2.1_electra/checkpoint-51/config.json\n",
      "Model weights saved in /home/elson/12.2.1_electra/checkpoint-51/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/12.2.1_electra/checkpoint-102\n",
      "Configuration saved in /home/elson/12.2.1_electra/checkpoint-102/config.json\n",
      "Model weights saved in /home/elson/12.2.1_electra/checkpoint-102/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/12.2.1_electra/checkpoint-153\n",
      "Configuration saved in /home/elson/12.2.1_electra/checkpoint-153/config.json\n",
      "Model weights saved in /home/elson/12.2.1_electra/checkpoint-153/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/12.2.1_electra/checkpoint-51] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/12.2.1_electra/checkpoint-102] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/12.2.1_electra/checkpoint-204\n",
      "Configuration saved in /home/elson/12.2.1_electra/checkpoint-204/config.json\n",
      "Model weights saved in /home/elson/12.2.1_electra/checkpoint-204/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/12.2.1_electra/checkpoint-255\n",
      "Configuration saved in /home/elson/12.2.1_electra/checkpoint-255/config.json\n",
      "Model weights saved in /home/elson/12.2.1_electra/checkpoint-255/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/12.2.1_electra/checkpoint-204] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/12.2.1_electra/checkpoint-306\n",
      "Configuration saved in /home/elson/12.2.1_electra/checkpoint-306/config.json\n",
      "Model weights saved in /home/elson/12.2.1_electra/checkpoint-306/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/12.2.1_electra/checkpoint-255] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/12.2.1_electra/checkpoint-357\n",
      "Configuration saved in /home/elson/12.2.1_electra/checkpoint-357/config.json\n",
      "Model weights saved in /home/elson/12.2.1_electra/checkpoint-357/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/12.2.1_electra/checkpoint-306] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/12.2.1_electra/checkpoint-408\n",
      "Configuration saved in /home/elson/12.2.1_electra/checkpoint-408/config.json\n",
      "Model weights saved in /home/elson/12.2.1_electra/checkpoint-408/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/12.2.1_electra/checkpoint-153] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/12.2.1_electra/checkpoint-357] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/12.2.1_electra/checkpoint-459\n",
      "Configuration saved in /home/elson/12.2.1_electra/checkpoint-459/config.json\n",
      "Model weights saved in /home/elson/12.2.1_electra/checkpoint-459/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/12.2.1_electra/checkpoint-510\n",
      "Configuration saved in /home/elson/12.2.1_electra/checkpoint-510/config.json\n",
      "Model weights saved in /home/elson/12.2.1_electra/checkpoint-510/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/12.2.1_electra/checkpoint-459] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/12.2.1_electra/checkpoint-561\n",
      "Configuration saved in /home/elson/12.2.1_electra/checkpoint-561/config.json\n",
      "Model weights saved in /home/elson/12.2.1_electra/checkpoint-561/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/12.2.1_electra/checkpoint-510] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/12.2.1_electra/checkpoint-612\n",
      "Configuration saved in /home/elson/12.2.1_electra/checkpoint-612/config.json\n",
      "Model weights saved in /home/elson/12.2.1_electra/checkpoint-612/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/12.2.1_electra/checkpoint-561] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/12.2.1_electra/checkpoint-663\n",
      "Configuration saved in /home/elson/12.2.1_electra/checkpoint-663/config.json\n",
      "Model weights saved in /home/elson/12.2.1_electra/checkpoint-663/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/12.2.1_electra/checkpoint-612] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/12.2.1_electra/checkpoint-714\n",
      "Configuration saved in /home/elson/12.2.1_electra/checkpoint-714/config.json\n",
      "Model weights saved in /home/elson/12.2.1_electra/checkpoint-714/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/12.2.1_electra/checkpoint-663] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/12.2.1_electra/checkpoint-765\n",
      "Configuration saved in /home/elson/12.2.1_electra/checkpoint-765/config.json\n",
      "Model weights saved in /home/elson/12.2.1_electra/checkpoint-765/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/12.2.1_electra/checkpoint-714] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/elson/12.2.1_electra/checkpoint-408 (score: 0.6946236559139785).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /home/elson/12.2.1_electra/best_model/config.json\n",
      "Model weights saved in /home/elson/12.2.1_electra/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/12.2.1_electra/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/12.2.1_electra/best_model/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/12.2.1_electra/best_model/tokenizer_config.json',\n",
       " '/home/elson/12.2.1_electra/best_model/special_tokens_map.json',\n",
       " '/home/elson/12.2.1_electra/best_model/vocab.txt',\n",
       " '/home/elson/12.2.1_electra/best_model/added_tokens.json',\n",
       " '/home/elson/12.2.1_electra/best_model/tokenizer.json')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/12.2.1_electra/',\n",
    "    num_train_epochs=15,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.06,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/12.2.1_electra/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/12.2.1_electra/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63deaea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/12.2.1_electra/best_model/config.json\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"/home/elson/12.2.1_electra/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"finetuning_task\": \"mnli\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"entailment\",\n",
      "    \"1\": \"neutral\",\n",
      "    \"2\": \"contradiction\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"contradiction\": 2,\n",
      "    \"entailment\": 0,\n",
      "    \"neutral\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file /home/elson/12.2.1_electra/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing ElectraForSequenceClassification.\n",
      "\n",
      "All the weights of ElectraForSequenceClassification were initialized from the model checkpoint at /home/elson/12.2.1_electra/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ElectraForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 32\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/12.2.1_electra/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[-4.6250e+00,  4.7031e+00,  5.7422e-01],\n",
      "       [-3.3320e+00,  6.1680e+00, -2.4844e+00],\n",
      "       [-3.6680e+00,  6.3047e+00, -2.2383e+00],\n",
      "       [-1.1973e+00,  3.6699e+00, -2.4434e+00],\n",
      "       [-3.0664e+00,  4.8906e+00, -1.2959e+00],\n",
      "       [-3.9023e+00,  6.2148e+00, -1.9082e+00],\n",
      "       [-2.7188e+00,  6.1211e+00, -3.2012e+00],\n",
      "       [-1.7861e+00,  5.0430e+00, -3.1367e+00],\n",
      "       [-3.4023e+00,  6.2773e+00, -2.5449e+00],\n",
      "       [-2.4961e+00,  5.7969e+00, -3.1523e+00],\n",
      "       [-3.6504e+00,  6.1602e+00, -2.0742e+00],\n",
      "       [-2.7227e+00,  5.9609e+00, -3.0820e+00],\n",
      "       [-2.2168e+00,  4.7930e+00, -2.3828e+00],\n",
      "       [-3.3145e+00,  5.8750e+00, -2.1562e+00],\n",
      "       [-4.5078e+00,  6.0430e+00, -9.9170e-01],\n",
      "       [ 3.1445e+00, -7.5256e-02, -3.8887e+00],\n",
      "       [-3.8594e+00,  6.2344e+00, -1.9932e+00],\n",
      "       [-4.0977e+00,  6.1836e+00, -1.6201e+00],\n",
      "       [-3.4688e+00,  6.2734e+00, -2.4414e+00],\n",
      "       [-3.1875e+00,  6.1055e+00, -2.5332e+00],\n",
      "       [-3.3730e+00,  5.5430e+00, -1.7881e+00],\n",
      "       [-2.8359e+00, -6.5674e-01,  3.7891e+00],\n",
      "       [-7.1924e-01,  4.9258e+00, -4.3750e+00],\n",
      "       [ 2.1465e+00, -3.8125e+00,  1.6123e+00],\n",
      "       [ 3.8770e+00, -2.8833e-01, -4.5586e+00],\n",
      "       [ 2.2246e+00, -4.3984e+00,  2.0957e+00],\n",
      "       [-3.8516e+00,  6.2812e+00, -2.0137e+00],\n",
      "       [-4.2148e+00,  6.0938e+00, -1.3682e+00],\n",
      "       [-5.7500e+00,  4.0742e+00,  2.2617e+00],\n",
      "       [-3.6875e+00,  6.2891e+00, -2.1836e+00],\n",
      "       [-3.6113e+00,  4.8984e+00, -7.3828e-01],\n",
      "       [-3.3262e+00,  6.2812e+00, -2.6055e+00],\n",
      "       [-3.8906e+00,  6.2461e+00, -1.9502e+00],\n",
      "       [-3.6895e+00,  6.0117e+00, -1.8828e+00],\n",
      "       [-3.7891e+00,  6.1680e+00, -1.8633e+00],\n",
      "       [-3.8379e+00,  6.2305e+00, -2.0332e+00],\n",
      "       [-4.6836e+00,  5.6992e+00, -4.2993e-01],\n",
      "       [-4.6211e+00,  4.0625e+00,  1.1387e+00],\n",
      "       [ 4.5000e+00, -1.7070e+00, -3.7227e+00],\n",
      "       [-3.8594e+00,  6.1914e+00, -1.9551e+00],\n",
      "       [-2.7910e+00, -2.3984e+00,  5.4180e+00],\n",
      "       [-4.0859e+00,  6.1250e+00, -1.5029e+00],\n",
      "       [-3.4219e+00,  6.1992e+00, -2.3965e+00],\n",
      "       [ 4.1758e+00, -2.1562e+00, -2.8125e+00],\n",
      "       [-4.8867e+00,  5.4805e+00, -8.4045e-02],\n",
      "       [-4.5273e+00,  6.0078e+00, -9.6582e-01],\n",
      "       [-3.5703e+00,  5.8086e+00, -1.7285e+00],\n",
      "       [-4.0273e+00,  6.0586e+00, -1.5146e+00],\n",
      "       [-3.8926e+00,  6.0859e+00, -1.6973e+00],\n",
      "       [ 4.3320e+00, -1.4814e+00, -3.7266e+00],\n",
      "       [ 4.6094e+00, -2.3516e+00, -3.1035e+00],\n",
      "       [-3.6445e+00,  6.1836e+00, -2.1094e+00],\n",
      "       [ 2.0605e+00, -2.9785e+00,  8.0566e-01],\n",
      "       [-3.8770e+00,  6.1602e+00, -1.8369e+00],\n",
      "       [ 3.9121e+00, -7.3877e-01, -4.0312e+00],\n",
      "       [-3.9707e+00,  6.1914e+00, -1.7705e+00],\n",
      "       [ 4.0430e+00, -2.4883e+00, -2.0723e+00],\n",
      "       [-3.5566e+00,  6.0391e+00, -1.9922e+00],\n",
      "       [-2.4590e+00,  5.8242e+00, -3.0781e+00],\n",
      "       [-2.3320e+00,  5.8984e+00, -3.4199e+00],\n",
      "       [-3.9453e+00,  6.2344e+00, -1.8418e+00],\n",
      "       [ 3.7969e+00, -1.8018e-01, -4.6836e+00],\n",
      "       [-4.7773e+00,  5.6055e+00, -2.3730e-01],\n",
      "       [-3.2598e+00,  5.6484e+00, -1.9326e+00],\n",
      "       [-3.7266e+00,  5.7305e+00, -1.5049e+00],\n",
      "       [-3.5234e+00,  6.2695e+00, -2.3926e+00],\n",
      "       [-3.5430e+00,  6.2500e+00, -2.3164e+00],\n",
      "       [-3.8320e+00,  6.2500e+00, -1.9971e+00],\n",
      "       [-2.7598e+00,  5.9844e+00, -2.9238e+00],\n",
      "       [-5.2344e-01, -1.6396e+00,  2.2832e+00],\n",
      "       [-3.3984e+00, -5.8643e-01,  4.2852e+00],\n",
      "       [-3.2539e+00,  5.8320e+00, -2.3750e+00],\n",
      "       [-4.0352e+00,  6.1719e+00, -1.7158e+00],\n",
      "       [-2.0469e+00,  5.1328e+00, -2.9512e+00],\n",
      "       [-4.1172e+00, -1.0977e+00,  5.5312e+00],\n",
      "       [-3.1836e+00,  6.1523e+00, -2.6680e+00],\n",
      "       [-2.8809e+00,  5.9688e+00, -2.7949e+00],\n",
      "       [-3.2051e+00,  6.0430e+00, -2.4336e+00],\n",
      "       [-3.8828e+00,  6.2344e+00, -1.9248e+00],\n",
      "       [-3.1592e-01,  4.6562e+00, -4.6406e+00],\n",
      "       [-3.9023e+00,  6.1641e+00, -1.8633e+00],\n",
      "       [-3.0488e+00,  6.2656e+00, -2.9395e+00],\n",
      "       [-4.4688e+00,  5.5938e+00, -5.7959e-01],\n",
      "       [-3.4062e+00,  6.1602e+00, -2.3555e+00],\n",
      "       [-4.6602e+00,  5.9922e+00, -7.8564e-01],\n",
      "       [ 7.0557e-01,  1.9541e+00, -2.7891e+00],\n",
      "       [-3.6133e+00,  5.9766e+00, -1.8506e+00],\n",
      "       [-3.0566e+00,  3.6934e+00, -2.3767e-01],\n",
      "       [-4.2656e+00,  4.8047e+00, -5.9967e-03],\n",
      "       [-4.1719e+00,  5.9102e+00, -1.2783e+00],\n",
      "       [-3.6582e+00,  6.3008e+00, -2.2500e+00],\n",
      "       [-4.2188e+00,  5.1172e+00, -2.4060e-01],\n",
      "       [-3.5488e+00,  3.8262e+00,  9.1858e-02],\n",
      "       [-3.8203e+00,  6.1719e+00, -1.8672e+00],\n",
      "       [ 4.4531e+00, -1.4004e+00, -4.0195e+00],\n",
      "       [-4.1641e+00,  6.0000e+00, -1.3057e+00],\n",
      "       [-3.2266e+00,  6.1758e+00, -2.5938e+00],\n",
      "       [ 4.4805e+00, -9.3555e-01, -4.6445e+00],\n",
      "       [-3.2539e+00,  6.2695e+00, -2.6973e+00],\n",
      "       [-4.0312e+00,  6.2539e+00, -1.7773e+00],\n",
      "       [ 4.4531e+00, -2.3340e+00, -2.8672e+00],\n",
      "       [-3.2871e+00,  6.2656e+00, -2.6250e+00],\n",
      "       [-4.0117e+00,  6.2773e+00, -1.7891e+00],\n",
      "       [-4.2031e+00,  6.0625e+00, -1.4160e+00],\n",
      "       [-2.2578e+00,  4.3906e+00, -1.8350e+00],\n",
      "       [-3.9844e+00,  6.2500e+00, -1.7822e+00],\n",
      "       [-3.4922e+00,  5.8203e+00, -1.8369e+00],\n",
      "       [ 4.3086e+00, -2.6719e+00, -2.2656e+00],\n",
      "       [-4.3008e+00,  5.9453e+00, -1.1592e+00],\n",
      "       [-3.3926e+00,  6.2188e+00, -2.4805e+00],\n",
      "       [ 8.2764e-01,  1.0176e+00, -1.9824e+00],\n",
      "       [-3.5293e+00,  6.2539e+00, -2.3555e+00],\n",
      "       [-3.3711e+00,  6.2500e+00, -2.4766e+00],\n",
      "       [-3.7656e+00,  6.2656e+00, -2.0859e+00],\n",
      "       [-3.9023e+00,  6.1797e+00, -1.8281e+00],\n",
      "       [-3.7734e+00,  6.1562e+00, -1.9727e+00],\n",
      "       [-3.7559e+00,  6.1992e+00, -2.0059e+00],\n",
      "       [-1.3896e+00,  4.8789e+00, -3.4434e+00],\n",
      "       [-3.1074e+00,  5.8516e+00, -2.3613e+00],\n",
      "       [-5.5664e+00,  1.8037e+00,  4.1445e+00],\n",
      "       [-3.3789e+00,  6.2812e+00, -2.5742e+00],\n",
      "       [-3.1543e+00,  6.1797e+00, -2.7480e+00],\n",
      "       [-3.9688e+00,  6.1523e+00, -1.7715e+00],\n",
      "       [-3.5215e+00,  6.2578e+00, -2.3320e+00],\n",
      "       [-3.3516e+00,  6.2773e+00, -2.5898e+00],\n",
      "       [-2.3965e+00,  6.0312e+00, -3.4492e+00],\n",
      "       [-3.4941e+00,  5.9375e+00, -1.9297e+00],\n",
      "       [-3.2051e+00,  6.2305e+00, -2.7266e+00],\n",
      "       [-2.9277e+00, -8.8086e-01,  4.1055e+00],\n",
      "       [-3.7930e+00,  6.2266e+00, -2.0117e+00],\n",
      "       [-2.9258e+00,  4.7734e+00, -1.6543e+00],\n",
      "       [ 3.4883e+00, -1.0771e+00, -3.0664e+00],\n",
      "       [-5.2656e+00,  3.5312e+00,  2.3242e+00],\n",
      "       [-2.5527e+00,  4.8750e+00, -2.1797e+00],\n",
      "       [-1.5449e+00,  5.5508e+00, -4.0664e+00],\n",
      "       [-4.2227e+00,  5.3086e+00, -5.0830e-01],\n",
      "       [-2.7891e+00,  6.0352e+00, -3.0137e+00],\n",
      "       [ 3.5547e+00, -2.1953e+00, -1.8359e+00],\n",
      "       [ 3.9766e+00, -3.1830e-02, -4.9570e+00],\n",
      "       [-2.9414e+00, -1.5859e+00,  4.8008e+00],\n",
      "       [-3.9473e+00,  6.1211e+00, -1.7451e+00],\n",
      "       [-4.2305e+00,  5.7930e+00, -1.0332e+00],\n",
      "       [-1.2842e+00,  4.4609e+00, -3.2812e+00],\n",
      "       [-3.5508e+00,  6.2695e+00, -2.3789e+00],\n",
      "       [-3.7617e+00,  5.7891e+00, -1.4863e+00],\n",
      "       [-4.4102e+00,  6.0664e+00, -1.1035e+00],\n",
      "       [ 4.7852e+00, -2.1621e+00, -3.5410e+00],\n",
      "       [ 3.0996e+00, -2.8320e+00, -5.0146e-01],\n",
      "       [-2.8574e+00,  6.1367e+00, -3.0078e+00],\n",
      "       [ 2.0273e+00, -2.7891e+00,  6.9434e-01],\n",
      "       [-2.5293e+00,  6.0742e+00, -3.4082e+00],\n",
      "       [-3.9141e+00,  6.2305e+00, -1.8604e+00],\n",
      "       [-3.5293e+00,  6.2969e+00, -2.4023e+00],\n",
      "       [-2.9883e+00,  6.2422e+00, -2.9805e+00],\n",
      "       [-3.5840e+00,  6.1445e+00, -2.0879e+00],\n",
      "       [-4.1172e+00,  5.6484e+00, -9.5801e-01],\n",
      "       [-3.3281e+00,  6.2773e+00, -2.5918e+00],\n",
      "       [-4.1641e+00,  5.8750e+00, -1.1504e+00],\n",
      "       [ 3.3965e+00, -2.4355e+00, -1.4492e+00],\n",
      "       [ 4.4336e+00, -2.7773e+00, -2.3711e+00],\n",
      "       [ 3.8262e+00, -2.2871e+00, -2.0723e+00],\n",
      "       [ 1.5244e+00, -2.6602e+00,  1.1787e+00],\n",
      "       [-3.9844e+00,  6.1836e+00, -1.6924e+00],\n",
      "       [ 4.7344e+00, -2.3652e+00, -3.1973e+00],\n",
      "       [-4.0078e+00,  5.9727e+00, -1.5215e+00],\n",
      "       [ 2.2858e-02,  4.2031e+00, -4.5312e+00],\n",
      "       [-4.9219e-01,  4.0977e+00, -3.7461e+00],\n",
      "       [-1.6211e+00,  5.1523e+00, -3.3516e+00],\n",
      "       [-2.0957e+00, -2.2324e+00,  4.5977e+00],\n",
      "       [-2.9336e+00,  5.6602e+00, -2.3066e+00],\n",
      "       [ 3.9043e+00, -1.4629e+00, -3.1543e+00],\n",
      "       [-1.7207e+00,  5.4688e+00, -3.7246e+00],\n",
      "       [ 4.3828e+00, -2.6504e+00, -2.4941e+00],\n",
      "       [-2.8125e+00,  6.1875e+00, -3.1777e+00],\n",
      "       [-4.4219e+00,  6.0547e+00, -1.1162e+00],\n",
      "       [-4.1328e+00,  5.6758e+00, -9.6045e-01],\n",
      "       [-3.4082e+00,  6.0430e+00, -2.2148e+00],\n",
      "       [-1.5215e+00,  4.7188e+00, -2.8750e+00],\n",
      "       [-3.9727e+00,  6.1523e+00, -1.6895e+00],\n",
      "       [ 3.8438e+00,  6.1584e-02, -5.0156e+00],\n",
      "       [ 4.3125e+00, -3.4521e-01, -5.1133e+00],\n",
      "       [-3.7930e+00, -2.6782e-01,  4.4258e+00],\n",
      "       [ 4.6289e+00, -2.0391e+00, -3.4570e+00],\n",
      "       [-3.8652e+00,  2.0469e+00,  2.2480e+00],\n",
      "       [-5.3398e+00,  4.5039e+00,  1.3252e+00],\n",
      "       [-3.9199e+00,  6.2461e+00, -1.8662e+00],\n",
      "       [-3.5469e+00,  6.2539e+00, -2.2891e+00],\n",
      "       [-4.4531e+00,  5.9102e+00, -8.8379e-01],\n",
      "       [-2.8301e+00,  2.7656e+00,  4.3359e-01],\n",
      "       [-3.6973e+00,  6.2773e+00, -2.1699e+00],\n",
      "       [-4.1328e+00,  5.9688e+00, -1.3281e+00],\n",
      "       [-3.2578e+00,  6.1562e+00, -2.5469e+00],\n",
      "       [-3.3359e+00,  6.1406e+00, -2.5156e+00],\n",
      "       [-3.3789e+00,  6.1445e+00, -2.3398e+00],\n",
      "       [ 4.7578e+00, -2.0781e+00, -3.6348e+00],\n",
      "       [-3.3320e+00,  6.2734e+00, -2.6367e+00],\n",
      "       [-4.2617e+00,  5.6250e+00, -7.8662e-01],\n",
      "       [-4.0430e+00,  6.2109e+00, -1.7207e+00],\n",
      "       [-4.0234e+00,  6.1992e+00, -1.7510e+00],\n",
      "       [-7.2607e-01,  4.3750e+00, -3.8457e+00],\n",
      "       [-3.2930e+00,  6.2734e+00, -2.6602e+00],\n",
      "       [-3.2031e+00,  6.2266e+00, -2.7012e+00],\n",
      "       [-1.0908e+00,  2.4551e+00, -1.1582e+00],\n",
      "       [-2.7148e+00,  6.1289e+00, -3.2500e+00],\n",
      "       [-3.3047e+00,  6.2422e+00, -2.6113e+00],\n",
      "       [ 6.4453e-01,  3.2402e+00, -4.4375e+00],\n",
      "       [-3.1504e+00,  6.1367e+00, -2.6699e+00],\n",
      "       [-4.3047e+00,  6.1758e+00, -1.3525e+00],\n",
      "       [-3.3164e+00,  6.2422e+00, -2.5723e+00],\n",
      "       [ 3.1562e+00, -2.8008e+00, -6.7822e-01],\n",
      "       [-4.6523e+00,  2.7090e+00,  2.4023e+00],\n",
      "       [-4.6055e+00,  5.2188e+00, -1.3855e-01],\n",
      "       [-3.2754e+00,  6.2344e+00, -2.6582e+00],\n",
      "       [-3.5977e+00,  6.0859e+00, -2.0625e+00],\n",
      "       [-4.8984e+00,  5.1445e+00,  4.3042e-01],\n",
      "       [-3.3711e+00,  3.0527e+00,  5.8887e-01],\n",
      "       [-3.3027e+00,  5.9102e+00, -2.1973e+00],\n",
      "       [-4.2891e+00,  5.8125e+00, -9.7217e-01],\n",
      "       [-3.5293e+00,  6.2500e+00, -2.3672e+00],\n",
      "       [ 4.4180e+00, -1.5332e+00, -3.8301e+00],\n",
      "       [-3.5215e+00,  6.2812e+00, -2.4316e+00],\n",
      "       [-3.5117e+00,  6.2539e+00, -2.3906e+00],\n",
      "       [-2.8984e+00,  6.2031e+00, -3.0312e+00],\n",
      "       [-3.4922e+00,  6.2578e+00, -2.4043e+00],\n",
      "       [-3.4570e+00,  5.9023e+00, -1.9453e+00],\n",
      "       [-3.1328e+00,  6.1758e+00, -2.7246e+00],\n",
      "       [-3.8379e+00,  6.1914e+00, -1.9639e+00],\n",
      "       [-1.7617e+00, -2.8340e+00,  4.8320e+00],\n",
      "       [-3.4492e+00,  5.6836e+00, -1.7900e+00],\n",
      "       [ 5.4785e-01,  9.3213e-01, -1.5547e+00],\n",
      "       [-3.6680e+00,  6.2031e+00, -2.2051e+00],\n",
      "       [-3.5781e+00,  5.7656e+00, -1.7197e+00],\n",
      "       [-3.9082e+00,  6.1914e+00, -1.7930e+00],\n",
      "       [ 3.9355e+00, -2.8262e+00, -1.6855e+00]], dtype=float16), label_ids=array([1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 2, 2, 1, 2, 1, 1, 2, 2,\n",
      "       1, 2, 0, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 0, 2, 1, 1,\n",
      "       1, 2, 1, 1, 1, 0, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 0, 2, 1, 2, 0,\n",
      "       1, 1, 0, 0, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       0, 2, 1, 2, 0, 1, 1, 1, 1, 1, 1, 2, 0, 2, 1, 2, 1, 1, 1, 2, 1, 1,\n",
      "       2, 1, 2, 1, 2, 1, 1, 1, 0, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 2, 1, 2, 1, 1, 1, 2, 0, 2, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2,\n",
      "       1, 1, 1, 2, 1, 0, 0, 0, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1,\n",
      "       1, 0, 1, 1, 1, 1, 0, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 0, 2, 1, 1, 1,\n",
      "       1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 0, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 0]), metrics={'test_loss': 2.4771711826324463, 'test_accuracy': 0.6367521367521367, 'test_balanced_accuracy': 0.4694727078452434, 'test_precision': 0.595391814477836, 'test_recall': 0.6367521367521367, 'test_f1': 0.5862242604082366, 'test_runtime': 1.2715, 'test_samples_per_second': 184.042, 'test_steps_per_second': 6.292})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1cd75bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "probabilities = torch.softmax(torch.tensor(test_results.predictions).to(torch.float32), dim=-1)\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)\n",
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "766c4460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_save = []\n",
    "for idx in range(len(test_data)):\n",
    "    item = dataset['test'][idx]\n",
    "    actual_label = item['label']\n",
    "    predicted_label = predictions[idx]\n",
    "    claim = item['claim'] \n",
    "    premise = item['premise'] \n",
    "    category = item['category']\n",
    "    \n",
    "    # Append the information as a dictionary to the list\n",
    "    data_to_save.append({\n",
    "        'Claim': claim,\n",
    "        'Premise': premise,\n",
    "        'Actual Label': actual_label,\n",
    "        'Predicted Label': predicted_label,\n",
    "        'Category' : category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_to_save)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/home/elson/results/12.2.1_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3e1cc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correctly classified instances\n",
    "correctly_classified = df[df['Actual Label'] == df['Predicted Label']]\n",
    "\n",
    "# Calculate misclassified instances\n",
    "misclassified = df[df['Actual Label'] != df['Predicted Label']]\n",
    "\n",
    "# Count the number of correctly classified and misclassified by category\n",
    "correct_classification_counts = correctly_classified['Category'].value_counts()\n",
    "misclassification_counts = misclassified['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "afd884e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           34\n",
       "Cancer                   12\n",
       "Bone health              12\n",
       "Diabetes                 12\n",
       "Fitness                  10\n",
       "Throat                    9\n",
       "Cardiovascular Health     9\n",
       "Eye                       8\n",
       "Neurological health       7\n",
       "Skin                      7\n",
       "Ear                       6\n",
       "Hair                      6\n",
       "Women' s Health           4\n",
       "COVID                     4\n",
       "Blood                     4\n",
       "Mental Health             2\n",
       "Men's health              1\n",
       "Muscles                   1\n",
       "Vascular                  1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6477f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           17\n",
       "Skin                     17\n",
       "Bone health               9\n",
       "Hair                      6\n",
       "Fitness                   5\n",
       "Men's health              5\n",
       "Muscles                   5\n",
       "Blood                     5\n",
       "Cardiovascular Health     3\n",
       "Dental Health             3\n",
       "Women' s Health           2\n",
       "COVID                     2\n",
       "Neurological health       2\n",
       "Vascular                  2\n",
       "Eye                       1\n",
       "Mental Health             1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
