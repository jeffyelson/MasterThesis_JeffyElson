{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-022bc67e9c58e92d\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 207.82it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('csv',data_files='dataset_propositionattribution_nerfeatures.csv',delimiter=',',column_names=[\"claim\",\"premise\",\"label\",\"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\",\"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\",\"url\", \"entities\",\"entity_map\",\"entity_map_ev\",\"entities_ev\",\"gem_exp\",\"gem_label\",\"gpt_label\",\"gpt_exp\",\"gold_exp\",\"synonym\",\"voice\",\"split\"],skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "133f9357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-2b8e361375c0e153.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-0cc9bb699c2761fb.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-608a44ac65076739.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01252e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\"claim\", \"premise\", \"label\",\"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\",\"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\"]\n",
    "all_columns = dataset[\"train\"].column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-9c9ce51ae59f67f6.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-dafdc92566e23764.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-c71177a21a2978df.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 2, 'entailment': 0, 'neutral': 1}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 2,\n",
    "    \"entailment\": 0,\n",
    "    \"neutral\": 1\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e15010ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='bioformers/bioformer-8L-mnli'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "        # Extracting claim and evidence texts\n",
    "        claim = item['claim'].lower() \n",
    "        evidences = item['premise']\n",
    "        item['premise']=evidences\n",
    "        item['claim']=claim\n",
    "        additional_features_evidence = [\n",
    "            \"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\"]\n",
    "    \n",
    "        for feature in additional_features_evidence:\n",
    "            if feature in item:\n",
    "                evidences += \"[SEP]\" + str(item[feature])\n",
    "        additional_features = [\n",
    "            \"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\"]\n",
    "    \n",
    "        for feature_ev in additional_features:\n",
    "            if feature_ev in item:\n",
    "                claim += \"[SEP]\" + str(item[feature_ev])\n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "            evidences,claim,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "         # Construct the output item\n",
    "        output_item = {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),  # Remove batch dimension\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),  # Remove batch dimension\n",
    "            'claim': claim,  # Include augmented claim text\n",
    "            'evidences': evidences  # Include original evidence text\n",
    "        }\n",
    "        \n",
    "        if 'label' in item:\n",
    "            output_item['label'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return output_item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62421eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(32768, 512, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 512)\n",
       "      (token_type_embeddings): Embedding(2, 512)\n",
       "      (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=512, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"bioformers/bioformer-8L-mnli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=512)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=3, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    return {\"accuracy\": acc, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f5cf584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  101,  1480,  3720, 15658,  1431,  2132,  4765,  2848,  9507,  1111,\n",
       "          1435,  2573,  1109,  4258,  2161,  1425, 26267,  1431,  1425,  3460,\n",
       "         14360,  1427,  1425, 26669,  1435,  2731,  1425,  2784,  1456,  1435,\n",
       "         10036,  2700,  1446,  2161,  1425,  7805,  1431,  1425,  3550,  1435,\n",
       "          3026,  1425,  6245,  1997,   119,   102,   121,   102,   121,   102,\n",
       "           121,   102,   121,   102,   121,   102,   121,   102,   121,   102,\n",
       "           121,   102,   121,   102,   121,   102,   121,   102,   121,   102,\n",
       "          2573,  1109,  4258,  3720,  6187,  1478,  8811,  1822,  1427,  3550,\n",
       "          5183,  4030,  1446,  3346,  2520,  1425,  6875,  1431,  1425,  3550,\n",
       "           119,   102,   121,   102,   121,   102,   121,   102,   121,   102,\n",
       "           121,   102,   121,   102,   121,   102,   121,   102,   121,   102,\n",
       "           121,   102,   121,   102,   121,   102,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'claim': 'myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0',\n",
       " 'evidences': 'The essential oils of frankincense and myrrh increase the fluidity of the lipid bilayer in the cuticle and change the orderly and dense structure to increase the permeability of the skin and decrease the barrier effect.[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0',\n",
       " 'label': tensor(0)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1530\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1530' max='1530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1530/1530 03:22, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.851200</td>\n",
       "      <td>0.814864</td>\n",
       "      <td>0.658065</td>\n",
       "      <td>0.638967</td>\n",
       "      <td>0.658065</td>\n",
       "      <td>0.610856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.611500</td>\n",
       "      <td>1.040923</td>\n",
       "      <td>0.587097</td>\n",
       "      <td>0.644304</td>\n",
       "      <td>0.587097</td>\n",
       "      <td>0.606847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.378200</td>\n",
       "      <td>1.142252</td>\n",
       "      <td>0.636559</td>\n",
       "      <td>0.646508</td>\n",
       "      <td>0.636559</td>\n",
       "      <td>0.638571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.247400</td>\n",
       "      <td>1.317869</td>\n",
       "      <td>0.617204</td>\n",
       "      <td>0.638818</td>\n",
       "      <td>0.617204</td>\n",
       "      <td>0.625921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.258200</td>\n",
       "      <td>1.458067</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.626857</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.633049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.130200</td>\n",
       "      <td>1.750810</td>\n",
       "      <td>0.602151</td>\n",
       "      <td>0.627407</td>\n",
       "      <td>0.602151</td>\n",
       "      <td>0.612320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.213100</td>\n",
       "      <td>1.820872</td>\n",
       "      <td>0.623656</td>\n",
       "      <td>0.639657</td>\n",
       "      <td>0.623656</td>\n",
       "      <td>0.630384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.071700</td>\n",
       "      <td>1.970088</td>\n",
       "      <td>0.647312</td>\n",
       "      <td>0.645236</td>\n",
       "      <td>0.647312</td>\n",
       "      <td>0.644737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.089400</td>\n",
       "      <td>2.105761</td>\n",
       "      <td>0.621505</td>\n",
       "      <td>0.637763</td>\n",
       "      <td>0.621505</td>\n",
       "      <td>0.628365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.056000</td>\n",
       "      <td>2.210646</td>\n",
       "      <td>0.640860</td>\n",
       "      <td>0.645871</td>\n",
       "      <td>0.640860</td>\n",
       "      <td>0.642519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.023100</td>\n",
       "      <td>2.319622</td>\n",
       "      <td>0.627957</td>\n",
       "      <td>0.632558</td>\n",
       "      <td>0.627957</td>\n",
       "      <td>0.629650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.036500</td>\n",
       "      <td>2.352972</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.641598</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.639247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>2.391728</td>\n",
       "      <td>0.634409</td>\n",
       "      <td>0.637490</td>\n",
       "      <td>0.634409</td>\n",
       "      <td>0.635570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.019700</td>\n",
       "      <td>2.408275</td>\n",
       "      <td>0.636559</td>\n",
       "      <td>0.640102</td>\n",
       "      <td>0.636559</td>\n",
       "      <td>0.637343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>2.418085</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.648222</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.644654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.5_bioformer/checkpoint-102\n",
      "Configuration saved in /home/elson/11.4.5_bioformer/checkpoint-102/config.json\n",
      "Model weights saved in /home/elson/11.4.5_bioformer/checkpoint-102/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.5_bioformer/checkpoint-51] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/11.4.5_bioformer/checkpoint-765] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.5_bioformer/checkpoint-204\n",
      "Configuration saved in /home/elson/11.4.5_bioformer/checkpoint-204/config.json\n",
      "Model weights saved in /home/elson/11.4.5_bioformer/checkpoint-204/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.5_bioformer/checkpoint-306\n",
      "Configuration saved in /home/elson/11.4.5_bioformer/checkpoint-306/config.json\n",
      "Model weights saved in /home/elson/11.4.5_bioformer/checkpoint-306/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.5_bioformer/checkpoint-204] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.5_bioformer/checkpoint-408\n",
      "Configuration saved in /home/elson/11.4.5_bioformer/checkpoint-408/config.json\n",
      "Model weights saved in /home/elson/11.4.5_bioformer/checkpoint-408/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.5_bioformer/checkpoint-306] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.5_bioformer/checkpoint-510\n",
      "Configuration saved in /home/elson/11.4.5_bioformer/checkpoint-510/config.json\n",
      "Model weights saved in /home/elson/11.4.5_bioformer/checkpoint-510/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.5_bioformer/checkpoint-408] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.5_bioformer/checkpoint-612\n",
      "Configuration saved in /home/elson/11.4.5_bioformer/checkpoint-612/config.json\n",
      "Model weights saved in /home/elson/11.4.5_bioformer/checkpoint-612/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.5_bioformer/checkpoint-510] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.5_bioformer/checkpoint-714\n",
      "Configuration saved in /home/elson/11.4.5_bioformer/checkpoint-714/config.json\n",
      "Model weights saved in /home/elson/11.4.5_bioformer/checkpoint-714/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.5_bioformer/checkpoint-612] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.5_bioformer/checkpoint-816\n",
      "Configuration saved in /home/elson/11.4.5_bioformer/checkpoint-816/config.json\n",
      "Model weights saved in /home/elson/11.4.5_bioformer/checkpoint-816/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.5_bioformer/checkpoint-714] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.5_bioformer/checkpoint-918\n",
      "Configuration saved in /home/elson/11.4.5_bioformer/checkpoint-918/config.json\n",
      "Model weights saved in /home/elson/11.4.5_bioformer/checkpoint-918/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.5_bioformer/checkpoint-816] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.5_bioformer/checkpoint-1020\n",
      "Configuration saved in /home/elson/11.4.5_bioformer/checkpoint-1020/config.json\n",
      "Model weights saved in /home/elson/11.4.5_bioformer/checkpoint-1020/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.5_bioformer/checkpoint-918] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.5_bioformer/checkpoint-1122\n",
      "Configuration saved in /home/elson/11.4.5_bioformer/checkpoint-1122/config.json\n",
      "Model weights saved in /home/elson/11.4.5_bioformer/checkpoint-1122/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.5_bioformer/checkpoint-1020] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.5_bioformer/checkpoint-1224\n",
      "Configuration saved in /home/elson/11.4.5_bioformer/checkpoint-1224/config.json\n",
      "Model weights saved in /home/elson/11.4.5_bioformer/checkpoint-1224/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.5_bioformer/checkpoint-1122] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.5_bioformer/checkpoint-1326\n",
      "Configuration saved in /home/elson/11.4.5_bioformer/checkpoint-1326/config.json\n",
      "Model weights saved in /home/elson/11.4.5_bioformer/checkpoint-1326/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.5_bioformer/checkpoint-1224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.5_bioformer/checkpoint-1428\n",
      "Configuration saved in /home/elson/11.4.5_bioformer/checkpoint-1428/config.json\n",
      "Model weights saved in /home/elson/11.4.5_bioformer/checkpoint-1428/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.5_bioformer/checkpoint-1326] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.5_bioformer/checkpoint-1530\n",
      "Configuration saved in /home/elson/11.4.5_bioformer/checkpoint-1530/config.json\n",
      "Model weights saved in /home/elson/11.4.5_bioformer/checkpoint-1530/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.5_bioformer/checkpoint-1428] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/elson/11.4.5_bioformer/checkpoint-102 (score: 0.6580645161290323).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /home/elson/11.4.5_bioformer/best_model/config.json\n",
      "Model weights saved in /home/elson/11.4.5_bioformer/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/11.4.5_bioformer/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/11.4.5_bioformer/best_model/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/11.4.5_bioformer/best_model/tokenizer_config.json',\n",
       " '/home/elson/11.4.5_bioformer/best_model/special_tokens_map.json',\n",
       " '/home/elson/11.4.5_bioformer/best_model/vocab.txt',\n",
       " '/home/elson/11.4.5_bioformer/best_model/added_tokens.json',\n",
       " '/home/elson/11.4.5_bioformer/best_model/tokenizer.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/11.4.5_bioformer/',\n",
    "    num_train_epochs=15,\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.1,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/11.4.5_bioformer/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/11.4.5_bioformer/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63deaea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/11.4.5_bioformer/best_model/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"/home/elson/11.4.5_bioformer/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"finetuning_task\": \"mnli\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 512,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"entailment\",\n",
      "    \"1\": \"neutral\",\n",
      "    \"2\": \"contradiction\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2048,\n",
      "  \"label2id\": {\n",
      "    \"contradiction\": 2,\n",
      "    \"entailment\": 0,\n",
      "    \"neutral\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 8,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32768\n",
      "}\n",
      "\n",
      "loading weights file /home/elson/11.4.5_bioformer/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at /home/elson/11.4.5_bioformer/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 16\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/11.4.5_bioformer/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[ 7.0459e-01, -2.6489e-01, -5.1465e-01],\n",
      "       [ 1.4062e+00, -5.0000e-01, -1.1992e+00],\n",
      "       [ 1.4805e+00, -7.6660e-01, -1.0166e+00],\n",
      "       [-6.9727e-01, -5.1270e-01,  1.2236e+00],\n",
      "       [ 1.6338e+00, -2.8564e-01, -1.4014e+00],\n",
      "       [ 2.3105e+00, -4.9512e-01, -2.0195e+00],\n",
      "       [ 1.4014e+00, -6.8652e-01, -8.9648e-01],\n",
      "       [ 1.2686e+00, -3.6060e-01, -1.1641e+00],\n",
      "       [ 1.0068e+00, -5.3613e-01, -6.4160e-01],\n",
      "       [ 9.2871e-01, -4.2529e-01, -5.6982e-01],\n",
      "       [ 1.1807e+00, -8.7744e-01, -4.8828e-01],\n",
      "       [ 1.9814e+00, -6.1572e-01, -1.5059e+00],\n",
      "       [ 1.8301e+00, -3.2690e-01, -1.7344e+00],\n",
      "       [ 1.4180e+00, -4.0918e-01, -1.2119e+00],\n",
      "       [ 1.9092e+00, -4.9658e-01, -1.7314e+00],\n",
      "       [ 2.0312e-01, -1.3135e-01, -3.2202e-01],\n",
      "       [ 1.9014e+00, -5.0537e-01, -1.7080e+00],\n",
      "       [ 2.2520e+00, -3.6230e-01, -2.0664e+00],\n",
      "       [ 1.4375e+00, -5.4297e-01, -1.0469e+00],\n",
      "       [ 2.1133e+00, -5.8105e-01, -1.7598e+00],\n",
      "       [ 1.0137e+00, -5.2881e-01, -7.9199e-01],\n",
      "       [ 7.0068e-01, -2.9102e-01, -6.1719e-01],\n",
      "       [ 1.6094e+00, -5.1172e-01, -1.2705e+00],\n",
      "       [-5.8154e-01, -4.3140e-01,  8.9453e-01],\n",
      "       [-1.9922e-01, -5.4346e-01,  6.3574e-01],\n",
      "       [-8.6328e-01, -2.0532e-01,  9.5117e-01],\n",
      "       [ 1.5918e+00, -1.9934e-01, -1.6025e+00],\n",
      "       [ 6.8408e-01, -3.4888e-01, -4.7217e-01],\n",
      "       [ 1.7783e+00, -1.5918e-01, -1.8281e+00],\n",
      "       [ 1.1885e+00, -6.9678e-01, -6.3281e-01],\n",
      "       [-3.3032e-01, -8.4229e-02,  2.1033e-01],\n",
      "       [ 1.6279e+00, -4.3384e-01, -1.3428e+00],\n",
      "       [ 1.1689e+00, -5.0488e-01, -8.0518e-01],\n",
      "       [ 7.9541e-01, -8.7036e-02, -7.7246e-01],\n",
      "       [ 1.7676e-01, -3.4595e-01, -1.2398e-02],\n",
      "       [ 1.5654e+00, -3.4424e-01, -1.5244e+00],\n",
      "       [ 1.4082e+00, -1.0699e-01, -1.4883e+00],\n",
      "       [ 1.9824e+00, -1.1584e-01, -2.0645e+00],\n",
      "       [-8.9746e-01, -3.6426e-01,  1.2764e+00],\n",
      "       [ 1.5938e+00, -4.3604e-01, -1.5088e+00],\n",
      "       [ 5.4199e-01, -8.1253e-03, -7.2559e-01],\n",
      "       [ 1.7480e+00, -2.0227e-01, -1.7432e+00],\n",
      "       [ 7.5342e-01, -3.7549e-01, -6.9336e-01],\n",
      "       [ 1.3008e+00, -5.0830e-01, -9.6924e-01],\n",
      "       [ 9.8724e-03, -2.8857e-01,  1.1328e-01],\n",
      "       [ 1.4482e+00, -5.2002e-01, -1.1699e+00],\n",
      "       [ 1.0137e+00, -5.6104e-01, -6.8115e-01],\n",
      "       [ 1.3945e+00, -3.1738e-01, -1.2266e+00],\n",
      "       [ 1.4014e+00, -1.5369e-01, -1.3906e+00],\n",
      "       [-6.0352e-01, -2.3083e-01,  8.9258e-01],\n",
      "       [ 6.0596e-01, -1.6492e-01, -6.6211e-01],\n",
      "       [ 7.5781e-01, -1.7957e-01, -7.0898e-01],\n",
      "       [ 9.5508e-01, -3.4082e-01, -7.2559e-01],\n",
      "       [ 1.1357e+00, -4.3091e-01, -9.5166e-01],\n",
      "       [ 1.1450e-01, -5.6250e-01,  3.3813e-01],\n",
      "       [ 1.8037e+00, -3.8232e-01, -1.6260e+00],\n",
      "       [ 8.6768e-01, -3.3569e-01, -7.5586e-01],\n",
      "       [ 1.4023e+00, -3.7280e-01, -1.3008e+00],\n",
      "       [ 1.6924e+00, -4.7974e-01, -1.4668e+00],\n",
      "       [ 1.6719e+00, -4.4312e-01, -1.4570e+00],\n",
      "       [ 8.9697e-01, -2.2241e-01, -8.7695e-01],\n",
      "       [-4.7607e-01, -2.7319e-01,  7.2559e-01],\n",
      "       [ 1.2793e+00, -2.2815e-01, -1.2354e+00],\n",
      "       [ 1.5596e+00, -1.7627e-01, -1.4600e+00],\n",
      "       [ 1.1895e+00, -3.2031e-01, -1.1758e+00],\n",
      "       [ 1.6631e+00, -2.4451e-01, -1.5566e+00],\n",
      "       [ 1.8262e+00, -5.5371e-01, -1.4688e+00],\n",
      "       [ 2.1074e+00, -5.2490e-01, -1.7812e+00],\n",
      "       [ 1.0947e+00, -8.7109e-01, -4.0015e-01],\n",
      "       [-3.1592e-01, -3.8525e-01,  5.8984e-01],\n",
      "       [ 1.4072e+00, -3.5400e-01, -1.2881e+00],\n",
      "       [ 1.1396e+00, -1.8665e-01, -1.1582e+00],\n",
      "       [ 1.5801e+00, -4.9683e-01, -1.3760e+00],\n",
      "       [ 2.1094e+00,  3.8300e-02, -2.3691e+00],\n",
      "       [ 5.4688e-01, -3.2178e-01, -4.5801e-01],\n",
      "       [ 3.9746e-01, -3.6353e-01, -2.0642e-01],\n",
      "       [ 8.6963e-01,  6.8054e-02, -1.0986e+00],\n",
      "       [ 5.4883e-01, -1.5784e-01, -6.1182e-01],\n",
      "       [ 1.2637e+00, -5.0586e-01, -8.7549e-01],\n",
      "       [ 8.9014e-01, -5.0146e-01, -4.8901e-01],\n",
      "       [ 2.1211e+00, -6.2988e-01, -1.7246e+00],\n",
      "       [ 1.9268e+00, -5.2832e-01, -1.5479e+00],\n",
      "       [ 1.1924e+00, -5.8643e-01, -9.1748e-01],\n",
      "       [ 1.5381e+00, -6.2744e-01, -1.0869e+00],\n",
      "       [ 1.6572e+00, -5.1221e-01, -1.3848e+00],\n",
      "       [-2.5903e-01, -1.4771e-01,  2.5073e-01],\n",
      "       [ 1.1377e+00,  7.0312e-02, -1.3877e+00],\n",
      "       [ 1.0107e+00, -6.2695e-01, -6.0059e-01],\n",
      "       [ 9.1602e-01, -3.8770e-01, -8.3447e-01],\n",
      "       [ 1.3486e+00, -2.3547e-01, -1.3516e+00],\n",
      "       [ 1.4893e+00, -8.3984e-01, -1.0322e+00],\n",
      "       [ 1.4502e+00, -7.1240e-01, -8.5840e-01],\n",
      "       [ 2.7344e-01, -4.8364e-01,  8.5938e-02],\n",
      "       [ 1.2656e+00, -3.9355e-01, -1.0361e+00],\n",
      "       [ 1.4197e-01, -2.9126e-01, -9.5596e-03],\n",
      "       [ 5.2295e-01, -3.1250e-01, -4.8047e-01],\n",
      "       [ 2.2815e-01, -5.0049e-01,  5.7526e-02],\n",
      "       [ 8.9307e-01, -2.2766e-01, -8.7744e-01],\n",
      "       [ 1.3066e+00, -5.0342e-01, -1.0166e+00],\n",
      "       [ 1.5381e+00, -2.2668e-01, -1.5225e+00],\n",
      "       [-4.0332e-01, -5.7471e-01,  1.0117e+00],\n",
      "       [ 2.0215e+00, -2.9126e-01, -1.9355e+00],\n",
      "       [ 2.4121e+00, -5.3223e-01, -2.1641e+00],\n",
      "       [ 1.3838e+00, -5.0000e-01, -1.1660e+00],\n",
      "       [ 2.0996e+00,  2.3468e-02, -2.1953e+00],\n",
      "       [ 1.0703e+00, -6.5625e-01, -5.4004e-01],\n",
      "       [ 9.1748e-01, -4.7583e-01, -6.6064e-01],\n",
      "       [ 7.6025e-01, -4.1064e-01, -5.1611e-01],\n",
      "       [ 1.3350e+00, -5.2051e-01, -9.8047e-01],\n",
      "       [ 1.2031e+00, -1.5723e-01, -1.2637e+00],\n",
      "       [ 1.3438e+00, -3.3350e-01, -1.2061e+00],\n",
      "       [ 1.5068e+00, -5.1807e-01, -1.2354e+00],\n",
      "       [ 1.2246e+00, -5.3760e-01, -9.8145e-01],\n",
      "       [ 1.4346e+00, -9.7717e-02, -1.5371e+00],\n",
      "       [ 2.0059e+00, -1.4526e-01, -2.0566e+00],\n",
      "       [ 1.3457e+00, -2.9590e-01, -1.2461e+00],\n",
      "       [ 2.1562e+00, -6.0400e-01, -1.7314e+00],\n",
      "       [-1.7395e-01, -4.8730e-01,  5.1855e-01],\n",
      "       [ 1.2275e+00, -7.8955e-01, -6.1621e-01],\n",
      "       [ 1.5693e+00, -1.8042e-01, -1.5527e+00],\n",
      "       [ 1.5342e+00, -3.3203e-01, -1.4160e+00],\n",
      "       [ 1.4014e+00, -4.9243e-01, -1.1299e+00],\n",
      "       [ 1.8428e+00, -4.4092e-01, -1.6348e+00],\n",
      "       [ 4.4092e-01, -6.8970e-02, -5.0537e-01],\n",
      "       [ 1.1133e+00, -3.6572e-01, -8.5889e-01],\n",
      "       [ 1.6426e+00, -3.7109e-01, -1.4844e+00],\n",
      "       [ 2.0137e+00, -2.8394e-01, -1.9414e+00],\n",
      "       [ 2.0547e+00, -4.9927e-01, -1.7744e+00],\n",
      "       [ 1.3564e+00, -2.4268e-01, -1.3320e+00],\n",
      "       [ 1.2266e+00, -3.8770e-01, -1.1768e+00],\n",
      "       [ 8.9258e-01, -5.2002e-01, -3.9600e-01],\n",
      "       [-5.1465e-01, -2.1252e-01,  7.3535e-01],\n",
      "       [ 1.9170e+00, -1.3928e-01, -1.9893e+00],\n",
      "       [ 7.2217e-01, -4.8535e-01, -4.8462e-01],\n",
      "       [ 2.0000e+00, -1.9397e-01, -2.0156e+00],\n",
      "       [ 1.7295e+00, -1.2000e-01, -1.7500e+00],\n",
      "       [ 1.0498e+00, -4.6924e-01, -7.8027e-01],\n",
      "       [ 1.0947e+00, -3.6572e-01, -9.5068e-01],\n",
      "       [ 9.6924e-01, -3.4424e-01, -6.5186e-01],\n",
      "       [ 2.3887e+00, -3.8159e-01, -2.2930e+00],\n",
      "       [ 1.5596e+00, -4.8413e-01, -1.2607e+00],\n",
      "       [ 9.7607e-01, -5.7422e-01, -5.5420e-01],\n",
      "       [ 4.8926e-01, -3.4058e-02, -4.9731e-01],\n",
      "       [ 1.6797e+00, -4.8438e-01, -1.3613e+00],\n",
      "       [ 7.6465e-01, -4.5190e-01, -3.9722e-01],\n",
      "       [ 7.5781e-01, -8.1787e-01, -3.2397e-01],\n",
      "       [-7.5049e-01, -1.6272e-01,  8.7061e-01],\n",
      "       [-1.8396e-01, -3.2446e-01,  4.9658e-01],\n",
      "       [ 1.3779e+00, -4.7144e-01, -1.1143e+00],\n",
      "       [ 1.0547e+00, -3.8232e-01, -8.4521e-01],\n",
      "       [ 1.9131e+00, -1.8677e-01, -1.9395e+00],\n",
      "       [ 1.5312e+00, -8.1152e-01, -1.0947e+00],\n",
      "       [ 2.0801e+00, -3.2739e-01, -1.9609e+00],\n",
      "       [ 1.2207e+00, -5.8643e-01, -9.0625e-01],\n",
      "       [ 1.7451e+00, -5.0098e-01, -1.4746e+00],\n",
      "       [ 1.4717e+00, -7.7393e-01, -7.6904e-01],\n",
      "       [ 1.9199e+00, -7.4170e-01, -1.3770e+00],\n",
      "       [ 1.7021e+00,  1.4221e-02, -1.8564e+00],\n",
      "       [-3.2886e-01, -3.1055e-01,  5.0098e-01],\n",
      "       [-1.5526e-02, -2.9785e-01,  1.6626e-01],\n",
      "       [-9.6582e-01, -3.7866e-01,  1.2646e+00],\n",
      "       [-6.6602e-01, -5.1953e-01,  1.1738e+00],\n",
      "       [ 1.0312e+00, -2.3718e-01, -1.0244e+00],\n",
      "       [ 4.2603e-01, -4.8022e-01, -2.1155e-01],\n",
      "       [ 4.0771e-01, -2.1948e-01, -5.2100e-01],\n",
      "       [ 1.1113e+00, -4.3921e-01, -8.9062e-01],\n",
      "       [ 1.3945e+00, -2.9565e-01, -1.3037e+00],\n",
      "       [ 1.8054e-01, -6.9336e-02, -3.2837e-01],\n",
      "       [-2.1094e-01, -2.5269e-01,  4.4263e-01],\n",
      "       [ 9.3311e-01, -4.6338e-01, -4.4580e-01],\n",
      "       [-1.0322e+00, -2.4683e-01,  1.1338e+00],\n",
      "       [ 8.7793e-01, -3.2715e-01, -5.9375e-01],\n",
      "       [ 8.3447e-01, -4.0942e-01, -6.0840e-01],\n",
      "       [ 2.0723e+00, -9.9548e-02, -2.0391e+00],\n",
      "       [ 2.5430e+00, -4.5801e-01, -2.2656e+00],\n",
      "       [ 3.1433e-02, -1.6321e-01, -1.5930e-02],\n",
      "       [ 1.5293e+00, -6.6846e-01, -1.1006e+00],\n",
      "       [-3.5303e-01, -3.1860e-01,  5.1123e-01],\n",
      "       [ 1.4209e+00, -1.7981e-01, -1.3223e+00],\n",
      "       [ 7.8613e-01, -3.3472e-01, -4.1211e-01],\n",
      "       [-2.4815e-03,  2.9964e-03, -1.8408e-01],\n",
      "       [ 1.4905e-01, -4.9341e-01,  1.3306e-01],\n",
      "       [-9.2725e-01, -7.4219e-02,  1.0322e+00],\n",
      "       [ 1.0889e+00, -1.5442e-01, -1.0254e+00],\n",
      "       [-1.8164e+00, -6.6504e-01,  2.3906e+00],\n",
      "       [ 1.5830e+00, -5.4443e-01, -1.1338e+00],\n",
      "       [ 2.2227e+00, -1.7236e-01, -2.2891e+00],\n",
      "       [ 2.2812e+00, -2.3413e-01, -2.2441e+00],\n",
      "       [ 1.8848e+00, -7.3425e-02, -1.8662e+00],\n",
      "       [ 1.8584e+00, -6.1768e-01, -1.4648e+00],\n",
      "       [-1.9019e-01, -7.9651e-02,  1.6431e-01],\n",
      "       [ 1.3389e+00, -4.8999e-01, -9.7412e-01],\n",
      "       [ 1.0244e+00, -6.6357e-01, -5.0146e-01],\n",
      "       [ 1.1279e+00, -7.1289e-01, -6.9287e-01],\n",
      "       [-6.7139e-01, -2.8491e-01,  9.2822e-01],\n",
      "       [ 1.5508e+00, -3.9722e-01, -1.2773e+00],\n",
      "       [ 1.0771e+00, -5.8789e-01, -8.0957e-01],\n",
      "       [ 2.3711e+00, -4.4458e-01, -2.2090e+00],\n",
      "       [ 1.3789e+00, -5.8691e-01, -1.0342e+00],\n",
      "       [ 1.0557e+00, -5.2277e-02, -1.1973e+00],\n",
      "       [ 1.5127e+00, -6.5234e-01, -1.0215e+00],\n",
      "       [ 2.3379e+00, -4.1187e-01, -2.1582e+00],\n",
      "       [ 5.8301e-01, -1.5344e-01, -5.2148e-01],\n",
      "       [ 1.8457e+00,  5.8174e-03, -1.9512e+00],\n",
      "       [-7.2632e-02, -3.5156e-01,  2.2192e-01],\n",
      "       [ 2.0166e-01, -1.4185e-01, -3.2983e-01],\n",
      "       [ 2.3164e+00, -7.0459e-01, -1.8076e+00],\n",
      "       [ 1.0176e+00, -8.6621e-01, -5.2344e-01],\n",
      "       [ 1.6836e+00, -6.0889e-01, -1.2822e+00],\n",
      "       [ 1.0186e+00, -4.1309e-01, -8.6865e-01],\n",
      "       [ 7.7295e-01, -1.0901e-01, -7.9590e-01],\n",
      "       [ 1.0078e+00, -1.3220e-01, -1.0938e+00],\n",
      "       [ 1.4678e+00, -3.9795e-01, -1.2959e+00],\n",
      "       [ 9.8779e-01, -4.6338e-01, -7.3047e-01],\n",
      "       [ 1.9033e+00, -6.1719e-01, -1.4941e+00],\n",
      "       [ 7.8076e-01, -5.6152e-01, -4.7095e-01],\n",
      "       [ 7.2119e-01, -5.2637e-01, -3.7451e-01],\n",
      "       [ 6.3916e-01, -4.0845e-01, -3.3057e-01],\n",
      "       [ 1.4502e+00, -4.6851e-01, -1.1436e+00],\n",
      "       [ 8.3887e-01, -2.3816e-01, -5.2734e-01],\n",
      "       [ 1.6406e+00, -1.9287e-01, -1.6533e+00],\n",
      "       [ 1.5742e+00, -4.4336e-01, -1.3301e+00],\n",
      "       [ 3.6346e-02, -3.8525e-01,  1.2952e-01],\n",
      "       [ 1.2939e+00, -4.9561e-01, -9.2871e-01],\n",
      "       [ 1.4482e+00, -1.8921e-01, -1.3584e+00],\n",
      "       [ 2.4434e+00, -3.0127e-01, -2.2949e+00],\n",
      "       [ 2.1699e+00, -7.4463e-01, -1.6787e+00],\n",
      "       [ 8.3618e-02, -1.1322e-01, -1.9214e-01],\n",
      "       [ 2.8076e-01, -3.7646e-01, -1.3281e-01],\n",
      "       [-7.6904e-01, -4.0527e-01,  1.0166e+00],\n",
      "       [ 1.7217e+00, -4.8901e-01, -1.4424e+00],\n",
      "       [ 8.8037e-01, -3.1104e-01, -7.0312e-01],\n",
      "       [ 1.3164e+00, -2.8906e-01, -1.0596e+00],\n",
      "       [ 5.5127e-01, -4.2944e-01, -1.3464e-01]], dtype=float16), label_ids=array([0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
      "       0, 1, 2, 2, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 2, 0, 2, 1, 0, 0,\n",
      "       1, 2, 0, 0, 0, 2, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 2, 1, 0, 1, 0,\n",
      "       0, 1, 2, 2, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
      "       0, 1, 0, 0, 1, 0, 1, 1, 2, 0, 0, 1, 2, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "       1, 2, 0, 0, 1, 0, 0, 0, 1, 2, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
      "       0, 1, 0, 1, 0, 0, 1, 0, 2, 0, 0, 0, 1, 1, 2, 1, 0, 0, 0, 0, 1, 1,\n",
      "       2, 0, 0, 1, 0, 2, 2, 2, 1, 0, 0, 1, 0, 1, 2, 0, 2, 0, 1, 0, 0, 0,\n",
      "       0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 2, 2, 0, 1, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 2, 0, 0,\n",
      "       0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 2, 0, 0, 1]), metrics={'test_loss': 0.8969194293022156, 'test_accuracy': 0.6239316239316239, 'test_precision': 0.43828874202556733, 'test_recall': 0.6239316239316239, 'test_f1': 0.5141311697092631, 'test_runtime': 0.6141, 'test_samples_per_second': 381.069, 'test_steps_per_second': 24.428})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "808dd68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48fb2163",
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = torch.softmax(torch.tensor(test_results.predictions).to(torch.float32), dim=-1)\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed6cfde2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")  # Adjust xticklabels and yticklabels as needed\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "346c6d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_save = []\n",
    "for idx in range(len(test_data)):\n",
    "    item = dataset['test'][idx]\n",
    "    actual_label = item['label']\n",
    "    predicted_label = predictions[idx]\n",
    "    claim = item['claim'] \n",
    "    premise = item['premise'] \n",
    "    category = item['category']\n",
    "    \n",
    "    # Append the information as a dictionary to the list\n",
    "    data_to_save.append({\n",
    "        'Claim': claim,\n",
    "        'Premise': premise,\n",
    "        'Actual Label': actual_label,\n",
    "        'Predicted Label': predicted_label,\n",
    "        'Category' : category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_to_save)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/home/elson/results/11.4.5_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4543aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correctly classified instances\n",
    "correctly_classified = df[df['Actual Label'] == df['Predicted Label']]\n",
    "\n",
    "# Calculate misclassified instances\n",
    "misclassified = df[df['Actual Label'] != df['Predicted Label']]\n",
    "\n",
    "# Count the number of correctly classified and misclassified by category\n",
    "correct_classification_counts = correctly_classified['Category'].value_counts()\n",
    "misclassification_counts = misclassified['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad099d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           37\n",
       "Bone health              13\n",
       "Fitness                  13\n",
       "Diabetes                 10\n",
       "Skin                     10\n",
       "Throat                    9\n",
       "Cancer                    9\n",
       "Neurological health       8\n",
       "Cardiovascular Health     7\n",
       "Hair                      6\n",
       "Ear                       6\n",
       "Blood                     4\n",
       "COVID                     3\n",
       "Men's health              3\n",
       "Women' s Health           3\n",
       "Mental Health             3\n",
       "Muscles                   1\n",
       "Eye                       1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d45817c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Skin                     14\n",
       "General Health           14\n",
       "Eye                       8\n",
       "Bone health               8\n",
       "Hair                      6\n",
       "Cardiovascular Health     5\n",
       "Muscles                   5\n",
       "Blood                     5\n",
       "Cancer                    3\n",
       "COVID                     3\n",
       "Vascular                  3\n",
       "Men's health              3\n",
       "Dental Health             3\n",
       "Women' s Health           3\n",
       "Diabetes                  2\n",
       "Fitness                   2\n",
       "Neurological health       1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
