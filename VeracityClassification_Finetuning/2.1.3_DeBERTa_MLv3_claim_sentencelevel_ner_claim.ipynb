{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-cfbf7584a6bb7c13\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 220.02it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('csv',data_files='dataset_sentenceattribution_nerfeatures_split.csv',delimiter=',',column_names=[\"claim\",\"premise\",\"label\",\"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\",\"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\",\"url\", \"entities\",\"entity_map\",\"gem_exp\",\"gem_label\",\"gpt_label\",\"gpt_exp\",\"gold_exp\",\"entity_map_ev\",\"entity_ev\",\"synonym\",\"voice\",\"split\"],skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ca8e735",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-aa1fd4d2889f655e.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-9cd628f4430f2ace.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-df968f39da4ad12a.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01252e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\"claim\", \"premise\", \"label\", \"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\"]\n",
    "all_columns = dataset[\"train\"].column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-b638575a29a2a369.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-c40e649fdc04fbe6.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-b1db050fd6262d30.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 2, 'entailment': 0, 'neutral': 1}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 2,\n",
    "    \"entailment\": 0,\n",
    "    \"neutral\": 1\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e15010ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "        # Extracting claim and evidence texts\n",
    "        claim = item['claim'] \n",
    "        evidences = item['premise']\n",
    "        item['premise']=evidences\n",
    "        item['claim']=claim\n",
    "        additional_features = [\n",
    "            \"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\"]\n",
    "    \n",
    "        for feature in additional_features:\n",
    "            if feature in item:\n",
    "                claim += \"[SEP]\" + str(item[feature])\n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "            evidences,claim,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "         # Construct the output item\n",
    "        output_item = {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),  # Remove batch dimension\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),  # Remove batch dimension\n",
    "            'claim': claim,  # Include augmented claim text\n",
    "            'evidences': evidences  # Include original evidence text\n",
    "        }\n",
    "        \n",
    "        if 'label' in item:\n",
    "            output_item['label'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return output_item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62421eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DebertaV2ForSequenceClassification(\n",
       "  (deberta): DebertaV2Model(\n",
       "    (embeddings): DebertaV2Embeddings(\n",
       "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaV2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (1): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (2): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (3): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (4): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (5): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (6): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (7): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (8): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (9): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (10): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (11): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (pooler): ContextPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): StableDropout()\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (dropout): StableDropout()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=512)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=3, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    return {\"accuracy\": acc, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f5cf584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([    1,  4081,   261,  5042,   333, 73325,  1452,  2155,  6116,  1938,\n",
       "           272,   262, 88609,   263, 98237,  1830,  1080,  7355,   387,  2655,\n",
       "           262, 12682,   265, 65008,   292,  1158, 53245,   264, 75840,   293,\n",
       "          2376,  1158,  1452,  2155,   260,     2,   573, 52341,  1830,  1080,\n",
       "           269,  1359,   427,   267, 17847,   633,   264,   408,  1300,   262,\n",
       "          2658,   265,   262,  1158,   260,     2,   767,     2,   767,     2,\n",
       "           767,     2,   767,     2,   767,     2,   767,     2,   767,     2,\n",
       "           767,     2,   767,     2,   767,     2,   767,     2,   767,     2,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'claim': 'Myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0',\n",
       " 'evidences': 'Additionally, laser doppler blood flow measurement showed that the frankincense and myrrh essential oil compound could promote the elimination of capillaries from skin epidermis to dermis by increasing skin blood flow.',\n",
       " 'label': tensor(1)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 765\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='765' max='765' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [765/765 11:30, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.719700</td>\n",
       "      <td>0.823577</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.605207</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.594127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.666400</td>\n",
       "      <td>0.773161</td>\n",
       "      <td>0.679570</td>\n",
       "      <td>0.673637</td>\n",
       "      <td>0.679570</td>\n",
       "      <td>0.676050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.479600</td>\n",
       "      <td>0.800578</td>\n",
       "      <td>0.692473</td>\n",
       "      <td>0.696010</td>\n",
       "      <td>0.692473</td>\n",
       "      <td>0.691663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.333100</td>\n",
       "      <td>0.957869</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.670232</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.672543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.327600</td>\n",
       "      <td>1.081264</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.682322</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.672219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.210300</td>\n",
       "      <td>1.353984</td>\n",
       "      <td>0.683871</td>\n",
       "      <td>0.703216</td>\n",
       "      <td>0.683871</td>\n",
       "      <td>0.689833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.207400</td>\n",
       "      <td>1.307299</td>\n",
       "      <td>0.658065</td>\n",
       "      <td>0.683555</td>\n",
       "      <td>0.658065</td>\n",
       "      <td>0.665743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.159900</td>\n",
       "      <td>1.441404</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.683206</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.675515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.151800</td>\n",
       "      <td>1.363435</td>\n",
       "      <td>0.683871</td>\n",
       "      <td>0.704333</td>\n",
       "      <td>0.683871</td>\n",
       "      <td>0.689063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.175300</td>\n",
       "      <td>1.553594</td>\n",
       "      <td>0.668817</td>\n",
       "      <td>0.689560</td>\n",
       "      <td>0.668817</td>\n",
       "      <td>0.673795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.088900</td>\n",
       "      <td>1.664095</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.673372</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.674265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.039900</td>\n",
       "      <td>1.985015</td>\n",
       "      <td>0.679570</td>\n",
       "      <td>0.672220</td>\n",
       "      <td>0.679570</td>\n",
       "      <td>0.674764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.016400</td>\n",
       "      <td>2.117512</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.670546</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.667807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>2.154817</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.670526</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.672909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.014800</td>\n",
       "      <td>2.151200</td>\n",
       "      <td>0.673118</td>\n",
       "      <td>0.668606</td>\n",
       "      <td>0.673118</td>\n",
       "      <td>0.670254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.1.3_deberta/checkpoint-51\n",
      "Configuration saved in /home/elson/2.1.3_deberta/checkpoint-51/config.json\n",
      "Model weights saved in /home/elson/2.1.3_deberta/checkpoint-51/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.1.3_deberta/checkpoint-306] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/2.1.3_deberta/checkpoint-765] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.1.3_deberta/checkpoint-102\n",
      "Configuration saved in /home/elson/2.1.3_deberta/checkpoint-102/config.json\n",
      "Model weights saved in /home/elson/2.1.3_deberta/checkpoint-102/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.1.3_deberta/checkpoint-51] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.1.3_deberta/checkpoint-153\n",
      "Configuration saved in /home/elson/2.1.3_deberta/checkpoint-153/config.json\n",
      "Model weights saved in /home/elson/2.1.3_deberta/checkpoint-153/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.1.3_deberta/checkpoint-102] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.1.3_deberta/checkpoint-204\n",
      "Configuration saved in /home/elson/2.1.3_deberta/checkpoint-204/config.json\n",
      "Model weights saved in /home/elson/2.1.3_deberta/checkpoint-204/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.1.3_deberta/checkpoint-255\n",
      "Configuration saved in /home/elson/2.1.3_deberta/checkpoint-255/config.json\n",
      "Model weights saved in /home/elson/2.1.3_deberta/checkpoint-255/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.1.3_deberta/checkpoint-204] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.1.3_deberta/checkpoint-306\n",
      "Configuration saved in /home/elson/2.1.3_deberta/checkpoint-306/config.json\n",
      "Model weights saved in /home/elson/2.1.3_deberta/checkpoint-306/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.1.3_deberta/checkpoint-255] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.1.3_deberta/checkpoint-357\n",
      "Configuration saved in /home/elson/2.1.3_deberta/checkpoint-357/config.json\n",
      "Model weights saved in /home/elson/2.1.3_deberta/checkpoint-357/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.1.3_deberta/checkpoint-306] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.1.3_deberta/checkpoint-408\n",
      "Configuration saved in /home/elson/2.1.3_deberta/checkpoint-408/config.json\n",
      "Model weights saved in /home/elson/2.1.3_deberta/checkpoint-408/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.1.3_deberta/checkpoint-357] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.1.3_deberta/checkpoint-459\n",
      "Configuration saved in /home/elson/2.1.3_deberta/checkpoint-459/config.json\n",
      "Model weights saved in /home/elson/2.1.3_deberta/checkpoint-459/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.1.3_deberta/checkpoint-408] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.1.3_deberta/checkpoint-510\n",
      "Configuration saved in /home/elson/2.1.3_deberta/checkpoint-510/config.json\n",
      "Model weights saved in /home/elson/2.1.3_deberta/checkpoint-510/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.1.3_deberta/checkpoint-459] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.1.3_deberta/checkpoint-561\n",
      "Configuration saved in /home/elson/2.1.3_deberta/checkpoint-561/config.json\n",
      "Model weights saved in /home/elson/2.1.3_deberta/checkpoint-561/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.1.3_deberta/checkpoint-510] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.1.3_deberta/checkpoint-612\n",
      "Configuration saved in /home/elson/2.1.3_deberta/checkpoint-612/config.json\n",
      "Model weights saved in /home/elson/2.1.3_deberta/checkpoint-612/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.1.3_deberta/checkpoint-561] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.1.3_deberta/checkpoint-663\n",
      "Configuration saved in /home/elson/2.1.3_deberta/checkpoint-663/config.json\n",
      "Model weights saved in /home/elson/2.1.3_deberta/checkpoint-663/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.1.3_deberta/checkpoint-612] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.1.3_deberta/checkpoint-714\n",
      "Configuration saved in /home/elson/2.1.3_deberta/checkpoint-714/config.json\n",
      "Model weights saved in /home/elson/2.1.3_deberta/checkpoint-714/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.1.3_deberta/checkpoint-663] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.1.3_deberta/checkpoint-765\n",
      "Configuration saved in /home/elson/2.1.3_deberta/checkpoint-765/config.json\n",
      "Model weights saved in /home/elson/2.1.3_deberta/checkpoint-765/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.1.3_deberta/checkpoint-714] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/elson/2.1.3_deberta/checkpoint-153 (score: 0.6924731182795699).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /home/elson/2.1.3_deberta/best_model/config.json\n",
      "Model weights saved in /home/elson/2.1.3_deberta/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/2.1.3_deberta/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/2.1.3_deberta/best_model/special_tokens_map.json\n",
      "added tokens file saved in /home/elson/2.1.3_deberta/best_model/added_tokens.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/2.1.3_deberta/best_model/tokenizer_config.json',\n",
       " '/home/elson/2.1.3_deberta/best_model/special_tokens_map.json',\n",
       " '/home/elson/2.1.3_deberta/best_model/spm.model',\n",
       " '/home/elson/2.1.3_deberta/best_model/added_tokens.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/2.1.3_deberta/',\n",
    "    num_train_epochs=15,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.6,\n",
    "    weight_decay=0.1,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/2.1.3_deberta/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/2.1.3_deberta/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63deaea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/2.1.3_deberta/best_model/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"/home/elson/2.1.3_deberta/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"entailment\",\n",
      "    \"1\": \"neutral\",\n",
      "    \"2\": \"contradiction\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"contradiction\": 2,\n",
      "    \"entailment\": 0,\n",
      "    \"neutral\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file /home/elson/2.1.3_deberta/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at /home/elson/2.1.3_deberta/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 32\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/2.1.3_deberta/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[ 2.1328e+00,  7.3779e-01, -2.8828e+00],\n",
      "       [ 3.1914e+00, -2.5195e-01, -2.9277e+00],\n",
      "       [ 3.0059e+00, -5.7666e-01, -2.3770e+00],\n",
      "       [-3.0933e-01,  7.8662e-01, -4.6118e-01],\n",
      "       [ 2.7949e+00, -2.9858e-01, -2.4082e+00],\n",
      "       [ 3.2383e+00, -3.3374e-01, -2.8496e+00],\n",
      "       [ 2.5703e+00, -3.9941e-01, -2.1641e+00],\n",
      "       [ 3.3574e+00, -8.9893e-01, -2.3750e+00],\n",
      "       [ 2.6094e+00, -8.1909e-02, -2.4707e+00],\n",
      "       [ 3.9380e-01,  1.3340e+00, -1.7627e+00],\n",
      "       [-9.6826e-01, -2.7771e-02,  1.0811e+00],\n",
      "       [ 3.9453e+00, -1.2080e+00, -2.5859e+00],\n",
      "       [ 2.6318e-01,  9.6631e-01, -1.1895e+00],\n",
      "       [ 3.6992e+00, -9.6533e-01, -2.5957e+00],\n",
      "       [-7.6562e-01,  1.6719e+00, -8.8184e-01],\n",
      "       [-8.1396e-01,  9.7754e-01, -3.6499e-02],\n",
      "       [ 1.2861e+00,  1.5557e+00, -3.0332e+00],\n",
      "       [ 3.5791e-01,  2.6807e-01, -6.0693e-01],\n",
      "       [ 3.7168e+00, -9.3750e-01, -2.6504e+00],\n",
      "       [ 2.4922e+00,  1.0229e-01, -2.6172e+00],\n",
      "       [ 1.6494e+00,  9.2822e-01, -2.7109e+00],\n",
      "       [ 3.9062e-01,  9.2432e-01, -1.3398e+00],\n",
      "       [-9.3079e-02,  1.9346e+00, -1.9238e+00],\n",
      "       [-1.8945e-01,  1.1611e+00, -1.0010e+00],\n",
      "       [-4.8193e-01,  1.1310e-01,  4.0967e-01],\n",
      "       [-2.1895e+00, -6.3135e-01,  2.8418e+00],\n",
      "       [ 4.0820e+00, -9.6094e-01, -2.9062e+00],\n",
      "       [ 5.7568e-01,  1.1318e+00, -1.7764e+00],\n",
      "       [ 2.2012e+00, -2.5928e-01, -1.9023e+00],\n",
      "       [ 1.5557e+00, -5.2588e-01, -1.0557e+00],\n",
      "       [ 1.3037e+00,  4.9756e-01, -1.8408e+00],\n",
      "       [ 2.8594e+00, -3.6957e-02, -2.8066e+00],\n",
      "       [ 1.1240e+00,  5.5176e-01, -1.7822e+00],\n",
      "       [ 2.0977e+00, -2.4939e-01, -1.8174e+00],\n",
      "       [ 2.1753e-01,  1.1836e+00, -1.4463e+00],\n",
      "       [ 4.9365e-01,  1.8926e+00, -2.6582e+00],\n",
      "       [ 1.2705e+00,  4.8657e-01, -1.7363e+00],\n",
      "       [ 3.3652e+00, -2.9395e-01, -2.9668e+00],\n",
      "       [-8.8818e-01,  6.4307e-01,  3.8232e-01],\n",
      "       [ 3.9697e-01,  2.0918e+00, -2.7305e+00],\n",
      "       [-4.4043e-01,  2.0762e+00, -1.7578e+00],\n",
      "       [ 2.2637e+00,  9.1895e-01, -3.2734e+00],\n",
      "       [ 1.0537e+00,  6.1914e-01, -1.7246e+00],\n",
      "       [-1.7354e+00,  1.0996e+00,  8.0322e-01],\n",
      "       [-2.1533e-01,  1.5381e+00, -1.2881e+00],\n",
      "       [ 6.2012e-01,  1.5332e+00, -2.3477e+00],\n",
      "       [-1.0828e-01,  2.3711e+00, -2.3906e+00],\n",
      "       [ 1.7803e+00, -1.1383e-01, -1.6562e+00],\n",
      "       [ 3.1875e+00, -7.7515e-02, -3.0488e+00],\n",
      "       [-7.0410e-01, -2.3880e-02,  7.5977e-01],\n",
      "       [ 7.0361e-01,  8.5107e-01, -1.6123e+00],\n",
      "       [ 2.1367e+00, -4.0479e-01, -1.7002e+00],\n",
      "       [ 6.1133e-01,  1.7412e+00, -2.4824e+00],\n",
      "       [ 7.8076e-01,  5.6885e-01, -1.2939e+00],\n",
      "       [-5.5811e-01,  2.3965e+00, -2.1035e+00],\n",
      "       [ 2.4297e+00, -3.3722e-02, -2.4238e+00],\n",
      "       [ 1.4087e-01,  1.0410e+00, -1.2314e+00],\n",
      "       [ 1.2881e+00,  1.7871e+00, -3.3008e+00],\n",
      "       [ 2.6934e+00, -2.7856e-01, -2.3594e+00],\n",
      "       [ 2.9570e+00, -5.1074e-01, -2.4238e+00],\n",
      "       [ 3.2695e+00, -4.7314e-01, -2.6484e+00],\n",
      "       [-1.3730e+00, -2.3364e-01,  1.6484e+00],\n",
      "       [ 1.8662e+00,  1.1292e-01, -2.0039e+00],\n",
      "       [ 9.5947e-01,  2.1055e+00, -3.2520e+00],\n",
      "       [-1.9250e-01,  1.1475e+00, -1.0566e+00],\n",
      "       [ 3.8086e+00, -5.5811e-01, -3.1016e+00],\n",
      "       [ 8.0225e-01,  5.3076e-01, -1.3848e+00],\n",
      "       [ 2.4473e+00, -2.0166e-01, -2.2480e+00],\n",
      "       [-6.8945e-01,  1.0674e+00, -2.4731e-01],\n",
      "       [ 5.6152e-01,  7.8308e-02, -6.8506e-01],\n",
      "       [ 1.9365e+00,  2.5708e-01, -2.1680e+00],\n",
      "       [-7.9785e-01,  2.2754e+00, -1.4570e+00],\n",
      "       [ 4.9780e-01,  1.1328e+00, -1.7754e+00],\n",
      "       [ 1.0278e-01,  6.2549e-01, -6.5430e-01],\n",
      "       [-2.2485e-01,  4.0112e-01, -1.0791e-01],\n",
      "       [ 4.4385e-01,  1.8770e+00, -2.5156e+00],\n",
      "       [ 2.7520e+00, -5.0781e-01, -2.1816e+00],\n",
      "       [ 1.9131e+00,  4.2773e-01, -2.3262e+00],\n",
      "       [ 3.2754e+00, -5.9570e-01, -2.5762e+00],\n",
      "       [ 2.0625e+00, -1.3269e-01, -1.8994e+00],\n",
      "       [ 2.4082e+00, -3.4229e-01, -2.0527e+00],\n",
      "       [ 1.8525e+00,  7.3340e-01, -2.6758e+00],\n",
      "       [ 2.7617e+00, -1.4941e-01, -2.5898e+00],\n",
      "       [ 3.4980e+00, -6.0400e-01, -2.7930e+00],\n",
      "       [ 1.7451e+00,  4.3945e-01, -2.3008e+00],\n",
      "       [-1.3516e+00,  5.0342e-01,  9.7607e-01],\n",
      "       [ 3.7305e+00, -9.0576e-01, -2.6953e+00],\n",
      "       [-9.6863e-02,  2.2773e+00, -2.2598e+00],\n",
      "       [ 1.3418e+00,  1.3037e+00, -2.7520e+00],\n",
      "       [ 1.9082e+00, -1.0368e-02, -1.9072e+00],\n",
      "       [ 2.7383e+00, -4.2969e-01, -2.2773e+00],\n",
      "       [ 2.6680e+00, -2.8418e-01, -2.3965e+00],\n",
      "       [-6.2158e-01,  7.5049e-01, -2.7573e-02],\n",
      "       [ 1.1123e+00,  4.7583e-01, -1.5977e+00],\n",
      "       [-2.5684e-01,  2.8555e+00, -2.8516e+00],\n",
      "       [ 1.3887e+00,  3.7695e-01, -1.8145e+00],\n",
      "       [ 1.5859e+00,  7.0251e-02, -1.6826e+00],\n",
      "       [ 1.3635e-01,  2.2930e+00, -2.6934e+00],\n",
      "       [ 3.4258e+00, -5.2588e-01, -2.7832e+00],\n",
      "       [ 3.5020e+00, -6.0693e-01, -2.7754e+00],\n",
      "       [ 2.1375e-01,  1.4026e-01, -4.0527e-01],\n",
      "       [ 7.5977e-01,  1.4609e+00, -2.4277e+00],\n",
      "       [ 3.2949e+00, -5.9570e-01, -2.5957e+00],\n",
      "       [ 8.7549e-01,  1.4727e+00, -2.5391e+00],\n",
      "       [ 1.5205e+00,  6.9971e-01, -2.3301e+00],\n",
      "       [ 2.4648e+00, -4.8187e-02, -2.3926e+00],\n",
      "       [ 9.2090e-01,  1.7812e+00, -2.8242e+00],\n",
      "       [-3.5864e-01,  1.5791e+00, -1.2783e+00],\n",
      "       [ 2.4629e+00, -2.2842e-02, -2.4922e+00],\n",
      "       [ 1.8936e+00, -1.1755e-01, -1.7656e+00],\n",
      "       [ 1.1494e+00,  8.3008e-01, -1.9736e+00],\n",
      "       [ 3.7207e+00, -9.0332e-01, -2.6660e+00],\n",
      "       [ 1.3770e+00,  3.0591e-01, -1.7666e+00],\n",
      "       [ 2.0703e+00, -1.1597e-01, -1.9775e+00],\n",
      "       [ 2.7031e+00,  2.4097e-01, -2.9434e+00],\n",
      "       [ 3.1465e+00, -2.0068e-01, -2.8691e+00],\n",
      "       [ 3.9512e+00, -1.1299e+00, -2.6738e+00],\n",
      "       [ 3.1035e+00, -4.4922e-01, -2.6113e+00],\n",
      "       [ 1.3740e+00,  7.0215e-01, -2.1641e+00],\n",
      "       [ 3.1777e+00, -6.5765e-03, -3.1191e+00],\n",
      "       [ 2.5156e+00, -3.9429e-01, -2.0918e+00],\n",
      "       [ 1.3604e+00, -8.3801e-02, -1.3340e+00],\n",
      "       [ 1.8965e+00,  7.4316e-01, -2.6699e+00],\n",
      "       [ 1.1680e+00,  1.5088e+00, -2.8887e+00],\n",
      "       [ 4.8853e-01,  8.9746e-01, -1.4307e+00],\n",
      "       [ 7.2461e-01,  9.4336e-01, -1.7334e+00],\n",
      "       [-9.9756e-01,  1.6396e+00, -6.1572e-01],\n",
      "       [ 2.9707e+00, -5.1367e-01, -2.4141e+00],\n",
      "       [ 1.9580e+00, -1.5149e-01, -1.8145e+00],\n",
      "       [ 1.7607e+00,  1.1445e+00, -3.0820e+00],\n",
      "       [ 1.3818e+00,  7.3486e-01, -2.2148e+00],\n",
      "       [-2.6514e-01,  1.1846e+00, -9.2627e-01],\n",
      "       [ 3.1055e+00,  1.7664e-01, -3.2480e+00],\n",
      "       [-1.5781e+00,  1.7676e+00, -4.4830e-02],\n",
      "       [ 3.3447e-01,  1.4170e+00, -1.9473e+00],\n",
      "       [ 4.4727e-01,  1.8301e+00, -2.3594e+00],\n",
      "       [ 2.5469e+00, -3.2910e-01, -2.1758e+00],\n",
      "       [-7.4023e-01,  1.4199e+00, -6.3330e-01],\n",
      "       [-4.7241e-01,  2.1523e+00, -1.9102e+00],\n",
      "       [ 2.8164e+00,  1.0535e-01, -2.9375e+00],\n",
      "       [ 9.5605e-01,  1.0039e+00, -2.0332e+00],\n",
      "       [ 2.0957e+00,  3.9941e-01, -2.5020e+00],\n",
      "       [ 2.4980e+00, -2.0557e-01, -2.2656e+00],\n",
      "       [ 4.1445e+00, -1.0898e+00, -2.8848e+00],\n",
      "       [ 2.3496e+00, -4.4678e-01, -1.8848e+00],\n",
      "       [ 1.6553e+00,  2.1399e-01, -1.9600e+00],\n",
      "       [-2.3340e-01,  2.1738e+00, -2.1309e+00],\n",
      "       [ 1.0449e+00,  3.4448e-01, -1.4502e+00],\n",
      "       [ 3.7354e-01,  1.0635e+00, -1.4873e+00],\n",
      "       [ 6.0693e-01,  1.0010e+00, -1.6699e+00],\n",
      "       [-1.2285e+00,  2.1562e+00, -9.2334e-01],\n",
      "       [ 2.9180e+00, -4.6924e-01, -2.3867e+00],\n",
      "       [ 3.0352e+00, -7.5745e-02, -2.9023e+00],\n",
      "       [ 1.7549e+00,  3.0981e-01, -2.1309e+00],\n",
      "       [ 2.4023e+00,  5.3906e-01, -2.9492e+00],\n",
      "       [ 3.3750e+00, -1.0732e+00, -2.2148e+00],\n",
      "       [ 1.2148e+00, -3.4863e-01, -9.0039e-01],\n",
      "       [ 4.6582e-01,  1.8223e+00, -2.3730e+00],\n",
      "       [ 1.6699e+00,  1.8420e-01, -1.8955e+00],\n",
      "       [-2.1777e+00,  7.9102e-01,  1.7588e+00],\n",
      "       [-1.6953e+00,  3.0591e-01,  1.5059e+00],\n",
      "       [-1.7988e+00, -7.8467e-01,  2.6309e+00],\n",
      "       [ 4.1289e+00, -1.0693e+00, -2.8750e+00],\n",
      "       [ 2.9150e-01,  1.0699e-01, -4.3945e-01],\n",
      "       [ 5.2246e-01,  1.0455e-01, -6.0352e-01],\n",
      "       [ 2.7559e+00,  2.2070e-01, -3.0020e+00],\n",
      "       [ 2.2422e+00,  2.7075e-01, -2.4805e+00],\n",
      "       [-1.5312e+00,  2.5078e+00, -9.9219e-01],\n",
      "       [-1.5381e+00,  2.7710e-01,  1.3789e+00],\n",
      "       [-6.8164e-01, -4.5801e-01,  1.0596e+00],\n",
      "       [-2.1816e+00, -2.7905e-01,  2.5391e+00],\n",
      "       [ 2.2012e+00,  2.1765e-01, -2.4551e+00],\n",
      "       [-2.2498e-01,  1.5703e+00, -1.4199e+00],\n",
      "       [ 3.4746e+00, -6.5918e-01, -2.7148e+00],\n",
      "       [ 2.4707e+00, -2.4719e-03, -2.4238e+00],\n",
      "       [-5.2148e-01,  1.7031e+00, -1.1562e+00],\n",
      "       [ 3.2402e+00, -6.2451e-01, -2.5020e+00],\n",
      "       [ 1.1504e+00, -1.7151e-01, -1.0273e+00],\n",
      "       [ 2.8867e+00, -1.2256e-01, -2.6680e+00],\n",
      "       [ 6.7078e-02,  5.0977e-01, -5.3369e-01],\n",
      "       [-8.6475e-01,  1.1299e+00, -1.7944e-01],\n",
      "       [-1.1749e-01,  1.0803e-01, -2.7557e-02],\n",
      "       [-3.3112e-02,  8.3496e-01, -7.5879e-01],\n",
      "       [ 2.7559e+00,  5.0830e-01, -3.2812e+00],\n",
      "       [-2.7905e-01,  2.0469e+00, -1.8857e+00],\n",
      "       [ 3.7559e+00, -9.1455e-01, -2.7012e+00],\n",
      "       [ 2.4180e+00, -1.6220e-02, -2.3926e+00],\n",
      "       [ 1.5137e+00,  1.2832e+00, -2.9062e+00],\n",
      "       [ 1.9131e+00,  9.5215e-01, -2.9902e+00],\n",
      "       [ 9.2188e-01,  5.5566e-01, -1.5732e+00],\n",
      "       [-1.7217e+00,  9.0283e-01,  1.0059e+00],\n",
      "       [ 1.0583e-01,  1.9414e+00, -2.1328e+00],\n",
      "       [ 1.6719e+00,  5.7080e-01, -2.3164e+00],\n",
      "       [ 1.5410e+00,  2.7368e-01, -1.8867e+00],\n",
      "       [-9.6289e-01,  2.2058e-01,  8.0957e-01],\n",
      "       [ 3.9004e+00, -8.4277e-01, -2.9297e+00],\n",
      "       [ 3.4180e+00, -3.8306e-01, -2.9453e+00],\n",
      "       [ 2.8984e+00, -1.6223e-01, -2.6934e+00],\n",
      "       [ 3.0156e+00, -3.3740e-01, -2.6406e+00],\n",
      "       [ 2.7661e-01,  1.8125e+00, -2.1680e+00],\n",
      "       [ 3.0859e+00, -6.7773e-01, -2.3594e+00],\n",
      "       [ 2.8242e+00,  1.9653e-01, -3.0156e+00],\n",
      "       [ 2.5039e+00,  3.6206e-01, -2.8477e+00],\n",
      "       [ 2.7734e+00,  6.5918e-02, -2.8613e+00],\n",
      "       [-8.6279e-01,  1.3730e+00, -3.9282e-01],\n",
      "       [-5.7959e-01,  1.3867e+00, -8.4180e-01],\n",
      "       [ 2.8887e+00, -2.1094e-01, -2.7207e+00],\n",
      "       [ 3.2754e+00, -5.6348e-01, -2.6113e+00],\n",
      "       [ 3.3945e+00, -5.2246e-01, -2.7734e+00],\n",
      "       [ 6.2891e-01,  1.6582e+00, -2.4688e+00],\n",
      "       [ 1.9736e+00,  2.2229e-01, -2.1855e+00],\n",
      "       [-4.8706e-01,  8.5986e-01, -2.6416e-01],\n",
      "       [ 3.8555e+00, -8.5449e-01, -2.8223e+00],\n",
      "       [ 1.1533e+00,  6.9043e-01, -1.8535e+00],\n",
      "       [ 2.1094e+00,  1.8628e-01, -2.3457e+00],\n",
      "       [-6.4453e-01,  1.6533e+00, -1.0234e+00],\n",
      "       [-8.7549e-01,  1.6758e+00, -7.5928e-01],\n",
      "       [ 1.8311e-01, -4.1626e-01,  1.7920e-01],\n",
      "       [ 3.7793e+00, -7.0654e-01, -2.9551e+00],\n",
      "       [-1.3486e+00, -3.2166e-02,  1.4775e+00],\n",
      "       [ 3.9141e+00, -9.3018e-01, -2.8164e+00],\n",
      "       [ 1.7920e+00,  1.3611e-01, -2.0117e+00],\n",
      "       [ 3.2129e+00, -3.7939e-01, -2.7539e+00],\n",
      "       [ 2.9316e+00, -1.7407e-01, -2.6992e+00],\n",
      "       [ 2.2031e+00,  1.8677e-01, -2.3457e+00],\n",
      "       [ 3.3730e+00, -3.0469e-01, -2.9805e+00],\n",
      "       [ 2.8613e+00, -3.6646e-01, -2.4688e+00],\n",
      "       [-1.1396e+00,  1.4756e+00, -2.5586e-01],\n",
      "       [ 4.2310e-01,  1.9885e-01, -6.5674e-01],\n",
      "       [ 3.1035e+00, -4.3506e-01, -2.6270e+00],\n",
      "       [ 2.7500e+00, -2.4109e-01, -2.4414e+00],\n",
      "       [ 3.3379e+00, -1.8909e-01, -3.0332e+00],\n",
      "       [ 2.7383e+00,  4.2419e-02, -2.7168e+00],\n",
      "       [ 1.6289e+00, -7.2900e-01, -9.3604e-01]], dtype=float16), label_ids=array([1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 2, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n",
      "       1, 1, 1, 2, 0, 2, 1, 0, 0, 0, 0, 0, 1, 1, 2, 0, 2, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 2, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 2, 1, 0, 1, 0,\n",
      "       1, 0, 2, 1, 0, 1, 1, 1, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "       1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 2, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
      "       1, 0, 0, 0, 1, 0, 0, 0, 2, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
      "       0, 1, 0, 1, 0, 0, 1, 0, 2, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
      "       0, 0, 0, 1, 0, 0, 2, 2, 0, 2, 0, 1, 0, 1, 1, 0, 2, 0, 1, 0, 0, 1,\n",
      "       0, 1, 0, 0, 1, 2, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 2,\n",
      "       0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 2, 0, 0, 2]), metrics={'test_loss': 0.7384978532791138, 'test_accuracy': 0.7051282051282052, 'test_precision': 0.6974827303594426, 'test_recall': 0.7051282051282052, 'test_f1': 0.6945588996755552, 'test_runtime': 2.0148, 'test_samples_per_second': 116.139, 'test_steps_per_second': 3.971})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e098b45f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "probabilities = torch.softmax(torch.tensor(test_results.predictions).to(torch.float32), dim=-1)\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)\n",
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9020641b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_save = []\n",
    "for idx in range(len(test_data)):\n",
    "    item = dataset['test'][idx]\n",
    "    actual_label = item['label']\n",
    "    predicted_label = predictions[idx]\n",
    "    claim = item['claim'] \n",
    "    premise = item['premise'] \n",
    "    category = item['category']\n",
    "    \n",
    "    # Append the information as a dictionary to the list\n",
    "    data_to_save.append({\n",
    "        'Claim': claim,\n",
    "        'Premise': premise,\n",
    "        'Actual Label': actual_label,\n",
    "        'Predicted Label': predicted_label,\n",
    "        'Category' : category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_to_save)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/home/elson/results/2.1.3_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "797ffc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correctly classified instances\n",
    "correctly_classified = df[df['Actual Label'] == df['Predicted Label']]\n",
    "\n",
    "# Calculate misclassified instances\n",
    "misclassified = df[df['Actual Label'] != df['Predicted Label']]\n",
    "\n",
    "# Count the number of correctly classified and misclassified by category\n",
    "correct_classification_counts = correctly_classified['Category'].value_counts()\n",
    "misclassification_counts = misclassified['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0d83b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           40\n",
       "Bone health              17\n",
       "Skin                     15\n",
       "Cancer                   12\n",
       "Fitness                  11\n",
       "Diabetes                 10\n",
       "Cardiovascular Health     7\n",
       "Ear                       6\n",
       "Throat                    6\n",
       "Neurological health       6\n",
       "Hair                      5\n",
       "Blood                     5\n",
       "Eye                       5\n",
       "COVID                     5\n",
       "Muscles                   4\n",
       "Men's health              3\n",
       "Mental Health             3\n",
       "Women' s Health           2\n",
       "Vascular                  2\n",
       "Dental Health             1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "947d26ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           11\n",
       "Skin                      9\n",
       "Hair                      7\n",
       "Cardiovascular Health     5\n",
       "Women' s Health           4\n",
       "Eye                       4\n",
       "Fitness                   4\n",
       "Bone health               4\n",
       "Blood                     4\n",
       "Neurological health       3\n",
       "Men's health              3\n",
       "Throat                    3\n",
       "Diabetes                  2\n",
       "Dental Health             2\n",
       "Muscles                   2\n",
       "COVID                     1\n",
       "Vascular                  1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
