{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc7d301c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d30e63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-cfbf7584a6bb7c13\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 183.54it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('csv',data_files='dataset_sentenceattribution_nerfeatures_split.csv',delimiter=',',column_names=[\"claim\",\"premise\",\"label\",\"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\",\"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\",\"url\", \"entities\",\"entity_map\",\"gem_exp\",\"gem_label\",\"gpt_label\",\"gpt_exp\",\"gold_exp\",\"entity_map_ev\",\"entity_ev\",\"synonym\",\"voice\",\"split\"],skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9fdc5a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'gem_exp', 'gem_label', 'gpt_label', 'gpt_exp', 'gold_exp', 'entity_map_ev', 'entity_ev', 'synonym', 'voice', 'split'],\n",
       "    num_rows: 2322\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3afaa22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-aa1fd4d2889f655e.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-9cd628f4430f2ace.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-df968f39da4ad12a.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8006f8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\"claim\", \"premise\", \"label\",\"category\"]\n",
    "all_columns = dataset[\"train\"].column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa3a919f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7191d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-e8dc3bd2c646ced3.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-7bec47e524518b7d.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-e2623f6a029e90cb.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 0, 'entailment': 1, 'neutral': 2}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 0,\n",
    "    \"entailment\": 1,\n",
    "    \"neutral\": 2\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83fa950e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(dataset[\"train\"][\"claim\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7750d122",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15b16c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='pritamdeka/PubMedBERT-MNLI-MedNLI'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "        # Extracting claim and evidence texts\n",
    "\n",
    "        claim = item['claim']\n",
    "        evidences = item['premise']\n",
    "        item['premise']=evidences\n",
    "        item['claim']=claim\n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "            evidences,claim,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "        item['input_ids'] = inputs['input_ids'].squeeze()  # Remove batch dimension\n",
    "        item['attention_mask']= inputs['attention_mask'].squeeze() # Remove batch dimension\n",
    "        \n",
    "        if 'label' in item:\n",
    "            item['labels'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78f4a138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6196a657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"pritamdeka/PubMedBERT-MNLI-MedNLI\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=512)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=3, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e81cd488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    return {\"accuracy\": acc, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ffe138a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3981634b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2736f511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cfbbbf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6fd4729",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23ec496f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'claim': 'Triglycerides are stored in your fat cells.',\n",
       " 'premise': 'The hydrolysis of the triglycerides stored in the fat cell is a complex phenomenon involving lipases, plasma membrane transporters, fatty acid binding proteins and proteins associated with the lipid droplet.',\n",
       " 'label': 1,\n",
       " 'category': 'General Health',\n",
       " 'input_ids': tensor([    2,  1920,  9128,  1927,  1920, 13631,  6574,  1922,  1920,  3777,\n",
       "          2024,  1977,    43,  2796,  7902,  5884, 16653,  1036,    16,  3582,\n",
       "          3260, 10538,    16,  5934,  2687,  2743,  2697,  1930,  2697,  2458,\n",
       "          1956,  1920,  4486, 10622,    18,     3, 13631,  2032,  6574,  1922,\n",
       "         10186,  3777,  2094,    18,     3,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'labels': tensor(1)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b81a5af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 765\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='765' max='765' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [765/765 06:20, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.707300</td>\n",
       "      <td>0.838400</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.693716</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.592255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.568300</td>\n",
       "      <td>0.845998</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.629295</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.633422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.284400</td>\n",
       "      <td>1.015986</td>\n",
       "      <td>0.636559</td>\n",
       "      <td>0.668650</td>\n",
       "      <td>0.636559</td>\n",
       "      <td>0.646359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.173800</td>\n",
       "      <td>1.342589</td>\n",
       "      <td>0.653763</td>\n",
       "      <td>0.645842</td>\n",
       "      <td>0.653763</td>\n",
       "      <td>0.649035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.132200</td>\n",
       "      <td>1.348108</td>\n",
       "      <td>0.658065</td>\n",
       "      <td>0.659336</td>\n",
       "      <td>0.658065</td>\n",
       "      <td>0.654604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.060100</td>\n",
       "      <td>1.635960</td>\n",
       "      <td>0.647312</td>\n",
       "      <td>0.661652</td>\n",
       "      <td>0.647312</td>\n",
       "      <td>0.651128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.052100</td>\n",
       "      <td>1.938051</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>0.640053</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>0.631403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.070400</td>\n",
       "      <td>1.930611</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.640324</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.643351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.070300</td>\n",
       "      <td>1.851776</td>\n",
       "      <td>0.660215</td>\n",
       "      <td>0.651492</td>\n",
       "      <td>0.660215</td>\n",
       "      <td>0.654097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.032100</td>\n",
       "      <td>2.273826</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.652793</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.647636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>2.272213</td>\n",
       "      <td>0.640860</td>\n",
       "      <td>0.646867</td>\n",
       "      <td>0.640860</td>\n",
       "      <td>0.643426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.020500</td>\n",
       "      <td>2.336695</td>\n",
       "      <td>0.634409</td>\n",
       "      <td>0.648506</td>\n",
       "      <td>0.634409</td>\n",
       "      <td>0.639924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>2.345867</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.653364</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.651154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>2.354612</td>\n",
       "      <td>0.662366</td>\n",
       "      <td>0.658417</td>\n",
       "      <td>0.662366</td>\n",
       "      <td>0.659638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.022000</td>\n",
       "      <td>2.382225</td>\n",
       "      <td>0.660215</td>\n",
       "      <td>0.659036</td>\n",
       "      <td>0.660215</td>\n",
       "      <td>0.658845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.1.1_pubmedbert/checkpoint-51\n",
      "Configuration saved in /home/elson/1.1.1_pubmedbert/checkpoint-51/config.json\n",
      "Model weights saved in /home/elson/1.1.1_pubmedbert/checkpoint-51/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.1.1_pubmedbert/checkpoint-102\n",
      "Configuration saved in /home/elson/1.1.1_pubmedbert/checkpoint-102/config.json\n",
      "Model weights saved in /home/elson/1.1.1_pubmedbert/checkpoint-102/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.1.1_pubmedbert/checkpoint-153\n",
      "Configuration saved in /home/elson/1.1.1_pubmedbert/checkpoint-153/config.json\n",
      "Model weights saved in /home/elson/1.1.1_pubmedbert/checkpoint-153/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.1.1_pubmedbert/checkpoint-102] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.1.1_pubmedbert/checkpoint-204\n",
      "Configuration saved in /home/elson/1.1.1_pubmedbert/checkpoint-204/config.json\n",
      "Model weights saved in /home/elson/1.1.1_pubmedbert/checkpoint-204/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.1.1_pubmedbert/checkpoint-51] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/1.1.1_pubmedbert/checkpoint-153] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.1.1_pubmedbert/checkpoint-255\n",
      "Configuration saved in /home/elson/1.1.1_pubmedbert/checkpoint-255/config.json\n",
      "Model weights saved in /home/elson/1.1.1_pubmedbert/checkpoint-255/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.1.1_pubmedbert/checkpoint-204] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.1.1_pubmedbert/checkpoint-306\n",
      "Configuration saved in /home/elson/1.1.1_pubmedbert/checkpoint-306/config.json\n",
      "Model weights saved in /home/elson/1.1.1_pubmedbert/checkpoint-306/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.1.1_pubmedbert/checkpoint-357\n",
      "Configuration saved in /home/elson/1.1.1_pubmedbert/checkpoint-357/config.json\n",
      "Model weights saved in /home/elson/1.1.1_pubmedbert/checkpoint-357/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.1.1_pubmedbert/checkpoint-306] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.1.1_pubmedbert/checkpoint-408\n",
      "Configuration saved in /home/elson/1.1.1_pubmedbert/checkpoint-408/config.json\n",
      "Model weights saved in /home/elson/1.1.1_pubmedbert/checkpoint-408/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.1.1_pubmedbert/checkpoint-357] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.1.1_pubmedbert/checkpoint-459\n",
      "Configuration saved in /home/elson/1.1.1_pubmedbert/checkpoint-459/config.json\n",
      "Model weights saved in /home/elson/1.1.1_pubmedbert/checkpoint-459/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.1.1_pubmedbert/checkpoint-255] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/1.1.1_pubmedbert/checkpoint-408] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.1.1_pubmedbert/checkpoint-510\n",
      "Configuration saved in /home/elson/1.1.1_pubmedbert/checkpoint-510/config.json\n",
      "Model weights saved in /home/elson/1.1.1_pubmedbert/checkpoint-510/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.1.1_pubmedbert/checkpoint-561\n",
      "Configuration saved in /home/elson/1.1.1_pubmedbert/checkpoint-561/config.json\n",
      "Model weights saved in /home/elson/1.1.1_pubmedbert/checkpoint-561/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.1.1_pubmedbert/checkpoint-510] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.1.1_pubmedbert/checkpoint-612\n",
      "Configuration saved in /home/elson/1.1.1_pubmedbert/checkpoint-612/config.json\n",
      "Model weights saved in /home/elson/1.1.1_pubmedbert/checkpoint-612/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.1.1_pubmedbert/checkpoint-561] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.1.1_pubmedbert/checkpoint-663\n",
      "Configuration saved in /home/elson/1.1.1_pubmedbert/checkpoint-663/config.json\n",
      "Model weights saved in /home/elson/1.1.1_pubmedbert/checkpoint-663/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.1.1_pubmedbert/checkpoint-612] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.1.1_pubmedbert/checkpoint-714\n",
      "Configuration saved in /home/elson/1.1.1_pubmedbert/checkpoint-714/config.json\n",
      "Model weights saved in /home/elson/1.1.1_pubmedbert/checkpoint-714/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.1.1_pubmedbert/checkpoint-459] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/1.1.1_pubmedbert/checkpoint-663] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.1.1_pubmedbert/checkpoint-765\n",
      "Configuration saved in /home/elson/1.1.1_pubmedbert/checkpoint-765/config.json\n",
      "Model weights saved in /home/elson/1.1.1_pubmedbert/checkpoint-765/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/elson/1.1.1_pubmedbert/checkpoint-714 (score: 0.6623655913978495).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /home/elson/1.1.1_pubmedbert/best_model/config.json\n",
      "Model weights saved in /home/elson/1.1.1_pubmedbert/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/1.1.1_pubmedbert/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/1.1.1_pubmedbert/best_model/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/1.1.1_pubmedbert/best_model/tokenizer_config.json',\n",
       " '/home/elson/1.1.1_pubmedbert/best_model/special_tokens_map.json',\n",
       " '/home/elson/1.1.1_pubmedbert/best_model/vocab.txt',\n",
       " '/home/elson/1.1.1_pubmedbert/best_model/added_tokens.json',\n",
       " '/home/elson/1.1.1_pubmedbert/best_model/tokenizer.json')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/1.1.1_pubmedbert/',\n",
    "    num_train_epochs=15,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.06,\n",
    "    weight_decay=0.1,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/1.1.1_pubmedbert/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/1.1.1_pubmedbert/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d828208",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/1.1.1_pubmedbert/best_model/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"/home/elson/1.1.1_pubmedbert/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"contradiction\",\n",
      "    \"1\": \"entailment\",\n",
      "    \"2\": \"neutral\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"contradiction\": 0,\n",
      "    \"entailment\": 1,\n",
      "    \"neutral\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file /home/elson/1.1.1_pubmedbert/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at /home/elson/1.1.1_pubmedbert/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 32\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/1.1.1_pubmedbert/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43948eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[-4.605  ,  1.184  ,  2.479  ],\n",
      "       [-3.62   ,  6.387  , -3.902  ],\n",
      "       [-4.195  ,  5.91   , -3.15   ],\n",
      "       [-3.951  , -0.9253 ,  4.387  ],\n",
      "       [-3.955  ,  6.355  , -3.56   ],\n",
      "       [-3.568  ,  6.3    , -3.848  ],\n",
      "       [-3.855  ,  6.37   , -3.686  ],\n",
      "       [-3.89   ,  6.383  , -3.605  ],\n",
      "       [-3.842  ,  6.32   , -3.574  ],\n",
      "       [ 5.934  , -2.795  , -2.303  ],\n",
      "       [-3.604  ,  5.047  , -2.775  ],\n",
      "       [-3.248  ,  6.332  , -4.004  ],\n",
      "       [-4.16   ,  5.81   , -2.754  ],\n",
      "       [-3.684  ,  6.387  , -3.76   ],\n",
      "       [-4.27   , -1.42   ,  5.164  ],\n",
      "       [-2.64   , -2.2    ,  4.797  ],\n",
      "       [-3.32   ,  6.332  , -4.047  ],\n",
      "       [-4.9    ,  5.58   , -2.023  ],\n",
      "       [-3.23   ,  6.344  , -4.027  ],\n",
      "       [-3.748  ,  6.395  , -3.81   ],\n",
      "       [-4.645  ,  5.977  , -2.676  ],\n",
      "       [-5.184  ,  4.938  , -1.025  ],\n",
      "       [-3.295  , -1.949  ,  5.402  ],\n",
      "       [-0.656  , -1.351  ,  1.858  ],\n",
      "       [ 5.94   , -2.178  , -2.959  ],\n",
      "       [ 6.336  , -2.934  , -2.332  ],\n",
      "       [-3.05   ,  6.27   , -4.004  ],\n",
      "       [-5.15   ,  0.3613 ,  4.555  ],\n",
      "       [-4.37   ,  5.926  , -2.889  ],\n",
      "       [-3.316  , -1.285  ,  4.273  ],\n",
      "       [-4.055  , -0.729  ,  4.473  ],\n",
      "       [-3.44   ,  6.332  , -3.96   ],\n",
      "       [-3.156  ,  6.3    , -4.1    ],\n",
      "       [-2.834  , -3.293  ,  6.17   ],\n",
      "       [-2.91   , -3.172  ,  6.234  ],\n",
      "       [-3.459  ,  6.38   , -3.965  ],\n",
      "       [-3.58   ,  6.35   , -3.78   ],\n",
      "       [-3.412  ,  6.297  , -3.854  ],\n",
      "       [ 4.797  , -3.074  , -0.759  ],\n",
      "       [-3.93   ,  6.344  , -3.555  ],\n",
      "       [-3.953  ,  4.652  , -1.897  ],\n",
      "       [-5.49   ,  5.082  , -0.9087 ],\n",
      "       [-4.09   ,  5.15   , -2.477  ],\n",
      "       [-0.7725 , -3.41   ,  4.254  ],\n",
      "       [-5.15   ,  5.25   , -1.23   ],\n",
      "       [-4.723  ,  6.12   , -2.783  ],\n",
      "       [-3.635  , -2.07   ,  5.67   ],\n",
      "       [-3.5    ,  6.414  , -3.982  ],\n",
      "       [-3.01   ,  6.254  , -4.227  ],\n",
      "       [ 4.65   , -2.63   , -1.12   ],\n",
      "       [-4.02   ,  6.184  , -3.47   ],\n",
      "       [-3.934  , -1.839  ,  5.664  ],\n",
      "       [-2.389  , -1.158  ,  3.262  ],\n",
      "       [-4.87   ,  5.906  , -2.346  ],\n",
      "       [ 5.625  , -3.28   , -1.199  ],\n",
      "       [-3.676  ,  6.4    , -3.861  ],\n",
      "       [ 6.188  , -2.844  , -2.371  ],\n",
      "       [-4.76   ,  5.76   , -2.629  ],\n",
      "       [-3.324  ,  6.31   , -4.04   ],\n",
      "       [-3.697  ,  6.387  , -3.844  ],\n",
      "       [-3.72   ,  6.406  , -3.836  ],\n",
      "       [ 6.28   , -2.73   , -2.627  ],\n",
      "       [-2.32   , -3.568  ,  6.2    ],\n",
      "       [-4.613  ,  6.207  , -2.863  ],\n",
      "       [-3.29   , -1.969  ,  5.06   ],\n",
      "       [-3.098  ,  6.293  , -4.2    ],\n",
      "       [-3.48   ,  6.348  , -3.88   ],\n",
      "       [-4.     ,  6.426  , -3.465  ],\n",
      "       [-2.49   , -3.133  ,  5.74   ],\n",
      "       [ 5.633  , -2.684  , -2.113  ],\n",
      "       [-5.797  ,  4.508  ,  0.03806],\n",
      "       [-5.145  ,  4.54   , -0.6655 ],\n",
      "       [-4.863  ,  2.021  ,  2.041  ],\n",
      "       [-4.69   ,  4.414  , -0.764  ],\n",
      "       [-3.867  ,  6.332  , -3.621  ],\n",
      "       [-3.87   ,  6.426  , -3.666  ],\n",
      "       [-3.672  ,  6.125  , -3.582  ],\n",
      "       [-3.707  ,  6.438  , -3.752  ],\n",
      "       [-3.307  ,  6.355  , -4.008  ],\n",
      "       [-4.164  ,  6.098  , -3.334  ],\n",
      "       [-3.469  ,  6.41   , -3.87   ],\n",
      "       [-3.863  ,  6.35   , -3.627  ],\n",
      "       [-4.215  ,  6.332  , -3.383  ],\n",
      "       [-3.037  ,  6.254  , -4.164  ],\n",
      "       [-3.422  ,  6.348  , -3.912  ],\n",
      "       [-2.004  , -3.621  ,  6.023  ],\n",
      "       [-3.797  ,  6.254  , -3.611  ],\n",
      "       [-3.273  ,  3.455  , -1.449  ],\n",
      "       [-5.094  ,  3.047  ,  0.8486 ],\n",
      "       [-2.32   , -3.568  ,  6.2    ],\n",
      "       [-4.066  ,  6.293  , -3.57   ],\n",
      "       [-3.703  ,  6.383  , -3.758  ],\n",
      "       [-3.357  , -1.985  ,  5.016  ],\n",
      "       [-3.484  ,  6.406  , -3.984  ],\n",
      "       [-3.697  ,  6.414  , -3.809  ],\n",
      "       [-3.834  ,  5.555  , -3.154  ],\n",
      "       [-4.258  ,  5.21   , -2.406  ],\n",
      "       [-3.977  , -1.378  ,  5.184  ],\n",
      "       [-3.303  ,  6.35   , -4.01   ],\n",
      "       [-3.604  ,  6.406  , -3.898  ],\n",
      "       [ 5.69   , -2.266  , -2.73   ],\n",
      "       [-4.316  ,  6.19   , -3.145  ],\n",
      "       [-3.53   ,  6.38   , -3.814  ],\n",
      "       [-4.22   , -0.1696 ,  3.842  ],\n",
      "       [-5.277  ,  5.402  , -1.433  ],\n",
      "       [-4.02   ,  6.08   , -3.395  ],\n",
      "       [-4.76   ,  4.965  , -1.574  ],\n",
      "       [-3.059  , -2.703  ,  5.742  ],\n",
      "       [-3.621  ,  6.36   , -3.87   ],\n",
      "       [-5.645  ,  3.043  ,  1.776  ],\n",
      "       [-4.09   ,  6.35   , -3.459  ],\n",
      "       [-3.299  ,  6.34   , -3.959  ],\n",
      "       [-3.441  ,  6.36   , -3.97   ],\n",
      "       [-3.922  ,  5.7    , -2.818  ],\n",
      "       [-3.818  ,  6.383  , -3.76   ],\n",
      "       [-3.64   ,  6.266  , -3.686  ],\n",
      "       [-3.441  ,  6.375  , -3.947  ],\n",
      "       [-4.543  ,  6.258  , -2.783  ],\n",
      "       [-4.066  , -0.8994 ,  4.855  ],\n",
      "       [-3.377  ,  6.367  , -4.055  ],\n",
      "       [-3.414  ,  6.37   , -3.98   ],\n",
      "       [-4.812  , -0.595  ,  5.062  ],\n",
      "       [-4.293  , -1.453  ,  5.34   ],\n",
      "       [-5.367  ,  4.996  , -0.975  ],\n",
      "       [-4.316  , -1.33   ,  5.332  ],\n",
      "       [-3.682  ,  6.383  , -3.725  ],\n",
      "       [-4.727  , -0.4407 ,  4.656  ],\n",
      "       [-3.54   ,  6.367  , -3.941  ],\n",
      "       [-4.77   ,  5.836  , -2.59   ],\n",
      "       [-2.902  , -3.104  ,  6.047  ],\n",
      "       [-4.625  ,  5.566  , -2.352  ],\n",
      "       [-3.719  , -1.077  ,  4.363  ],\n",
      "       [-3.895  ,  6.258  , -3.424  ],\n",
      "       [ 0.4895 , -3.205  ,  2.928  ],\n",
      "       [-4.965  ,  1.374  ,  2.688  ],\n",
      "       [-3.969  ,  6.336  , -3.53   ],\n",
      "       [-3.793  ,  6.277  , -3.771  ],\n",
      "       [-1.326  , -3.441  ,  4.72   ],\n",
      "       [-2.553  , -2.777  ,  4.965  ],\n",
      "       [-3.385  ,  6.332  , -3.93   ],\n",
      "       [-3.559  ,  6.316  , -3.91   ],\n",
      "       [-3.928  , -1.622  ,  5.293  ],\n",
      "       [-3.63   , -2.365  ,  6.1    ],\n",
      "       [-3.244  ,  6.312  , -3.986  ],\n",
      "       [-4.06   ,  6.035  , -3.322  ],\n",
      "       [-3.918  ,  6.156  , -3.531  ],\n",
      "       [-4.445  ,  5.766  , -2.758  ],\n",
      "       [-2.736  ,  2.607  , -1.014  ],\n",
      "       [-3.52   ,  6.39   , -3.965  ],\n",
      "       [-2.828  , -2.926  ,  5.78   ],\n",
      "       [-5.4    ,  0.5874 ,  4.35   ],\n",
      "       [-4.105  ,  6.11   , -3.404  ],\n",
      "       [-3.85   ,  6.375  , -3.748  ],\n",
      "       [-3.748  ,  6.414  , -3.793  ],\n",
      "       [-3.58   ,  6.34   , -3.812  ],\n",
      "       [-3.572  ,  6.355  , -3.895  ],\n",
      "       [-3.191  ,  6.336  , -4.117  ],\n",
      "       [-3.95   ,  6.363  , -3.55   ],\n",
      "       [-3.09   , -2.969  ,  6.047  ],\n",
      "       [ 5.023  , -2.49   , -1.751  ],\n",
      "       [ 5.887  , -3.324  , -1.393  ],\n",
      "       [ 6.277  , -3.045  , -2.043  ],\n",
      "       [-3.238  ,  6.348  , -4.11   ],\n",
      "       [ 4.688  , -2.97   , -0.963  ],\n",
      "       [-3.94   ,  6.305  , -3.562  ],\n",
      "       [-4.08   ,  6.242  , -3.426  ],\n",
      "       [-5.137  ,  1.965  ,  1.944  ],\n",
      "       [-1.348  , -3.1    ,  4.23   ],\n",
      "       [ 5.957  , -2.24   , -2.916  ],\n",
      "       [-3.822  ,  5.91   , -3.156  ],\n",
      "       [ 6.324  , -2.936  , -2.355  ],\n",
      "       [-3.605  ,  6.406  , -3.908  ],\n",
      "       [-2.434  , -3.586  ,  6.246  ],\n",
      "       [-3.656  ,  6.383  , -3.791  ],\n",
      "       [-5.2    ,  2.549  ,  1.954  ],\n",
      "       [-3.414  , -2.443  ,  5.977  ],\n",
      "       [-3.611  ,  6.43   , -3.756  ],\n",
      "       [ 3.533  , -4.027  ,  1.244  ],\n",
      "       [-4.05   ,  5.938  , -3.264  ],\n",
      "       [-0.9614 ,  3.336  , -2.828  ],\n",
      "       [-2.816  ,  2.209  , -0.4426 ],\n",
      "       [-2.6    ,  4.914  , -3.416  ],\n",
      "       [ 0.6187 , -0.4358 , -0.5977 ],\n",
      "       [-4.957  ,  5.383  , -1.932  ],\n",
      "       [-5.566  ,  1.249  ,  3.297  ],\n",
      "       [-3.082  ,  6.32   , -4.133  ],\n",
      "       [-4.32   ,  6.     , -2.973  ],\n",
      "       [-3.646  ,  6.293  , -3.723  ],\n",
      "       [-3.658  ,  6.098  , -3.729  ],\n",
      "       [-3.223  ,  6.332  , -4.023  ],\n",
      "       [-1.494  , -3.803  ,  5.51   ],\n",
      "       [-5.14   ,  1.587  ,  2.99   ],\n",
      "       [-3.066  , -1.751  ,  4.633  ],\n",
      "       [-4.145  ,  6.254  , -3.467  ],\n",
      "       [ 2.113  , -2.383  ,  0.328  ],\n",
      "       [-3.477  ,  6.37   , -4.01   ],\n",
      "       [-5.664  ,  3.555  ,  0.996  ],\n",
      "       [-3.512  ,  6.363  , -3.85   ],\n",
      "       [-3.158  ,  6.33   , -4.164  ],\n",
      "       [-3.875  ,  5.75   , -3.139  ],\n",
      "       [-4.035  ,  6.402  , -3.527  ],\n",
      "       [-3.61   ,  6.29   , -3.8    ],\n",
      "       [-4.54   ,  5.754  , -2.592  ],\n",
      "       [-3.95   ,  6.38   , -3.54   ],\n",
      "       [-3.715  , -2.203  ,  5.883  ],\n",
      "       [-2.697  , -2.527  ,  5.08   ],\n",
      "       [-3.6    ,  6.387  , -3.861  ],\n",
      "       [-5.48   ,  5.246  , -1.001  ],\n",
      "       [-3.51   ,  6.355  , -3.887  ],\n",
      "       [-4.566  ,  6.207  , -2.97   ],\n",
      "       [-3.902  ,  5.926  , -3.297  ],\n",
      "       [-4.64   ,  5.53   , -2.424  ],\n",
      "       [-2.855  ,  6.254  , -4.21   ],\n",
      "       [-4.395  ,  6.23   , -3.031  ],\n",
      "       [-3.494  ,  6.426  , -3.885  ],\n",
      "       [-2.33   , -2.38   ,  4.28   ],\n",
      "       [-3.316  , -1.887  ,  4.63   ],\n",
      "       [ 5.297  , -2.166  , -2.354  ],\n",
      "       [-3.4    ,  6.36   , -4.027  ],\n",
      "       [-0.8047 ,  2.09   , -1.763  ],\n",
      "       [-2.979  ,  6.242  , -4.17   ],\n",
      "       [-3.422  ,  6.383  , -3.955  ],\n",
      "       [-3.574  ,  6.355  , -3.92   ],\n",
      "       [-3.352  ,  6.363  , -3.992  ],\n",
      "       [-3.463  ,  6.316  , -3.938  ],\n",
      "       [-3.26   ,  6.28   , -4.027  ],\n",
      "       [-3.482  ,  6.375  , -3.883  ],\n",
      "       [ 2.227  , -1.858  , -0.168  ],\n",
      "       [-4.363  ,  6.15   , -3.24   ],\n",
      "       [-4.523  ,  6.254  , -2.822  ],\n",
      "       [-2.996  ,  6.29   , -4.145  ],\n",
      "       [-3.953  ,  6.406  , -3.592  ],\n",
      "       [-3.744  ,  6.23   , -3.674  ],\n",
      "       [ 5.246  , -2.584  , -1.587  ]], dtype=float16), label_ids=array([2, 2, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, 0, 1, 2, 1, 2, 2, 1, 1, 2, 2,\n",
      "       2, 2, 2, 0, 1, 0, 2, 1, 1, 1, 1, 1, 2, 2, 0, 1, 0, 2, 2, 2, 1, 2,\n",
      "       2, 2, 2, 2, 2, 0, 2, 1, 2, 2, 2, 1, 2, 2, 1, 1, 1, 0, 2, 1, 2, 1,\n",
      "       2, 1, 0, 2, 1, 2, 2, 2, 1, 0, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1,\n",
      "       2, 2, 1, 1, 2, 1, 2, 1, 2, 2, 1, 2, 0, 2, 1, 2, 1, 1, 2, 2, 1, 1,\n",
      "       2, 1, 1, 1, 2, 1, 1, 1, 0, 2, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 2,\n",
      "       1, 2, 1, 2, 1, 1, 2, 1, 0, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 1, 2, 2,\n",
      "       1, 1, 1, 2, 1, 1, 0, 0, 1, 0, 1, 2, 1, 2, 2, 1, 0, 1, 2, 1, 1, 2,\n",
      "       1, 2, 1, 1, 2, 0, 2, 1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 2, 2, 1, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 2, 0, 1, 0, 1, 1, 0]), metrics={'test_loss': 2.956740379333496, 'test_accuracy': 0.6282051282051282, 'test_precision': 0.6224308544020082, 'test_recall': 0.6282051282051282, 'test_f1': 0.6051406279820897, 'test_runtime': 1.1188, 'test_samples_per_second': 209.152, 'test_steps_per_second': 7.15})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b74804c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "89f7772f",
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = torch.softmax(torch.tensor(test_results.predictions).to(torch.float32), dim=-1)\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "61cc1733",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")  # Adjust xticklabels and yticklabels as needed\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e6bb92",
   "metadata": {},
   "source": [
    "The first row (Actual Label 0) shows that there are 26 instances correctly predicted as class 0 (true positives for class 0), 16 instances where the actual class was 0 but the model predicted them as class 1 (false negatives for class 0 and false positives for class 1), and 0 instances where the actual class was 0 but the model predicted them as class 2.\n",
    "The second row (Actual Label 1) indicates 24 instances where the actual class was 1 but the model predicted them as class 0, 126 instances correctly predicted as class 1, and 0 instances misclassified as class 2.\n",
    "The third row (Actual Label 2) shows that 3 instances were misclassified as class 0, 39 instances were correctly predicted as class 2, and there were no instances misclassified as class 1.\n",
    "The diagonal cells (from the top left to the bottom right) indicate correct predictions, where the predicted class matches the actual class. The other cells indicate incorrect predictions. Ideally, you want the numbers on the diagonal (true positives) to be as high as possible, indicating correct classifications.\n",
    "\n",
    "The shading corresponds to the number of instances, with darker shades typically representing higher counts. In your confusion matrix, the majority of predictions fall on the diagonal for classes 0 and 1, which indicates that the model performs well for these classes. For class 2, while the model does have a correct prediction count of 39, it also has a number of instances misclassified as class 1.\n",
    "\n",
    "It is also noticeable that class 0 and class 1 have a higher rate of being confused with each other, as evidenced by the 16 and 24 misclassifications between these two classes.\n",
    "\n",
    "This matrix helps you understand not only the overall accuracy of the model but also provides insights into how it performs on each individual class, which is crucial for improving the model and addressing any class-specific biases or weaknesses."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
