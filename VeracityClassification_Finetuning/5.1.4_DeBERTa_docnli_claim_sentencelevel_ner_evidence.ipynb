{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45f1f111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/nvidia-modprobe: unrecognized option: \"-s\"\n",
      "\n",
      "ERROR: Invalid commandline, please run `/usr/bin/nvidia-modprobe --help` for\n",
      "       usage information.\n",
      "\n",
      "/usr/bin/nvidia-modprobe: unrecognized option: \"-s\"\n",
      "\n",
      "ERROR: Invalid commandline, please run `/usr/bin/nvidia-modprobe --help` for\n",
      "       usage information.\n",
      "\n",
      "Sun Aug  4 19:12:08 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.29.06              Driver Version: 545.29.06    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-SXM2-32GB           Off | 00000000:61:00.0 Off |                    0 |\n",
      "| N/A   47C    P0              59W / 300W |  25897MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2-32GB           Off | 00000000:62:00.0 Off |                    0 |\n",
      "| N/A   46C    P0              60W / 300W |  25897MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2-32GB           Off | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   46C    P0              63W / 300W |  15153MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2-32GB           Off | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   45C    P0              61W / 300W |      0MiB / 32768MiB |      2%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A     45122      C   /home/elson/factcheck/bin/python3         25894MiB |\n",
      "|    1   N/A  N/A     44521      C   /home/elson/factcheck/bin/python3         25894MiB |\n",
      "|    2   N/A  N/A     43641      C   /home/elson/factcheck/bin/python3         15150MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-47509a4ace11a992\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-47509a4ace11a992/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 173.72it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('csv',data_files='dataset_sentenceattribution_nerfeatures_split.csv',delimiter=',',column_names=[\"claim\",\"premise\",\"label\",\"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\",\"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\",\"url\", \"entities\",\"entity_map\",\"entity_map_ev\",\"entity_ev\",\"gem_exp\",\"gem_label\",\"gpt_exp\",\"gpt_label\",\"gold_exp\",\"synonym\",\"voice\",\"split\"],skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e2914c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'entity_map_ev', 'entity_ev', 'gem_exp', 'gem_label', 'gpt_exp', 'gpt_label', 'gold_exp', 'synonym', 'voice', 'split'],\n",
       "        num_rows: 2322\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57d56e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'test',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['split']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ce96b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-47509a4ace11a992/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-cd7ed25d4d332523.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-47509a4ace11a992/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-caadbcafda8de4b1.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-47509a4ace11a992/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-9e929b5a7841f440.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'entity_map_ev', 'entity_ev', 'gem_exp', 'gem_label', 'gpt_exp', 'gpt_label', 'gold_exp', 'synonym', 'voice', 'split'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'entity_map_ev', 'entity_ev', 'gem_exp', 'gem_label', 'gpt_exp', 'gpt_label', 'gold_exp', 'synonym', 'voice', 'split'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'entity_map_ev', 'entity_ev', 'gem_exp', 'gem_label', 'gpt_exp', 'gpt_label', 'gold_exp', 'synonym', 'voice', 'split'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41f1db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\"claim\", \"premise\", \"label\",\"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\",\"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\"]\n",
    "all_columns = dataset[\"train\"].column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-47509a4ace11a992/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-a721033a0c0d5713.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-47509a4ace11a992/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-fe2d9c401282aa7e.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-47509a4ace11a992/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-2924d1e1772aba33.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 1, 'entailment': 0, 'neutral': 1}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 1,\n",
    "    \"entailment\": 0,\n",
    "    \"neutral\": 1\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='MoritzLaurer/DeBERTa-v3-base-mnli-fever-docnli-ling-2c'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "        # Extracting claim and evidence texts\n",
    "        claim = item['claim'] \n",
    "        evidences = item['premise']\n",
    "        item['premise']=evidences\n",
    "        item['claim']=claim\n",
    "        additional_features = [\n",
    "            \"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\"]\n",
    "    \n",
    "        for feature in additional_features:\n",
    "            if feature in item:\n",
    "                evidences += \"[SEP]\" + str(item[feature])\n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "            evidences, claim,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "         # Construct the output item\n",
    "        output_item = {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),  # Remove batch dimension\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),  # Remove batch dimension\n",
    "            'claim': claim,  # Include augmented claim text\n",
    "            'evidences': evidences  # Include original evidence text\n",
    "        }\n",
    "        \n",
    "        if 'label' in item:\n",
    "            output_item['label'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return output_item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62421eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at MoritzLaurer/DeBERTa-v3-base-mnli-fever-docnli-ling-2c and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([3, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([2]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DebertaV2ForSequenceClassification(\n",
       "  (deberta): DebertaV2Model(\n",
       "    (embeddings): DebertaV2Embeddings(\n",
       "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaV2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (1): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (2): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (3): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (4): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (5): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (6): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (7): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (8): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (9): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (10): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (11): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (pooler): ContextPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): StableDropout()\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (dropout): StableDropout()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"MoritzLaurer/DeBERTa-v3-base-mnli-fever-docnli-ling-2c\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=3, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    bal_accuracy = balanced_accuracy_score(labels,preds)\n",
    "\n",
    "    return {\"accuracy\": acc, \"balanced_accuracy\":bal_accuracy, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17c5e0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([    1,  4081,   261,  5042,   333, 73325,  1452,  2155,  6116,  1938,\n",
       "           272,   262, 88609,   263, 98237,  1830,  1080,  7355,   387,  2655,\n",
       "           262, 12682,   265, 65008,   292,  1158, 53245,   264, 75840,   293,\n",
       "          2376,  1158,  1452,  2155,   260,     2,   767,     2,   767,     2,\n",
       "           767,     2,   767,     2,   767,     2,   767,     2,   767,     2,\n",
       "           767,     2,   767,     2,   767,     2,   767,     2,   767,     2,\n",
       "           573, 52341,  1830,  1080,   269,  1359,   427,   267, 17847,   633,\n",
       "           264,   408,  1300,   262,  2658,   265,   262,  1158,   260,     2,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'claim': 'Myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.',\n",
       " 'evidences': 'Additionally, laser doppler blood flow measurement showed that the frankincense and myrrh essential oil compound could promote the elimination of capillaries from skin epidermis to dermis by increasing skin blood flow.[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0',\n",
       " 'label': tensor(1)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 765\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 31.74 GiB total capacity; 4.85 GiB already allocated; 131.56 MiB free; 4.98 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-899e4d7d3586>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Training and Evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0meval_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/factcheck/lib/python3.6/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1420\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1421\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1422\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m                 if (\n",
      "\u001b[0;32m~/factcheck/lib/python3.6/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast_smart_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2011\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/factcheck/lib/python3.6/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2041\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2042\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2043\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2044\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2045\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/factcheck/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/factcheck/lib/python3.6/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1284\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1286\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1287\u001b[0m         )\n\u001b[1;32m   1288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/factcheck/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/factcheck/lib/python3.6/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1052\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m         )\n\u001b[1;32m   1056\u001b[0m         \u001b[0mencoded_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/factcheck/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/factcheck/lib/python3.6/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, output_hidden_states, output_attentions, query_states, relative_pos, return_dict)\u001b[0m\n\u001b[1;32m    502\u001b[0m                     \u001b[0mrelative_pos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrelative_pos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m                     \u001b[0mrel_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrel_embeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m                 )\n\u001b[1;32m    506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/factcheck/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/factcheck/lib/python3.6/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, query_states, relative_pos, rel_embeddings, output_attentions)\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0mquery_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[0mrelative_pos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrelative_pos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m             \u001b[0mrel_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrel_embeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m         )\n\u001b[1;32m    350\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/factcheck/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/factcheck/lib/python3.6/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[1;32m    277\u001b[0m             \u001b[0mquery_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0mrelative_pos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrelative_pos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0mrel_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrel_embeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         )\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/factcheck/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/factcheck/lib/python3.6/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, output_attentions, query_states, relative_pos, rel_embeddings)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0mrel_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_dropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrel_embeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m             rel_att = self.disentangled_attention_bias(\n\u001b[0;32m--> 699\u001b[0;31m                 \u001b[0mquery_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelative_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrel_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_factor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m             )\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/factcheck/lib/python3.6/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\u001b[0m in \u001b[0;36mdisentangled_attention_bias\u001b[0;34m(self, query_layer, key_layer, relative_pos, rel_embeddings, scale_factor)\u001b[0m\n\u001b[1;32m    775\u001b[0m                 \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mc2p_pos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrelative_pos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             )\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mc2p_att\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0;31m# position->content\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 31.74 GiB total capacity; 4.85 GiB already allocated; 131.56 MiB free; 4.98 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/5.1.4_deberta_docnli/',\n",
    "    num_train_epochs=15,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.06,\n",
    "    weight_decay=0.1,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/5.1.4_deberta_docnli/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/5.1.4_deberta_docnli/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63deaea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/home/elson/5.1.4_deberta_docnli/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73395d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "probabilities = torch.softmax(torch.tensor(test_results.predictions).to(torch.float32), dim=-1)\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)\n",
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb603377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_save = []\n",
    "for idx in range(len(test_data)):\n",
    "    item = dataset['test'][idx]\n",
    "    actual_label = item['label']\n",
    "    predicted_label = predictions[idx]\n",
    "    claim = item['claim'] \n",
    "    premise = item['premise'] \n",
    "    category = item['category']\n",
    "    \n",
    "    # Append the information as a dictionary to the list\n",
    "    data_to_save.append({\n",
    "        'Claim': claim,\n",
    "        'Premise': premise,\n",
    "        'Actual Label': actual_label,\n",
    "        'Predicted Label': predicted_label,\n",
    "        'Category' : category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_to_save)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/home/elson/results/5.1.4_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c23339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correctly classified instances\n",
    "correctly_classified = df[df['Actual Label'] == df['Predicted Label']]\n",
    "\n",
    "# Calculate misclassified instances\n",
    "misclassified = df[df['Actual Label'] != df['Predicted Label']]\n",
    "\n",
    "# Count the number of correctly classified and misclassified by category\n",
    "correct_classification_counts = correctly_classified['Category'].value_counts()\n",
    "misclassification_counts = misclassified['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0def77",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fddd944",
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b899b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_counts = df['Category'].value_counts()\n",
    "\n",
    "# Calculate ratios\n",
    "correct_classification_ratios = correct_classification_counts / total_counts\n",
    "misclassification_ratios = misclassification_counts / total_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3598b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(correct_classification_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27602a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(misclassification_ratios)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
