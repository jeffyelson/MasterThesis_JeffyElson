{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45f1f111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jul 29 09:18:09 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:61:00.0 Off |                    0 |\n",
      "| N/A   44C    P0    57W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  Off  | 00000000:62:00.0 Off |                    0 |\n",
      "| N/A   45C    P0    58W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  Off  | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   44C    P0    61W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  Off  | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   44C    P0    60W / 300W |      0MiB / 32768MiB |      1%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-47509a4ace11a992\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-47509a4ace11a992/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 212.56it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('csv',data_files='dataset_sentenceattribution_nerfeatures_split.csv',delimiter=',',column_names=[\"claim\",\"premise\",\"label\",\"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\",\"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\",\"url\", \"entities\",\"entity_map\",\"entity_map_ev\",\"entity_ev\",\"gem_exp\",\"gem_label\",\"gpt_exp\",\"gpt_label\",\"gold_exp\",\"synonym\",\"voice\",\"split\"],skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e2914c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'entity_map_ev', 'entity_ev', 'gem_exp', 'gem_label', 'gpt_exp', 'gpt_label', 'gold_exp', 'synonym', 'voice', 'split'],\n",
       "        num_rows: 2322\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57d56e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'test',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['split']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ce96b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-47509a4ace11a992/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-cd7ed25d4d332523.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-47509a4ace11a992/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-caadbcafda8de4b1.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-47509a4ace11a992/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-9e929b5a7841f440.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'entity_map_ev', 'entity_ev', 'gem_exp', 'gem_label', 'gpt_exp', 'gpt_label', 'gold_exp', 'synonym', 'voice', 'split'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'entity_map_ev', 'entity_ev', 'gem_exp', 'gem_label', 'gpt_exp', 'gpt_label', 'gold_exp', 'synonym', 'voice', 'split'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'entity_map_ev', 'entity_ev', 'gem_exp', 'gem_label', 'gpt_exp', 'gpt_label', 'gold_exp', 'synonym', 'voice', 'split'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41f1db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\"claim\", \"premise\", \"label\",\"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\",\"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\"]\n",
    "all_columns = dataset[\"train\"].column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-47509a4ace11a992/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-a721033a0c0d5713.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-47509a4ace11a992/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-fe2d9c401282aa7e.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-47509a4ace11a992/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-2924d1e1772aba33.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 1, 'entailment': 0, 'neutral': 1}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 1,\n",
    "    \"entailment\": 0,\n",
    "    \"neutral\": 1\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='MoritzLaurer/DeBERTa-v3-base-mnli-fever-docnli-ling-2c'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "        # Extracting claim and evidence texts\n",
    "        claim = item['claim'].lower() \n",
    "        evidences = item['premise']\n",
    "        item['premise']=evidences\n",
    "        item['claim']=claim\n",
    "        additional_features_evidence = [\n",
    "            \"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\"]\n",
    "    \n",
    "        for feature in additional_features_evidence:\n",
    "            if feature in item:\n",
    "                evidences += \"[SEP]\" + str(item[feature])\n",
    "        additional_features = [\n",
    "            \"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\"]\n",
    "    \n",
    "        for feature_ev in additional_features:\n",
    "            if feature_ev in item:\n",
    "                claim += \"[SEP]\" + str(item[feature_ev])\n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "            evidences,claim,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "         # Construct the output item\n",
    "        output_item = {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),  # Remove batch dimension\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),  # Remove batch dimension\n",
    "            'claim': claim,  # Include augmented claim text\n",
    "            'evidences': evidences  # Include original evidence text\n",
    "        }\n",
    "        \n",
    "        if 'label' in item:\n",
    "            output_item['label'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return output_item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62421eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at MoritzLaurer/DeBERTa-v3-base-mnli-fever-docnli-ling-2c and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([3, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([2]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DebertaV2ForSequenceClassification(\n",
       "  (deberta): DebertaV2Model(\n",
       "    (embeddings): DebertaV2Embeddings(\n",
       "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaV2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (1): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (2): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (3): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (4): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (5): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (6): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (7): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (8): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (9): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (10): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (11): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (pooler): ContextPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): StableDropout()\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (dropout): StableDropout()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"MoritzLaurer/DeBERTa-v3-base-mnli-fever-docnli-ling-2c\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=3, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    bal_accuracy = balanced_accuracy_score(labels,preds)\n",
    "\n",
    "    return {\"accuracy\": acc, \"balanced_accuracy\":bal_accuracy, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17c5e0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([    1,  4081,   261,  5042,   333, 73325,  1452,  2155,  6116,  1938,\n",
       "           272,   262, 88609,   263, 98237,  1830,  1080,  7355,   387,  2655,\n",
       "           262, 12682,   265, 65008,   292,  1158, 53245,   264, 75840,   293,\n",
       "          2376,  1158,  1452,  2155,   260,     2,   767,     2,   767,     2,\n",
       "           767,     2,   767,     2,   767,     2,   767,     2,   767,     2,\n",
       "           767,     2,   767,     2,   767,     2,   767,     2,   767,     2,\n",
       "         98237,  1830,  1080,   269,  1359,   427,   267, 17847,   633,   264,\n",
       "           408,  1300,   262,  2658,   265,   262,  1158,   260,     2,   767,\n",
       "             2,   767,     2,   767,     2,   767,     2,   767,     2,   767,\n",
       "             2,   767,     2,   767,     2,   767,     2,   767,     2,   767,\n",
       "             2,   767,     2,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'claim': 'myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0',\n",
       " 'evidences': 'Additionally, laser doppler blood flow measurement showed that the frankincense and myrrh essential oil compound could promote the elimination of capillaries from skin epidermis to dermis by increasing skin blood flow.[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0',\n",
       " 'label': tensor(1)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 765\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='765' max='765' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [765/765 11:31, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.965200</td>\n",
       "      <td>0.903205</td>\n",
       "      <td>0.658065</td>\n",
       "      <td>0.605116</td>\n",
       "      <td>0.651065</td>\n",
       "      <td>0.658065</td>\n",
       "      <td>0.630690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.635800</td>\n",
       "      <td>0.601762</td>\n",
       "      <td>0.746237</td>\n",
       "      <td>0.714093</td>\n",
       "      <td>0.745499</td>\n",
       "      <td>0.746237</td>\n",
       "      <td>0.737854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.416600</td>\n",
       "      <td>0.635230</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.705743</td>\n",
       "      <td>0.716020</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.711669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.278100</td>\n",
       "      <td>0.736055</td>\n",
       "      <td>0.724731</td>\n",
       "      <td>0.723745</td>\n",
       "      <td>0.733016</td>\n",
       "      <td>0.724731</td>\n",
       "      <td>0.726952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.212900</td>\n",
       "      <td>0.766083</td>\n",
       "      <td>0.735484</td>\n",
       "      <td>0.720753</td>\n",
       "      <td>0.733988</td>\n",
       "      <td>0.735484</td>\n",
       "      <td>0.734566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.209000</td>\n",
       "      <td>0.889147</td>\n",
       "      <td>0.754839</td>\n",
       "      <td>0.734073</td>\n",
       "      <td>0.752140</td>\n",
       "      <td>0.754839</td>\n",
       "      <td>0.751723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.186300</td>\n",
       "      <td>1.120221</td>\n",
       "      <td>0.729032</td>\n",
       "      <td>0.721815</td>\n",
       "      <td>0.731912</td>\n",
       "      <td>0.729032</td>\n",
       "      <td>0.730134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.252600</td>\n",
       "      <td>1.167677</td>\n",
       "      <td>0.746237</td>\n",
       "      <td>0.724180</td>\n",
       "      <td>0.743224</td>\n",
       "      <td>0.746237</td>\n",
       "      <td>0.742650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.123400</td>\n",
       "      <td>1.203903</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.682625</td>\n",
       "      <td>0.695124</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.680784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.129000</td>\n",
       "      <td>1.351719</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.687210</td>\n",
       "      <td>0.701043</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.680784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.114900</td>\n",
       "      <td>1.337127</td>\n",
       "      <td>0.705376</td>\n",
       "      <td>0.707674</td>\n",
       "      <td>0.718107</td>\n",
       "      <td>0.705376</td>\n",
       "      <td>0.708215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.042200</td>\n",
       "      <td>1.461127</td>\n",
       "      <td>0.705376</td>\n",
       "      <td>0.704923</td>\n",
       "      <td>0.715213</td>\n",
       "      <td>0.705376</td>\n",
       "      <td>0.707933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>1.618953</td>\n",
       "      <td>0.703226</td>\n",
       "      <td>0.702220</td>\n",
       "      <td>0.712628</td>\n",
       "      <td>0.703226</td>\n",
       "      <td>0.705744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.033600</td>\n",
       "      <td>1.730157</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.702992</td>\n",
       "      <td>0.713739</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.711155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>1.775197</td>\n",
       "      <td>0.722581</td>\n",
       "      <td>0.713707</td>\n",
       "      <td>0.724549</td>\n",
       "      <td>0.722581</td>\n",
       "      <td>0.723400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.5_deberta_docnli/checkpoint-51\n",
      "Configuration saved in /home/elson/5.1.5_deberta_docnli/checkpoint-51/config.json\n",
      "Model weights saved in /home/elson/5.1.5_deberta_docnli/checkpoint-51/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.5_deberta_docnli/checkpoint-102\n",
      "Configuration saved in /home/elson/5.1.5_deberta_docnli/checkpoint-102/config.json\n",
      "Model weights saved in /home/elson/5.1.5_deberta_docnli/checkpoint-102/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.5_deberta_docnli/checkpoint-51] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.5_deberta_docnli/checkpoint-153\n",
      "Configuration saved in /home/elson/5.1.5_deberta_docnli/checkpoint-153/config.json\n",
      "Model weights saved in /home/elson/5.1.5_deberta_docnli/checkpoint-153/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.5_deberta_docnli/checkpoint-204\n",
      "Configuration saved in /home/elson/5.1.5_deberta_docnli/checkpoint-204/config.json\n",
      "Model weights saved in /home/elson/5.1.5_deberta_docnli/checkpoint-204/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.5_deberta_docnli/checkpoint-153] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.5_deberta_docnli/checkpoint-255\n",
      "Configuration saved in /home/elson/5.1.5_deberta_docnli/checkpoint-255/config.json\n",
      "Model weights saved in /home/elson/5.1.5_deberta_docnli/checkpoint-255/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.5_deberta_docnli/checkpoint-204] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.5_deberta_docnli/checkpoint-306\n",
      "Configuration saved in /home/elson/5.1.5_deberta_docnli/checkpoint-306/config.json\n",
      "Model weights saved in /home/elson/5.1.5_deberta_docnli/checkpoint-306/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.5_deberta_docnli/checkpoint-102] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/5.1.5_deberta_docnli/checkpoint-255] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.5_deberta_docnli/checkpoint-357\n",
      "Configuration saved in /home/elson/5.1.5_deberta_docnli/checkpoint-357/config.json\n",
      "Model weights saved in /home/elson/5.1.5_deberta_docnli/checkpoint-357/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.5_deberta_docnli/checkpoint-408\n",
      "Configuration saved in /home/elson/5.1.5_deberta_docnli/checkpoint-408/config.json\n",
      "Model weights saved in /home/elson/5.1.5_deberta_docnli/checkpoint-408/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.5_deberta_docnli/checkpoint-357] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.5_deberta_docnli/checkpoint-459\n",
      "Configuration saved in /home/elson/5.1.5_deberta_docnli/checkpoint-459/config.json\n",
      "Model weights saved in /home/elson/5.1.5_deberta_docnli/checkpoint-459/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.5_deberta_docnli/checkpoint-408] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.5_deberta_docnli/checkpoint-510\n",
      "Configuration saved in /home/elson/5.1.5_deberta_docnli/checkpoint-510/config.json\n",
      "Model weights saved in /home/elson/5.1.5_deberta_docnli/checkpoint-510/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.5_deberta_docnli/checkpoint-459] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.5_deberta_docnli/checkpoint-561\n",
      "Configuration saved in /home/elson/5.1.5_deberta_docnli/checkpoint-561/config.json\n",
      "Model weights saved in /home/elson/5.1.5_deberta_docnli/checkpoint-561/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.5_deberta_docnli/checkpoint-510] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.5_deberta_docnli/checkpoint-612\n",
      "Configuration saved in /home/elson/5.1.5_deberta_docnli/checkpoint-612/config.json\n",
      "Model weights saved in /home/elson/5.1.5_deberta_docnli/checkpoint-612/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.5_deberta_docnli/checkpoint-561] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.5_deberta_docnli/checkpoint-663\n",
      "Configuration saved in /home/elson/5.1.5_deberta_docnli/checkpoint-663/config.json\n",
      "Model weights saved in /home/elson/5.1.5_deberta_docnli/checkpoint-663/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.5_deberta_docnli/checkpoint-612] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.5_deberta_docnli/checkpoint-714\n",
      "Configuration saved in /home/elson/5.1.5_deberta_docnli/checkpoint-714/config.json\n",
      "Model weights saved in /home/elson/5.1.5_deberta_docnli/checkpoint-714/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.5_deberta_docnli/checkpoint-663] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.5_deberta_docnli/checkpoint-765\n",
      "Configuration saved in /home/elson/5.1.5_deberta_docnli/checkpoint-765/config.json\n",
      "Model weights saved in /home/elson/5.1.5_deberta_docnli/checkpoint-765/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.5_deberta_docnli/checkpoint-714] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/elson/5.1.5_deberta_docnli/checkpoint-306 (score: 0.7548387096774194).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /home/elson/5.1.5_deberta_docnli/best_model/config.json\n",
      "Model weights saved in /home/elson/5.1.5_deberta_docnli/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/5.1.5_deberta_docnli/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/5.1.5_deberta_docnli/best_model/special_tokens_map.json\n",
      "added tokens file saved in /home/elson/5.1.5_deberta_docnli/best_model/added_tokens.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/5.1.5_deberta_docnli/best_model/tokenizer_config.json',\n",
       " '/home/elson/5.1.5_deberta_docnli/best_model/special_tokens_map.json',\n",
       " '/home/elson/5.1.5_deberta_docnli/best_model/spm.model',\n",
       " '/home/elson/5.1.5_deberta_docnli/best_model/added_tokens.json')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/5.1.5_deberta_docnli/',\n",
    "    num_train_epochs=15,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.6,\n",
    "    weight_decay=0.1,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/5.1.5_deberta_docnli/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/5.1.5_deberta_docnli/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63deaea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/5.1.5_deberta_docnli/best_model/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"/home/elson/5.1.5_deberta_docnli/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file /home/elson/5.1.5_deberta_docnli/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at /home/elson/5.1.5_deberta_docnli/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 32\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/5.1.5_deberta_docnli/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[ 2.7266e+00,  3.9575e-01, -4.2461e+00],\n",
      "       [ 3.9160e+00, -9.7070e-01, -3.6211e+00],\n",
      "       [ 4.0117e+00, -1.0684e+00, -3.5918e+00],\n",
      "       [-7.6416e-01,  2.8711e+00, -3.1328e+00],\n",
      "       [ 3.8398e+00, -1.0342e+00, -3.3828e+00],\n",
      "       [ 4.0469e+00, -1.2080e+00, -3.3867e+00],\n",
      "       [ 3.9531e+00, -1.0947e+00, -3.4434e+00],\n",
      "       [ 3.6445e+00, -5.0146e-01, -4.0781e+00],\n",
      "       [ 4.0664e+00, -1.3135e+00, -3.2031e+00],\n",
      "       [ 8.2129e-01,  1.9609e+00, -3.9648e+00],\n",
      "       [ 3.5273e+00, -4.1772e-01, -4.0391e+00],\n",
      "       [ 4.0664e+00, -1.2656e+00, -3.3438e+00],\n",
      "       [ 3.5449e+00, -5.0146e-01, -3.9219e+00],\n",
      "       [ 4.0820e+00, -1.2529e+00, -3.3496e+00],\n",
      "       [ 8.9551e-01,  1.8584e+00, -3.9004e+00],\n",
      "       [-7.6123e-01,  2.8984e+00, -3.2090e+00],\n",
      "       [ 7.7197e-01,  1.9834e+00, -4.0156e+00],\n",
      "       [ 4.0586e+00, -1.2324e+00, -3.3926e+00],\n",
      "       [ 4.0625e+00, -1.4248e+00, -3.0469e+00],\n",
      "       [ 4.0586e+00, -1.2539e+00, -3.3320e+00],\n",
      "       [ 2.4766e+00,  3.9282e-01, -3.6719e+00],\n",
      "       [ 9.8193e-01,  1.8555e+00, -4.1797e+00],\n",
      "       [ 1.6387e+00,  1.2910e+00, -4.0156e+00],\n",
      "       [ 1.3164e+00,  1.4863e+00, -3.7129e+00],\n",
      "       [ 1.0166e+00,  1.7549e+00, -3.8047e+00],\n",
      "       [-1.4365e+00,  3.1895e+00, -3.1152e+00],\n",
      "       [ 3.7383e+00, -1.4893e+00, -2.4062e+00],\n",
      "       [ 3.2832e+00, -2.0850e-01, -4.0352e+00],\n",
      "       [ 4.0312e+00, -1.1758e+00, -3.4316e+00],\n",
      "       [ 3.9004e+00, -9.0381e-01, -3.7012e+00],\n",
      "       [-1.2314e+00,  3.1133e+00, -3.2910e+00],\n",
      "       [ 3.8730e+00, -8.6621e-01, -3.7324e+00],\n",
      "       [ 4.0664e+00, -1.3389e+00, -3.1934e+00],\n",
      "       [ 3.3164e+00, -2.4341e-01, -4.0117e+00],\n",
      "       [-8.4180e-01,  2.9570e+00, -3.3262e+00],\n",
      "       [-6.5979e-02,  2.5059e+00, -3.5176e+00],\n",
      "       [ 3.1426e+00, -2.6031e-02, -4.1406e+00],\n",
      "       [ 4.0391e+00, -1.3926e+00, -3.0254e+00],\n",
      "       [-3.0396e-01,  2.6562e+00, -3.4062e+00],\n",
      "       [ 6.4209e-02,  2.4766e+00, -3.7637e+00],\n",
      "       [ 1.6396e+00,  1.1904e+00, -3.7266e+00],\n",
      "       [ 3.9824e+00, -1.0859e+00, -3.4961e+00],\n",
      "       [ 3.3643e-01,  2.2559e+00, -3.6367e+00],\n",
      "       [-9.6143e-01,  3.0410e+00, -3.3027e+00],\n",
      "       [-1.2607e+00,  3.1309e+00, -3.2207e+00],\n",
      "       [-8.6548e-02,  2.5449e+00, -3.6387e+00],\n",
      "       [-6.6357e-01,  2.8906e+00, -3.5117e+00],\n",
      "       [ 3.9316e+00, -9.5264e-01, -3.6973e+00],\n",
      "       [ 4.0234e+00, -1.3477e+00, -3.1113e+00],\n",
      "       [ 1.9547e-02,  2.4219e+00, -3.4004e+00],\n",
      "       [ 2.1753e-01,  2.3945e+00, -3.8262e+00],\n",
      "       [ 1.7539e+00,  1.2295e+00, -4.1641e+00],\n",
      "       [ 2.3450e-01,  2.3223e+00, -3.5859e+00],\n",
      "       [-8.8379e-01,  2.9824e+00, -3.3887e+00],\n",
      "       [-5.1709e-01,  2.7852e+00, -3.3848e+00],\n",
      "       [ 4.0859e+00, -1.2803e+00, -3.3262e+00],\n",
      "       [-1.0703e+00,  3.0898e+00, -3.2695e+00],\n",
      "       [ 3.9121e+00, -1.0137e+00, -3.5410e+00],\n",
      "       [ 4.0508e+00, -1.2539e+00, -3.3242e+00],\n",
      "       [ 3.9316e+00, -9.9023e-01, -3.5879e+00],\n",
      "       [ 4.0430e+00, -1.2871e+00, -3.2500e+00],\n",
      "       [-1.2805e-01,  2.5371e+00, -3.4453e+00],\n",
      "       [ 2.9414e+00,  9.9182e-02, -3.9902e+00],\n",
      "       [ 1.4736e+00,  1.4277e+00, -4.0039e+00],\n",
      "       [ 2.8438e+00,  2.6221e-01, -4.1914e+00],\n",
      "       [ 3.8125e+00, -1.4902e+00, -2.4844e+00],\n",
      "       [ 3.9766e+00, -1.0488e+00, -3.5566e+00],\n",
      "       [ 4.0820e+00, -1.1826e+00, -3.4746e+00],\n",
      "       [ 3.1738e+00, -2.4612e-02, -4.1914e+00],\n",
      "       [ 1.4854e+00,  1.3076e+00, -3.6934e+00],\n",
      "       [ 3.1465e+00, -2.7908e-02, -4.1211e+00],\n",
      "       [ 2.2461e+00,  7.3193e-01, -3.9590e+00],\n",
      "       [ 2.9336e+00,  1.6528e-01, -4.1445e+00],\n",
      "       [ 3.6348e+00, -5.9180e-01, -3.9062e+00],\n",
      "       [ 3.1094e+00, -3.1967e-03, -4.1250e+00],\n",
      "       [ 1.8838e+00,  1.0986e+00, -4.0664e+00],\n",
      "       [ 4.0156e+00, -1.2070e+00, -3.3145e+00],\n",
      "       [ 3.9922e+00, -1.3320e+00, -3.1016e+00],\n",
      "       [ 4.0430e+00, -1.2383e+00, -3.3457e+00],\n",
      "       [ 4.0039e+00, -1.1699e+00, -3.4082e+00],\n",
      "       [ 3.9648e+00, -9.6729e-01, -3.6992e+00],\n",
      "       [ 3.8164e+00, -8.0762e-01, -3.7812e+00],\n",
      "       [ 4.0312e+00, -1.1895e+00, -3.4219e+00],\n",
      "       [ 3.9961e+00, -1.4648e+00, -2.8398e+00],\n",
      "       [ 4.0742e+00, -1.2881e+00, -3.2676e+00],\n",
      "       [-1.3555e+00,  3.1562e+00, -3.2012e+00],\n",
      "       [ 4.0117e+00, -1.4434e+00, -2.9023e+00],\n",
      "       [ 4.8340e-01,  2.1816e+00, -3.8184e+00],\n",
      "       [ 2.6133e+00,  3.7842e-01, -3.8867e+00],\n",
      "       [ 3.2754e+00, -2.3804e-01, -3.9258e+00],\n",
      "       [ 3.9121e+00, -9.1162e-01, -3.7188e+00],\n",
      "       [ 3.8652e+00, -8.5645e-01, -3.7383e+00],\n",
      "       [-8.9014e-01,  2.9492e+00, -3.1465e+00],\n",
      "       [ 3.9082e+00, -8.9502e-01, -3.7617e+00],\n",
      "       [ 3.1816e+00, -8.6182e-02, -4.0820e+00],\n",
      "       [ 2.3816e-01,  2.3359e+00, -3.6602e+00],\n",
      "       [ 2.0410e+00,  9.9658e-01, -4.1523e+00],\n",
      "       [ 2.6562e+00,  3.8672e-01, -4.0898e+00],\n",
      "       [ 3.9043e+00, -8.8818e-01, -3.7715e+00],\n",
      "       [ 4.0664e+00, -1.4541e+00, -2.9648e+00],\n",
      "       [ 1.3252e+00,  1.4033e+00, -3.5488e+00],\n",
      "       [ 3.8574e+00, -9.4482e-01, -3.5137e+00],\n",
      "       [ 4.0625e+00, -1.3516e+00, -3.1719e+00],\n",
      "       [ 3.7695e+00, -7.2363e-01, -3.8672e+00],\n",
      "       [ 3.9434e+00, -1.1230e+00, -3.3887e+00],\n",
      "       [ 3.5996e+00, -5.0586e-01, -3.9648e+00],\n",
      "       [ 5.0830e-01,  2.1328e+00, -3.7031e+00],\n",
      "       [-1.1816e+00,  3.1211e+00, -3.2266e+00],\n",
      "       [ 4.0234e+00, -1.1582e+00, -3.4277e+00],\n",
      "       [ 1.4832e-01,  2.4219e+00, -3.9043e+00],\n",
      "       [ 7.8003e-02,  2.4102e+00, -3.6523e+00],\n",
      "       [ 4.0859e+00, -1.3564e+00, -3.1445e+00],\n",
      "       [ 3.9805e+00, -1.0576e+00, -3.5859e+00],\n",
      "       [ 3.8516e+00, -1.1699e+00, -3.1055e+00],\n",
      "       [ 4.0547e+00, -1.2676e+00, -3.2930e+00],\n",
      "       [ 4.0742e+00, -1.2939e+00, -3.2598e+00],\n",
      "       [ 4.0312e+00, -1.4004e+00, -3.0156e+00],\n",
      "       [ 3.8770e+00, -1.4082e+00, -2.7930e+00],\n",
      "       [ 3.4551e+00, -3.5522e-01, -4.0391e+00],\n",
      "       [ 3.9961e+00, -1.3291e+00, -3.0840e+00],\n",
      "       [ 3.5410e+00, -4.8804e-01, -3.9121e+00],\n",
      "       [ 2.3865e-01,  2.3633e+00, -3.8340e+00],\n",
      "       [ 4.0703e+00, -1.3857e+00, -3.0898e+00],\n",
      "       [ 2.7910e+00,  2.7515e-01, -4.0742e+00],\n",
      "       [ 7.1729e-01,  2.0430e+00, -3.9648e+00],\n",
      "       [ 6.2793e-01,  2.1211e+00, -4.0117e+00],\n",
      "       [ 9.8877e-02,  2.4766e+00, -3.8848e+00],\n",
      "       [ 3.6836e+00, -6.4404e-01, -3.8496e+00],\n",
      "       [ 3.9648e+00, -1.1367e+00, -3.3984e+00],\n",
      "       [ 3.3477e+00, -2.6978e-01, -3.9688e+00],\n",
      "       [ 2.9062e+00,  3.4882e-02, -3.8223e+00],\n",
      "       [-3.8892e-01,  2.7363e+00, -3.4766e+00],\n",
      "       [ 4.0820e+00, -1.2764e+00, -3.2871e+00],\n",
      "       [-6.3330e-01,  2.8770e+00, -3.5117e+00],\n",
      "       [ 1.4863e+00,  1.4199e+00, -4.0586e+00],\n",
      "       [ 2.7734e+00,  3.0640e-01, -4.1133e+00],\n",
      "       [ 3.9609e+00, -1.0928e+00, -3.4805e+00],\n",
      "       [-8.2715e-01,  2.9863e+00, -3.4238e+00],\n",
      "       [-6.3281e-01,  2.8594e+00, -3.3418e+00],\n",
      "       [ 4.0625e+00, -1.4102e+00, -3.0801e+00],\n",
      "       [ 2.6934e+00,  4.1748e-01, -4.2383e+00],\n",
      "       [ 3.4277e+00, -3.5107e-01, -4.0234e+00],\n",
      "       [ 2.0664e+00,  9.6631e-01, -4.2109e+00],\n",
      "       [ 3.9863e+00, -1.4551e+00, -2.8320e+00],\n",
      "       [ 1.0752e+00,  1.7764e+00, -4.0430e+00],\n",
      "       [ 3.9922e+00, -1.0840e+00, -3.5547e+00],\n",
      "       [ 4.8920e-02,  2.4180e+00, -3.4648e+00],\n",
      "       [ 5.3711e-01,  2.0215e+00, -3.4023e+00],\n",
      "       [ 3.7559e+00, -7.2510e-01, -3.8496e+00],\n",
      "       [-8.3545e-01,  2.9707e+00, -3.3125e+00],\n",
      "       [-4.8120e-01,  2.8223e+00, -3.6445e+00],\n",
      "       [ 4.0586e+00, -1.1562e+00, -3.5156e+00],\n",
      "       [ 4.0703e+00, -1.2480e+00, -3.3477e+00],\n",
      "       [ 4.0273e+00, -1.1602e+00, -3.4727e+00],\n",
      "       [ 4.0547e+00, -1.3701e+00, -3.0859e+00],\n",
      "       [ 4.0078e+00, -1.0986e+00, -3.5469e+00],\n",
      "       [ 3.8672e+00, -8.8965e-01, -3.7012e+00],\n",
      "       [ 3.4453e+00, -3.9673e-01, -3.9336e+00],\n",
      "       [ 3.0898e+00, -1.1401e-01, -3.8555e+00],\n",
      "       [-1.2422e+00,  3.1348e+00, -3.2129e+00],\n",
      "       [-1.3740e+00,  3.1758e+00, -3.1465e+00],\n",
      "       [-1.1582e+00,  3.0879e+00, -3.1641e+00],\n",
      "       [ 4.0000e+00, -1.4150e+00, -2.9258e+00],\n",
      "       [ 2.0740e-01,  2.3828e+00, -3.8086e+00],\n",
      "       [ 1.0518e+00,  1.6992e+00, -3.7871e+00],\n",
      "       [ 3.5879e+00, -7.9932e-01, -3.4023e+00],\n",
      "       [ 2.8535e+00,  3.0322e-01, -4.2773e+00],\n",
      "       [-9.7656e-01,  3.0273e+00, -3.2129e+00],\n",
      "       [-8.9209e-01,  2.9453e+00, -3.1289e+00],\n",
      "       [-6.5527e-01,  2.9023e+00, -3.6172e+00],\n",
      "       [-1.4609e+00,  3.1953e+00, -3.0977e+00],\n",
      "       [ 1.4209e+00,  1.4287e+00, -3.8281e+00],\n",
      "       [-1.0898e+00,  3.0879e+00, -3.2832e+00],\n",
      "       [ 4.0117e+00, -1.1348e+00, -3.4668e+00],\n",
      "       [ 3.4766e+00, -4.7974e-01, -3.8086e+00],\n",
      "       [-7.8711e-01,  2.9434e+00, -3.4121e+00],\n",
      "       [ 3.9824e+00, -1.0430e+00, -3.5820e+00],\n",
      "       [ 3.9453e+00, -1.3076e+00, -3.0625e+00],\n",
      "       [ 4.0078e+00, -1.1523e+00, -3.4219e+00],\n",
      "       [ 4.0820e-01,  2.2305e+00, -3.8027e+00],\n",
      "       [ 1.7578e-01,  2.3438e+00, -3.4707e+00],\n",
      "       [ 8.3350e-01,  1.9502e+00, -4.0234e+00],\n",
      "       [-3.0933e-01,  2.6387e+00, -3.3320e+00],\n",
      "       [ 2.6035e+00,  5.0879e-01, -4.2539e+00],\n",
      "       [-1.2292e-01,  2.5703e+00, -3.7773e+00],\n",
      "       [ 4.0742e+00, -1.2461e+00, -3.3711e+00],\n",
      "       [ 3.8105e+00, -8.6914e-01, -3.6602e+00],\n",
      "       [ 3.9453e+00, -1.0303e+00, -3.5488e+00],\n",
      "       [ 1.9111e+00,  9.1992e-01, -3.6582e+00],\n",
      "       [ 4.0273e+00, -1.2109e+00, -3.3496e+00],\n",
      "       [-5.6885e-01,  2.8262e+00, -3.5723e+00],\n",
      "       [ 1.6221e+00,  1.3223e+00, -4.0664e+00],\n",
      "       [ 3.2910e+00, -2.4084e-01, -3.9062e+00],\n",
      "       [ 3.7363e+00, -6.9922e-01, -3.8691e+00],\n",
      "       [-5.1611e-01,  2.7695e+00, -3.3008e+00],\n",
      "       [ 3.9375e+00, -9.7510e-01, -3.6328e+00],\n",
      "       [ 3.7090e+00, -8.5840e-01, -3.4492e+00],\n",
      "       [ 4.0664e+00, -1.3994e+00, -3.0859e+00],\n",
      "       [ 4.0391e+00, -1.2656e+00, -3.2812e+00],\n",
      "       [ 2.5723e+00,  4.1870e-01, -3.9355e+00],\n",
      "       [ 4.0039e+00, -1.1963e+00, -3.3438e+00],\n",
      "       [ 3.7363e+00, -7.8320e-01, -3.6211e+00],\n",
      "       [ 3.0488e+00,  4.8096e-02, -4.0859e+00],\n",
      "       [ 4.0039e+00, -1.1396e+00, -3.4512e+00],\n",
      "       [-1.0791e+00,  3.0645e+00, -3.2148e+00],\n",
      "       [-2.3926e-01,  2.6289e+00, -3.4141e+00],\n",
      "       [ 3.7793e+00, -7.2021e-01, -3.8379e+00],\n",
      "       [ 3.9062e+00, -9.5850e-01, -3.6465e+00],\n",
      "       [ 4.0039e+00, -1.4434e+00, -2.8652e+00],\n",
      "       [ 2.9785e+00,  1.0223e-01, -4.1211e+00],\n",
      "       [ 2.8652e+00,  2.3242e-01, -4.1680e+00],\n",
      "       [-8.9478e-02,  2.5273e+00, -3.5117e+00],\n",
      "       [ 4.0820e+00, -1.3945e+00, -3.1016e+00],\n",
      "       [ 3.3359e+00, -2.1899e-01, -4.0469e+00],\n",
      "       [ 4.0703e+00, -1.3848e+00, -3.0781e+00],\n",
      "       [ 4.0405e-01,  2.2441e+00, -3.8086e+00],\n",
      "       [ 6.2646e-01,  2.0723e+00, -3.8477e+00],\n",
      "       [ 2.1326e-01,  2.3848e+00, -3.9375e+00],\n",
      "       [ 4.0586e+00, -1.1973e+00, -3.4121e+00],\n",
      "       [ 8.2568e-01,  1.9775e+00, -4.0195e+00],\n",
      "       [ 3.9102e+00, -1.5039e+00, -2.6621e+00],\n",
      "       [ 4.0469e+00, -1.2480e+00, -3.3184e+00],\n",
      "       [ 1.5596e+00,  1.4072e+00, -4.3398e+00],\n",
      "       [ 3.9180e+00, -1.0020e+00, -3.5879e+00],\n",
      "       [ 4.0273e+00, -1.2178e+00, -3.3242e+00],\n",
      "       [ 4.0469e+00, -1.2441e+00, -3.3008e+00],\n",
      "       [ 4.1055e+00, -1.3105e+00, -3.2871e+00],\n",
      "       [-3.7109e-01,  2.7285e+00, -3.4785e+00],\n",
      "       [ 1.1309e+00,  1.7129e+00, -4.0742e+00],\n",
      "       [ 3.8828e+00, -1.3438e+00, -2.9199e+00],\n",
      "       [ 3.7168e+00, -7.2510e-01, -3.7832e+00],\n",
      "       [ 3.9336e+00, -1.3906e+00, -2.8809e+00],\n",
      "       [ 3.9434e+00, -1.0537e+00, -3.4961e+00],\n",
      "       [ 3.9668e+00, -1.2705e+00, -3.1680e+00]], dtype=float16), label_ids=array([1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n",
      "       1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "       1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
      "       1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
      "       0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
      "       0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n",
      "       0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1,\n",
      "       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1]), metrics={'test_loss': 1.0706684589385986, 'test_accuracy': 0.7136752136752137, 'test_balanced_accuracy': 0.7052296198637662, 'test_precision': 0.7304660141102512, 'test_recall': 0.7136752136752137, 'test_f1': 0.7047117281574055, 'test_runtime': 2.0145, 'test_samples_per_second': 116.158, 'test_steps_per_second': 3.971})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73395d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "probabilities = torch.softmax(torch.tensor(test_results.predictions).to(torch.float32), dim=-1)\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)\n",
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb603377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_save = []\n",
    "for idx in range(len(test_data)):\n",
    "    item = dataset['test'][idx]\n",
    "    actual_label = item['label']\n",
    "    predicted_label = predictions[idx]\n",
    "    claim = item['claim'] \n",
    "    premise = item['premise'] \n",
    "    category = item['category']\n",
    "    \n",
    "    # Append the information as a dictionary to the list\n",
    "    data_to_save.append({\n",
    "        'Claim': claim,\n",
    "        'Premise': premise,\n",
    "        'Actual Label': actual_label,\n",
    "        'Predicted Label': predicted_label,\n",
    "        'Category' : category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_to_save)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/home/elson/results/5.1.5_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c23339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correctly classified instances\n",
    "correctly_classified = df[df['Actual Label'] == df['Predicted Label']]\n",
    "\n",
    "# Calculate misclassified instances\n",
    "misclassified = df[df['Actual Label'] != df['Predicted Label']]\n",
    "\n",
    "# Count the number of correctly classified and misclassified by category\n",
    "correct_classification_counts = correctly_classified['Category'].value_counts()\n",
    "misclassification_counts = misclassified['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca0def77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           42\n",
       "Bone health              16\n",
       "Fitness                  11\n",
       "Skin                     11\n",
       "Diabetes                 10\n",
       "Cancer                   10\n",
       "Hair                      9\n",
       "Eye                       9\n",
       "Cardiovascular Health     8\n",
       "Throat                    7\n",
       "Ear                       6\n",
       "Blood                     5\n",
       "COVID                     5\n",
       "Men's health              4\n",
       "Women' s Health           4\n",
       "Mental Health             3\n",
       "Neurological health       3\n",
       "Muscles                   2\n",
       "Vascular                  2\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0fddd944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Skin                     13\n",
       "General Health            9\n",
       "Neurological health       6\n",
       "Bone health               5\n",
       "Cardiovascular Health     4\n",
       "Muscles                   4\n",
       "Blood                     4\n",
       "Fitness                   4\n",
       "Dental Health             3\n",
       "Hair                      3\n",
       "Diabetes                  2\n",
       "Men's health              2\n",
       "Throat                    2\n",
       "Cancer                    2\n",
       "Women' s Health           2\n",
       "Vascular                  1\n",
       "COVID                     1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38b899b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_counts = df['Category'].value_counts()\n",
    "\n",
    "# Calculate ratios\n",
    "correct_classification_ratios = correct_classification_counts / total_counts\n",
    "misclassification_ratios = misclassification_counts / total_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3598b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blood                    0.555556\n",
      "Bone health              0.761905\n",
      "COVID                    0.833333\n",
      "Cancer                   0.833333\n",
      "Cardiovascular Health    0.666667\n",
      "Dental Health                 NaN\n",
      "Diabetes                 0.833333\n",
      "Ear                      1.000000\n",
      "Eye                      1.000000\n",
      "Fitness                  0.733333\n",
      "General Health           0.823529\n",
      "Hair                     0.750000\n",
      "Men's health             0.666667\n",
      "Mental Health            1.000000\n",
      "Muscles                  0.333333\n",
      "Neurological health      0.333333\n",
      "Skin                     0.458333\n",
      "Throat                   0.777778\n",
      "Vascular                 0.666667\n",
      "Women' s Health          0.666667\n",
      "Name: Category, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(correct_classification_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27602a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blood                    0.444444\n",
      "Bone health              0.238095\n",
      "COVID                    0.166667\n",
      "Cancer                   0.166667\n",
      "Cardiovascular Health    0.333333\n",
      "Dental Health            1.000000\n",
      "Diabetes                 0.166667\n",
      "Ear                           NaN\n",
      "Eye                           NaN\n",
      "Fitness                  0.266667\n",
      "General Health           0.176471\n",
      "Hair                     0.250000\n",
      "Men's health             0.333333\n",
      "Mental Health                 NaN\n",
      "Muscles                  0.666667\n",
      "Neurological health      0.666667\n",
      "Skin                     0.541667\n",
      "Throat                   0.222222\n",
      "Vascular                 0.333333\n",
      "Women' s Health          0.333333\n",
      "Name: Category, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(misclassification_ratios)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
