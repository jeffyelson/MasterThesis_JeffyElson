{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-b4d5af22bd5d34d0\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-b4d5af22bd5d34d0/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 226.56it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('csv',data_files='dataset_propositionattribution_nerfeatures.csv',delimiter=',',column_names=[\"claim\",\"premise\",\"label\",\"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\",\"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\",\"url\", \"entities\",\"entity_map\",\"entity_map_ev\",\"entity_ev\",\"gem_exp\",\"gem_label\",\"gpt_exp\",\"gpt_label\",\"gold_exp\",\"split\"],skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e2914c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'entity_map_ev', 'entity_ev', 'gem_exp', 'gem_label', 'gpt_exp', 'gpt_label', 'gold_exp', 'split'],\n",
       "        num_rows: 2322\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57d56e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'test',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['split']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ce96b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-b4d5af22bd5d34d0/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-c7bf70b7c4f0e941.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-b4d5af22bd5d34d0/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-ca379e6fc623397c.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-b4d5af22bd5d34d0/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-41ed9283338b515a.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'entity_map_ev', 'entity_ev', 'gem_exp', 'gem_label', 'gpt_exp', 'gpt_label', 'gold_exp', 'split'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'entity_map_ev', 'entity_ev', 'gem_exp', 'gem_label', 'gpt_exp', 'gpt_label', 'gold_exp', 'split'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'entity_map_ev', 'entity_ev', 'gem_exp', 'gem_label', 'gpt_exp', 'gpt_label', 'gold_exp', 'split'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41f1db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\"claim\", \"premise\", \"label\",\"category\"]\n",
    "all_columns = dataset[\"train\"].column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-b4d5af22bd5d34d0/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-75e8c99ab375dc2c.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-b4d5af22bd5d34d0/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-efe7941581d35d4e.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-b4d5af22bd5d34d0/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-8165cb068de312e4.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 1, 'entailment': 0, 'neutral': 1}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 1,\n",
    "    \"entailment\": 0,\n",
    "    \"neutral\": 1\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='MoritzLaurer/DeBERTa-v3-base-mnli-fever-docnli-ling-2c'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "        # Extracting claim and evidence texts\n",
    "\n",
    "        claim = item['claim'].lower()\n",
    "        premise = item['premise'].lower().replace('\\n', '')\n",
    "        item['claim']=claim\n",
    "        item['premise']=premise\n",
    "        \n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "            premise,claim,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "        item['input_ids'] = inputs['input_ids'].squeeze()  # Remove batch dimension\n",
    "        item['attention_mask']= inputs['attention_mask'].squeeze() # Remove batch dimension\n",
    "        \n",
    "        if 'label' in item:\n",
    "            item['labels'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62421eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DebertaV2ForSequenceClassification(\n",
       "  (deberta): DebertaV2Model(\n",
       "    (embeddings): DebertaV2Embeddings(\n",
       "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaV2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (1): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (2): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (3): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (4): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (5): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (6): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (7): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (8): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (9): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (10): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (11): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (pooler): ContextPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): StableDropout()\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): StableDropout()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"MoritzLaurer/DeBERTa-v3-base-mnli-fever-docnli-ling-2c\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=2, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    bal_accuracy = balanced_accuracy_score(labels,preds)\n",
    "\n",
    "    return {\"accuracy\": acc, \"balanced_accuracy\":bal_accuracy, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17c5e0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'claim': 'myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.',\n",
       " 'premise': 'the essential oils of frankincense and myrrh increase the fluidity of the lipid bilayer in the cuticle and change the orderly and dense structure to increase the permeability of the skin and decrease the barrier effect.',\n",
       " 'label': 0,\n",
       " 'category': 'General Health',\n",
       " 'input_ids': tensor([    1,   262,  1830,  6725,   265, 88609,   263, 98237,   993,   262,\n",
       "         49462,   265,   262, 22003, 96579,   267,   262, 61462,   263,   575,\n",
       "           262, 26217,   263,  9854,  1730,   264,   993,   262, 39632,   265,\n",
       "           262,  1158,   263,  4843,   262,  7275,  1290,   260,     2, 98237,\n",
       "          1830,  1080,   269,  1359,   427,   267, 17847,   633,   264,   408,\n",
       "          1300,   262,  2658,   265,   262,  1158,   260,     2,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'labels': tensor(0)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1020\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1020' max='1020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1020/1020 15:20, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.308800</td>\n",
       "      <td>1.575452</td>\n",
       "      <td>0.604301</td>\n",
       "      <td>0.655958</td>\n",
       "      <td>0.716926</td>\n",
       "      <td>0.604301</td>\n",
       "      <td>0.616486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.702542</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.703563</td>\n",
       "      <td>0.739982</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.718352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.396800</td>\n",
       "      <td>0.629500</td>\n",
       "      <td>0.726882</td>\n",
       "      <td>0.706451</td>\n",
       "      <td>0.743153</td>\n",
       "      <td>0.726882</td>\n",
       "      <td>0.732592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.180500</td>\n",
       "      <td>0.836702</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.719269</td>\n",
       "      <td>0.754418</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.746514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.099900</td>\n",
       "      <td>1.174923</td>\n",
       "      <td>0.694624</td>\n",
       "      <td>0.696489</td>\n",
       "      <td>0.734695</td>\n",
       "      <td>0.694624</td>\n",
       "      <td>0.704889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.144300</td>\n",
       "      <td>1.190282</td>\n",
       "      <td>0.722581</td>\n",
       "      <td>0.710994</td>\n",
       "      <td>0.746180</td>\n",
       "      <td>0.722581</td>\n",
       "      <td>0.729889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.066900</td>\n",
       "      <td>1.665325</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.708788</td>\n",
       "      <td>0.755934</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.678722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.068700</td>\n",
       "      <td>1.588107</td>\n",
       "      <td>0.701075</td>\n",
       "      <td>0.695418</td>\n",
       "      <td>0.733321</td>\n",
       "      <td>0.701075</td>\n",
       "      <td>0.710238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.051500</td>\n",
       "      <td>1.722334</td>\n",
       "      <td>0.681720</td>\n",
       "      <td>0.704374</td>\n",
       "      <td>0.745006</td>\n",
       "      <td>0.681720</td>\n",
       "      <td>0.693663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>1.706122</td>\n",
       "      <td>0.692473</td>\n",
       "      <td>0.700675</td>\n",
       "      <td>0.738883</td>\n",
       "      <td>0.692473</td>\n",
       "      <td>0.703341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.025400</td>\n",
       "      <td>1.686355</td>\n",
       "      <td>0.705376</td>\n",
       "      <td>0.694704</td>\n",
       "      <td>0.732679</td>\n",
       "      <td>0.705376</td>\n",
       "      <td>0.713685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.035700</td>\n",
       "      <td>2.159881</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.682113</td>\n",
       "      <td>0.723377</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.688749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.071400</td>\n",
       "      <td>2.080061</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.685813</td>\n",
       "      <td>0.729126</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.679157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.032600</td>\n",
       "      <td>2.042073</td>\n",
       "      <td>0.716129</td>\n",
       "      <td>0.708236</td>\n",
       "      <td>0.743809</td>\n",
       "      <td>0.716129</td>\n",
       "      <td>0.724258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>1.981901</td>\n",
       "      <td>0.707527</td>\n",
       "      <td>0.703920</td>\n",
       "      <td>0.740352</td>\n",
       "      <td>0.707527</td>\n",
       "      <td>0.716601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.012600</td>\n",
       "      <td>1.991923</td>\n",
       "      <td>0.729032</td>\n",
       "      <td>0.715667</td>\n",
       "      <td>0.750175</td>\n",
       "      <td>0.729032</td>\n",
       "      <td>0.735762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>2.109069</td>\n",
       "      <td>0.726882</td>\n",
       "      <td>0.716024</td>\n",
       "      <td>0.750322</td>\n",
       "      <td>0.726882</td>\n",
       "      <td>0.734077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.190023</td>\n",
       "      <td>0.726882</td>\n",
       "      <td>0.714110</td>\n",
       "      <td>0.748836</td>\n",
       "      <td>0.726882</td>\n",
       "      <td>0.733805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.227813</td>\n",
       "      <td>0.726882</td>\n",
       "      <td>0.714110</td>\n",
       "      <td>0.748836</td>\n",
       "      <td>0.726882</td>\n",
       "      <td>0.733805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.242782</td>\n",
       "      <td>0.726882</td>\n",
       "      <td>0.714110</td>\n",
       "      <td>0.748836</td>\n",
       "      <td>0.726882</td>\n",
       "      <td>0.733805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.1_deberta_docnli/checkpoint-51\n",
      "Configuration saved in /home/elson/5.1.1_deberta_docnli/checkpoint-51/config.json\n",
      "Model weights saved in /home/elson/5.1.1_deberta_docnli/checkpoint-51/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.1_deberta_docnli/checkpoint-102\n",
      "Configuration saved in /home/elson/5.1.1_deberta_docnli/checkpoint-102/config.json\n",
      "Model weights saved in /home/elson/5.1.1_deberta_docnli/checkpoint-102/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.1_deberta_docnli/checkpoint-51] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.1_deberta_docnli/checkpoint-153\n",
      "Configuration saved in /home/elson/5.1.1_deberta_docnli/checkpoint-153/config.json\n",
      "Model weights saved in /home/elson/5.1.1_deberta_docnli/checkpoint-153/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.1_deberta_docnli/checkpoint-102] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.1_deberta_docnli/checkpoint-204\n",
      "Configuration saved in /home/elson/5.1.1_deberta_docnli/checkpoint-204/config.json\n",
      "Model weights saved in /home/elson/5.1.1_deberta_docnli/checkpoint-204/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.1_deberta_docnli/checkpoint-153] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.1_deberta_docnli/checkpoint-255\n",
      "Configuration saved in /home/elson/5.1.1_deberta_docnli/checkpoint-255/config.json\n",
      "Model weights saved in /home/elson/5.1.1_deberta_docnli/checkpoint-255/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.1_deberta_docnli/checkpoint-306\n",
      "Configuration saved in /home/elson/5.1.1_deberta_docnli/checkpoint-306/config.json\n",
      "Model weights saved in /home/elson/5.1.1_deberta_docnli/checkpoint-306/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.1_deberta_docnli/checkpoint-255] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.1_deberta_docnli/checkpoint-357\n",
      "Configuration saved in /home/elson/5.1.1_deberta_docnli/checkpoint-357/config.json\n",
      "Model weights saved in /home/elson/5.1.1_deberta_docnli/checkpoint-357/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.1_deberta_docnli/checkpoint-306] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.1_deberta_docnli/checkpoint-408\n",
      "Configuration saved in /home/elson/5.1.1_deberta_docnli/checkpoint-408/config.json\n",
      "Model weights saved in /home/elson/5.1.1_deberta_docnli/checkpoint-408/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.1_deberta_docnli/checkpoint-357] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.1_deberta_docnli/checkpoint-459\n",
      "Configuration saved in /home/elson/5.1.1_deberta_docnli/checkpoint-459/config.json\n",
      "Model weights saved in /home/elson/5.1.1_deberta_docnli/checkpoint-459/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.1_deberta_docnli/checkpoint-408] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.1_deberta_docnli/checkpoint-510\n",
      "Configuration saved in /home/elson/5.1.1_deberta_docnli/checkpoint-510/config.json\n",
      "Model weights saved in /home/elson/5.1.1_deberta_docnli/checkpoint-510/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.1_deberta_docnli/checkpoint-459] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.1_deberta_docnli/checkpoint-561\n",
      "Configuration saved in /home/elson/5.1.1_deberta_docnli/checkpoint-561/config.json\n",
      "Model weights saved in /home/elson/5.1.1_deberta_docnli/checkpoint-561/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.1_deberta_docnli/checkpoint-510] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.1_deberta_docnli/checkpoint-612\n",
      "Configuration saved in /home/elson/5.1.1_deberta_docnli/checkpoint-612/config.json\n",
      "Model weights saved in /home/elson/5.1.1_deberta_docnli/checkpoint-612/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.1_deberta_docnli/checkpoint-561] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.1_deberta_docnli/checkpoint-663\n",
      "Configuration saved in /home/elson/5.1.1_deberta_docnli/checkpoint-663/config.json\n",
      "Model weights saved in /home/elson/5.1.1_deberta_docnli/checkpoint-663/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.1_deberta_docnli/checkpoint-612] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.1_deberta_docnli/checkpoint-714\n",
      "Configuration saved in /home/elson/5.1.1_deberta_docnli/checkpoint-714/config.json\n",
      "Model weights saved in /home/elson/5.1.1_deberta_docnli/checkpoint-714/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.1_deberta_docnli/checkpoint-663] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.1_deberta_docnli/checkpoint-765\n",
      "Configuration saved in /home/elson/5.1.1_deberta_docnli/checkpoint-765/config.json\n",
      "Model weights saved in /home/elson/5.1.1_deberta_docnli/checkpoint-765/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.1_deberta_docnli/checkpoint-714] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.1_deberta_docnli/checkpoint-816\n",
      "Configuration saved in /home/elson/5.1.1_deberta_docnli/checkpoint-816/config.json\n",
      "Model weights saved in /home/elson/5.1.1_deberta_docnli/checkpoint-816/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.1_deberta_docnli/checkpoint-765] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.1_deberta_docnli/checkpoint-867\n",
      "Configuration saved in /home/elson/5.1.1_deberta_docnli/checkpoint-867/config.json\n",
      "Model weights saved in /home/elson/5.1.1_deberta_docnli/checkpoint-867/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.1_deberta_docnli/checkpoint-816] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.1_deberta_docnli/checkpoint-918\n",
      "Configuration saved in /home/elson/5.1.1_deberta_docnli/checkpoint-918/config.json\n",
      "Model weights saved in /home/elson/5.1.1_deberta_docnli/checkpoint-918/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.1_deberta_docnli/checkpoint-867] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.1_deberta_docnli/checkpoint-969\n",
      "Configuration saved in /home/elson/5.1.1_deberta_docnli/checkpoint-969/config.json\n",
      "Model weights saved in /home/elson/5.1.1_deberta_docnli/checkpoint-969/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.1_deberta_docnli/checkpoint-918] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.1_deberta_docnli/checkpoint-1020\n",
      "Configuration saved in /home/elson/5.1.1_deberta_docnli/checkpoint-1020/config.json\n",
      "Model weights saved in /home/elson/5.1.1_deberta_docnli/checkpoint-1020/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.1_deberta_docnli/checkpoint-969] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/elson/5.1.1_deberta_docnli/checkpoint-204 (score: 0.7419354838709677).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /home/elson/5.1.1_deberta_docnli/best_model/config.json\n",
      "Model weights saved in /home/elson/5.1.1_deberta_docnli/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/5.1.1_deberta_docnli/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/5.1.1_deberta_docnli/best_model/special_tokens_map.json\n",
      "added tokens file saved in /home/elson/5.1.1_deberta_docnli/best_model/added_tokens.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/5.1.1_deberta_docnli/best_model/tokenizer_config.json',\n",
       " '/home/elson/5.1.1_deberta_docnli/best_model/special_tokens_map.json',\n",
       " '/home/elson/5.1.1_deberta_docnli/best_model/spm.model',\n",
       " '/home/elson/5.1.1_deberta_docnli/best_model/added_tokens.json')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/5.4.1_deberta_docnli/',\n",
    "    num_train_epochs=20,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.6,\n",
    "    weight_decay=0.1,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/5.4.1_deberta_docnli/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/5.4.1_deberta_docnli/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63deaea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/5.1.1_deberta_docnli/best_model/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"/home/elson/5.1.1_deberta_docnli/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"entailment\",\n",
      "    \"1\": \"not_entailment\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"entailment\": 0,\n",
      "    \"not_entailment\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file /home/elson/5.1.1_deberta_docnli/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at /home/elson/5.1.1_deberta_docnli/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 32\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/5.1.1_deberta_docnli/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[ 1.251   , -1.207   ],\n",
      "       [ 1.272   , -1.237   ],\n",
      "       [ 2.746   , -2.645   ],\n",
      "       [-1.23    ,  1.46    ],\n",
      "       [ 1.003   , -0.972   ],\n",
      "       [ 2.096   , -2.037   ],\n",
      "       [ 1.5205  , -1.481   ],\n",
      "       [ 1.847   , -1.794   ],\n",
      "       [ 0.9097  , -0.8726  ],\n",
      "       [ 2.53    , -2.447   ],\n",
      "       [ 2.264   , -2.191   ],\n",
      "       [ 2.395   , -2.316   ],\n",
      "       [-0.4697  ,  0.5337  ],\n",
      "       [ 1.698   , -1.653   ],\n",
      "       [ 0.523   , -0.4958  ],\n",
      "       [-0.893   ,  1.031   ],\n",
      "       [ 1.017   , -0.987   ],\n",
      "       [ 1.874   , -1.823   ],\n",
      "       [ 2.91    , -2.803   ],\n",
      "       [ 2.008   , -1.952   ],\n",
      "       [-1.135   ,  1.358   ],\n",
      "       [ 2.275   , -2.203   ],\n",
      "       [ 1.85    , -1.798   ],\n",
      "       [-1.716   ,  1.989   ],\n",
      "       [ 0.858   , -0.8154  ],\n",
      "       [-2.732   ,  3.002   ],\n",
      "       [ 2.871   , -2.77    ],\n",
      "       [ 1.083   , -1.051   ],\n",
      "       [ 1.887   , -1.833   ],\n",
      "       [ 2.514   , -2.432   ],\n",
      "       [-1.244   ,  1.486   ],\n",
      "       [ 1.843   , -1.794   ],\n",
      "       [ 2.518   , -2.436   ],\n",
      "       [ 0.944   , -0.9023  ],\n",
      "       [-1.39    ,  1.643   ],\n",
      "       [-0.7773  ,  0.899   ],\n",
      "       [-1.061   ,  1.247   ],\n",
      "       [ 1.755   , -1.713   ],\n",
      "       [-1.743   ,  2.008   ],\n",
      "       [-1.039   ,  1.24    ],\n",
      "       [ 1.202   , -1.166   ],\n",
      "       [ 2.443   , -2.37    ],\n",
      "       [ 1.177   , -1.142   ],\n",
      "       [-1.781   ,  2.049   ],\n",
      "       [-1.554   ,  1.808   ],\n",
      "       [ 2.764   , -2.666   ],\n",
      "       [ 0.2742  , -0.2482  ],\n",
      "       [ 2.85    , -2.75    ],\n",
      "       [ 3.102   , -2.986   ],\n",
      "       [-1.384   ,  1.635   ],\n",
      "       [-1.314   ,  1.569   ],\n",
      "       [ 1.329   , -1.282   ],\n",
      "       [ 1.398   , -1.352   ],\n",
      "       [ 1.957   , -1.901   ],\n",
      "       [-1.58    ,  1.853   ],\n",
      "       [ 2.344   , -2.273   ],\n",
      "       [-1.34    ,  1.592   ],\n",
      "       [ 1.843   , -1.795   ],\n",
      "       [ 2.166   , -2.105   ],\n",
      "       [ 1.225   , -1.191   ],\n",
      "       [ 0.5557  , -0.519   ],\n",
      "       [-1.242   ,  1.472   ],\n",
      "       [ 2.078   , -2.016   ],\n",
      "       [ 1.186   , -1.15    ],\n",
      "       [ 0.8555  , -0.8115  ],\n",
      "       [ 1.817   , -1.768   ],\n",
      "       [ 2.012   , -1.956   ],\n",
      "       [ 1.651   , -1.607   ],\n",
      "       [ 1.763   , -1.71    ],\n",
      "       [ 0.7705  , -0.7363  ],\n",
      "       [ 1.997   , -1.9375  ],\n",
      "       [-0.06088 ,  0.0834  ],\n",
      "       [ 0.918   , -0.8813  ],\n",
      "       [-0.9473  ,  1.111   ],\n",
      "       [ 1.263   , -1.223   ],\n",
      "       [ 1.907   , -1.852   ],\n",
      "       [ 1.989   , -1.927   ],\n",
      "       [ 1.512   , -1.475   ],\n",
      "       [ 2.525   , -2.441   ],\n",
      "       [ 1.324   , -1.282   ],\n",
      "       [ 1.773   , -1.725   ],\n",
      "       [ 2.695   , -2.604   ],\n",
      "       [-0.4338  ,  0.4817  ],\n",
      "       [ 2.285   , -2.215   ],\n",
      "       [ 2.473   , -2.395   ],\n",
      "       [-1.401   ,  1.662   ],\n",
      "       [ 2.066   , -2.002   ],\n",
      "       [-0.1744  ,  0.2047  ],\n",
      "       [ 2.232   , -2.166   ],\n",
      "       [ 1.987   , -1.93    ],\n",
      "       [ 2.883   , -2.773   ],\n",
      "       [ 2.088   , -2.025   ],\n",
      "       [-0.865   ,  1.      ],\n",
      "       [ 2.693   , -2.604   ],\n",
      "       [ 1.889   , -1.836   ],\n",
      "       [ 1.109   , -1.074   ],\n",
      "       [-1.734   ,  2.014   ],\n",
      "       [ 1.613   , -1.569   ],\n",
      "       [ 2.443   , -2.363   ],\n",
      "       [ 0.84    , -0.807   ],\n",
      "       [-0.83    ,  0.964   ],\n",
      "       [ 2.246   , -2.18    ],\n",
      "       [ 2.049   , -1.987   ],\n",
      "       [ 1.147   , -1.113   ],\n",
      "       [ 2.104   , -2.041   ],\n",
      "       [ 1.777   , -1.729   ],\n",
      "       [ 2.002   , -1.942   ],\n",
      "       [-1.443   ,  1.705   ],\n",
      "       [ 1.483   , -1.441   ],\n",
      "       [ 2.012   , -1.952   ],\n",
      "       [ 1.501   , -1.464   ],\n",
      "       [ 2.264   , -2.191   ],\n",
      "       [ 2.357   , -2.281   ],\n",
      "       [ 2.295   , -2.219   ],\n",
      "       [ 1.73    , -1.692   ],\n",
      "       [ 1.998   , -1.941   ],\n",
      "       [ 2.494   , -2.414   ],\n",
      "       [ 2.008   , -1.95    ],\n",
      "       [ 2.242   , -2.172   ],\n",
      "       [ 1.755   , -1.708   ],\n",
      "       [ 1.91    , -1.858   ],\n",
      "       [ 2.613   , -2.525   ],\n",
      "       [ 1.915   , -1.864   ],\n",
      "       [ 0.331   , -0.299   ],\n",
      "       [ 2.76    , -2.662   ],\n",
      "       [ 2.146   , -2.086   ],\n",
      "       [-0.2246  ,  0.2732  ],\n",
      "       [ 2.021   , -1.966   ],\n",
      "       [ 1.921   , -1.864   ],\n",
      "       [-0.9297  ,  1.103   ],\n",
      "       [-0.863   ,  1.      ],\n",
      "       [-1.197   ,  1.427   ],\n",
      "       [ 1.612   , -1.574   ],\n",
      "       [-1.218   ,  1.451   ],\n",
      "       [ 1.85    , -1.799   ],\n",
      "       [-1.816   ,  2.094   ],\n",
      "       [ 1.178   , -1.132   ],\n",
      "       [-1.737   ,  2.012   ],\n",
      "       [-1.3955  ,  1.655   ],\n",
      "       [ 1.995   , -1.937   ],\n",
      "       [ 2.812   , -2.713   ],\n",
      "       [-1.079   ,  1.284   ],\n",
      "       [ 0.7964  , -0.7515  ],\n",
      "       [ 2.947   , -2.84    ],\n",
      "       [-0.7983  ,  0.9185  ],\n",
      "       [-0.71    ,  0.801   ],\n",
      "       [ 1.201   , -1.161   ],\n",
      "       [-1.208   ,  1.443   ],\n",
      "       [ 1.312   , -1.274   ],\n",
      "       [-1.698   ,  1.957   ],\n",
      "       [-0.8965  ,  1.047   ],\n",
      "       [ 2.86    , -2.752   ],\n",
      "       [ 1.891   , -1.845   ],\n",
      "       [ 1.389   , -1.353   ],\n",
      "       [ 1.989   , -1.932   ],\n",
      "       [ 2.734   , -2.639   ],\n",
      "       [ 1.938   , -1.88    ],\n",
      "       [-2.3     ,  2.594   ],\n",
      "       [-1.207   ,  1.4375  ],\n",
      "       [-1.274   ,  1.491   ],\n",
      "       [-2.791   ,  3.064   ],\n",
      "       [-1.964   ,  2.236   ],\n",
      "       [ 1.127   , -1.1     ],\n",
      "       [ 0.4563  , -0.4255  ],\n",
      "       [ 0.951   , -0.92    ],\n",
      "       [-1.158   ,  1.392   ],\n",
      "       [ 2.027   , -1.968   ],\n",
      "       [-1.1045  ,  1.31    ],\n",
      "       [-0.8125  ,  0.928   ],\n",
      "       [ 2.33    , -2.252   ],\n",
      "       [-2.998   ,  3.275   ],\n",
      "       [ 1.497   , -1.451   ],\n",
      "       [ 1.053   , -1.02    ],\n",
      "       [ 2.623   , -2.533   ],\n",
      "       [ 2.477   , -2.398   ],\n",
      "       [-1.642   ,  1.916   ],\n",
      "       [ 2.574   , -2.486   ],\n",
      "       [-0.8486  ,  0.9717  ],\n",
      "       [ 1.102   , -1.071   ],\n",
      "       [ 1.127   , -1.084   ],\n",
      "       [-0.3936  ,  0.4268  ],\n",
      "       [ 1.317   , -1.283   ],\n",
      "       [-1.365   ,  1.608   ],\n",
      "       [ 0.2837  , -0.2328  ],\n",
      "       [-0.8774  ,  1.016   ],\n",
      "       [ 2.65    , -2.56    ],\n",
      "       [ 0.05176 , -0.003645],\n",
      "       [ 2.34    , -2.266   ],\n",
      "       [ 0.768   , -0.7383  ],\n",
      "       [ 2.436   , -2.357   ],\n",
      "       [ 0.02539 ,  0.013596],\n",
      "       [-0.474   ,  0.519   ],\n",
      "       [ 3.168   , -3.043   ],\n",
      "       [-1.228   ,  1.441   ],\n",
      "       [-1.636   ,  1.896   ],\n",
      "       [ 2.36    , -2.285   ],\n",
      "       [ 1.602   , -1.561   ],\n",
      "       [ 1.792   , -1.741   ],\n",
      "       [ 1.846   , -1.791   ],\n",
      "       [ 1.536   , -1.497   ],\n",
      "       [ 2.984   , -2.875   ],\n",
      "       [ 1.821   , -1.7705  ],\n",
      "       [ 0.983   , -0.94    ],\n",
      "       [ 2.023   , -1.964   ],\n",
      "       [-1.614   ,  1.88    ],\n",
      "       [-1.293   ,  1.537   ],\n",
      "       [ 1.683   , -1.64    ],\n",
      "       [-0.988   ,  1.154   ],\n",
      "       [ 2.307   , -2.234   ],\n",
      "       [ 1.72    , -1.674   ],\n",
      "       [ 1.154   , -1.115   ],\n",
      "       [ 1.512   , -1.475   ],\n",
      "       [ 1.439   , -1.404   ],\n",
      "       [ 1.088   , -1.051   ],\n",
      "       [ 1.718   , -1.674   ],\n",
      "       [-1.15    ,  1.364   ],\n",
      "       [-0.884   ,  1.03    ],\n",
      "       [-1.171   ,  1.393   ],\n",
      "       [ 1.869   , -1.817   ],\n",
      "       [ 2.346   , -2.271   ],\n",
      "       [ 2.5     , -2.42    ],\n",
      "       [ 3.04    , -2.926   ],\n",
      "       [-1.261   ,  1.506   ],\n",
      "       [ 2.324   , -2.25    ],\n",
      "       [ 1.284   , -1.253   ],\n",
      "       [ 1.874   , -1.82    ],\n",
      "       [ 2.316   , -2.246   ],\n",
      "       [-1.328   ,  1.577   ],\n",
      "       [ 1.325   , -1.287   ],\n",
      "       [ 0.7764  , -0.744   ],\n",
      "       [ 2.777   , -2.682   ],\n",
      "       [ 1.478   , -1.439   ],\n",
      "       [ 1.124   , -1.098   ],\n",
      "       [-1.211   ,  1.434   ]], dtype=float16), label_ids=array([0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
      "       0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
      "       0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1,\n",
      "       0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "       1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "       1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "       0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
      "       0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
      "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1]), metrics={'test_loss': 0.9360501766204834, 'test_accuracy': 0.7094017094017094, 'test_balanced_accuracy': 0.6633333333333333, 'test_precision': 0.7005578876592342, 'test_recall': 0.7094017094017094, 'test_f1': 0.701463981277439, 'test_runtime': 1.9611, 'test_samples_per_second': 119.319, 'test_steps_per_second': 4.079})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73395d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "probabilities = torch.softmax(torch.tensor(test_results.predictions).to(torch.float32), dim=-1)\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)\n",
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb603377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_save = []\n",
    "for idx in range(len(test_data)):\n",
    "    item = dataset['test'][idx]\n",
    "    actual_label = item['label']\n",
    "    predicted_label = predictions[idx]\n",
    "    claim = item['claim'] \n",
    "    premise = item['premise'] \n",
    "    category = item['category']\n",
    "    \n",
    "    # Append the information as a dictionary to the list\n",
    "    data_to_save.append({\n",
    "        'Claim': claim,\n",
    "        'Premise': premise,\n",
    "        'Actual Label': actual_label,\n",
    "        'Predicted Label': predicted_label,\n",
    "        'Category' : category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_to_save)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/home/elson/results/5.4.1_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c23339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correctly classified instances\n",
    "correctly_classified = df[df['Actual Label'] == df['Predicted Label']]\n",
    "\n",
    "# Calculate misclassified instances\n",
    "misclassified = df[df['Actual Label'] != df['Predicted Label']]\n",
    "\n",
    "# Count the number of correctly classified and misclassified by category\n",
    "correct_classification_counts = correctly_classified['Category'].value_counts()\n",
    "misclassification_counts = misclassified['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca0def77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           35\n",
       "Bone health              17\n",
       "Fitness                  13\n",
       "Cancer                   12\n",
       "Cardiovascular Health    10\n",
       "Hair                      9\n",
       "Neurological health       9\n",
       "Diabetes                  9\n",
       "Throat                    8\n",
       "Skin                      7\n",
       "Ear                       6\n",
       "COVID                     5\n",
       "Eye                       5\n",
       "Women' s Health           5\n",
       "Blood                     4\n",
       "Men's health              3\n",
       "Mental Health             3\n",
       "Vascular                  3\n",
       "Muscles                   3\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0fddd944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Skin                     17\n",
       "General Health           16\n",
       "Blood                     5\n",
       "Eye                       4\n",
       "Bone health               4\n",
       "Hair                      3\n",
       "Muscles                   3\n",
       "Dental Health             3\n",
       "Men's health              3\n",
       "Diabetes                  3\n",
       "Cardiovascular Health     2\n",
       "Fitness                   2\n",
       "COVID                     1\n",
       "Women' s Health           1\n",
       "Throat                    1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38b899b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_counts = df['Category'].value_counts()\n",
    "\n",
    "# Calculate ratios\n",
    "correct_classification_ratios = correct_classification_counts / total_counts\n",
    "misclassification_ratios = misclassification_counts / total_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c3598b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blood                    0.444444\n",
      "Bone health              0.809524\n",
      "COVID                    0.833333\n",
      "Cancer                   1.000000\n",
      "Cardiovascular Health    0.833333\n",
      "Dental Health                 NaN\n",
      "Diabetes                 0.750000\n",
      "Ear                      1.000000\n",
      "Eye                      0.555556\n",
      "Fitness                  0.866667\n",
      "General Health           0.686275\n",
      "Hair                     0.750000\n",
      "Men's health             0.500000\n",
      "Mental Health            1.000000\n",
      "Muscles                  0.500000\n",
      "Neurological health      1.000000\n",
      "Skin                     0.291667\n",
      "Throat                   0.888889\n",
      "Vascular                 1.000000\n",
      "Women' s Health          0.833333\n",
      "Name: Category, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(correct_classification_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27602a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blood                    0.555556\n",
      "Bone health              0.190476\n",
      "COVID                    0.166667\n",
      "Cancer                        NaN\n",
      "Cardiovascular Health    0.166667\n",
      "Dental Health            1.000000\n",
      "Diabetes                 0.250000\n",
      "Ear                           NaN\n",
      "Eye                      0.444444\n",
      "Fitness                  0.133333\n",
      "General Health           0.313725\n",
      "Hair                     0.250000\n",
      "Men's health             0.500000\n",
      "Mental Health                 NaN\n",
      "Muscles                  0.500000\n",
      "Neurological health           NaN\n",
      "Skin                     0.708333\n",
      "Throat                   0.111111\n",
      "Vascular                      NaN\n",
      "Women' s Health          0.166667\n",
      "Name: Category, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(misclassification_ratios)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
