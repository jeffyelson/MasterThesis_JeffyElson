{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-022bc67e9c58e92d\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 212.28it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('csv',data_files='dataset_propositionattribution_nerfeatures.csv',delimiter=',',column_names=[\"claim\",\"premise\",\"label\",\"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\",\"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\",\"url\", \"entities\",\"entity_map\",\"entity_map_ev\",\"entities_ev\",\"gem_exp\",\"gem_label\",\"gpt_label\",\"gpt_exp\",\"gold_exp\",\"synonym\",\"voice\",\"split\"],skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e2914c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'entity_map_ev', 'entities_ev', 'gem_exp', 'gem_label', 'gpt_label', 'gpt_exp', 'gold_exp', 'synonym', 'voice', 'split'],\n",
       "        num_rows: 2322\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57d56e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'test',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['split']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ce96b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-2b8e361375c0e153.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-0cc9bb699c2761fb.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-608a44ac65076739.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'entity_map_ev', 'entities_ev', 'gem_exp', 'gem_label', 'gpt_label', 'gpt_exp', 'gold_exp', 'synonym', 'voice', 'split'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'entity_map_ev', 'entities_ev', 'gem_exp', 'gem_label', 'gpt_label', 'gpt_exp', 'gold_exp', 'synonym', 'voice', 'split'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'entity_map_ev', 'entities_ev', 'gem_exp', 'gem_label', 'gpt_label', 'gpt_exp', 'gold_exp', 'synonym', 'voice', 'split'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41f1db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\"claim\", \"premise\", \"label\",\"category\"]\n",
    "all_columns = dataset[\"train\"].column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1623/1623 [00:00<00:00, 7271.25ex/s]\n",
      "100%|██████████| 465/465 [00:00<00:00, 7518.62ex/s]\n",
      "100%|██████████| 234/234 [00:00<00:00, 7283.51ex/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 1, 'entailment': 0, 'neutral': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 1,\n",
    "    \"entailment\": 0,\n",
    "    \"neutral\": 1\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='MoritzLaurer/DeBERTa-v3-base-mnli-fever-docnli-ling-2c'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "        # Extracting claim and evidence texts\n",
    "\n",
    "        claim = item['claim'].lower()\n",
    "        premise = item['premise'].lower().replace('\\n', '')\n",
    "        item['claim']=claim\n",
    "        item['premise']=premise\n",
    "        \n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "            premise,claim,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "        item['input_ids'] = inputs['input_ids'].squeeze()  # Remove batch dimension\n",
    "        item['attention_mask']= inputs['attention_mask'].squeeze() # Remove batch dimension\n",
    "        \n",
    "        if 'label' in item:\n",
    "            item['labels'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62421eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DebertaV2ForSequenceClassification(\n",
       "  (deberta): DebertaV2Model(\n",
       "    (embeddings): DebertaV2Embeddings(\n",
       "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaV2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (1): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (2): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (3): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (4): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (5): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (6): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (7): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (8): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (9): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (10): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (11): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (pooler): ContextPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): StableDropout()\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): StableDropout()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"MoritzLaurer/DeBERTa-v3-base-mnli-fever-docnli-ling-2c\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=2, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    bal_accuracy = balanced_accuracy_score(labels,preds)\n",
    "\n",
    "    return {\"accuracy\": acc, \"balanced_accuracy\":bal_accuracy, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17c5e0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'claim': 'myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.',\n",
       " 'premise': 'the essential oils of frankincense and myrrh increase the fluidity of the lipid bilayer in the cuticle and change the orderly and dense structure to increase the permeability of the skin and decrease the barrier effect.',\n",
       " 'label': 0,\n",
       " 'category': 'General Health',\n",
       " 'input_ids': tensor([    1,   262,  1830,  6725,   265, 88609,   263, 98237,   993,   262,\n",
       "         49462,   265,   262, 22003, 96579,   267,   262, 61462,   263,   575,\n",
       "           262, 26217,   263,  9854,  1730,   264,   993,   262, 39632,   265,\n",
       "           262,  1158,   263,  4843,   262,  7275,  1290,   260,     2, 98237,\n",
       "          1830,  1080,   269,  1359,   427,   267, 17847,   633,   264,   408,\n",
       "          1300,   262,  2658,   265,   262,  1158,   260,     2,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'labels': tensor(0)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1020\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1020' max='1020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1020/1020 15:15, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.143000</td>\n",
       "      <td>1.302445</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.695152</td>\n",
       "      <td>0.733713</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.661067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.578400</td>\n",
       "      <td>0.681253</td>\n",
       "      <td>0.701075</td>\n",
       "      <td>0.705606</td>\n",
       "      <td>0.727038</td>\n",
       "      <td>0.701075</td>\n",
       "      <td>0.707006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.393800</td>\n",
       "      <td>0.628195</td>\n",
       "      <td>0.713978</td>\n",
       "      <td>0.719697</td>\n",
       "      <td>0.739709</td>\n",
       "      <td>0.713978</td>\n",
       "      <td>0.719653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.258100</td>\n",
       "      <td>0.660916</td>\n",
       "      <td>0.737634</td>\n",
       "      <td>0.725758</td>\n",
       "      <td>0.745303</td>\n",
       "      <td>0.737634</td>\n",
       "      <td>0.740363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.252200</td>\n",
       "      <td>0.903436</td>\n",
       "      <td>0.673118</td>\n",
       "      <td>0.696212</td>\n",
       "      <td>0.724545</td>\n",
       "      <td>0.673118</td>\n",
       "      <td>0.679942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.187700</td>\n",
       "      <td>0.836937</td>\n",
       "      <td>0.716129</td>\n",
       "      <td>0.717273</td>\n",
       "      <td>0.736997</td>\n",
       "      <td>0.716129</td>\n",
       "      <td>0.721335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.142800</td>\n",
       "      <td>1.150205</td>\n",
       "      <td>0.698925</td>\n",
       "      <td>0.709394</td>\n",
       "      <td>0.731598</td>\n",
       "      <td>0.698925</td>\n",
       "      <td>0.705268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.103100</td>\n",
       "      <td>1.196138</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.684242</td>\n",
       "      <td>0.708985</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.682139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.111000</td>\n",
       "      <td>1.482779</td>\n",
       "      <td>0.698925</td>\n",
       "      <td>0.706667</td>\n",
       "      <td>0.728557</td>\n",
       "      <td>0.698925</td>\n",
       "      <td>0.705132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.079200</td>\n",
       "      <td>1.298126</td>\n",
       "      <td>0.707527</td>\n",
       "      <td>0.701061</td>\n",
       "      <td>0.722323</td>\n",
       "      <td>0.707527</td>\n",
       "      <td>0.712017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.067700</td>\n",
       "      <td>1.191695</td>\n",
       "      <td>0.707527</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.709172</td>\n",
       "      <td>0.707527</td>\n",
       "      <td>0.708297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.110600</td>\n",
       "      <td>1.170825</td>\n",
       "      <td>0.679570</td>\n",
       "      <td>0.684848</td>\n",
       "      <td>0.708763</td>\n",
       "      <td>0.679570</td>\n",
       "      <td>0.686133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.062700</td>\n",
       "      <td>1.364763</td>\n",
       "      <td>0.696774</td>\n",
       "      <td>0.684545</td>\n",
       "      <td>0.707813</td>\n",
       "      <td>0.696774</td>\n",
       "      <td>0.700609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.055900</td>\n",
       "      <td>1.136590</td>\n",
       "      <td>0.716129</td>\n",
       "      <td>0.709091</td>\n",
       "      <td>0.729577</td>\n",
       "      <td>0.716129</td>\n",
       "      <td>0.720282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.048300</td>\n",
       "      <td>1.783934</td>\n",
       "      <td>0.698925</td>\n",
       "      <td>0.705303</td>\n",
       "      <td>0.727082</td>\n",
       "      <td>0.698925</td>\n",
       "      <td>0.705047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>1.872134</td>\n",
       "      <td>0.718280</td>\n",
       "      <td>0.694394</td>\n",
       "      <td>0.719462</td>\n",
       "      <td>0.718280</td>\n",
       "      <td>0.718841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>1.856010</td>\n",
       "      <td>0.692473</td>\n",
       "      <td>0.686667</td>\n",
       "      <td>0.709396</td>\n",
       "      <td>0.692473</td>\n",
       "      <td>0.697502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>2.015865</td>\n",
       "      <td>0.701075</td>\n",
       "      <td>0.690606</td>\n",
       "      <td>0.713135</td>\n",
       "      <td>0.701075</td>\n",
       "      <td>0.705102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>2.058934</td>\n",
       "      <td>0.694624</td>\n",
       "      <td>0.692424</td>\n",
       "      <td>0.714635</td>\n",
       "      <td>0.694624</td>\n",
       "      <td>0.700066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>2.081129</td>\n",
       "      <td>0.696774</td>\n",
       "      <td>0.692727</td>\n",
       "      <td>0.714839</td>\n",
       "      <td>0.696774</td>\n",
       "      <td>0.701920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.1_deberta_docnli/checkpoint-51\n",
      "Configuration saved in /home/elson/5.4.1_deberta_docnli/checkpoint-51/config.json\n",
      "Model weights saved in /home/elson/5.4.1_deberta_docnli/checkpoint-51/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.1_deberta_docnli/checkpoint-102\n",
      "Configuration saved in /home/elson/5.4.1_deberta_docnli/checkpoint-102/config.json\n",
      "Model weights saved in /home/elson/5.4.1_deberta_docnli/checkpoint-102/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.4.1_deberta_docnli/checkpoint-51] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.1_deberta_docnli/checkpoint-153\n",
      "Configuration saved in /home/elson/5.4.1_deberta_docnli/checkpoint-153/config.json\n",
      "Model weights saved in /home/elson/5.4.1_deberta_docnli/checkpoint-153/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.4.1_deberta_docnli/checkpoint-102] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.1_deberta_docnli/checkpoint-204\n",
      "Configuration saved in /home/elson/5.4.1_deberta_docnli/checkpoint-204/config.json\n",
      "Model weights saved in /home/elson/5.4.1_deberta_docnli/checkpoint-204/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.4.1_deberta_docnli/checkpoint-153] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.1_deberta_docnli/checkpoint-255\n",
      "Configuration saved in /home/elson/5.4.1_deberta_docnli/checkpoint-255/config.json\n",
      "Model weights saved in /home/elson/5.4.1_deberta_docnli/checkpoint-255/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.1_deberta_docnli/checkpoint-306\n",
      "Configuration saved in /home/elson/5.4.1_deberta_docnli/checkpoint-306/config.json\n",
      "Model weights saved in /home/elson/5.4.1_deberta_docnli/checkpoint-306/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.4.1_deberta_docnli/checkpoint-255] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.1_deberta_docnli/checkpoint-357\n",
      "Configuration saved in /home/elson/5.4.1_deberta_docnli/checkpoint-357/config.json\n",
      "Model weights saved in /home/elson/5.4.1_deberta_docnli/checkpoint-357/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.4.1_deberta_docnli/checkpoint-306] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.1_deberta_docnli/checkpoint-408\n",
      "Configuration saved in /home/elson/5.4.1_deberta_docnli/checkpoint-408/config.json\n",
      "Model weights saved in /home/elson/5.4.1_deberta_docnli/checkpoint-408/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.4.1_deberta_docnli/checkpoint-357] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.1_deberta_docnli/checkpoint-459\n",
      "Configuration saved in /home/elson/5.4.1_deberta_docnli/checkpoint-459/config.json\n",
      "Model weights saved in /home/elson/5.4.1_deberta_docnli/checkpoint-459/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.4.1_deberta_docnli/checkpoint-408] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.1_deberta_docnli/checkpoint-510\n",
      "Configuration saved in /home/elson/5.4.1_deberta_docnli/checkpoint-510/config.json\n",
      "Model weights saved in /home/elson/5.4.1_deberta_docnli/checkpoint-510/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.4.1_deberta_docnli/checkpoint-459] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.1_deberta_docnli/checkpoint-561\n",
      "Configuration saved in /home/elson/5.4.1_deberta_docnli/checkpoint-561/config.json\n",
      "Model weights saved in /home/elson/5.4.1_deberta_docnli/checkpoint-561/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.4.1_deberta_docnli/checkpoint-510] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.1_deberta_docnli/checkpoint-612\n",
      "Configuration saved in /home/elson/5.4.1_deberta_docnli/checkpoint-612/config.json\n",
      "Model weights saved in /home/elson/5.4.1_deberta_docnli/checkpoint-612/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.4.1_deberta_docnli/checkpoint-561] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.1_deberta_docnli/checkpoint-663\n",
      "Configuration saved in /home/elson/5.4.1_deberta_docnli/checkpoint-663/config.json\n",
      "Model weights saved in /home/elson/5.4.1_deberta_docnli/checkpoint-663/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.4.1_deberta_docnli/checkpoint-612] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.1_deberta_docnli/checkpoint-714\n",
      "Configuration saved in /home/elson/5.4.1_deberta_docnli/checkpoint-714/config.json\n",
      "Model weights saved in /home/elson/5.4.1_deberta_docnli/checkpoint-714/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.4.1_deberta_docnli/checkpoint-663] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.1_deberta_docnli/checkpoint-765\n",
      "Configuration saved in /home/elson/5.4.1_deberta_docnli/checkpoint-765/config.json\n",
      "Model weights saved in /home/elson/5.4.1_deberta_docnli/checkpoint-765/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.4.1_deberta_docnli/checkpoint-714] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.1_deberta_docnli/checkpoint-816\n",
      "Configuration saved in /home/elson/5.4.1_deberta_docnli/checkpoint-816/config.json\n",
      "Model weights saved in /home/elson/5.4.1_deberta_docnli/checkpoint-816/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.4.1_deberta_docnli/checkpoint-765] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.1_deberta_docnli/checkpoint-867\n",
      "Configuration saved in /home/elson/5.4.1_deberta_docnli/checkpoint-867/config.json\n",
      "Model weights saved in /home/elson/5.4.1_deberta_docnli/checkpoint-867/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.4.1_deberta_docnli/checkpoint-816] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.1_deberta_docnli/checkpoint-918\n",
      "Configuration saved in /home/elson/5.4.1_deberta_docnli/checkpoint-918/config.json\n",
      "Model weights saved in /home/elson/5.4.1_deberta_docnli/checkpoint-918/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.4.1_deberta_docnli/checkpoint-867] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.1_deberta_docnli/checkpoint-969\n",
      "Configuration saved in /home/elson/5.4.1_deberta_docnli/checkpoint-969/config.json\n",
      "Model weights saved in /home/elson/5.4.1_deberta_docnli/checkpoint-969/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.4.1_deberta_docnli/checkpoint-918] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.1_deberta_docnli/checkpoint-1020\n",
      "Configuration saved in /home/elson/5.4.1_deberta_docnli/checkpoint-1020/config.json\n",
      "Model weights saved in /home/elson/5.4.1_deberta_docnli/checkpoint-1020/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.4.1_deberta_docnli/checkpoint-969] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/elson/5.4.1_deberta_docnli/checkpoint-204 (score: 0.7376344086021506).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /home/elson/5.4.1_deberta_docnli/best_model/config.json\n",
      "Model weights saved in /home/elson/5.4.1_deberta_docnli/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/5.4.1_deberta_docnli/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/5.4.1_deberta_docnli/best_model/special_tokens_map.json\n",
      "added tokens file saved in /home/elson/5.4.1_deberta_docnli/best_model/added_tokens.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/5.4.1_deberta_docnli/best_model/tokenizer_config.json',\n",
       " '/home/elson/5.4.1_deberta_docnli/best_model/special_tokens_map.json',\n",
       " '/home/elson/5.4.1_deberta_docnli/best_model/spm.model',\n",
       " '/home/elson/5.4.1_deberta_docnli/best_model/added_tokens.json')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/5.4.1_deberta_docnli/',\n",
    "    num_train_epochs=20,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.6,\n",
    "    weight_decay=0.1,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/5.4.1_deberta_docnli/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/5.4.1_deberta_docnli/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63deaea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/5.4.1_deberta_docnli/best_model/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"/home/elson/5.4.1_deberta_docnli/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"entailment\",\n",
      "    \"1\": \"not_entailment\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"entailment\": 0,\n",
      "    \"not_entailment\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file /home/elson/5.4.1_deberta_docnli/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at /home/elson/5.4.1_deberta_docnli/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 32\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/5.4.1_deberta_docnli/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[ 0.618  , -0.6025 ],\n",
      "       [ 1.395  , -1.363  ],\n",
      "       [ 1.927  , -1.875  ],\n",
      "       [-1.033  ,  1.253  ],\n",
      "       [ 1.468  , -1.434  ],\n",
      "       [ 2.11   , -2.055  ],\n",
      "       [ 0.571  , -0.5513 ],\n",
      "       [ 1.676  , -1.634  ],\n",
      "       [-0.6963 ,  0.792  ],\n",
      "       [ 1.607  , -1.566  ],\n",
      "       [ 1.785  , -1.737  ],\n",
      "       [ 2.506  , -2.426  ],\n",
      "       [ 0.6987 , -0.6777 ],\n",
      "       [ 1.869  , -1.822  ],\n",
      "       [ 1.282  , -1.254  ],\n",
      "       [-0.903  ,  1.081  ],\n",
      "       [ 1.138  , -1.117  ],\n",
      "       [ 1.78   , -1.736  ],\n",
      "       [ 2.787  , -2.691  ],\n",
      "       [ 1.469  , -1.4375 ],\n",
      "       [-0.6343 ,  0.706  ],\n",
      "       [ 1.408  , -1.377  ],\n",
      "       [ 1.723  , -1.68   ],\n",
      "       [-1.326  ,  1.584  ],\n",
      "       [-0.505  ,  0.528  ],\n",
      "       [-2.027  ,  2.291  ],\n",
      "       [ 2.506  , -2.426  ],\n",
      "       [ 1.181  , -1.155  ],\n",
      "       [ 1.73   , -1.687  ],\n",
      "       [ 2.062  , -2.002  ],\n",
      "       [-0.8364 ,  0.993  ],\n",
      "       [ 1.316  , -1.291  ],\n",
      "       [ 1.652  , -1.611  ],\n",
      "       [ 0.695  , -0.6675 ],\n",
      "       [-0.992  ,  1.205  ],\n",
      "       [ 0.821  , -0.7993 ],\n",
      "       [-0.2031 ,  0.2224 ],\n",
      "       [ 1.195  , -1.181  ],\n",
      "       [-1.312  ,  1.5625 ],\n",
      "       [ 1.089  , -1.064  ],\n",
      "       [ 0.9766 , -0.9556 ],\n",
      "       [ 1.832  , -1.788  ],\n",
      "       [ 0.844  , -0.826  ],\n",
      "       [-1.168  ,  1.405  ],\n",
      "       [-0.9966 ,  1.209  ],\n",
      "       [ 2.514  , -2.434  ],\n",
      "       [-0.92   ,  1.122  ],\n",
      "       [ 2.732  , -2.64   ],\n",
      "       [ 2.836  , -2.74   ],\n",
      "       [-1.045  ,  1.265  ],\n",
      "       [-0.669  ,  0.7554 ],\n",
      "       [ 0.891  , -0.8647 ],\n",
      "       [ 0.6416 , -0.617  ],\n",
      "       [ 1.176  , -1.152  ],\n",
      "       [-1.225  ,  1.477  ],\n",
      "       [ 2.033  , -1.98   ],\n",
      "       [ 0.2766 , -0.2651 ],\n",
      "       [ 1.517  , -1.484  ],\n",
      "       [ 1.63   , -1.597  ],\n",
      "       [ 0.6846 , -0.669  ],\n",
      "       [ 0.559  , -0.545  ],\n",
      "       [-1.016  ,  1.227  ],\n",
      "       [ 1.869  , -1.82   ],\n",
      "       [ 1.167  , -1.143  ],\n",
      "       [ 0.4854 , -0.4636 ],\n",
      "       [ 1.591  , -1.554  ],\n",
      "       [ 1.599  , -1.5625 ],\n",
      "       [ 1.045  , -1.023  ],\n",
      "       [ 1.256  , -1.223  ],\n",
      "       [-0.5815 ,  0.633  ],\n",
      "       [ 1.783  , -1.737  ],\n",
      "       [-0.746  ,  0.869  ],\n",
      "       [-0.4397 ,  0.456  ],\n",
      "       [ 1.308  , -1.275  ],\n",
      "       [ 1.198  , -1.17   ],\n",
      "       [ 1.8545 , -1.805  ],\n",
      "       [ 1.647  , -1.605  ],\n",
      "       [ 1.235  , -1.209  ],\n",
      "       [ 1.755  , -1.709  ],\n",
      "       [ 1.223  , -1.193  ],\n",
      "       [ 1.071  , -1.048  ],\n",
      "       [ 1.998  , -1.944  ],\n",
      "       [ 0.9243 , -0.9053 ],\n",
      "       [ 1.201  , -1.175  ],\n",
      "       [ 2.322  , -2.254  ],\n",
      "       [-0.8716 ,  1.055  ],\n",
      "       [ 1.574  , -1.537  ],\n",
      "       [-0.9775 ,  1.196  ],\n",
      "       [ 1.782  , -1.739  ],\n",
      "       [ 2.096  , -2.037  ],\n",
      "       [ 2.12   , -2.057  ],\n",
      "       [ 1.581  , -1.544  ],\n",
      "       [-0.6987 ,  0.792  ],\n",
      "       [ 2.438  , -2.363  ],\n",
      "       [ 1.24   , -1.213  ],\n",
      "       [ 0.349  , -0.3416 ],\n",
      "       [-1.335  ,  1.601  ],\n",
      "       [ 1.062  , -1.038  ],\n",
      "       [ 1.987  , -1.932  ],\n",
      "       [ 0.865  , -0.843  ],\n",
      "       [-0.4905 ,  0.5317 ],\n",
      "       [ 2.398  , -2.324  ],\n",
      "       [ 1.791  , -1.746  ],\n",
      "       [ 0.8105 , -0.798  ],\n",
      "       [ 1.373  , -1.345  ],\n",
      "       [ 1.201  , -1.176  ],\n",
      "       [ 1.397  , -1.368  ],\n",
      "       [-0.4795 ,  0.5073 ],\n",
      "       [ 1.233  , -1.206  ],\n",
      "       [ 0.615  , -0.6    ],\n",
      "       [-0.4592 ,  0.4712 ],\n",
      "       [ 2.27   , -2.201  ],\n",
      "       [ 2.404  , -2.328  ],\n",
      "       [ 1.888  , -1.835  ],\n",
      "       [ 0.7764 , -0.777  ],\n",
      "       [ 1.787  , -1.742  ],\n",
      "       [ 2.146  , -2.086  ],\n",
      "       [ 1.974  , -1.921  ],\n",
      "       [ 1.725  , -1.682  ],\n",
      "       [ 1.354  , -1.323  ],\n",
      "       [ 1.555  , -1.519  ],\n",
      "       [ 2.307  , -2.238  ],\n",
      "       [ 1.421  , -1.392  ],\n",
      "       [-0.883  ,  1.057  ],\n",
      "       [ 1.228  , -1.198  ],\n",
      "       [ 1.445  , -1.415  ],\n",
      "       [ 0.03995, -0.02824],\n",
      "       [ 1.504  , -1.472  ],\n",
      "       [ 1.703  , -1.661  ],\n",
      "       [-1.078  ,  1.314  ],\n",
      "       [-0.5166 ,  0.551  ],\n",
      "       [-1.144  ,  1.382  ],\n",
      "       [ 1.0625 , -1.051  ],\n",
      "       [-0.9326 ,  1.131  ],\n",
      "       [ 1.137  , -1.113  ],\n",
      "       [-0.784  ,  0.9136 ],\n",
      "       [ 1.349  , -1.314  ],\n",
      "       [-1.013  ,  1.229  ],\n",
      "       [-1.185  ,  1.434  ],\n",
      "       [ 1.624  , -1.586  ],\n",
      "       [ 2.535  , -2.453  ],\n",
      "       [-0.7783 ,  0.912  ],\n",
      "       [-0.4502 ,  0.478  ],\n",
      "       [ 2.596  , -2.512  ],\n",
      "       [ 0.9067 , -0.8823 ],\n",
      "       [ 0.5684 , -0.558  ],\n",
      "       [ 0.628  , -0.6113 ],\n",
      "       [-1.199  ,  1.446  ],\n",
      "       [ 1.272  , -1.243  ],\n",
      "       [-0.846  ,  0.9927 ],\n",
      "       [ 0.162  , -0.1484 ],\n",
      "       [ 2.045  , -1.986  ],\n",
      "       [ 0.787  , -0.7886 ],\n",
      "       [ 1.464  , -1.429  ],\n",
      "       [ 1.675  , -1.633  ],\n",
      "       [ 2.457  , -2.377  ],\n",
      "       [ 1.141  , -1.113  ],\n",
      "       [-1.292  ,  1.555  ],\n",
      "       [-0.766  ,  0.8853 ],\n",
      "       [-0.8413 ,  0.9785 ],\n",
      "       [-2.115  ,  2.393  ],\n",
      "       [-1.519  ,  1.778  ],\n",
      "       [-0.04996,  0.0521 ],\n",
      "       [ 0.843  , -0.823  ],\n",
      "       [ 0.698  , -0.6836 ],\n",
      "       [-0.2534 ,  0.2688 ],\n",
      "       [ 1.788  , -1.743  ],\n",
      "       [-0.828  ,  0.9727 ],\n",
      "       [-1.048  ,  1.266  ],\n",
      "       [ 2.082  , -2.018  ],\n",
      "       [-2.113  ,  2.389  ],\n",
      "       [ 0.766  , -0.7485 ],\n",
      "       [ 1.322  , -1.293  ],\n",
      "       [ 2.316  , -2.246  ],\n",
      "       [ 2.383  , -2.314  ],\n",
      "       [-1.171  ,  1.414  ],\n",
      "       [ 1.989  , -1.934  ],\n",
      "       [-0.903  ,  1.079  ],\n",
      "       [ 0.309  , -0.2993 ],\n",
      "       [ 0.11053, -0.0987 ],\n",
      "       [-0.376  ,  0.3772 ],\n",
      "       [ 0.859  , -0.84   ],\n",
      "       [-0.961  ,  1.158  ],\n",
      "       [-0.861  ,  1.024  ],\n",
      "       [-0.4846 ,  0.5127 ],\n",
      "       [ 2.639  , -2.549  ],\n",
      "       [ 1.307  , -1.272  ],\n",
      "       [ 2.09   , -2.033  ],\n",
      "       [ 1.325  , -1.297  ],\n",
      "       [ 1.67   , -1.628  ],\n",
      "       [-0.6377 ,  0.709  ],\n",
      "       [-0.493  ,  0.521  ],\n",
      "       [ 2.467  , -2.39   ],\n",
      "       [ 1.09   , -1.0625 ],\n",
      "       [-1.087  ,  1.314  ],\n",
      "       [ 2.28   , -2.21   ],\n",
      "       [ 1.3545 , -1.329  ],\n",
      "       [ 1.319  , -1.295  ],\n",
      "       [ 1.0625 , -1.038  ],\n",
      "       [ 1.353  , -1.323  ],\n",
      "       [ 2.398  , -2.324  ],\n",
      "       [ 1.561  , -1.524  ],\n",
      "       [ 0.554  , -0.5347 ],\n",
      "       [ 1.47   , -1.4375 ],\n",
      "       [-0.9365 ,  1.141  ],\n",
      "       [-1.199  ,  1.45   ],\n",
      "       [ 1.17   , -1.146  ],\n",
      "       [ 0.6396 , -0.632  ],\n",
      "       [ 2.05   , -1.994  ],\n",
      "       [ 1.191  , -1.166  ],\n",
      "       [ 1.013  , -0.9893 ],\n",
      "       [ 1.322  , -1.295  ],\n",
      "       [ 0.7886 , -0.769  ],\n",
      "       [ 0.4058 , -0.3953 ],\n",
      "       [ 1.326  , -1.298  ],\n",
      "       [-1.086  ,  1.3125 ],\n",
      "       [-0.8823 ,  1.055  ],\n",
      "       [ 0.596  , -0.58   ],\n",
      "       [ 1.624  , -1.585  ],\n",
      "       [ 1.451  , -1.418  ],\n",
      "       [ 1.871  , -1.824  ],\n",
      "       [ 2.342  , -2.271  ],\n",
      "       [-0.8037 ,  0.9487 ],\n",
      "       [ 1.152  , -1.128  ],\n",
      "       [ 0.848  , -0.833  ],\n",
      "       [ 1.452  , -1.418  ],\n",
      "       [ 2.129  , -2.072  ],\n",
      "       [-1.204  ,  1.456  ],\n",
      "       [ 1.203  , -1.174  ],\n",
      "       [ 0.4873 , -0.4722 ],\n",
      "       [ 2.605  , -2.52   ],\n",
      "       [ 1.434  , -1.4    ],\n",
      "       [ 0.276  , -0.2727 ],\n",
      "       [-0.4187 ,  0.4226 ]], dtype=float16), label_ids=array([0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
      "       0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
      "       1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
      "       0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
      "       0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "       1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
      "       0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
      "       1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
      "       0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1]), metrics={'test_loss': 0.8151163458824158, 'test_accuracy': 0.7008547008547008, 'test_balanced_accuracy': 0.6671195652173914, 'test_precision': 0.7001609501609501, 'test_recall': 0.7008547008547008, 'test_f1': 0.6878200472971715, 'test_runtime': 1.8975, 'test_samples_per_second': 123.323, 'test_steps_per_second': 4.216})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73395d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjQAAAG5CAYAAACZTa6YAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAi8ElEQVR4nO3de7xd853/8dfnJCJSchUaUYNxq2q1ilYNP0qVXjCtotUKY5peXNrSUb38ZPQ20w7KlGkbl7qV6oWiVGnKFG1JXItQQZEICYlLg0r4zB97xZxkkpOTY9/WWq+nx35k77XWXuu7T8t55/P5fveKzESSJKnMejo9AEmSpFfLQCNJkkrPQCNJkkrPQCNJkkrPQCNJkkrPQCNJkkrPQCOVRESsFhGXRcTTEfHTV3GeAyLiqmaOrRMi4lcRMaHT45DUHQw0UpNFxEciYlpE/DUiZhe/eP+hCafeB1gbGJOZHxroSTLzR5m5WxPGs4SI2CkiMiIuXmr7lsX2a/t5nn+NiPNWdFxm7pGZZw9wuJIqxkAjNVFEHAmcBHyTRvhYD/gvYK8mnP7vgD9n5qImnKtV5gLbRcSYXtsmAH9u1gWiwf92SVqC/1GQmiQiRgBfBQ7NzIsyc0FmLszMyzLzX4pjVo2IkyLi0eJxUkSsWuzbKSJmRsRRETGnqO4cXOw7DjgW2K+o/ByydCUjItYvKiGDi9cHRcQDEfFsRDwYEQf02n59r/e9IyKmFq2sqRHxjl77ro2Ir0XEDcV5roqINfv4MbwI/ALYv3j/IGA/4EdL/axOjohHIuKZiLg5InYotu8OfKnX57y91zi+ERE3AM8BGxbb/rnY/72I+Hmv838rIqZERPT3fz9J5WagkZpnO2AocHEfx3wZeDvwZmBLYFvgK732vxYYAYwHDgFOjYhRmTmJRtXnwsxcPTPP6GsgEfEa4D+BPTJzDeAdwG3LOG40cHlx7BjgRODypSosHwEOBtYChgCf7+vawDnAgcXzdwN3Ao8udcxUGj+D0cD5wE8jYmhmXrnU59yy13s+BkwE1gAeWup8RwFvLMLaDjR+dhPSe7tItWGgkZpnDPDEClpCBwBfzcw5mTkXOI7GL+rFFhb7F2bmFcBfgU0HOJ6XgS0iYrXMnJ2Zdy3jmPcC92XmuZm5KDMvAO4B3t/rmB9m5p8z83ngJzSCyHJl5u+B0RGxKY1gc84yjjkvM58srnkCsCor/pxnZeZdxXsWLnW+52j8HE8EzgMOz8yZKzifpAox0EjN8ySw5uKWz3Ksw5LVhYeKba+cY6lA9Byw+soOJDMX0Gj1fBKYHRGXR8Rm/RjP4jGN7/X6sQGM51zgMGBnllGxiojPR8T0os31FI2qVF+tLIBH+tqZmTcCDwBBI3hJqhEDjdQ8fwD+BuzdxzGP0pjcu9h6/N92TH8tAIb1ev3a3jsz89eZ+S5gHI2qy2n9GM/iMc0a4JgWOxf4NHBFUT15RdESOhrYFxiVmSOBp2kEEYDltYn6bB9FxKE0Kj2PFueXVCMGGqlJMvNpGhN3T42IvSNiWESsEhF7RMS3i8MuAL4SEWOLybXH0miRDMRtwI4RsV4xIfmLi3dExNoRsVcxl+ZvNFpXLy/jHFcAmxRLzQdHxH7A5sAvBzgmADLzQeD/0ZgztLQ1gEU0VkQNjohjgeG99j8OrL8yK5kiYhPg68BHabSejo6INw9s9JLKyEAjNVExH+RIGhN959JokxxGY+UPNH7pTgPuAP4E3FJsG8i1rgYuLM51M0uGkJ5iHI8C82iEi08t4xxPAu+jMan2SRqVjfdl5hMDGdNS574+M5dVffo1cCWNpdwPAS+wZDtp8ZcGPhkRt6zoOkWL7zzgW5l5e2beR2Ol1LmLV5BJqr5wEYAkSSo7KzSSJKn0DDSSJKn0DDSSJKn0DDSSJKn0+voCsI5a7S2HOVtZ6oD5U0/p9BCk2ho6mLbef6yZv2ufv/WUjt47zQqNJEkqva6t0EiSpBbr//dXdr3qfBJJklRbVmgkSaqr6Oi0l6Yy0EiSVFe2nCRJkrqHFRpJkurKlpMkSSo9W06SJEndwwqNJEl1ZctJkiSVni0nSZKk7mGFRpKkurLlJEmSSs+WkyRJUvewQiNJUl3ZcpIkSaVny0mSJKl7WKGRJKmubDlJkqTSs+UkSZLUPazQSJJUVxWq0BhoJEmqq57qzKGpTjSTJEm1ZYVGkqS6suUkSZJKr0LLtqsTzSRJUm1ZoZEkqa5sOUmSpNKz5SRJktQ9rNBIklRXtpwkSVLpVajlZKCRJKmuKlShqc4nkSRJtWWFRpKkurLlJEmSSs+WkyRJUvewQiNJUl3ZcpIkSaVny0mSJKl7WKGRJKmuKlShMdBIklRXFZpDU51oJkmSassKjSRJdWXLSZIklZ4tJ0mSpO5hhUaSpLqy5SRJkkrPlpMkSVL3sEIjSVJNRYUqNAYaSZJqqkqBxpaTJEkqPSs0kiTVVXUKNAYaSZLqypaTJElSF7FCI0lSTVWpQmOgkSSppqoUaGw5SZKk0rNCI0lSTVWpQmOgkSSprqqTZ2w5SZKk8rNCI0lSTdlykiRJpVelQGPLSZIklZ4VGkmSaqpKFRoDjSRJNVWlQGPLSZIktVxEnBkRcyLizl7bRkfE1RFxX/HnqGJ7RMR/RsSMiLgjIrZa0fkNNJIk1VU08bFiZwG7L7XtGGBKZm4MTCleA+wBbFw8JgLfW9HJDTSSJNVURDTtsSKZ+Ttg3lKb9wLOLp6fDezda/s52fBHYGREjOvr/AYaSZL0qkXExIiY1usxsR9vWzszZxfPHwPWLp6PBx7pddzMYttyOSlYkqSaauak4MycDEx+Fe/PiMiBvt9AI0lSTXXBKqfHI2JcZs4uWkpziu2zgNf1Om7dYtty2XKSJEmdcikwoXg+Abik1/YDi9VObwee7tWaWiYrNJIk1VUbCzQRcQGwE7BmRMwEJgH/DvwkIg4BHgL2LQ6/AngPMAN4Djh4Rec30EiSVFPtbDll5oeXs2uXZRybwKErc35bTpIkqfSs0EiSVFNdMCm4aQw0kiTVVJUCjS0nSZJUelZoJEmqqSpVaAw0kiTVVXXyjC0nSZJUflZoJEmqKVtOkiSp9KoUaGw5SZKk0rNCI0lSTVWpQmOgkSSprqqTZww0kiTVVZUqNM6hkSRJpWeFRpKkmqpShcZAo5X2/UkHsMeOWzB33rNs/aFvAvCBXd/Clz/5HjbbYG12+Njx3HL3wwAMHtzD9449gDdv9joGD+rhR5ffxPFnXtXJ4UuV8Njs2Xz5i0cz78knIYJ9PrQvB3xsAk8/9RRHf/5zPDprFuuMH89/nHASw0eM6PRw1aWqFGhsOWmlnXvZH9nr0FOX2HbX/Y+y/1Gncf0t9y+x/YO7bsWqQwazzb7f5B0HfIt//uD2rDdudDuHK1XSoMGD+PzRx3DxZVdw3gUX8uMLzuf+GTM48/TJbPu27bjsV1ex7du244zTJ3d6qFJbGGi00m645X7mPf3cEtvuffBx7ntozv85NkmGDR3CoEE9rLbqEF5c+BLPLnihXUOVKmvs2LV4/eZvAOA1r1mdDTfckDlzHueaa6aw5957A7Dn3ntzzW9/08FRqttFRNMendayllNEbAbsBYwvNs0CLs3M6a26prrPRb+5lfft9CYevPobDBs6hKOPv4j5zzy34jdK6rdZs2Zyz/TpvPFNWzLvyScZO3YtANZcc2yjJSUtT+dzSNO0pEITEV8AfkzjR3VT8Qjggog4po/3TYyIaRExbdETd7ViaGqzbd6wPi+99DIb7vZlXv/eSXzmY+9k/fFjOj0sqTKeW7CAoz57BP9yzJdYffXVl9gXEdAFf3OW2qFVFZpDgDdk5sLeGyPiROAu4N+X9abMnAxMBljtLYdli8amNtp3j6256vd3s2jRy8yd/1f+cNsDvHXz9fjLLP/WKL1aCxcu5MjPHsF73vt+dn3XbgCMHjOGuXPnMHbsWsydO4fRo52zpuXrhlZRs7RqDs3LwDrL2D6u2KeamPnYPHbaZlMAhg0dwrZvWp97//J4h0cllV9m8q/HfpkNN9yQAw86+JXtO+38Ti79xS8AuPQXv2DnnXfp0AhVBlWaQxOZzS+ERMTuwCnAfcAjxeb1gI2AwzLzyhWdwwpN9zr73w5ih7duzJojV2fOvGf42vevYP7TCzjxCx9izVGr89Szz3PHvbPY89BTec1qQ5h83EfZbMNxRMC5l/yR75wzpdMfQX2YP/WUTg9B/XDLzdM4+MAD2HiTTeiJxt9ND//skbzxTW/iX478LI/Nns24ddbhP044iREjR3Z2sOq3oYPbO6vl74/6VdN+195/wh4dTTUtCTQAEdEDbMuSk4KnZuZL/Xm/gUbqDAON1DntDjQbfb55gWbG8Z0NNC1b5ZSZLwN/bNX5JUnSq9MNraJm8XtoJElS6XnrA0mSaqpCBRoDjSRJdWXLSZIkqYtYoZEkqaYqVKAx0EiSVFc9PdVJNLacJElS6VmhkSSppmw5SZKk0nOVkyRJUhexQiNJUk1VqEBjoJEkqa5sOUmSJHURKzSSJNVUlSo0BhpJkmqqQnnGlpMkSSo/KzSSJNWULSdJklR6FcoztpwkSVL5WaGRJKmmbDlJkqTSq1CeseUkSZLKzwqNJEk1ZctJkiSVXoXyjC0nSZJUflZoJEmqKVtOkiSp9CqUZ2w5SZKk8rNCI0lSTdlykiRJpVehPGPLSZIklZ8VGkmSasqWkyRJKr0K5RlbTpIkqfys0EiSVFO2nCRJUulVKdDYcpIkSaVnhUaSpJqqUIHGQCNJUl3ZcpIkSeoiVmgkSaqpChVoDDSSJNVVlVpOBhpJkmqqQnnGOTSSJKn8DDSSJNVUT0TTHisSEZ+LiLsi4s6IuCAihkbEBhFxY0TMiIgLI2LIgD/LQN8oSZLKLaJ5j76vE+OBI4CtM3MLYBCwP/At4DuZuREwHzhkoJ/FQCNJktphMLBaRAwGhgGzgXcCPyv2nw3sPdCTG2gkSaqpiGjmY2JETOv1mLj4Opk5CzgeeJhGkHkauBl4KjMXFYfNBMYP9LO4ykmSpJrqaeIqp8ycDExe1r6IGAXsBWwAPAX8FNi9eVe3QiNJklpvV+DBzJybmQuBi4DtgZFFCwpgXWDWQC9goJEkqaaa2XJagYeBt0fEsGgcvAtwN3ANsE9xzATgkoF+FgONJEk11a5VTpl5I43Jv7cAf6KRPyYDXwCOjIgZwBjgjIF+FufQSJKklsvMScCkpTY/AGzbjPMbaCRJqqmgOvc+MNBIklRTzVzl1GnOoZEkSaVnhUaSpJrqx+qk0jDQSJJUUxXKM7acJElS+VmhkSSppnoqVKIx0EiSVFMVyjPLDzQR8V0gl7c/M49oyYgkSZJWUl8VmmltG4UkSWq7Wqxyysyze7+OiGGZ+VzrhyRJktqhQnlmxaucImK7iLgbuKd4vWVE/FfLRyZJktRP/ZkUfBLwbuBSgMy8PSJ2bOWgJElS69VulVNmPrJUn+2l1gxHkiS1S3XiTP8CzSMR8Q4gI2IV4DPA9NYOS5Ikqf/6E2g+CZwMjAceBX4NHNrKQUmSpNarxSqnxTLzCeCANoxFkiS1UU918ky/VjltGBGXRcTciJgTEZdExIbtGJwkSVJ/9OfmlOcDPwHGAesAPwUuaOWgJElS60VE0x6d1p9AMywzz83MRcXjPGBoqwcmSZJaK6J5j07r615Oo4unv4qIY4Af07i3037AFW0YmyRJUr/0NSn4ZhoBZnHu+kSvfQl8sVWDkiRJrdcNraJm6eteThu0cyCSJKm9qrTKqV/fFBwRWwCb02vuTGae06pBSZIkrYwVBpqImATsRCPQXAHsAVwPGGgkSSqxKrWc+rPKaR9gF+CxzDwY2BIY0dJRSZKklosmPjqtP4Hm+cx8GVgUEcOBOcDrWjssSZKk/uvPHJppETESOI3Gyqe/An9o5aAkSVLr9VSo5dSfezl9unj6/Yi4EhgOPNHSUUmSpJarUJ7p3yqnxTLzLwAR8TCwXisGJEmStLJWKtD0UqFMJ0lSPVVpldNAA002dRSSJKntKpRn+ryX03dZdnAJYGSrBiRJkrSy+qrQTBvgPkmSVAK1WOWUmWe3cyCSJKm9KpRn+vXFepIkSV1toJOCW+5n5x7b6SFItTT1gfmdHoJUWztsMqqt13OVkyRJKr0qtWkGssoJgMw8oiUjkiRJWkkDXeUkSZJKrhYtJ1c5SZJUbT3VyTMrnkMTEWOBLwCbA0MXb8/Md7ZwXJIkqcWqFGj6Mx/oR8B0YAPgOOAvwNQWjkmSJGml9CfQjMnMM4CFmfnfmflPgNUZSZJKLiKa9ui0/izbXlj8OTsi3gs8Coxu3ZAkSVI7VKnl1J9A8/WIGAEcBXwXGA58rqWjkiRJWgkrDDSZ+cvi6dPAzq0djiRJapcu6BQ1TX9WOf2QZXzBXjGXRpIklVQt7rbdyy97PR8K/CONeTSSJEldoT8tp5/3fh0RFwDXt2xEkiSpLWpxL6c+bAys1eyBSJKk9qpQx6lfc2ieZck5NI/R+OZgSZKkrtCfltMa7RiIJElqrypNCl5h+ywipvRnmyRJKpeI5j06bbkVmogYCgwD1oyIUcDi4Q4HxrdhbJIkSf3SV8vpE8BngXWAm/nfQPMMcEprhyVJklqtFrc+yMyTgZMj4vDM/G4bxyRJktqgVnNogJcjYuTiFxExKiI+3bohSZIkrZz+BJqPZ+ZTi19k5nzg4y0bkSRJaotaTAruZVBERGYmQEQMAoa0dliSJKnVajGHppcrgQsj4gfF608U2yRJkrpCfwLNF4CJwKeK11cDp7VsRJIkqS2C6pRoVjiHJjNfzszvZ+Y+mbkPcDfgqidJkkquJ5r36LR+3ZwyIt4CfBjYF3gQuKiVg5IkSVoZfX1T8CY0QsyHgSeAC4HIzJ3bNDZJktRC3VBZaZa+KjT3ANcB78vMGQAR8bm2jEqSJLVcdMN66ybpaw7NB4DZwDURcVpE7AIVmj0kSZIqY7mBJjN/kZn7A5sB19C4r9NaEfG9iNitTeOTJEktUqVJwf1Z5bQgM8/PzPcD6wK30ljKLUmSSqyd3xQcESMj4mcRcU9ETI+I7SJidERcHRH3FX+OGuhn6c+tD16RmfMzc3Jm7jLQC0qSpFo6GbgyMzcDtgSmA8cAUzJzY2BK8XpA+rVsW5IkVU+77rYdESOAHYGDADLzReDFiNgL2Kk47GzgWgbYBVqpCo0kSaqOZs6hiYiJETGt12Nir0ttAMwFfhgRt0bE6RHxGmDtzJxdHPMYsPZAP4sVGkmS9Kpl5mRg8nJ2Dwa2Ag7PzBsj4mSWai9lZkZEDvT6VmgkSaqpNk4KngnMzMwbi9c/oxFwHo+IcY2xxDhgzkA/i4FGkqSa6iGa9uhLZj4GPBIRmxabdqFxb8hLgQnFtgnAJQP9LLacJElSOxwO/CgihgAPAAfTKKz8JCIOAR6icc/IATHQSJJUU+2880Fm3gZsvYxdTfkqGAONJEk11Q3f8NsszqGRJEmlZ4VGkqSaatcX67WDgUaSpJqqUJ6x5SRJksrPCo0kSTVly0mSJJVehfKMLSdJklR+VmgkSaqpKlU1DDSSJNVUVKjnVKVwJkmSasoKjSRJNVWd+oyBRpKk2qrSsm1bTpIkqfSs0EiSVFPVqc8YaCRJqq0KdZxsOUmSpPKzQiNJUk1V6XtoDDSSJNVUldo0BhpJkmqqShWaKoUzSZJUU1ZoJEmqqerUZww0kiTVli0nSZKkLmKFRpKkmqpSVcNAI0lSTdlykiRJ6iJWaCRJqqnq1GcMNJIk1VaFOk62nCRJUvlZoZEkqaZ6KtR0MtBIklRTtpwkSZK6iBUaSZJqKmw5SZKksrPlJEmS1EWs0EiSVFOucpIkSaVny0mSJKmLWKGRJKmmqlShMdBIklRTVVq2bctJkiSVnhUaSZJqqqc6BRoDjSRJdWXLSZIkqYtYoZEkqaZc5SRJkkrPlpMkSVIXsUIjSVJNucpJkiSVni0nSZKkLmKFRq/a1z75IVZdbRg9PT30DBrEkd8+nQXPPsO5J05i3pzHGL3WaznwqK8ybPU1Oj1UqXJefuklvnbkwYwaPZYjJp1AZnLxud/n5ht+S/T0sNMeH2DXPffr9DDVpVzlJC3l08edzOrDR77y+rcXn8fGb3wru3zgo0y56DymXHwe7//Ypzo3QKmifnPZhYxbd31eeG4BADdMuZz5T8zha9+7kJ6eHp55al6HR6huVqE8Y8tJrXHn1OvZZufdAdhm592586brOjwiqXrmPTGHO6b+nh122/OVbddecRHv2/+f6Olp/Od9+MjRnRqe1FZWaPSqRQQ/+OqRRATbvWsvttttT559aj7DR60JwBojx/DsU/M7PEqpei487Tvsc/BhvPD8gle2zX1sJlOv+w23/vG/WWP4SD78iSNZe531OjhKdbOeCvWc2l6hiYiD+9g3MSKmRcS0K396TjuHpVfhsK+fylHHn8nHv3I81195EfffddsS+yOiUn1aqRvcftP1rDFiFOtvtNkS2xctXMgqQ4bw/79zFju8ey/OOvkbHRqhyiCa+Oi0TlRojgN+uKwdmTkZmAxw+Z1zsp2D0sCNHDMWgDVGjOKNb9uRh2dMZ42Ro3hm/hMMH7Umz8x/gtVHjOrwKKVqmTH9Dm6/6Tr+dPPvWfjii7zw3AJOO2ESo8asxVbb7QzAVtvtxFknf73DI5XaoyWBJiLuWN4uYO1WXFOd8bcXniczGbraMP72wvP8+fapvOtDB/GGrbdn6jVXsssHPsrUa65ki23+odNDlSrlgxM+zQcnfBqAe/50M1dddD4fP+o4fnbWqdz7p5sZ+9p1uPfOW2w3qW/dUFppklZVaNYG3g0sPXEigN+36JrqgL8+NZ8zv/0loLF8dKsd3sXr3/I21ttoM8454VhunHI5o8auzYFHfbXDI5Xq4T37HMhpJ0zi6kt+zKpDV2PCEV/q9JDUxar0xXqR2fzOTkScAfwwM69fxr7zM/MjKzqHLSepM4YPWaXTQ5Bqa4dNRrU1Ydx4/9NN+137tr8f0dF01JIKTWYe0se+FYYZSZLUelVasOGybUmSaqpCecYv1pMkSeVnhUaSpLqqUInGQCNJUk1VaZWTLSdJklR6VmgkSaopVzlJkqTSq1CeseUkSZLKz0AjSVJdtfl22xExKCJujYhfFq83iIgbI2JGRFwYEUMG+lEMNJIk1VQ08Z9++gwwvdfrbwHfycyNaNz/cbl3GlgRA40kSWq5iFgXeC9wevE6gHcCPysOORvYe6DnN9BIklRTEc18xMSImNbrMXGpy50EHA28XLweAzyVmYuK1zOB8QP9LK5ykiSpppq5yikzJwOTl3mdiPcBczLz5ojYqYmXfYWBRpKkumrfuu3tgT0j4j3AUGA4cDIwMiIGF1WadYFZA72ALSdJktRSmfnFzFw3M9cH9gd+m5kHANcA+xSHTQAuGeg1DDSSJNVUB1Y5Le0LwJERMYPGnJozBnoiW06SJNVUJ259kJnXAtcWzx8Atm3Gea3QSJKk0rNCI0lSTVXpXk4GGkmS6qpCicaWkyRJKj0rNJIk1dSrWJ3UdQw0kiTVVCdWObWKLSdJklR6VmgkSaqpChVoDDSSJNVWhRKNLSdJklR6VmgkSaopVzlJkqTSc5WTJElSF7FCI0lSTVWoQGOgkSSptiqUaGw5SZKk0rNCI0lSTbnKSZIklZ6rnCRJkrqIFRpJkmqqQgUaA40kSbVVoURjy0mSJJWeFRpJkmrKVU6SJKn0XOUkSZLURazQSJJUUxUq0BhoJEmqrQolGltOkiSp9KzQSJJUU65ykiRJpecqJ0mSpC5ihUaSpJqqUIHGQCNJUl3ZcpIkSeoiVmgkSaqt6pRoDDSSJNWULSdJkqQuYoVGkqSaqlCBxkAjSVJd2XKSJEnqIlZoJEmqKe/lJEmSyq86ecaWkyRJKj8rNJIk1VSFCjQGGkmS6spVTpIkSV3ECo0kSTXlKidJklR+1ckztpwkSVL5WaGRJKmmKlSgMdBIklRXVVrlZKCRJKmmqjQp2Dk0kiSp9KzQSJJUU1VqOVmhkSRJpWegkSRJpWfLSZKkmqpSy8lAI0lSTbnKSZIkqYtYoZEkqaZsOUmSpNKrUJ6x5SRJksrPCo0kSXVVoRKNgUaSpJpylZMkSVIXsUIjSVJNucpJkiSVXoXyjC0nSZJUflZoJEmqqwqVaKzQSJJUU9HEf/q8TsTrIuKaiLg7Iu6KiM8U20dHxNURcV/x56iBfhYDjSRJarVFwFGZuTnwduDQiNgcOAaYkpkbA1OK1wNioJEkqaYimvfoS2bOzsxbiufPAtOB8cBewNnFYWcDew/4s2TmQN8rLVdETMzMyZ0eh1Q3/runTomIicDEXpsmL+v/ixGxPvA7YAvg4cwcWWwPYP7i1yt9fQONWiEipmXm1p0eh1Q3/runbhYRqwP/DXwjMy+KiKd6B5iImJ+ZA5pHY8tJkiS1XESsAvwc+FFmXlRsfjwixhX7xwFzBnp+A40kSWqpop10BjA9M0/stetSYELxfAJwyUCv4ffQqFXs4Uud4b976kbbAx8D/hQRtxXbvgT8O/CTiDgEeAjYd6AXcA6NJEkqPVtOkiSp9Aw0kiSp9Aw0aqqI2D0i7o2IGREx4G98lLRyIuLMiJgTEXd2eixSJxho1DQRMQg4FdgD2Bz4cPHV1pJa7yxg904PQuoUA42aaVtgRmY+kJkvAj+m8bXWklosM38HzOv0OKROMdComcYDj/R6PbPYJklSSxloJElS6Rlo1EyzgNf1er1usU2SpJYy0KiZpgIbR8QGETEE2J/G11pLktRSBho1TWYuAg4Dfg1MB36SmXd1dlRSPUTEBcAfgE0jYmbxVfJSbXjrA0mSVHpWaCRJUukZaCRJUukZaCRJUukZaCRJUukZaCRJUukZaKQOioiXIuK2iLgzIn4aEcNexbnOioh9iuen93Vj0IjYKSLeMYBr/CUi1uzv9uWc46CIOKUZ15WkxQw0Umc9n5lvzswtgBeBT/beGRGDB3LSzPznzLy7j0N2AlY60EhStzLQSN3jOmCjonpyXURcCtwdEYMi4j8iYmpE3BERnwCIhlMi4t6I+A2w1uITRcS1EbF18Xz3iLglIm6PiCkRsT6N4PS5ojq0Q0SMjYifF9eYGhHbF+8dExFXRcRdEXE6EP39MBGxbUT8ISJujYjfR8SmvXa/rhjjfRExqdd7PhoRNxXj+kFEDBr4j1NSnQzob3+SmquoxOwBXFls2grYIjMfjIiJwNOZuU1ErArcEBFXAW8BNgU2B9YG7gbOXOq8Y4HTgB2Lc43OzHkR8X3gr5l5fHHc+cB3MvP6iFiPxrc9vx6YBFyfmV+NiPcCK/Pts/cAO2TmoojYFfgm8MFi37bAFsBzwNSIuBxYAOwHbJ+ZCyPiv4ADgHNW4pqSaspAI3XWahFxW/H8OuAMGq2gmzLzwWL7bsCbFs+PAUYAGwM7Ahdk5kvAoxHx22Wc/+3A7xafKzPnLWccuwKbR7xSgBkeEasX1/hA8d7LI2L+Sny2EcDZEbExkMAqvfZdnZlPAkTERcA/AIuAt9IIOACrAXNW4nqSasxAI3XW85n55t4bil/mC3pvAg7PzF8vddx7mjiOHuDtmfnCMsYyUF8DrsnMfyzaXNf22rf0PVeSxuc8OzO/+GouKqmenEMjdb9fA5+KiFUAImKTiHgN8Dtgv2KOzThg52W894/AjhGxQfHe0cX2Z4E1eh13FXD44hcR8ebi6e+AjxTb9gBGrcS4RwCziucHLbXvXRExOiJWA/YGbgCmAPtExFqLxxoRf7cS15NUYwYaqfudTmN+zC0RcSfwAxrV1YuB+4p959C40/ISMnMuMBG4KCJuBy4sdl0G/OPiScHAEcDWxaTju/nf1VbH0QhEd9FoPT3cxzjvKO7yPDMiTgS+DfxbRNzK/60G3wT8HLgD+HlmTitWZX0FuCoi7gCuBsb182ckqea827YkSSo9KzSSJKn0DDSSJKn0DDSSJKn0DDSSJKn0DDSSJKn0DDSSJKn0DDSSJKn0/gcbLlt/OCQKYwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "probabilities = torch.softmax(torch.tensor(test_results.predictions).to(torch.float32), dim=-1)\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)\n",
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb603377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_save = []\n",
    "for idx in range(len(test_data)):\n",
    "    item = dataset['test'][idx]\n",
    "    actual_label = item['label']\n",
    "    predicted_label = predictions[idx]\n",
    "    claim = item['claim'] \n",
    "    premise = item['premise'] \n",
    "    category = item['category']\n",
    "    \n",
    "    # Append the information as a dictionary to the list\n",
    "    data_to_save.append({\n",
    "        'Claim': claim,\n",
    "        'Premise': premise,\n",
    "        'Actual Label': actual_label,\n",
    "        'Predicted Label': predicted_label,\n",
    "        'Category' : category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_to_save)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/home/elson/results/5.4.1_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c23339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correctly classified instances\n",
    "correctly_classified = df[df['Actual Label'] == df['Predicted Label']]\n",
    "\n",
    "# Calculate misclassified instances\n",
    "misclassified = df[df['Actual Label'] != df['Predicted Label']]\n",
    "\n",
    "# Count the number of correctly classified and misclassified by category\n",
    "correct_classification_counts = correctly_classified['Category'].value_counts()\n",
    "misclassification_counts = misclassified['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca0def77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           42\n",
       "Bone health              17\n",
       "Skin                     11\n",
       "Fitness                  11\n",
       "Cancer                    9\n",
       "Diabetes                  8\n",
       "Neurological health       8\n",
       "Eye                       8\n",
       "Throat                    7\n",
       "Hair                      6\n",
       "Cardiovascular Health     6\n",
       "Women' s Health           6\n",
       "Ear                       6\n",
       "Men's health              4\n",
       "COVID                     4\n",
       "Muscles                   4\n",
       "Blood                     4\n",
       "Mental Health             3\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0fddd944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Skin                     13\n",
       "General Health            9\n",
       "Hair                      6\n",
       "Cardiovascular Health     6\n",
       "Blood                     5\n",
       "Diabetes                  4\n",
       "Fitness                   4\n",
       "Bone health               4\n",
       "Cancer                    3\n",
       "Vascular                  3\n",
       "Dental Health             3\n",
       "Throat                    2\n",
       "COVID                     2\n",
       "Muscles                   2\n",
       "Men's health              2\n",
       "Eye                       1\n",
       "Neurological health       1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38b899b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_counts = df['Category'].value_counts()\n",
    "\n",
    "# Calculate ratios\n",
    "correct_classification_ratios = correct_classification_counts / total_counts\n",
    "misclassification_ratios = misclassification_counts / total_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c3598b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blood                    0.444444\n",
      "Bone health              0.809524\n",
      "COVID                    0.666667\n",
      "Cancer                   0.750000\n",
      "Cardiovascular Health    0.500000\n",
      "Dental Health                 NaN\n",
      "Diabetes                 0.666667\n",
      "Ear                      1.000000\n",
      "Eye                      0.888889\n",
      "Fitness                  0.733333\n",
      "General Health           0.823529\n",
      "Hair                     0.500000\n",
      "Men's health             0.666667\n",
      "Mental Health            1.000000\n",
      "Muscles                  0.666667\n",
      "Neurological health      0.888889\n",
      "Skin                     0.458333\n",
      "Throat                   0.777778\n",
      "Vascular                      NaN\n",
      "Women' s Health          1.000000\n",
      "Name: Category, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(correct_classification_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27602a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blood                    0.555556\n",
      "Bone health              0.190476\n",
      "COVID                    0.333333\n",
      "Cancer                   0.250000\n",
      "Cardiovascular Health    0.500000\n",
      "Dental Health            1.000000\n",
      "Diabetes                 0.333333\n",
      "Ear                           NaN\n",
      "Eye                      0.111111\n",
      "Fitness                  0.266667\n",
      "General Health           0.176471\n",
      "Hair                     0.500000\n",
      "Men's health             0.333333\n",
      "Mental Health                 NaN\n",
      "Muscles                  0.333333\n",
      "Neurological health      0.111111\n",
      "Skin                     0.541667\n",
      "Throat                   0.222222\n",
      "Vascular                 1.000000\n",
      "Women' s Health               NaN\n",
      "Name: Category, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(misclassification_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ac23d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
