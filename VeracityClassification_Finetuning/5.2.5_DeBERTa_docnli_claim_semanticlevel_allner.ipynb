{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-056e0caec74e8696\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-056e0caec74e8696/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 222.21it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('csv',data_files='dataset_semanticattribution_nerfeatures_split.csv',delimiter=',',column_names=[\"claim\",\"premise\",\"label\",\"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\",\"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\",\"url\", \"entities\",\"entity_map\",\"gold_exp\",\"gem_exp\",\"gem_label\",\"entity_map_ev\",\"entity_ev\",\"split\"],skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e2914c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'gold_exp', 'gem_exp', 'gem_label', 'entity_map_ev', 'entity_ev', 'split'],\n",
       "        num_rows: 2322\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57d56e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'test',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['split']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ce96b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-056e0caec74e8696/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-2a2c42dfce2e5962.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-056e0caec74e8696/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-30c3c2aed9ee6058.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-056e0caec74e8696/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-2aa654a7b533269e.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'gold_exp', 'gem_exp', 'gem_label', 'entity_map_ev', 'entity_ev', 'split'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'gold_exp', 'gem_exp', 'gem_label', 'entity_map_ev', 'entity_ev', 'split'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'gold_exp', 'gem_exp', 'gem_label', 'entity_map_ev', 'entity_ev', 'split'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41f1db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['claim', 'premise', 'label','category','count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat','counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat']\n",
    "all_columns = train_dataset.column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-056e0caec74e8696/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-028471e2a2bfb5ad.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-056e0caec74e8696/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-0344ef8596cd0df0.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-056e0caec74e8696/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-14ae10d3bdd00042.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 1, 'entailment': 0, 'neutral': 1}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 1,\n",
    "    \"entailment\": 0,\n",
    "    \"neutral\": 1\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='MoritzLaurer/DeBERTa-v3-base-mnli-fever-docnli-ling-2c'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "        # Extracting claim and evidence texts\n",
    "        category = item['category']\n",
    "\n",
    "        claim = item['claim'].lower() + \"[\" + category + \"]\"\n",
    "        premise = item['premise'].lower().replace('\\n', '').replace('[','').replace(']','')\n",
    "        \n",
    "        additional_features = [\n",
    "            \"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\"]\n",
    "    \n",
    "        for feature in additional_features:\n",
    "            if feature in item:\n",
    "                claim += \"[SEP]\" + str(item[feature])\n",
    "        \n",
    "        additional_features_ev = [\n",
    "            'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat']\n",
    "    \n",
    "        for feature_ev in additional_features_ev:\n",
    "            if feature_ev in item:\n",
    "                premise += \"[SEP]\" + str(item[feature])\n",
    "        item['claim']=claim\n",
    "        item['premise']=premise        \n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "             premise, claim,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "        item['input_ids'] = inputs['input_ids'].squeeze()  # Remove batch dimension\n",
    "        item['attention_mask']= inputs['attention_mask'].squeeze() # Remove batch dimension\n",
    "        \n",
    "        output_item = {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),  # Remove batch dimension\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),  # Remove batch dimension\n",
    "            'claim': claim,  # Include augmented claim text\n",
    "            'evidences': premise  # Include original evidence text\n",
    "        }\n",
    "        \n",
    "        if 'label' in item:\n",
    "            output_item['label'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return output_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62421eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DebertaV2ForSequenceClassification(\n",
       "  (deberta): DebertaV2Model(\n",
       "    (embeddings): DebertaV2Embeddings(\n",
       "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaV2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (1): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (2): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (3): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (4): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (5): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (6): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (7): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (8): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (9): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (10): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (11): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (pooler): ContextPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): StableDropout()\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): StableDropout()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"MoritzLaurer/DeBERTa-v3-base-mnli-fever-docnli-ling-2c\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=2, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    bal_accuracy = balanced_accuracy_score(labels,preds)\n",
    "\n",
    "    return {\"accuracy\": acc, \"balanced_accuracy\":bal_accuracy, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17c5e0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([     1,   2600,   1655,  16876,    667,  15726,  61593,    261,   2030,\n",
       "            260,    346,  15302,   6848,  15726,  61593,    261,    584,    260,\n",
       "            346,  33770,    452,  15726,  61593,  16876,    667,  15726,  61593,\n",
       "            261,    845,    260,    346,  14033,   2179,  24360,  34984,  15726,\n",
       "          61593,    261,   1917,    260,    346,  51194,  73907,   8007,  15726,\n",
       "          61593,    261,   2673,    260,    346,   1942,   3359,  73907,   8007,\n",
       "          15726,  61593,    261,   4402,    260,  88609,    263,  98237,   1830,\n",
       "           6725,    263,   5134,  30055,  77487,    532,   4014,    271,    547,\n",
       "          52263,  16224,    265,  86207,  14178,    268,    260,  62713,   4379,\n",
       "            261,    584,    260,  41529,  23399,    429,   8068,   1068,    268,\n",
       "            265,  42543,    834,   1917, 110269,    287,    260, 116367,   2148,\n",
       "            263,  25348,  20413,   1563,    265,    917,    263,    308,    266,\n",
       "          84530,  62542,    275,  98237,    287,    549,   6177,  65073,  44845,\n",
       "          22317,    285,  36774,    260,  30689,   6725,    294,   6162,   2731,\n",
       "            270,   1158,    599,    260,  46362,  41546,  71547,    261,   2030,\n",
       "            260,    346,  10918,    436,  80984,    261,   2285,    260,    346,\n",
       "            266,  46177,  28220,    261,   4402,    260,    346,  56545,  15150,\n",
       "            261,   2673,    260,    346,  95311,    261,   1917,    260,  54761,\n",
       "           1856,    293,   1008,    633,    294,   2285,    260,  98237,    452,\n",
       "           1080,   4796,  18839,    260,   5720,   4765,  39151,    261,   3638,\n",
       "            260,    346,  11965,   4765,  39151,    261,   1550,    260,    346,\n",
       "          11965,   4765,  39151,    261,   1917,    260,    346,  93607,  60641,\n",
       "            261,   1917,    260,  88609,    287,  15726,   2209,   5858,  25499,\n",
       "           3004,   3638,  27197,    318,  58813,  15726,    198,    133,   5900,\n",
       "            346,    260,  43427,    285,    294,    292,    262,   1857,    265,\n",
       "           1471,   1567,    264,    262,   2626,  41529,  28479,    270,    262,\n",
       "           5937,    263,   1035,    265,   1721,   4253,    260,  35753,    263,\n",
       "         121470,   1506,    265,  88609,   1080,    260,  99352,    268,   4086,\n",
       "          75371,   4191,   2767,  15808,    260,    346,  62510,    261,    865,\n",
       "            260,  88609,    263,  98237,    283,  11882,    267,    572,    260,\n",
       "              2,    767,      2,    767,      2,    767,      2,    767,      2,\n",
       "            767,      2,    767,      2,    767,      2,    767,      2,    767,\n",
       "              2,    767,      2,    767,      2,    767,      2,  98237,   1830,\n",
       "           1080,    269,   1359,    427,    267,  17847,    633,    264,    408,\n",
       "           1300,    262,   2658,    265,    262,   1158,    260,   2550,  12082,\n",
       "           1516,    592,      2,    767,      2,    767,      2,    767,      2,\n",
       "            767,      2,    767,      2,    767,      2,    767,      2,    767,\n",
       "              2,    767,      2,    767,      2,    767,      2,    767,      2,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'claim': 'myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.[General Health][SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0',\n",
       " 'evidences': '; unkoviä‡, n.; dimkiä‡, i.; janaä‡koviä‡, p.; gavriloviä‡, m.; stanojeviä‡, o.; vukojeviä‡, j. frankincense and myrrh essential oils and burn incense fume against micro-inhabitants of sacral ambients.shameem, i. phytochemical & therapeutic potentials of murr makki (.oxidative stress and immunotoxic effects of lead and their amelioration with myrrh (commiphora molmol) emulsion.essential oils: magical ingredients for skin care.chakravarty, n.; kellogg, c.; alvarez, j.; equils, o.; morgan, m. uv protection by natural products: c. myrrha oil versus sunscreen.hamidpour, r.; hamidpour, s.; hamidpour, m.; shahlari, m. frankincense (ä¹³é¦™ rç” xiä\\x81ng;.species): from the selection of traditional applications to the novel phytotherapy for the prevention and treatment of serious diseases.chemistry and immunomodulatory activity of frankincense oil.compositions containing boswellia extracts.; cooper, e. frankincense and myrrh as remedies in children.[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0',\n",
       " 'label': tensor(0)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1530\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1530' max='1530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1530/1530 12:36, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.508300</td>\n",
       "      <td>0.595460</td>\n",
       "      <td>0.737634</td>\n",
       "      <td>0.684578</td>\n",
       "      <td>0.729775</td>\n",
       "      <td>0.737634</td>\n",
       "      <td>0.731940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.359600</td>\n",
       "      <td>0.647949</td>\n",
       "      <td>0.737634</td>\n",
       "      <td>0.719551</td>\n",
       "      <td>0.747774</td>\n",
       "      <td>0.737634</td>\n",
       "      <td>0.741339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.269100</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.731183</td>\n",
       "      <td>0.714744</td>\n",
       "      <td>0.743251</td>\n",
       "      <td>0.731183</td>\n",
       "      <td>0.735435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.107700</td>\n",
       "      <td>1.186982</td>\n",
       "      <td>0.763441</td>\n",
       "      <td>0.732120</td>\n",
       "      <td>0.763441</td>\n",
       "      <td>0.763441</td>\n",
       "      <td>0.763441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>0.954238</td>\n",
       "      <td>0.748387</td>\n",
       "      <td>0.695921</td>\n",
       "      <td>0.740840</td>\n",
       "      <td>0.748387</td>\n",
       "      <td>0.742635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.049800</td>\n",
       "      <td>1.476530</td>\n",
       "      <td>0.735484</td>\n",
       "      <td>0.739599</td>\n",
       "      <td>0.763947</td>\n",
       "      <td>0.735484</td>\n",
       "      <td>0.742320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>2.046816</td>\n",
       "      <td>0.701075</td>\n",
       "      <td>0.700635</td>\n",
       "      <td>0.730530</td>\n",
       "      <td>0.701075</td>\n",
       "      <td>0.708801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>2.145291</td>\n",
       "      <td>0.718280</td>\n",
       "      <td>0.720117</td>\n",
       "      <td>0.747239</td>\n",
       "      <td>0.718280</td>\n",
       "      <td>0.725560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.124743</td>\n",
       "      <td>0.750538</td>\n",
       "      <td>0.735828</td>\n",
       "      <td>0.761524</td>\n",
       "      <td>0.750538</td>\n",
       "      <td>0.754345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>2.298436</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.731083</td>\n",
       "      <td>0.756801</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.746691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.344108</td>\n",
       "      <td>0.746237</td>\n",
       "      <td>0.734289</td>\n",
       "      <td>0.759734</td>\n",
       "      <td>0.746237</td>\n",
       "      <td>0.750656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.405440</td>\n",
       "      <td>0.746237</td>\n",
       "      <td>0.735954</td>\n",
       "      <td>0.760981</td>\n",
       "      <td>0.746237</td>\n",
       "      <td>0.750912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.421618</td>\n",
       "      <td>0.746237</td>\n",
       "      <td>0.735954</td>\n",
       "      <td>0.760981</td>\n",
       "      <td>0.746237</td>\n",
       "      <td>0.750912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.433804</td>\n",
       "      <td>0.746237</td>\n",
       "      <td>0.735954</td>\n",
       "      <td>0.760981</td>\n",
       "      <td>0.746237</td>\n",
       "      <td>0.750912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.433465</td>\n",
       "      <td>0.746237</td>\n",
       "      <td>0.735954</td>\n",
       "      <td>0.760981</td>\n",
       "      <td>0.746237</td>\n",
       "      <td>0.750912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.5_deberta_docnli/checkpoint-102\n",
      "Configuration saved in /home/elson/5.2.5_deberta_docnli/checkpoint-102/config.json\n",
      "Model weights saved in /home/elson/5.2.5_deberta_docnli/checkpoint-102/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.2.5_deberta_docnli/checkpoint-1122] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/5.2.5_deberta_docnli/checkpoint-1530] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.5_deberta_docnli/checkpoint-204\n",
      "Configuration saved in /home/elson/5.2.5_deberta_docnli/checkpoint-204/config.json\n",
      "Model weights saved in /home/elson/5.2.5_deberta_docnli/checkpoint-204/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.5_deberta_docnli/checkpoint-306\n",
      "Configuration saved in /home/elson/5.2.5_deberta_docnli/checkpoint-306/config.json\n",
      "Model weights saved in /home/elson/5.2.5_deberta_docnli/checkpoint-306/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.2.5_deberta_docnli/checkpoint-204] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.5_deberta_docnli/checkpoint-408\n",
      "Configuration saved in /home/elson/5.2.5_deberta_docnli/checkpoint-408/config.json\n",
      "Model weights saved in /home/elson/5.2.5_deberta_docnli/checkpoint-408/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.2.5_deberta_docnli/checkpoint-102] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/5.2.5_deberta_docnli/checkpoint-306] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.5_deberta_docnli/checkpoint-510\n",
      "Configuration saved in /home/elson/5.2.5_deberta_docnli/checkpoint-510/config.json\n",
      "Model weights saved in /home/elson/5.2.5_deberta_docnli/checkpoint-510/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.5_deberta_docnli/checkpoint-612\n",
      "Configuration saved in /home/elson/5.2.5_deberta_docnli/checkpoint-612/config.json\n",
      "Model weights saved in /home/elson/5.2.5_deberta_docnli/checkpoint-612/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.2.5_deberta_docnli/checkpoint-510] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.5_deberta_docnli/checkpoint-714\n",
      "Configuration saved in /home/elson/5.2.5_deberta_docnli/checkpoint-714/config.json\n",
      "Model weights saved in /home/elson/5.2.5_deberta_docnli/checkpoint-714/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.2.5_deberta_docnli/checkpoint-612] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.5_deberta_docnli/checkpoint-816\n",
      "Configuration saved in /home/elson/5.2.5_deberta_docnli/checkpoint-816/config.json\n",
      "Model weights saved in /home/elson/5.2.5_deberta_docnli/checkpoint-816/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.2.5_deberta_docnli/checkpoint-714] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.5_deberta_docnli/checkpoint-918\n",
      "Configuration saved in /home/elson/5.2.5_deberta_docnli/checkpoint-918/config.json\n",
      "Model weights saved in /home/elson/5.2.5_deberta_docnli/checkpoint-918/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.2.5_deberta_docnli/checkpoint-816] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.5_deberta_docnli/checkpoint-1020\n",
      "Configuration saved in /home/elson/5.2.5_deberta_docnli/checkpoint-1020/config.json\n",
      "Model weights saved in /home/elson/5.2.5_deberta_docnli/checkpoint-1020/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.2.5_deberta_docnli/checkpoint-918] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.5_deberta_docnli/checkpoint-1122\n",
      "Configuration saved in /home/elson/5.2.5_deberta_docnli/checkpoint-1122/config.json\n",
      "Model weights saved in /home/elson/5.2.5_deberta_docnli/checkpoint-1122/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.2.5_deberta_docnli/checkpoint-1020] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.5_deberta_docnli/checkpoint-1224\n",
      "Configuration saved in /home/elson/5.2.5_deberta_docnli/checkpoint-1224/config.json\n",
      "Model weights saved in /home/elson/5.2.5_deberta_docnli/checkpoint-1224/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.2.5_deberta_docnli/checkpoint-1122] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.5_deberta_docnli/checkpoint-1326\n",
      "Configuration saved in /home/elson/5.2.5_deberta_docnli/checkpoint-1326/config.json\n",
      "Model weights saved in /home/elson/5.2.5_deberta_docnli/checkpoint-1326/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.2.5_deberta_docnli/checkpoint-1224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.5_deberta_docnli/checkpoint-1428\n",
      "Configuration saved in /home/elson/5.2.5_deberta_docnli/checkpoint-1428/config.json\n",
      "Model weights saved in /home/elson/5.2.5_deberta_docnli/checkpoint-1428/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.2.5_deberta_docnli/checkpoint-1326] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.5_deberta_docnli/checkpoint-1530\n",
      "Configuration saved in /home/elson/5.2.5_deberta_docnli/checkpoint-1530/config.json\n",
      "Model weights saved in /home/elson/5.2.5_deberta_docnli/checkpoint-1530/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.2.5_deberta_docnli/checkpoint-1428] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/elson/5.2.5_deberta_docnli/checkpoint-408 (score: 0.7634408602150538).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /home/elson/5.2.5_deberta_docnli/best_model/config.json\n",
      "Model weights saved in /home/elson/5.2.5_deberta_docnli/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/5.2.5_deberta_docnli/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/5.2.5_deberta_docnli/best_model/special_tokens_map.json\n",
      "added tokens file saved in /home/elson/5.2.5_deberta_docnli/best_model/added_tokens.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/5.2.5_deberta_docnli/best_model/tokenizer_config.json',\n",
       " '/home/elson/5.2.5_deberta_docnli/best_model/special_tokens_map.json',\n",
       " '/home/elson/5.2.5_deberta_docnli/best_model/spm.model',\n",
       " '/home/elson/5.2.5_deberta_docnli/best_model/added_tokens.json')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/5.2.5_deberta_docnli/',\n",
    "    num_train_epochs=15,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.06,\n",
    "    weight_decay=0.1,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/5.2.5_deberta_docnli/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/5.2.5_deberta_docnli/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63deaea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/5.2.5_deberta_docnli/best_model/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"/home/elson/5.2.5_deberta_docnli/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"entailment\",\n",
      "    \"1\": \"not_entailment\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"entailment\": 0,\n",
      "    \"not_entailment\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file /home/elson/5.2.5_deberta_docnli/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at /home/elson/5.2.5_deberta_docnli/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 16\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/5.2.5_deberta_docnli/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[ 1.912 , -1.824 ],\n",
      "       [ 3.521 , -3.354 ],\n",
      "       [ 3.363 , -3.195 ],\n",
      "       [-3.568 ,  3.732 ],\n",
      "       [ 1.161 , -1.107 ],\n",
      "       [ 4.02  , -3.814 ],\n",
      "       [ 3.979 , -3.781 ],\n",
      "       [ 4.402 , -4.164 ],\n",
      "       [ 3.506 , -3.336 ],\n",
      "       [ 0.2537, -0.2386],\n",
      "       [ 4.21  , -3.99  ],\n",
      "       [ 4.383 , -4.152 ],\n",
      "       [-2.748 ,  2.95  ],\n",
      "       [ 4.375 , -4.14  ],\n",
      "       [ 3.768 , -3.582 ],\n",
      "       [-2.105 ,  2.295 ],\n",
      "       [ 3.797 , -3.611 ],\n",
      "       [ 3.594 , -3.418 ],\n",
      "       [ 4.418 , -4.184 ],\n",
      "       [ 4.004 , -3.803 ],\n",
      "       [-0.4023,  0.3967],\n",
      "       [ 2.969 , -2.826 ],\n",
      "       [ 2.84  , -2.72  ],\n",
      "       [-3.246 ,  3.43  ],\n",
      "       [ 2.664 , -2.553 ],\n",
      "       [-3.584 ,  3.748 ],\n",
      "       [ 4.383 , -4.15  ],\n",
      "       [ 3.623 , -3.445 ],\n",
      "       [ 4.195 , -3.979 ],\n",
      "       [ 4.477 , -4.234 ],\n",
      "       [ 0.788 , -0.759 ],\n",
      "       [ 3.986 , -3.787 ],\n",
      "       [ 3.48  , -3.314 ],\n",
      "       [ 2.639 , -2.525 ],\n",
      "       [ 2.441 , -2.322 ],\n",
      "       [ 3.844 , -3.656 ],\n",
      "       [-1.421 ,  1.604 ],\n",
      "       [ 3.926 , -3.73  ],\n",
      "       [-2.713 ,  2.9   ],\n",
      "       [ 3.273 , -3.125 ],\n",
      "       [-2.908 ,  3.086 ],\n",
      "       [ 4.598 , -4.344 ],\n",
      "       [ 2.88  , -2.756 ],\n",
      "       [-2.307 ,  2.496 ],\n",
      "       [ 0.4663, -0.4397],\n",
      "       [ 3.578 , -3.406 ],\n",
      "       [ 3.893 , -3.701 ],\n",
      "       [ 3.025 , -2.883 ],\n",
      "       [ 4.215 , -3.992 ],\n",
      "       [-3.658 ,  3.816 ],\n",
      "       [ 0.658 , -0.628 ],\n",
      "       [ 1.924 , -1.846 ],\n",
      "       [-2.92  ,  3.107 ],\n",
      "       [ 1.921 , -1.846 ],\n",
      "       [ 1.565 , -1.503 ],\n",
      "       [ 4.15  , -3.936 ],\n",
      "       [-3.934 ,  4.09  ],\n",
      "       [ 3.822 , -3.635 ],\n",
      "       [ 3.113 , -2.979 ],\n",
      "       [ 4.223 , -3.998 ],\n",
      "       [ 3.826 , -3.64  ],\n",
      "       [-3.191 ,  3.355 ],\n",
      "       [ 2.713 , -2.588 ],\n",
      "       [-0.549 ,  0.5137],\n",
      "       [ 3.303 , -3.148 ],\n",
      "       [ 3.98  , -3.785 ],\n",
      "       [ 4.082 , -3.877 ],\n",
      "       [ 4.266 , -4.043 ],\n",
      "       [ 4.176 , -3.959 ],\n",
      "       [ 2.938 , -2.809 ],\n",
      "       [ 4.17  , -3.947 ],\n",
      "       [ 2.826 , -2.705 ],\n",
      "       [ 2.977 , -2.846 ],\n",
      "       [ 3.54  , -3.371 ],\n",
      "       [ 2.469 , -2.363 ],\n",
      "       [ 2.283 , -2.178 ],\n",
      "       [ 4.164 , -3.95  ],\n",
      "       [ 4.08  , -3.873 ],\n",
      "       [ 4.523 , -4.273 ],\n",
      "       [ 2.615 , -2.5   ],\n",
      "       [ 4.21  , -3.99  ],\n",
      "       [ 4.28  , -4.06  ],\n",
      "       [ 3.158 , -3.004 ],\n",
      "       [ 3.826 , -3.635 ],\n",
      "       [ 3.875 , -3.684 ],\n",
      "       [ 2.75  , -2.627 ],\n",
      "       [ 4.207 , -3.986 ],\n",
      "       [ 3.283 , -3.129 ],\n",
      "       [ 3.16  , -3.012 ],\n",
      "       [ 3.525 , -3.357 ],\n",
      "       [ 3.58  , -3.4   ],\n",
      "       [ 4.05  , -3.844 ],\n",
      "       [-2.49  ,  2.684 ],\n",
      "       [ 3.734 , -3.55  ],\n",
      "       [-1.461 ,  1.656 ],\n",
      "       [ 0.4978, -0.483 ],\n",
      "       [ 2.945 , -2.812 ],\n",
      "       [ 2.486 , -2.389 ],\n",
      "       [ 4.152 , -3.938 ],\n",
      "       [ 4.145 , -3.93  ],\n",
      "       [-3.432 ,  3.6   ],\n",
      "       [ 4.215 , -3.998 ],\n",
      "       [ 3.584 , -3.412 ],\n",
      "       [ 3.322 , -3.17  ],\n",
      "       [ 3.77  , -3.578 ],\n",
      "       [ 3.873 , -3.682 ],\n",
      "       [ 3.88  , -3.688 ],\n",
      "       [-4.4   ,  4.55  ],\n",
      "       [ 4.004 , -3.803 ],\n",
      "       [ 4.027 , -3.82  ],\n",
      "       [ 1.437 , -1.388 ],\n",
      "       [ 4.633 , -4.375 ],\n",
      "       [ 3.66  , -3.484 ],\n",
      "       [ 4.113 , -3.902 ],\n",
      "       [ 3.283 , -3.133 ],\n",
      "       [ 3.83  , -3.64  ],\n",
      "       [ 4.45  , -4.21  ],\n",
      "       [ 2.6   , -2.488 ],\n",
      "       [ 4.336 , -4.1   ],\n",
      "       [ 3.943 , -3.748 ],\n",
      "       [ 3.72  , -3.541 ],\n",
      "       [ 3.549 , -3.379 ],\n",
      "       [ 3.955 , -3.756 ],\n",
      "       [ 3.07  , -2.928 ],\n",
      "       [ 4.05  , -3.846 ],\n",
      "       [ 4.223 , -4.004 ],\n",
      "       [ 3.432 , -3.262 ],\n",
      "       [ 4.426 , -4.184 ],\n",
      "       [ 3.996 , -3.79  ],\n",
      "       [ 0.773 , -0.7734],\n",
      "       [ 2.871 , -2.746 ],\n",
      "       [ 1.3   , -1.251 ],\n",
      "       [ 3.898 , -3.705 ],\n",
      "       [ 3.086 , -2.95  ],\n",
      "       [ 1.211 , -1.169 ],\n",
      "       [-2.82  ,  3.002 ],\n",
      "       [ 2.76  , -2.639 ],\n",
      "       [-4.113 ,  4.266 ],\n",
      "       [-2.178 ,  2.385 ],\n",
      "       [ 3.209 , -3.057 ],\n",
      "       [ 3.695 , -3.518 ],\n",
      "       [ 2.316 , -2.223 ],\n",
      "       [ 1.8   , -1.73  ],\n",
      "       [ 4.344 , -4.117 ],\n",
      "       [-0.911 ,  1.004 ],\n",
      "       [ 1.422 , -1.367 ],\n",
      "       [-2.361 ,  2.547 ],\n",
      "       [ 1.495 , -1.442 ],\n",
      "       [ 4.617 , -4.36  ],\n",
      "       [ 1.85  , -1.773 ],\n",
      "       [-1.173 ,  1.245 ],\n",
      "       [ 3.42  , -3.25  ],\n",
      "       [ 4.562 , -4.312 ],\n",
      "       [ 2.938 , -2.805 ],\n",
      "       [ 3.578 , -3.406 ],\n",
      "       [ 4.445 , -4.203 ],\n",
      "       [ 3.814 , -3.62  ],\n",
      "       [-3.52  ,  3.693 ],\n",
      "       [ 3.475 , -3.316 ],\n",
      "       [-2.727 ,  2.91  ],\n",
      "       [-3.867 ,  4.016 ],\n",
      "       [-3.562 ,  3.727 ],\n",
      "       [ 4.16  , -3.947 ],\n",
      "       [-1.644 ,  1.855 ],\n",
      "       [ 1.996 , -1.92  ],\n",
      "       [-0.98  ,  1.124 ],\n",
      "       [ 3.947 , -3.744 ],\n",
      "       [ 0.7915, -0.764 ],\n",
      "       [-0.485 ,  0.508 ],\n",
      "       [ 3.525 , -3.36  ],\n",
      "       [-3.795 ,  3.945 ],\n",
      "       [ 3.52  , -3.355 ],\n",
      "       [-4.047 ,  4.203 ],\n",
      "       [ 4.195 , -3.98  ],\n",
      "       [ 4.086 , -3.875 ],\n",
      "       [-0.6895,  0.704 ],\n",
      "       [ 3.574 , -3.395 ],\n",
      "       [ 3.268 , -3.117 ],\n",
      "       [ 4.062 , -3.861 ],\n",
      "       [ 2.041 , -1.962 ],\n",
      "       [-1.752 ,  1.959 ],\n",
      "       [-0.6997,  0.759 ],\n",
      "       [-2.525 ,  2.719 ],\n",
      "       [ 2.502 , -2.383 ],\n",
      "       [ 1.914 , -1.829 ],\n",
      "       [ 4.48  , -4.24  ],\n",
      "       [ 4.125 , -3.912 ],\n",
      "       [ 3.146 , -3.004 ],\n",
      "       [-1.203 ,  1.272 ],\n",
      "       [ 4.035 , -3.83  ],\n",
      "       [ 3.191 , -3.045 ],\n",
      "       [ 2.75  , -2.627 ],\n",
      "       [ 3.959 , -3.758 ],\n",
      "       [ 1.874 , -1.795 ],\n",
      "       [-2.826 ,  3.01  ],\n",
      "       [ 4.39  , -4.156 ],\n",
      "       [ 2.043 , -1.956 ],\n",
      "       [ 3.787 , -3.598 ],\n",
      "       [ 0.889 , -0.855 ],\n",
      "       [ 3.432 , -3.273 ],\n",
      "       [ 4.05  , -3.848 ],\n",
      "       [ 3.941 , -3.746 ],\n",
      "       [ 2.945 , -2.803 ],\n",
      "       [ 4.133 , -3.92  ],\n",
      "       [ 2.293 , -2.186 ],\n",
      "       [-3.188 ,  3.365 ],\n",
      "       [ 4.38  , -4.14  ],\n",
      "       [ 1.928 , -1.849 ],\n",
      "       [ 4.297 , -4.07  ],\n",
      "       [ 0.58  , -0.5615],\n",
      "       [ 0.6455, -0.6147],\n",
      "       [-0.5723,  0.574 ],\n",
      "       [ 4.41  , -4.17  ],\n",
      "       [ 3.646 , -3.469 ],\n",
      "       [ 3.998 , -3.795 ],\n",
      "       [ 1.275 , -1.23  ],\n",
      "       [ 2.818 , -2.693 ],\n",
      "       [ 2.797 , -2.672 ],\n",
      "       [ 4.324 , -4.094 ],\n",
      "       [ 3.68  , -3.502 ],\n",
      "       [ 4.31  , -4.082 ],\n",
      "       [ 3.74  , -3.559 ],\n",
      "       [ 2.082 , -1.99  ],\n",
      "       [ 4.63  , -4.37  ],\n",
      "       [ 3.32  , -3.164 ],\n",
      "       [ 3.69  , -3.514 ],\n",
      "       [ 4.15  , -3.936 ],\n",
      "       [-3.357 ,  3.53  ],\n",
      "       [-2.3   ,  2.506 ],\n",
      "       [ 1.027 , -0.9937],\n",
      "       [ 3.857 , -3.666 ],\n",
      "       [ 3.705 , -3.527 ],\n",
      "       [ 4.08  , -3.873 ],\n",
      "       [-0.4697,  0.4634]], dtype=float16), label_ids=array([0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
      "       0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
      "       0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1,\n",
      "       0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "       1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "       0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
      "       0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "       0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
      "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
      "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1]), metrics={'test_loss': 1.6436936855316162, 'test_accuracy': 0.7094017094017094, 'test_balanced_accuracy': 0.6310540173940796, 'test_precision': 0.7008094785872563, 'test_recall': 0.7094017094017094, 'test_f1': 0.6825053418803418, 'test_runtime': 2.3583, 'test_samples_per_second': 99.222, 'test_steps_per_second': 6.36})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73395d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "probabilities = torch.softmax(torch.tensor(test_results.predictions).to(torch.float32), dim=-1)\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)\n",
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb603377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_save = []\n",
    "for idx in range(len(test_data)):\n",
    "    item = dataset['test'][idx]\n",
    "    actual_label = item['label']\n",
    "    predicted_label = predictions[idx]\n",
    "    claim = item['claim'] \n",
    "    premise = item['premise'] \n",
    "    category = item['category']\n",
    "    \n",
    "    # Append the information as a dictionary to the list\n",
    "    data_to_save.append({\n",
    "        'Claim': claim,\n",
    "        'Premise': premise,\n",
    "        'Actual Label': actual_label,\n",
    "        'Predicted Label': predicted_label,\n",
    "        'Category' : category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_to_save)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/home/elson/results/5.2.5_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c23339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correctly classified instances\n",
    "correctly_classified = df[df['Actual Label'] == df['Predicted Label']]\n",
    "\n",
    "# Calculate misclassified instances\n",
    "misclassified = df[df['Actual Label'] != df['Predicted Label']]\n",
    "\n",
    "# Count the number of correctly classified and misclassified by category\n",
    "correct_classification_counts = correctly_classified['Category'].value_counts()\n",
    "misclassification_counts = misclassified['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca0def77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           37\n",
       "Bone health              15\n",
       "Cancer                   12\n",
       "Diabetes                 11\n",
       "Cardiovascular Health    11\n",
       "Fitness                  10\n",
       "Throat                    9\n",
       "Neurological health       9\n",
       "Skin                      8\n",
       "COVID                     6\n",
       "Ear                       6\n",
       "Hair                      6\n",
       "Eye                       6\n",
       "Women' s Health           5\n",
       "Muscles                   5\n",
       "Blood                     4\n",
       "Men's health              3\n",
       "Mental Health             2\n",
       "Vascular                  1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0fddd944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Skin                     16\n",
       "General Health           14\n",
       "Bone health               6\n",
       "Hair                      6\n",
       "Fitness                   5\n",
       "Blood                     5\n",
       "Eye                       3\n",
       "Men's health              3\n",
       "Dental Health             3\n",
       "Vascular                  2\n",
       "Diabetes                  1\n",
       "Mental Health             1\n",
       "Women' s Health           1\n",
       "Muscles                   1\n",
       "Cardiovascular Health     1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38b899b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_counts = df['Category'].value_counts()\n",
    "\n",
    "# Calculate ratios\n",
    "correct_classification_ratios = correct_classification_counts / total_counts\n",
    "misclassification_ratios = misclassification_counts / total_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c3598b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blood                    0.444444\n",
      "Bone health              0.714286\n",
      "COVID                    1.000000\n",
      "Cancer                   1.000000\n",
      "Cardiovascular Health    0.916667\n",
      "Dental Health                 NaN\n",
      "Diabetes                 0.916667\n",
      "Ear                      1.000000\n",
      "Eye                      0.666667\n",
      "Fitness                  0.666667\n",
      "General Health           0.725490\n",
      "Hair                     0.500000\n",
      "Men's health             0.500000\n",
      "Mental Health            0.666667\n",
      "Muscles                  0.833333\n",
      "Neurological health      1.000000\n",
      "Skin                     0.333333\n",
      "Throat                   1.000000\n",
      "Vascular                 0.333333\n",
      "Women' s Health          0.833333\n",
      "Name: Category, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(correct_classification_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27602a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blood                    0.555556\n",
      "Bone health              0.285714\n",
      "COVID                         NaN\n",
      "Cancer                        NaN\n",
      "Cardiovascular Health    0.083333\n",
      "Dental Health            1.000000\n",
      "Diabetes                 0.083333\n",
      "Ear                           NaN\n",
      "Eye                      0.333333\n",
      "Fitness                  0.333333\n",
      "General Health           0.274510\n",
      "Hair                     0.500000\n",
      "Men's health             0.500000\n",
      "Mental Health            0.333333\n",
      "Muscles                  0.166667\n",
      "Neurological health           NaN\n",
      "Skin                     0.666667\n",
      "Throat                        NaN\n",
      "Vascular                 0.666667\n",
      "Women' s Health          0.166667\n",
      "Name: Category, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(misclassification_ratios)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
