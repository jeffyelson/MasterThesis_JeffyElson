{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score,balanced_accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82806f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jul 30 19:26:48 2024       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:61:00.0 Off |                    0 |\r\n",
      "| N/A   45C    P0    57W / 300W |  16713MiB / 32768MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla V100-SXM2...  Off  | 00000000:62:00.0 Off |                    0 |\r\n",
      "| N/A   45C    P0    58W / 300W |  15162MiB / 32768MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   2  Tesla V100-SXM2...  Off  | 00000000:89:00.0 Off |                    0 |\r\n",
      "| N/A   44C    P0    61W / 300W |      0MiB / 32768MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   3  Tesla V100-SXM2...  Off  | 00000000:8A:00.0 Off |                    0 |\r\n",
      "| N/A   44C    P0    59W / 300W |      0MiB / 32768MiB |      2%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A     24885      C   ...son/factcheck/bin/python3    15159MiB |\r\n",
      "|    0   N/A  N/A     34177      C   ...son/factcheck/bin/python3     1551MiB |\r\n",
      "|    1   N/A  N/A     24305      C   ...son/factcheck/bin/python3    15159MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-31dfe7adddcf5ced\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 138.79it/s]\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-ad71be204b279b28.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-e7b6b615907c24ca.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-bee802838a3bfaea.arrow\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset from the CSV file\n",
    "dataset = load_dataset(\n",
    "    'csv',\n",
    "    data_files='dataset_semanticattribution_nerfeatures_split.csv',\n",
    "    delimiter=',',\n",
    "    column_names=[\n",
    "        \"claim\", \"premise\", \"label\", \"category\", \"count_bf\", \"count_ca\", \"count_dis\",\n",
    "        \"count_food\", \"count_lipid\", \"count_treat\", \"pres_bf\", \"pres_ca\", \"pres_dis\",\n",
    "        \"pres_food\", \"pres_lipid\", \"pres_treat\", \"counte_bf\", \"counte_ca\", \"counte_dis\",\n",
    "        \"counte_food\", \"counte_lipid\", \"counte_treat\", \"prese_bf\", \"prese_ca\", \"prese_dis\",\n",
    "        \"prese_food\", \"prese_lipid\", \"prese_treat\", \"url\", \"entities\", \"entity_map\",\n",
    "        \"gold_exp\", \"gemini_exp\", \"gemini_label\",\"entity_ev\",\"entity_map_ev\", \"split\"\n",
    "    ],\n",
    "    skiprows=1\n",
    ")\n",
    "\n",
    "# Assuming 'split' column contains strings 'train', 'validation', 'test'\n",
    "# Filter the loaded dataset into subsets\n",
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'gold_exp', 'gemini_exp', 'gemini_label', 'entity_ev', 'entity_map_ev', 'split'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f3e71be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41f1db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['claim', 'premise', 'label','category','counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat']\n",
    "all_columns = train_dataset.column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-192f7cd55308f437.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-628e09c96e321cd1.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-1df942f735662e2b.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 0, 'entailment': 1, 'neutral': 2}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 0,\n",
    "    \"entailment\": 1,\n",
    "    \"neutral\": 2\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b5bb17f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "465"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['val']['claim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='bioformers/bioformer-8L-mnli'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "        # Extracting claim and evidence texts\n",
    "\n",
    "        claim = item['claim']\n",
    "        premise = item['premise'].replace('\\n', '').replace('[','').replace(']','')\n",
    "        additional_features = [\n",
    "            'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat']\n",
    "    \n",
    "        for feature in additional_features:\n",
    "            if feature in item:\n",
    "                premise += \"[SEP]\" + str(item[feature])\n",
    "        item['claim']=claim\n",
    "        item['premise']=premise        \n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "             premise, claim,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "        item['input_ids'] = inputs['input_ids'].squeeze()  # Remove batch dimension\n",
    "        item['attention_mask']= inputs['attention_mask'].squeeze() # Remove batch dimension\n",
    "        \n",
    "        output_item = {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),  # Remove batch dimension\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),  # Remove batch dimension\n",
    "            'claim': claim,  # Include augmented claim text\n",
    "            'evidences': premise  # Include original evidence text\n",
    "        }\n",
    "        \n",
    "        if 'label' in item:\n",
    "            output_item['label'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return output_item\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62421eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bioformers/bioformer-8L-mnli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=3, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f72c5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model is on device: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    bal_accuracy = balanced_accuracy_score(labels,preds)\n",
    "\n",
    "    return {\"accuracy\": acc, \"balanced_accuracy\":bal_accuracy, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17c5e0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  101,   132,   100,   336,   117,   151,   119,   132,   100,   336,\n",
       "           117,   146,   119,   132,   100,   336,   100,   336,   117,   153,\n",
       "           119,   132,   100,   336,   117,   150,   119,   132,   100,   336,\n",
       "           117,   152,   119,   132,   100,   336,   117,   147,   119, 26248,\n",
       "          2848,  9507,  1111,  1435,  2573,  1109,  4258,  3720, 15658,  1435,\n",
       "          8619,  1544,  3670, 13976,  1111,  2782,  2110,   118, 21901,  1431,\n",
       "         24417, 11643,  1113,   119, 26904,  4910,  1121,   117,   146,   119,\n",
       "         23293,  3919,   111,  3131,  8132,  1431, 24011,  1109,  2067,  1137,\n",
       "         14997,   113,   119, 21770,  2543,  1435, 10270,  5097, 30192,  1115,\n",
       "          1990,  1431,  2387,  1435,  1785, 28458,  1461,  2573,  1109,  4258,\n",
       "           113, 24383,  6169,  9565,  6814,  8952,   114, 18260,   119, 31651,\n",
       "           152,  4661,   131, 28447,  1527, 25714,  3062,  5642,  1471, 19601,\n",
       "          9248,   119, 23525, 26279, 17196,  1109,  2534,   117,   151,   119,\n",
       "           132, 11860,  3141,  1518,  1138,   117,   140,   119,   132,  1999,\n",
       "         23576, 14015,   117,   147,   119,   132, 11349,  4661,   117,   152,\n",
       "           119,   132,  9738,  2287,   117,   150,   119,  5959, 23114,  1520,\n",
       "         19077, 24358,  1481,   131,   140,   119,  2573,  1109,  4258,  1118,\n",
       "           152,  1473, 27495,  1463, 21906, 12695, 22906,   119, 31992,  1462,\n",
       "         12488,  1452,   117,   155,   119,   132, 31992,  1462, 12488,  1452,\n",
       "           117,   156,   119,   132, 31992,  1462, 12488,  1452,   117,   150,\n",
       "           119,   132, 25473, 22952,  1699,   117,   150,   119, 26248,  2848,\n",
       "          9507,  1111,   113,   100,   100,   333,   100,   132,   119,  2439,\n",
       "           114,   131,  5299,  1425,  4115,  1431,  5329,  4647,  1446,  1425,\n",
       "          3036, 20924, 17338,  1471,  1425,  4573,  1435,  1786,  1431,  5876,\n",
       "          3054,   119, 12459,  4503,  1435, 16228,  1950,  1431,  2132,  4765,\n",
       "          2848,  9507,  1111,  6187,   119,  6784,  3108,  1113,  3264, 27579,\n",
       "         15864,  1619,  6688,   119,   132,  3985,  2565,   117,   142,   119,\n",
       "         26248,  2848,  9507,  1111,  1435,  2573,  1109,  4258,  1475, 14868,\n",
       "          1559,  1427,  2409,   119,   102,   121,   102,   121,   102,   121,\n",
       "           102,   121,   102,   121,   102,   121,   102,   121,   102,   121,\n",
       "           102,   121,   102,   121,   102,   121,   102,   121,   102, 31487,\n",
       "          4258,  3720,  6187,  1478,  8811,  1822,  1427,  3550,  5183,  4030,\n",
       "          1446,  3346,  2520,  1425,  6875,  1431,  1425,  3550,   119,   102,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'claim': 'Myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.',\n",
       " 'evidences': '; UnkoviÄ‡, N.; DimkiÄ‡, I.; JanaÄ‡koviÄ‡, P.; GavriloviÄ‡, M.; StanojeviÄ‡, O.; VukojeviÄ‡, J. Frankincense and myrrh essential oils and burn incense fume against micro-inhabitants of sacral ambients.Shameem, I. Phytochemical & therapeutic potentials of Murr makki (.Oxidative stress and immunotoxic effects of lead and their amelioration with myrrh (Commiphora molmol) emulsion.Essential Oils: Magical Ingredients for Skin Care.Chakravarty, N.; Kellogg, C.; Alvarez, J.; Equils, O.; Morgan, M. UV Protection by Natural Products: C. myrrha Oil Versus Sunscreen.Hamidpour, R.; Hamidpour, S.; Hamidpour, M.; Shahlari, M. Frankincense (ä¹³é¦™ RÇ” XiÄ\\x81ng;.species): From the selection of traditional applications to the novel phytotherapy for the prevention and treatment of serious diseases.Chemistry and immunomodulatory activity of frankincense oil.Compositions containing Boswellia extracts.; Cooper, E. Frankincense and myrrh as remedies in children.[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0',\n",
       " 'label': tensor(1)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on device: cuda:0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='765' max='765' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [765/765 03:00, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.871100</td>\n",
       "      <td>0.848312</td>\n",
       "      <td>0.670968</td>\n",
       "      <td>0.345753</td>\n",
       "      <td>0.521501</td>\n",
       "      <td>0.670968</td>\n",
       "      <td>0.550314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.770600</td>\n",
       "      <td>0.823067</td>\n",
       "      <td>0.630108</td>\n",
       "      <td>0.403366</td>\n",
       "      <td>0.604585</td>\n",
       "      <td>0.630108</td>\n",
       "      <td>0.594492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.920239</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.451702</td>\n",
       "      <td>0.630129</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.639190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.201500</td>\n",
       "      <td>1.204528</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.469634</td>\n",
       "      <td>0.632254</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.637303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.200100</td>\n",
       "      <td>1.488789</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.469664</td>\n",
       "      <td>0.629790</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.637335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.130800</td>\n",
       "      <td>2.001163</td>\n",
       "      <td>0.578495</td>\n",
       "      <td>0.441473</td>\n",
       "      <td>0.606960</td>\n",
       "      <td>0.578495</td>\n",
       "      <td>0.589138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.085700</td>\n",
       "      <td>1.713063</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.476202</td>\n",
       "      <td>0.640035</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.641044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.072100</td>\n",
       "      <td>1.764475</td>\n",
       "      <td>0.640860</td>\n",
       "      <td>0.479522</td>\n",
       "      <td>0.639682</td>\n",
       "      <td>0.640860</td>\n",
       "      <td>0.640268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.063700</td>\n",
       "      <td>1.925736</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.481161</td>\n",
       "      <td>0.638413</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.639325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.042500</td>\n",
       "      <td>2.051055</td>\n",
       "      <td>0.630108</td>\n",
       "      <td>0.462259</td>\n",
       "      <td>0.631206</td>\n",
       "      <td>0.630108</td>\n",
       "      <td>0.629936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.041500</td>\n",
       "      <td>2.205341</td>\n",
       "      <td>0.627957</td>\n",
       "      <td>0.504271</td>\n",
       "      <td>0.651526</td>\n",
       "      <td>0.627957</td>\n",
       "      <td>0.637215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>2.207840</td>\n",
       "      <td>0.619355</td>\n",
       "      <td>0.468340</td>\n",
       "      <td>0.624080</td>\n",
       "      <td>0.619355</td>\n",
       "      <td>0.619739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>2.274359</td>\n",
       "      <td>0.627957</td>\n",
       "      <td>0.487711</td>\n",
       "      <td>0.639334</td>\n",
       "      <td>0.627957</td>\n",
       "      <td>0.631824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.018500</td>\n",
       "      <td>2.221211</td>\n",
       "      <td>0.634409</td>\n",
       "      <td>0.469251</td>\n",
       "      <td>0.626642</td>\n",
       "      <td>0.634409</td>\n",
       "      <td>0.629947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>2.284576</td>\n",
       "      <td>0.632258</td>\n",
       "      <td>0.485707</td>\n",
       "      <td>0.635793</td>\n",
       "      <td>0.632258</td>\n",
       "      <td>0.632322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.2.4_bioformer/checkpoint-51\n",
      "Configuration saved in /home/elson/11.2.4_bioformer/checkpoint-51/config.json\n",
      "Model weights saved in /home/elson/11.2.4_bioformer/checkpoint-51/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.2.4_bioformer/checkpoint-102\n",
      "Configuration saved in /home/elson/11.2.4_bioformer/checkpoint-102/config.json\n",
      "Model weights saved in /home/elson/11.2.4_bioformer/checkpoint-102/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.2.4_bioformer/checkpoint-153\n",
      "Configuration saved in /home/elson/11.2.4_bioformer/checkpoint-153/config.json\n",
      "Model weights saved in /home/elson/11.2.4_bioformer/checkpoint-153/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.2.4_bioformer/checkpoint-102] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.2.4_bioformer/checkpoint-204\n",
      "Configuration saved in /home/elson/11.2.4_bioformer/checkpoint-204/config.json\n",
      "Model weights saved in /home/elson/11.2.4_bioformer/checkpoint-204/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.2.4_bioformer/checkpoint-153] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.2.4_bioformer/checkpoint-255\n",
      "Configuration saved in /home/elson/11.2.4_bioformer/checkpoint-255/config.json\n",
      "Model weights saved in /home/elson/11.2.4_bioformer/checkpoint-255/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.2.4_bioformer/checkpoint-204] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.2.4_bioformer/checkpoint-306\n",
      "Configuration saved in /home/elson/11.2.4_bioformer/checkpoint-306/config.json\n",
      "Model weights saved in /home/elson/11.2.4_bioformer/checkpoint-306/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.2.4_bioformer/checkpoint-255] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.2.4_bioformer/checkpoint-357\n",
      "Configuration saved in /home/elson/11.2.4_bioformer/checkpoint-357/config.json\n",
      "Model weights saved in /home/elson/11.2.4_bioformer/checkpoint-357/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.2.4_bioformer/checkpoint-306] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.2.4_bioformer/checkpoint-408\n",
      "Configuration saved in /home/elson/11.2.4_bioformer/checkpoint-408/config.json\n",
      "Model weights saved in /home/elson/11.2.4_bioformer/checkpoint-408/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.2.4_bioformer/checkpoint-357] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.2.4_bioformer/checkpoint-459\n",
      "Configuration saved in /home/elson/11.2.4_bioformer/checkpoint-459/config.json\n",
      "Model weights saved in /home/elson/11.2.4_bioformer/checkpoint-459/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.2.4_bioformer/checkpoint-408] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.2.4_bioformer/checkpoint-510\n",
      "Configuration saved in /home/elson/11.2.4_bioformer/checkpoint-510/config.json\n",
      "Model weights saved in /home/elson/11.2.4_bioformer/checkpoint-510/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.2.4_bioformer/checkpoint-459] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.2.4_bioformer/checkpoint-561\n",
      "Configuration saved in /home/elson/11.2.4_bioformer/checkpoint-561/config.json\n",
      "Model weights saved in /home/elson/11.2.4_bioformer/checkpoint-561/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.2.4_bioformer/checkpoint-510] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.2.4_bioformer/checkpoint-612\n",
      "Configuration saved in /home/elson/11.2.4_bioformer/checkpoint-612/config.json\n",
      "Model weights saved in /home/elson/11.2.4_bioformer/checkpoint-612/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.2.4_bioformer/checkpoint-561] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.2.4_bioformer/checkpoint-663\n",
      "Configuration saved in /home/elson/11.2.4_bioformer/checkpoint-663/config.json\n",
      "Model weights saved in /home/elson/11.2.4_bioformer/checkpoint-663/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.2.4_bioformer/checkpoint-612] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.2.4_bioformer/checkpoint-714\n",
      "Configuration saved in /home/elson/11.2.4_bioformer/checkpoint-714/config.json\n",
      "Model weights saved in /home/elson/11.2.4_bioformer/checkpoint-714/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.2.4_bioformer/checkpoint-663] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.2.4_bioformer/checkpoint-765\n",
      "Configuration saved in /home/elson/11.2.4_bioformer/checkpoint-765/config.json\n",
      "Model weights saved in /home/elson/11.2.4_bioformer/checkpoint-765/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.2.4_bioformer/checkpoint-714] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/elson/11.2.4_bioformer/checkpoint-51 (score: 0.6709677419354839).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /home/elson/11.2.4_bioformer/best_model/config.json\n",
      "Model weights saved in /home/elson/11.2.4_bioformer/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/11.2.4_bioformer/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/11.2.4_bioformer/best_model/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/11.2.4_bioformer/best_model/tokenizer_config.json',\n",
       " '/home/elson/11.2.4_bioformer/best_model/special_tokens_map.json',\n",
       " '/home/elson/11.2.4_bioformer/best_model/vocab.txt',\n",
       " '/home/elson/11.2.4_bioformer/best_model/added_tokens.json',\n",
       " '/home/elson/11.2.4_bioformer/best_model/tokenizer.json')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/11.2.4_bioformer/',\n",
    "    num_train_epochs=15,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.06,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(\"cuda:0\"),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "print(f\"Model is on device: {next(model.parameters()).device}\")\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/11.2.4_bioformer/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/11.2.4_bioformer/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cdee1665",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/11.2.4_bioformer/best_model/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"/home/elson/11.2.4_bioformer/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"finetuning_task\": \"mnli\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 512,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"entailment\",\n",
      "    \"1\": \"neutral\",\n",
      "    \"2\": \"contradiction\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2048,\n",
      "  \"label2id\": {\n",
      "    \"contradiction\": 2,\n",
      "    \"entailment\": 0,\n",
      "    \"neutral\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 8,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32768\n",
      "}\n",
      "\n",
      "loading weights file /home/elson/11.2.4_bioformer/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at /home/elson/11.2.4_bioformer/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 32\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/11.2.4_bioformer/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[-4.6606e-01,  5.6396e-01, -1.3672e-01],\n",
      "       [-6.5576e-01,  1.1787e+00, -6.3916e-01],\n",
      "       [-6.6553e-01,  9.0234e-01, -3.5181e-01],\n",
      "       [-4.2920e-01,  6.9922e-01, -3.1909e-01],\n",
      "       [ 3.3521e-01,  1.0127e+00, -1.1318e+00],\n",
      "       [-4.1846e-01,  1.5430e+00, -1.0957e+00],\n",
      "       [-1.0040e-01,  3.5571e-01, -1.9897e-01],\n",
      "       [-4.9854e-01,  7.0996e-01, -2.3010e-01],\n",
      "       [ 1.4429e-01,  1.0273e+00, -1.0537e+00],\n",
      "       [-2.6245e-01,  6.8555e-01, -4.5898e-01],\n",
      "       [-9.6191e-02,  1.2725e+00, -1.1182e+00],\n",
      "       [-3.1128e-01,  6.6797e-01, -4.7705e-01],\n",
      "       [-2.1582e-01,  9.7168e-01, -7.0752e-01],\n",
      "       [-6.2042e-02,  5.1416e-01, -3.7793e-01],\n",
      "       [-2.6831e-01,  8.8281e-01, -4.8682e-01],\n",
      "       [-5.3613e-01,  7.2754e-01, -3.5254e-01],\n",
      "       [-4.2798e-01,  7.7441e-01, -3.2812e-01],\n",
      "       [-4.7412e-01,  3.8281e-01,  4.0771e-02],\n",
      "       [-3.7646e-01,  8.3594e-01, -4.8364e-01],\n",
      "       [-2.0776e-01,  7.8662e-01, -6.8750e-01],\n",
      "       [-4.0039e-01,  5.7471e-01, -1.6455e-01],\n",
      "       [-4.7656e-01,  5.6641e-01, -1.5051e-01],\n",
      "       [-6.5088e-01,  9.1406e-01, -3.2373e-01],\n",
      "       [-3.0957e-01,  4.7339e-01, -2.1179e-01],\n",
      "       [-2.1038e-03,  8.8379e-01, -7.6416e-01],\n",
      "       [-1.8262e-01,  6.3672e-01, -4.6021e-01],\n",
      "       [ 2.3218e-01,  7.8418e-01, -7.9932e-01],\n",
      "       [-3.6304e-01,  6.3281e-01, -4.6045e-01],\n",
      "       [-7.0117e-01,  6.7920e-01, -1.6144e-02],\n",
      "       [ 1.2274e-01,  9.6289e-01, -9.6045e-01],\n",
      "       [ 7.1106e-02,  5.2051e-01, -5.4785e-01],\n",
      "       [ 2.9102e-01,  1.1680e+00, -1.1777e+00],\n",
      "       [-5.3564e-01,  5.2881e-01, -1.1133e-01],\n",
      "       [-2.7539e-01,  6.2256e-01, -3.5352e-01],\n",
      "       [-6.3916e-01,  4.0210e-01,  2.0251e-01],\n",
      "       [-4.9341e-01,  7.4707e-01, -3.4155e-01],\n",
      "       [-2.2046e-01,  1.0322e+00, -8.0518e-01],\n",
      "       [-4.4995e-01,  5.7373e-01, -2.4573e-01],\n",
      "       [-3.8477e-01,  7.7246e-01, -5.3369e-01],\n",
      "       [-7.8906e-01,  7.6221e-01, -3.6835e-02],\n",
      "       [-3.4204e-01,  4.6582e-01, -1.6028e-01],\n",
      "       [-6.3184e-01,  1.0254e+00, -4.9316e-01],\n",
      "       [-3.1763e-01,  7.8271e-01, -5.5225e-01],\n",
      "       [-3.9722e-01,  4.4092e-01, -1.3342e-01],\n",
      "       [-3.6377e-01,  8.7061e-01, -4.6729e-01],\n",
      "       [-5.7227e-01,  7.3340e-01, -2.0764e-01],\n",
      "       [-5.9033e-01,  9.4385e-01, -3.6255e-01],\n",
      "       [-2.2705e-01,  2.3938e-01, -7.4829e-02],\n",
      "       [-5.5078e-01,  6.7041e-01, -2.7344e-01],\n",
      "       [-1.4478e-01,  3.7842e-01, -2.8418e-01],\n",
      "       [-4.8511e-01,  4.5923e-01, -6.5918e-02],\n",
      "       [ 1.7444e-01,  6.2744e-01, -7.1826e-01],\n",
      "       [-2.2278e-01,  6.3525e-01, -4.3799e-01],\n",
      "       [-5.5615e-01,  1.0312e+00, -4.1504e-01],\n",
      "       [-2.7490e-01,  4.5166e-01, -3.0957e-01],\n",
      "       [ 1.9348e-01,  8.1836e-01, -9.0723e-01],\n",
      "       [-4.3311e-01,  5.0146e-01, -1.8481e-01],\n",
      "       [-1.1621e-01,  1.4131e+00, -1.1230e+00],\n",
      "       [ 1.4282e-01,  7.5684e-01, -8.1787e-01],\n",
      "       [-3.3350e-01,  6.0693e-01, -3.6987e-01],\n",
      "       [-5.6250e-01,  7.8076e-01, -2.0312e-01],\n",
      "       [-3.2251e-01,  5.4346e-01, -2.9004e-01],\n",
      "       [-4.5532e-01,  6.8701e-01, -2.0972e-01],\n",
      "       [-2.6514e-01,  1.0996e+00, -8.6572e-01],\n",
      "       [-7.1777e-01,  7.4463e-01, -1.6223e-01],\n",
      "       [-1.0950e-01,  7.6855e-01, -5.6348e-01],\n",
      "       [ 1.3708e-01,  1.1221e+00, -1.1299e+00],\n",
      "       [-1.1639e-01,  7.7051e-01, -6.4551e-01],\n",
      "       [-2.3840e-01,  1.3477e+00, -1.1299e+00],\n",
      "       [ 2.3083e-01,  6.8604e-02, -1.8518e-01],\n",
      "       [-5.0732e-01,  1.2373e+00, -7.3096e-01],\n",
      "       [-7.8564e-01,  8.4863e-01, -1.0132e-01],\n",
      "       [-4.7827e-01,  7.7002e-01, -2.7295e-01],\n",
      "       [-4.2676e-01,  7.5781e-01, -4.3066e-01],\n",
      "       [-6.1572e-01,  4.8804e-01, -2.9907e-02],\n",
      "       [-4.2407e-01,  3.1860e-01,  1.8654e-03],\n",
      "       [-3.2227e-01,  6.8262e-01, -3.7866e-01],\n",
      "       [-4.7607e-01,  6.0400e-01, -2.5146e-01],\n",
      "       [-6.6406e-01,  7.6123e-01, -1.4832e-01],\n",
      "       [-3.0029e-01,  4.6753e-01, -1.9812e-01],\n",
      "       [ 5.7465e-02,  7.9541e-01, -7.6318e-01],\n",
      "       [-1.3135e-01,  9.5020e-01, -8.1152e-01],\n",
      "       [-5.7080e-01,  8.5352e-01, -4.2383e-01],\n",
      "       [-1.7725e-01,  1.0684e+00, -9.0234e-01],\n",
      "       [-4.2432e-01,  6.6504e-01, -3.5010e-01],\n",
      "       [-8.9722e-02,  1.2561e-01, -1.3293e-01],\n",
      "       [-4.1919e-01,  5.8154e-01, -2.1582e-01],\n",
      "       [-5.0732e-01,  7.0654e-01, -3.2520e-01],\n",
      "       [-4.4141e-01,  4.0308e-01, -5.1361e-02],\n",
      "       [-7.7344e-01,  7.4023e-01, -2.6825e-02],\n",
      "       [-1.6492e-01,  9.6826e-01, -7.7783e-01],\n",
      "       [ 4.3915e-02,  6.8701e-01, -6.4258e-01],\n",
      "       [ 4.1412e-02,  5.1172e-01, -4.0015e-01],\n",
      "       [-5.5908e-01,  8.0859e-01, -3.6523e-01],\n",
      "       [-4.3091e-02,  4.7119e-01, -4.2432e-01],\n",
      "       [-3.1909e-01,  6.6992e-01, -3.8330e-01],\n",
      "       [-3.1689e-01,  3.5034e-01, -1.4331e-01],\n",
      "       [-3.0664e-01,  6.3672e-01, -4.2480e-01],\n",
      "       [-1.0193e-01,  1.2412e+00, -1.0127e+00],\n",
      "       [-2.0105e-01,  6.5918e-01, -4.4434e-01],\n",
      "       [ 7.2212e-03,  5.4736e-01, -5.3613e-01],\n",
      "       [-6.0986e-01,  1.0020e+00, -4.1724e-01],\n",
      "       [-6.0986e-01,  8.4570e-01, -3.3594e-01],\n",
      "       [-5.0098e-01,  7.3975e-01, -3.2690e-01],\n",
      "       [-2.8711e-01,  6.0938e-01, -3.9893e-01],\n",
      "       [-6.5381e-01,  1.2051e+00, -6.1719e-01],\n",
      "       [-5.6982e-01,  7.1533e-01, -2.8857e-01],\n",
      "       [-5.6299e-01,  9.3555e-01, -3.9893e-01],\n",
      "       [-2.3804e-01,  6.7627e-01, -4.6851e-01],\n",
      "       [-5.6592e-01,  1.0781e+00, -6.1182e-01],\n",
      "       [-3.3765e-01,  8.2080e-01, -3.5864e-01],\n",
      "       [-1.7944e-01,  7.0654e-01, -4.7021e-01],\n",
      "       [-3.0933e-01,  3.2788e-01, -1.8036e-02],\n",
      "       [-1.0590e-01,  7.2119e-01, -5.3271e-01],\n",
      "       [-3.1909e-01,  1.2246e+00, -7.5830e-01],\n",
      "       [-1.9580e-01,  1.0479e+00, -8.6084e-01],\n",
      "       [-3.6792e-01,  6.0840e-01, -3.0884e-01],\n",
      "       [-5.4443e-01,  2.4512e-01,  2.6440e-01],\n",
      "       [ 1.5515e-01,  1.1270e+00, -1.2686e+00],\n",
      "       [-2.9272e-01,  7.6855e-01, -4.6118e-01],\n",
      "       [-8.5059e-01,  1.4531e+00, -6.5430e-01],\n",
      "       [-6.3965e-02,  9.4678e-01, -8.4229e-01],\n",
      "       [-3.4961e-01,  1.0459e+00, -6.4502e-01],\n",
      "       [-7.3096e-01,  7.4756e-01, -1.1066e-01],\n",
      "       [-5.9033e-01,  1.1924e+00, -6.9092e-01],\n",
      "       [ 2.3584e-01,  1.3779e+00, -1.3691e+00],\n",
      "       [-4.3262e-01,  5.2588e-01, -2.3840e-01],\n",
      "       [-5.8154e-01,  9.2529e-01, -4.8267e-01],\n",
      "       [-5.2051e-01,  6.8359e-01, -2.1582e-01],\n",
      "       [ 3.9520e-02,  1.0703e+00, -9.0869e-01],\n",
      "       [-2.0190e-01,  3.7109e-01, -1.3440e-01],\n",
      "       [-4.2432e-01,  4.1260e-01, -1.4702e-02],\n",
      "       [-5.9033e-01,  7.9395e-01, -2.8564e-01],\n",
      "       [-3.5767e-01,  3.7622e-01, -1.0571e-01],\n",
      "       [-4.1235e-01,  1.4199e+00, -9.6436e-01],\n",
      "       [-4.9463e-01,  7.3779e-01, -2.9639e-01],\n",
      "       [-5.6982e-01,  6.7236e-01, -2.6318e-01],\n",
      "       [-2.4731e-01,  5.9814e-01, -4.0356e-01],\n",
      "       [-2.1667e-01,  4.3359e-01, -2.7124e-01],\n",
      "       [-4.8926e-01,  6.1133e-01, -2.0850e-01],\n",
      "       [-4.4263e-01,  5.0098e-01, -1.7383e-01],\n",
      "       [-2.1960e-01,  1.0527e+00, -7.1191e-01],\n",
      "       [-4.1431e-01,  8.0469e-01, -5.1074e-01],\n",
      "       [ 1.4722e-01,  1.0381e+00, -9.9072e-01],\n",
      "       [-4.2212e-01,  1.0459e+00, -7.0996e-01],\n",
      "       [-5.3955e-01,  5.3760e-01, -9.6985e-02],\n",
      "       [ 7.1167e-02,  5.0732e-01, -5.3418e-01],\n",
      "       [-2.6514e-01,  4.6265e-01, -1.6541e-01],\n",
      "       [-5.4834e-01,  7.4707e-01, -2.7393e-01],\n",
      "       [ 3.5083e-01,  3.5693e-01, -6.0693e-01],\n",
      "       [-3.0884e-01,  1.3486e+00, -9.1406e-01],\n",
      "       [-5.6836e-01,  7.6611e-01, -2.9321e-01],\n",
      "       [-7.0752e-01,  8.6182e-01, -2.4597e-01],\n",
      "       [-5.4736e-01,  7.3389e-01, -2.0032e-01],\n",
      "       [-3.8721e-01,  5.5225e-01, -2.6001e-01],\n",
      "       [-5.6122e-02,  8.9453e-01, -7.0557e-01],\n",
      "       [-6.5796e-02,  1.2148e+00, -1.1104e+00],\n",
      "       [-4.3213e-01,  5.5127e-01, -1.8066e-01],\n",
      "       [-2.8027e-01,  1.6769e-02,  2.7612e-01],\n",
      "       [-1.2164e-01,  4.4116e-01, -2.8638e-01],\n",
      "       [ 9.9243e-02,  7.5146e-01, -7.1094e-01],\n",
      "       [-3.7598e-01,  8.9990e-01, -6.1133e-01],\n",
      "       [-3.3057e-01,  6.9482e-01, -4.6851e-01],\n",
      "       [-3.4424e-01,  3.6768e-01, -7.6904e-02],\n",
      "       [-1.3684e-01,  3.9648e-01, -3.1592e-01],\n",
      "       [-4.0845e-01,  6.2451e-01, -3.2642e-01],\n",
      "       [-3.8013e-01,  7.4219e-01, -4.2798e-01],\n",
      "       [-3.9941e-01,  6.5967e-01, -3.3276e-01],\n",
      "       [-4.2383e-01,  6.8604e-01, -2.6807e-01],\n",
      "       [-2.0984e-01,  1.1299e+00, -8.9502e-01],\n",
      "       [-2.8589e-01,  2.7856e-01, -3.2867e-02],\n",
      "       [-3.2330e-04,  1.0322e+00, -9.7900e-01],\n",
      "       [-3.8721e-01,  7.5635e-01, -4.4360e-01],\n",
      "       [-1.0214e-03,  1.1299e+00, -8.9502e-01],\n",
      "       [-5.4346e-01,  6.7432e-01, -1.9812e-01],\n",
      "       [-4.5117e-01,  5.6445e-01, -1.9104e-01],\n",
      "       [-2.4841e-02,  1.0811e+00, -1.0039e+00],\n",
      "       [-1.9531e-01,  2.0496e-01, -8.8684e-02],\n",
      "       [-5.0586e-01,  6.3086e-01, -2.1387e-01],\n",
      "       [-3.5815e-01,  4.9365e-01, -2.4084e-01],\n",
      "       [-2.9663e-01,  4.4458e-01, -2.1643e-01],\n",
      "       [-4.3091e-01,  6.2408e-02,  2.5244e-01],\n",
      "       [-4.3530e-01,  4.6362e-01, -1.2012e-01],\n",
      "       [-5.2588e-01,  7.4854e-01, -2.5537e-01],\n",
      "       [-2.8345e-01,  9.8779e-01, -6.2988e-01],\n",
      "       [-5.6055e-01,  1.2080e+00, -6.6895e-01],\n",
      "       [-6.8311e-01,  6.0791e-01, -3.1525e-02],\n",
      "       [ 6.6605e-03,  1.3438e+00, -1.1777e+00],\n",
      "       [-2.8589e-01,  5.8057e-01, -3.4521e-01],\n",
      "       [-5.4492e-01,  8.1396e-01, -3.8770e-01],\n",
      "       [-4.6143e-01,  8.7842e-01, -3.6987e-01],\n",
      "       [-6.2061e-01,  9.5850e-01, -4.4824e-01],\n",
      "       [-3.9185e-01,  8.0371e-01, -4.8071e-01],\n",
      "       [-5.4736e-01,  7.2266e-01, -1.9836e-01],\n",
      "       [-3.9307e-01,  9.3994e-01, -6.4355e-01],\n",
      "       [-2.1570e-01,  7.0605e-01, -5.0000e-01],\n",
      "       [-5.4395e-01,  6.2793e-01, -1.6870e-01],\n",
      "       [-4.2358e-01,  1.0645e+00, -7.2363e-01],\n",
      "       [-1.3123e-02,  1.0166e+00, -8.5010e-01],\n",
      "       [-6.0742e-01,  7.1338e-01, -1.0077e-01],\n",
      "       [-1.6272e-01,  1.3789e+00, -1.0664e+00],\n",
      "       [-5.4346e-01,  8.3203e-01, -3.0811e-01],\n",
      "       [-5.0830e-01,  3.3179e-01,  1.2878e-01],\n",
      "       [-5.0110e-02,  8.6182e-01, -6.1523e-01],\n",
      "       [-5.3369e-01,  8.4521e-01, -2.9565e-01],\n",
      "       [-3.6890e-01,  5.9912e-01, -2.4695e-01],\n",
      "       [-3.6890e-01,  7.2461e-01, -4.5605e-01],\n",
      "       [-4.8413e-01,  4.4531e-01,  1.0925e-02],\n",
      "       [-9.0576e-02,  1.1094e+00, -9.4092e-01],\n",
      "       [ 1.3504e-02,  5.5957e-01, -5.6299e-01],\n",
      "       [-6.3867e-01,  9.2871e-01, -3.1689e-01],\n",
      "       [-3.9648e-01,  1.1064e+00, -6.2891e-01],\n",
      "       [-1.7517e-01,  9.8486e-01, -7.5146e-01],\n",
      "       [-3.9258e-01,  8.6182e-01, -5.6982e-01],\n",
      "       [ 2.0520e-01,  8.1445e-01, -9.5703e-01],\n",
      "       [-5.3809e-01,  6.8848e-01, -2.5854e-01],\n",
      "       [-5.5225e-01,  8.5059e-01, -4.1040e-01],\n",
      "       [-5.7520e-01,  5.3613e-01, -8.0627e-02],\n",
      "       [ 2.7466e-01,  1.0068e+00, -1.0537e+00],\n",
      "       [-1.7542e-01,  4.0796e-01, -2.3047e-01],\n",
      "       [ 1.0431e-01,  1.1162e+00, -9.9023e-01],\n",
      "       [-4.1309e-01,  8.4570e-01, -4.2383e-01],\n",
      "       [-3.6499e-01,  7.8418e-01, -4.2358e-01],\n",
      "       [-2.5928e-01,  1.5820e+00, -1.2188e+00],\n",
      "       [-4.8608e-01,  8.4131e-01, -4.3311e-01],\n",
      "       [-1.6516e-01,  7.5732e-01, -6.0938e-01],\n",
      "       [-1.6675e-01,  6.3330e-01, -4.4922e-01],\n",
      "       [-4.4629e-01,  7.7490e-01, -4.3042e-01],\n",
      "       [-3.8232e-01,  4.5483e-01, -1.1450e-01],\n",
      "       [-4.4507e-01,  2.9663e-01,  7.3303e-02],\n",
      "       [-6.0938e-01,  6.8750e-01, -1.6541e-01],\n",
      "       [-3.2764e-01,  2.0044e-01,  2.8503e-02],\n",
      "       [-5.3418e-01,  6.2744e-01, -1.6821e-01],\n",
      "       [-2.6440e-01,  6.0645e-01, -4.2920e-01]], dtype=float16), label_ids=array([1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 2, 2, 1, 2, 1, 1, 2, 2,\n",
      "       1, 2, 0, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 0, 2, 1, 1,\n",
      "       1, 2, 1, 1, 1, 0, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 0, 2, 1, 2, 0,\n",
      "       1, 1, 0, 0, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       0, 2, 1, 2, 0, 1, 1, 1, 1, 1, 1, 2, 0, 2, 1, 2, 1, 1, 1, 2, 1, 1,\n",
      "       2, 1, 2, 1, 2, 1, 1, 1, 0, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 2, 1, 2, 1, 1, 1, 2, 0, 2, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2,\n",
      "       1, 1, 1, 2, 1, 0, 0, 0, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1,\n",
      "       1, 0, 1, 1, 1, 1, 0, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 0, 2, 1, 1, 1,\n",
      "       1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 0, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 0]), metrics={'test_loss': 0.9028659462928772, 'test_accuracy': 0.6367521367521367, 'test_balanced_accuracy': 0.33820506965060515, 'test_precision': 0.5391675956893348, 'test_recall': 0.6367521367521367, 'test_f1': 0.5095968773134127, 'test_runtime': 0.6662, 'test_samples_per_second': 351.262, 'test_steps_per_second': 12.009})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be81d0c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "probabilities = torch.softmax(torch.tensor(test_results.predictions).to(torch.float32), dim=-1)\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)\n",
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef4c67fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_save = []\n",
    "for idx in range(len(test_data)):\n",
    "    item = dataset['test'][idx]\n",
    "    actual_label = item['label']\n",
    "    predicted_label = predictions[idx]\n",
    "    claim = item['claim'] \n",
    "    premise = item['premise'] \n",
    "    category = item['category']\n",
    "    \n",
    "    # Append the information as a dictionary to the list\n",
    "    data_to_save.append({\n",
    "        'Claim': claim,\n",
    "        'Premise': premise,\n",
    "        'Actual Label': actual_label,\n",
    "        'Predicted Label': predicted_label,\n",
    "        'Category' : category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_to_save)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/home/elson/results/11.2.4_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a1a63a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correctly classified instances\n",
    "correctly_classified = df[df['Actual Label'] == df['Predicted Label']]\n",
    "\n",
    "# Calculate misclassified instances\n",
    "misclassified = df[df['Actual Label'] != df['Predicted Label']]\n",
    "\n",
    "# Count the number of correctly classified and misclassified by category\n",
    "correct_classification_counts = correctly_classified['Category'].value_counts()\n",
    "misclassification_counts = misclassified['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c4055e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           35\n",
       "Fitness                  13\n",
       "Cancer                   12\n",
       "Bone health              11\n",
       "Skin                     10\n",
       "Neurological health       9\n",
       "Throat                    9\n",
       "Diabetes                  9\n",
       "Hair                      8\n",
       "Ear                       6\n",
       "Cardiovascular Health     6\n",
       "Eye                       5\n",
       "Blood                     4\n",
       "COVID                     4\n",
       "Mental Health             2\n",
       "Muscles                   2\n",
       "Women' s Health           2\n",
       "Men's health              1\n",
       "Vascular                  1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "117a1d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           16\n",
       "Skin                     14\n",
       "Bone health              10\n",
       "Cardiovascular Health     6\n",
       "Blood                     5\n",
       "Men's health              5\n",
       "Hair                      4\n",
       "Eye                       4\n",
       "Muscles                   4\n",
       "Women' s Health           4\n",
       "Dental Health             3\n",
       "Diabetes                  3\n",
       "COVID                     2\n",
       "Vascular                  2\n",
       "Fitness                   2\n",
       "Mental Health             1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
