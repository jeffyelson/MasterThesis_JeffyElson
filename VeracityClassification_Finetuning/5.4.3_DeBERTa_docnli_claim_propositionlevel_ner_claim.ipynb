{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-b4d5af22bd5d34d0\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-b4d5af22bd5d34d0/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 246.33it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('csv',data_files='dataset_propositionattribution_nerfeatures.csv',delimiter=',',column_names=[\"claim\",\"premise\",\"label\",\"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\",\"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\",\"url\", \"entities\",\"entity_map\",\"entity_map_ev\",\"entity_ev\",\"gem_exp\",\"gem_label\",\"gpt_exp\",\"gpt_label\",\"gold_exp\",\"split\"],skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e2914c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'entity_map_ev', 'entity_ev', 'gem_exp', 'gem_label', 'gpt_exp', 'gpt_label', 'gold_exp', 'split'],\n",
       "        num_rows: 2322\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57d56e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'test',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['split']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ce96b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-b4d5af22bd5d34d0/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-c7bf70b7c4f0e941.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-b4d5af22bd5d34d0/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-ca379e6fc623397c.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-b4d5af22bd5d34d0/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-41ed9283338b515a.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'entity_map_ev', 'entity_ev', 'gem_exp', 'gem_label', 'gpt_exp', 'gpt_label', 'gold_exp', 'split'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'entity_map_ev', 'entity_ev', 'gem_exp', 'gem_label', 'gpt_exp', 'gpt_label', 'gold_exp', 'split'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'entity_map_ev', 'entity_ev', 'gem_exp', 'gem_label', 'gpt_exp', 'gpt_label', 'gold_exp', 'split'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41f1db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat']\n",
    "all_columns = dataset[\"train\"].column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-b4d5af22bd5d34d0/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-6bfe193ce6a421b4.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-b4d5af22bd5d34d0/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-55ab17aa8ab3916c.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-b4d5af22bd5d34d0/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-f868192ba5e48b35.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 1, 'entailment': 0, 'neutral': 1}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 1,\n",
    "    \"entailment\": 0,\n",
    "    \"neutral\": 1\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='MoritzLaurer/DeBERTa-v3-base-mnli-fever-docnli-ling-2c'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "        # Extracting claim and evidence texts\n",
    "        claim = item['claim'] \n",
    "        evidences = item['premise']\n",
    "        item['premise']=evidences\n",
    "        item['claim']=claim\n",
    "        additional_features = [\n",
    "            \"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\"]\n",
    "    \n",
    "        for feature in additional_features:\n",
    "            if feature in item:\n",
    "                claim += \"[SEP]\" + str(item[feature])\n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "            evidences,claim,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "         # Construct the output item\n",
    "        output_item = {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),  # Remove batch dimension\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),  # Remove batch dimension\n",
    "            'claim': claim,  # Include augmented claim text\n",
    "            'evidences': evidences  # Include original evidence text\n",
    "        }\n",
    "        \n",
    "        if 'label' in item:\n",
    "            output_item['label'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return output_item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62421eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DebertaV2ForSequenceClassification(\n",
       "  (deberta): DebertaV2Model(\n",
       "    (embeddings): DebertaV2Embeddings(\n",
       "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaV2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (1): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (2): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (3): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (4): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (5): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (6): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (7): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (8): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (9): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (10): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (11): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (pooler): ContextPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): StableDropout()\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): StableDropout()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"MoritzLaurer/DeBERTa-v3-base-mnli-fever-docnli-ling-2c\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=2, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    bal_accuracy = balanced_accuracy_score(labels,preds)\n",
    "\n",
    "    return {\"accuracy\": acc, \"balanced_accuracy\":bal_accuracy, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17c5e0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([    1,   279,  1830,  6725,   265, 88609,   263, 98237,   993,   262,\n",
       "         49462,   265,   262, 22003, 96579,   267,   262, 61462,   263,   575,\n",
       "           262, 26217,   263,  9854,  1730,   264,   993,   262, 39632,   265,\n",
       "           262,  1158,   263,  4843,   262,  7275,  1290,   260,     2,   573,\n",
       "         52341,  1830,  1080,   269,  1359,   427,   267, 17847,   633,   264,\n",
       "           408,  1300,   262,  2658,   265,   262,  1158,   260,     2,   767,\n",
       "             2,   767,     2,   767,     2,   767,     2,   767,     2,   767,\n",
       "             2,   767,     2,   767,     2,   767,     2,   767,     2,   767,\n",
       "             2,   767,     2,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'claim': 'Myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0',\n",
       " 'evidences': 'The essential oils of frankincense and myrrh increase the fluidity of the lipid bilayer in the cuticle and change the orderly and dense structure to increase the permeability of the skin and decrease the barrier effect.',\n",
       " 'label': tensor(0)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 765\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='765' max='765' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [765/765 11:35, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.715900</td>\n",
       "      <td>0.807414</td>\n",
       "      <td>0.673118</td>\n",
       "      <td>0.652194</td>\n",
       "      <td>0.697793</td>\n",
       "      <td>0.673118</td>\n",
       "      <td>0.681569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.444100</td>\n",
       "      <td>0.712928</td>\n",
       "      <td>0.705376</td>\n",
       "      <td>0.706192</td>\n",
       "      <td>0.742478</td>\n",
       "      <td>0.705376</td>\n",
       "      <td>0.715017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.394300</td>\n",
       "      <td>0.660880</td>\n",
       "      <td>0.729032</td>\n",
       "      <td>0.694607</td>\n",
       "      <td>0.735686</td>\n",
       "      <td>0.729032</td>\n",
       "      <td>0.731871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.146700</td>\n",
       "      <td>0.907943</td>\n",
       "      <td>0.724731</td>\n",
       "      <td>0.681918</td>\n",
       "      <td>0.726885</td>\n",
       "      <td>0.724731</td>\n",
       "      <td>0.725754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.061100</td>\n",
       "      <td>1.527399</td>\n",
       "      <td>0.668817</td>\n",
       "      <td>0.677797</td>\n",
       "      <td>0.720530</td>\n",
       "      <td>0.668817</td>\n",
       "      <td>0.680830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.107500</td>\n",
       "      <td>1.569209</td>\n",
       "      <td>0.673118</td>\n",
       "      <td>0.675169</td>\n",
       "      <td>0.717423</td>\n",
       "      <td>0.673118</td>\n",
       "      <td>0.684448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.114800</td>\n",
       "      <td>1.683442</td>\n",
       "      <td>0.690323</td>\n",
       "      <td>0.702947</td>\n",
       "      <td>0.741476</td>\n",
       "      <td>0.690323</td>\n",
       "      <td>0.701555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.054800</td>\n",
       "      <td>1.674309</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.689772</td>\n",
       "      <td>0.730808</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.689218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.010100</td>\n",
       "      <td>2.067403</td>\n",
       "      <td>0.690323</td>\n",
       "      <td>0.662740</td>\n",
       "      <td>0.707097</td>\n",
       "      <td>0.690323</td>\n",
       "      <td>0.696608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.038500</td>\n",
       "      <td>1.938828</td>\n",
       "      <td>0.720430</td>\n",
       "      <td>0.684547</td>\n",
       "      <td>0.727248</td>\n",
       "      <td>0.720430</td>\n",
       "      <td>0.723359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>2.170630</td>\n",
       "      <td>0.711828</td>\n",
       "      <td>0.691719</td>\n",
       "      <td>0.730703</td>\n",
       "      <td>0.711828</td>\n",
       "      <td>0.718358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.031500</td>\n",
       "      <td>2.114223</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.676369</td>\n",
       "      <td>0.718082</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.688263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>2.325821</td>\n",
       "      <td>0.679570</td>\n",
       "      <td>0.676012</td>\n",
       "      <td>0.717592</td>\n",
       "      <td>0.679570</td>\n",
       "      <td>0.690055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.265683</td>\n",
       "      <td>0.713978</td>\n",
       "      <td>0.695191</td>\n",
       "      <td>0.733492</td>\n",
       "      <td>0.713978</td>\n",
       "      <td>0.720620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.277041</td>\n",
       "      <td>0.718280</td>\n",
       "      <td>0.696391</td>\n",
       "      <td>0.734835</td>\n",
       "      <td>0.718280</td>\n",
       "      <td>0.724169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.3_deberta_docnli/checkpoint-51\n",
      "Configuration saved in /home/elson/5.4.3_deberta_docnli/checkpoint-51/config.json\n",
      "Model weights saved in /home/elson/5.4.3_deberta_docnli/checkpoint-51/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.3_deberta_docnli/checkpoint-102\n",
      "Configuration saved in /home/elson/5.4.3_deberta_docnli/checkpoint-102/config.json\n",
      "Model weights saved in /home/elson/5.4.3_deberta_docnli/checkpoint-102/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.4.3_deberta_docnli/checkpoint-51] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.3_deberta_docnli/checkpoint-153\n",
      "Configuration saved in /home/elson/5.4.3_deberta_docnli/checkpoint-153/config.json\n",
      "Model weights saved in /home/elson/5.4.3_deberta_docnli/checkpoint-153/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.4.3_deberta_docnli/checkpoint-102] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.3_deberta_docnli/checkpoint-204\n",
      "Configuration saved in /home/elson/5.4.3_deberta_docnli/checkpoint-204/config.json\n",
      "Model weights saved in /home/elson/5.4.3_deberta_docnli/checkpoint-204/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.3_deberta_docnli/checkpoint-255\n",
      "Configuration saved in /home/elson/5.4.3_deberta_docnli/checkpoint-255/config.json\n",
      "Model weights saved in /home/elson/5.4.3_deberta_docnli/checkpoint-255/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.4.3_deberta_docnli/checkpoint-204] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.3_deberta_docnli/checkpoint-306\n",
      "Configuration saved in /home/elson/5.4.3_deberta_docnli/checkpoint-306/config.json\n",
      "Model weights saved in /home/elson/5.4.3_deberta_docnli/checkpoint-306/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.4.3_deberta_docnli/checkpoint-255] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.3_deberta_docnli/checkpoint-357\n",
      "Configuration saved in /home/elson/5.4.3_deberta_docnli/checkpoint-357/config.json\n",
      "Model weights saved in /home/elson/5.4.3_deberta_docnli/checkpoint-357/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.4.3_deberta_docnli/checkpoint-306] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.3_deberta_docnli/checkpoint-408\n",
      "Configuration saved in /home/elson/5.4.3_deberta_docnli/checkpoint-408/config.json\n",
      "Model weights saved in /home/elson/5.4.3_deberta_docnli/checkpoint-408/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.4.3_deberta_docnli/checkpoint-357] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.3_deberta_docnli/checkpoint-459\n",
      "Configuration saved in /home/elson/5.4.3_deberta_docnli/checkpoint-459/config.json\n",
      "Model weights saved in /home/elson/5.4.3_deberta_docnli/checkpoint-459/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.4.3_deberta_docnli/checkpoint-408] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.3_deberta_docnli/checkpoint-510\n",
      "Configuration saved in /home/elson/5.4.3_deberta_docnli/checkpoint-510/config.json\n",
      "Model weights saved in /home/elson/5.4.3_deberta_docnli/checkpoint-510/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.4.3_deberta_docnli/checkpoint-459] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.3_deberta_docnli/checkpoint-561\n",
      "Configuration saved in /home/elson/5.4.3_deberta_docnli/checkpoint-561/config.json\n",
      "Model weights saved in /home/elson/5.4.3_deberta_docnli/checkpoint-561/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.4.3_deberta_docnli/checkpoint-510] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.3_deberta_docnli/checkpoint-612\n",
      "Configuration saved in /home/elson/5.4.3_deberta_docnli/checkpoint-612/config.json\n",
      "Model weights saved in /home/elson/5.4.3_deberta_docnli/checkpoint-612/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.4.3_deberta_docnli/checkpoint-561] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.3_deberta_docnli/checkpoint-663\n",
      "Configuration saved in /home/elson/5.4.3_deberta_docnli/checkpoint-663/config.json\n",
      "Model weights saved in /home/elson/5.4.3_deberta_docnli/checkpoint-663/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.4.3_deberta_docnli/checkpoint-612] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.3_deberta_docnli/checkpoint-714\n",
      "Configuration saved in /home/elson/5.4.3_deberta_docnli/checkpoint-714/config.json\n",
      "Model weights saved in /home/elson/5.4.3_deberta_docnli/checkpoint-714/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.4.3_deberta_docnli/checkpoint-663] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.3_deberta_docnli/checkpoint-765\n",
      "Configuration saved in /home/elson/5.4.3_deberta_docnli/checkpoint-765/config.json\n",
      "Model weights saved in /home/elson/5.4.3_deberta_docnli/checkpoint-765/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.4.3_deberta_docnli/checkpoint-714] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/elson/5.4.3_deberta_docnli/checkpoint-153 (score: 0.7290322580645161).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /home/elson/5.4.3_deberta_docnli/best_model/config.json\n",
      "Model weights saved in /home/elson/5.4.3_deberta_docnli/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/5.4.3_deberta_docnli/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/5.4.3_deberta_docnli/best_model/special_tokens_map.json\n",
      "added tokens file saved in /home/elson/5.4.3_deberta_docnli/best_model/added_tokens.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/5.4.3_deberta_docnli/best_model/tokenizer_config.json',\n",
       " '/home/elson/5.4.3_deberta_docnli/best_model/special_tokens_map.json',\n",
       " '/home/elson/5.4.3_deberta_docnli/best_model/spm.model',\n",
       " '/home/elson/5.4.3_deberta_docnli/best_model/added_tokens.json')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/5.4.3_deberta_docnli/',\n",
    "    num_train_epochs=15,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.6,\n",
    "    weight_decay=0.1,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/5.4.3_deberta_docnli/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/5.4.3_deberta_docnli/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63deaea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/5.4.3_deberta_docnli/best_model/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"/home/elson/5.4.3_deberta_docnli/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"entailment\",\n",
      "    \"1\": \"not_entailment\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"entailment\": 0,\n",
      "    \"not_entailment\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file /home/elson/5.4.3_deberta_docnli/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at /home/elson/5.4.3_deberta_docnli/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 32\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/5.4.3_deberta_docnli/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[ 0.7437 , -0.7207 ],\n",
      "       [ 1.047  , -1.025  ],\n",
      "       [ 1.593  , -1.55   ],\n",
      "       [-1.209  ,  1.422  ],\n",
      "       [-1.092  ,  1.286  ],\n",
      "       [ 1.44   , -1.408  ],\n",
      "       [ 1.137  , -1.11   ],\n",
      "       [ 0.813  , -0.794  ],\n",
      "       [ 0.809  , -0.786  ],\n",
      "       [ 1.044  , -1.02   ],\n",
      "       [ 0.8813 , -0.858  ],\n",
      "       [ 1.26   , -1.233  ],\n",
      "       [-0.66   ,  0.715  ],\n",
      "       [ 1.298  , -1.269  ],\n",
      "       [ 1.05   , -1.028  ],\n",
      "       [-0.972  ,  1.125  ],\n",
      "       [-0.7993 ,  0.899  ],\n",
      "       [ 1.476  , -1.439  ],\n",
      "       [ 1.244  , -1.216  ],\n",
      "       [ 1.526  , -1.49   ],\n",
      "       [-1.232  ,  1.463  ],\n",
      "       [ 1.088  , -1.062  ],\n",
      "       [ 0.896  , -0.875  ],\n",
      "       [-1.328  ,  1.563  ],\n",
      "       [ 0.8013 , -0.779  ],\n",
      "       [-1.902  ,  2.174  ],\n",
      "       [ 1.386  , -1.3545 ],\n",
      "       [ 0.724  , -0.7075 ],\n",
      "       [ 1.175  , -1.149  ],\n",
      "       [ 0.8184 , -0.794  ],\n",
      "       [-1.514  ,  1.767  ],\n",
      "       [ 1.012  , -0.9907 ],\n",
      "       [ 0.829  , -0.8105 ],\n",
      "       [ 0.2345 , -0.2161 ],\n",
      "       [-0.8716 ,  0.9707 ],\n",
      "       [-0.8135 ,  0.921  ],\n",
      "       [-0.7275 ,  0.795  ],\n",
      "       [ 1.104  , -1.083  ],\n",
      "       [-1.325  ,  1.551  ],\n",
      "       [-0.9766 ,  1.144  ],\n",
      "       [ 0.0484 , -0.0327 ],\n",
      "       [ 0.86   , -0.8423 ],\n",
      "       [ 0.5996 , -0.5835 ],\n",
      "       [ 0.582  , -0.567  ],\n",
      "       [-0.875  ,  0.9717 ],\n",
      "       [ 1.247  , -1.22   ],\n",
      "       [ 0.626  , -0.6045 ],\n",
      "       [ 1.234  , -1.206  ],\n",
      "       [ 1.678  , -1.636  ],\n",
      "       [-1.075  ,  1.255  ],\n",
      "       [-1.327  ,  1.581  ],\n",
      "       [ 0.1793 , -0.1575 ],\n",
      "       [-0.1332 ,  0.159  ],\n",
      "       [ 0.7666 , -0.7363 ],\n",
      "       [-0.9907 ,  1.147  ],\n",
      "       [ 1.474  , -1.44   ],\n",
      "       [-1.27   ,  1.496  ],\n",
      "       [ 0.467  , -0.4534 ],\n",
      "       [ 1.471  , -1.438  ],\n",
      "       [ 0.7725 , -0.7524 ],\n",
      "       [ 0.858  , -0.836  ],\n",
      "       [-1.008  ,  1.163  ],\n",
      "       [ 1.173  , -1.148  ],\n",
      "       [-1.114  ,  1.315  ],\n",
      "       [ 0.458  , -0.4458 ],\n",
      "       [ 0.927  , -0.906  ],\n",
      "       [ 1.423  , -1.392  ],\n",
      "       [ 1.089  , -1.063  ],\n",
      "       [ 0.9683 , -0.944  ],\n",
      "       [ 0.5835 , -0.5654 ],\n",
      "       [ 1.297  , -1.266  ],\n",
      "       [-0.745  ,  0.816  ],\n",
      "       [ 0.3582 , -0.349  ],\n",
      "       [-0.937  ,  1.081  ],\n",
      "       [ 0.9336 , -0.909  ],\n",
      "       [ 1.053  , -1.027  ],\n",
      "       [ 0.6357 , -0.6206 ],\n",
      "       [ 1.192  , -1.169  ],\n",
      "       [ 0.9053 , -0.885  ],\n",
      "       [ 0.8794 , -0.8564 ],\n",
      "       [ 1.107  , -1.081  ],\n",
      "       [ 1.134  , -1.111  ],\n",
      "       [ 0.7393 , -0.7188 ],\n",
      "       [ 1.196  , -1.168  ],\n",
      "       [ 1.659  , -1.619  ],\n",
      "       [-1.518  ,  1.771  ],\n",
      "       [ 0.8994 , -0.879  ],\n",
      "       [ 0.8066 , -0.7837 ],\n",
      "       [ 1.304  , -1.273  ],\n",
      "       [ 1.052  , -1.029  ],\n",
      "       [ 1.463  , -1.427  ],\n",
      "       [ 1.237  , -1.209  ],\n",
      "       [-1.066  ,  1.248  ],\n",
      "       [ 1.255  , -1.228  ],\n",
      "       [ 0.579  , -0.5645 ],\n",
      "       [ 0.5796 , -0.564  ],\n",
      "       [-0.304  ,  0.3335 ],\n",
      "       [ 0.624  , -0.612  ],\n",
      "       [ 0.784  , -0.7646 ],\n",
      "       [ 0.448  , -0.4314 ],\n",
      "       [ 0.742  , -0.724  ],\n",
      "       [ 1.221  , -1.194  ],\n",
      "       [ 1.419  , -1.385  ],\n",
      "       [ 0.6    , -0.591  ],\n",
      "       [ 1.541  , -1.505  ],\n",
      "       [ 1.385  , -1.3545 ],\n",
      "       [ 1.352  , -1.318  ],\n",
      "       [-0.7627 ,  0.8535 ],\n",
      "       [ 0.934  , -0.912  ],\n",
      "       [ 1.038  , -1.015  ],\n",
      "       [ 1.119  , -1.094  ],\n",
      "       [ 1.198  , -1.171  ],\n",
      "       [ 1.37   , -1.338  ],\n",
      "       [ 0.943  , -0.922  ],\n",
      "       [ 1.258  , -1.23   ],\n",
      "       [ 1.307  , -1.278  ],\n",
      "       [ 1.498  , -1.462  ],\n",
      "       [ 1.347  , -1.314  ],\n",
      "       [ 0.9116 , -0.888  ],\n",
      "       [ 1.134  , -1.108  ],\n",
      "       [ 1.169  , -1.144  ],\n",
      "       [ 1.276  , -1.248  ],\n",
      "       [ 0.4543 , -0.4421 ],\n",
      "       [-0.6826 ,  0.74   ],\n",
      "       [ 0.58   , -0.561  ],\n",
      "       [ 1.073  , -1.05   ],\n",
      "       [-0.07227,  0.0925 ],\n",
      "       [ 1.14   , -1.114  ],\n",
      "       [ 1.142  , -1.115  ],\n",
      "       [ 0.1494 , -0.1381 ],\n",
      "       [-0.2905 ,  0.316  ],\n",
      "       [-0.9688 ,  1.12   ],\n",
      "       [ 1.013  , -0.993  ],\n",
      "       [-1.318  ,  1.541  ],\n",
      "       [ 0.6294 , -0.61   ],\n",
      "       [-1.349  ,  1.585  ],\n",
      "       [ 1.025  , -0.9985 ],\n",
      "       [ 0.542  , -0.5273 ],\n",
      "       [-0.991  ,  1.152  ],\n",
      "       [ 1.352  , -1.32   ],\n",
      "       [ 1.419  , -1.386  ],\n",
      "       [ 0.0957 , -0.0785 ],\n",
      "       [ 0.1465 , -0.1294 ],\n",
      "       [ 1.457  , -1.425  ],\n",
      "       [ 0.662  , -0.642  ],\n",
      "       [ 1.204  , -1.175  ],\n",
      "       [ 0.4812 , -0.4668 ],\n",
      "       [-0.9727 ,  1.123  ],\n",
      "       [ 0.7603 , -0.7393 ],\n",
      "       [ 0.67   , -0.6543 ],\n",
      "       [-0.854  ,  0.972  ],\n",
      "       [ 1.466  , -1.429  ],\n",
      "       [ 1.361  , -1.335  ],\n",
      "       [ 1.069  , -1.045  ],\n",
      "       [ 1.118  , -1.094  ],\n",
      "       [ 1.303  , -1.27   ],\n",
      "       [ 1.055  , -1.029  ],\n",
      "       [-1.182  ,  1.397  ],\n",
      "       [-0.07336,  0.09503],\n",
      "       [-1.013  ,  1.154  ],\n",
      "       [-1.7295 ,  1.992  ],\n",
      "       [-1.617  ,  1.871  ],\n",
      "       [ 0.5117 , -0.5034 ],\n",
      "       [ 0.4243 , -0.413  ],\n",
      "       [ 0.2026 , -0.1896 ],\n",
      "       [-1.314  ,  1.568  ],\n",
      "       [ 1.272  , -1.244  ],\n",
      "       [-1.114  ,  1.304  ],\n",
      "       [-0.8965 ,  1.021  ],\n",
      "       [-0.712  ,  0.7715 ],\n",
      "       [-1.702  ,  1.967  ],\n",
      "       [ 0.1437 , -0.1247 ],\n",
      "       [ 0.0969 , -0.0828 ],\n",
      "       [ 1.719  , -1.676  ],\n",
      "       [ 1.623  , -1.583  ],\n",
      "       [-1.822  ,  2.094  ],\n",
      "       [ 1.19   , -1.16   ],\n",
      "       [ 0.54   , -0.52   ],\n",
      "       [ 1.012  , -0.992  ],\n",
      "       [ 0.405  , -0.3887 ],\n",
      "       [-0.921  ,  1.058  ],\n",
      "       [ 0.2338 , -0.2241 ],\n",
      "       [-0.9067 ,  1.032  ],\n",
      "       [ 0.2961 , -0.2795 ],\n",
      "       [-1.128  ,  1.312  ],\n",
      "       [ 1.242  , -1.216  ],\n",
      "       [ 0.6626 , -0.6406 ],\n",
      "       [ 1.195  , -1.171  ],\n",
      "       [-1.235  ,  1.46   ],\n",
      "       [ 0.9683 , -0.947  ],\n",
      "       [-0.8467 ,  0.9404 ],\n",
      "       [-0.9697 ,  1.116  ],\n",
      "       [ 1.208  , -1.181  ],\n",
      "       [ 0.749  , -0.726  ],\n",
      "       [-1.276  ,  1.499  ],\n",
      "       [ 1.263  , -1.235  ],\n",
      "       [ 1.031  , -1.007  ],\n",
      "       [ 1.269  , -1.239  ],\n",
      "       [ 1.026  , -1.002  ],\n",
      "       [ 0.561  , -0.548  ],\n",
      "       [ 1.309  , -1.277  ],\n",
      "       [ 1.022  , -1.001  ],\n",
      "       [ 0.533  , -0.512  ],\n",
      "       [ 1.482  , -1.446  ],\n",
      "       [-0.934  ,  1.052  ],\n",
      "       [-1.323  ,  1.555  ],\n",
      "       [ 0.9995 , -0.9756 ],\n",
      "       [ 1.137  , -1.111  ],\n",
      "       [ 1.58   , -1.539  ],\n",
      "       [ 1.096  , -1.072  ],\n",
      "       [ 1.038  , -1.011  ],\n",
      "       [ 0.589  , -0.575  ],\n",
      "       [ 1.097  , -1.076  ],\n",
      "       [ 0.798  , -0.7764 ],\n",
      "       [ 1.318  , -1.29   ],\n",
      "       [-1.252  ,  1.461  ],\n",
      "       [-0.993  ,  1.143  ],\n",
      "       [ 0.2751 , -0.2595 ],\n",
      "       [ 1.142  , -1.118  ],\n",
      "       [ 0.9165 , -0.895  ],\n",
      "       [ 1.281  , -1.256  ],\n",
      "       [ 0.969  , -0.948  ],\n",
      "       [ 0.1071 , -0.08673],\n",
      "       [ 1.021  , -0.9985 ],\n",
      "       [ 1.0625 , -1.042  ],\n",
      "       [ 1.138  , -1.112  ],\n",
      "       [ 1.596  , -1.557  ],\n",
      "       [-1.293  ,  1.5205 ],\n",
      "       [-0.2761 ,  0.2964 ],\n",
      "       [ 0.6333 , -0.6113 ],\n",
      "       [ 1.467  , -1.433  ],\n",
      "       [ 1.423  , -1.391  ],\n",
      "       [ 1.192  , -1.17   ],\n",
      "       [-0.4624 ,  0.4985 ]], dtype=float16), label_ids=array([0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
      "       0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
      "       0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1,\n",
      "       0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "       1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "       1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "       0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
      "       0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
      "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1]), metrics={'test_loss': 0.7818431258201599, 'test_accuracy': 0.6581196581196581, 'test_balanced_accuracy': 0.5997619047619047, 'test_precision': 0.6420210821936253, 'test_recall': 0.6581196581196581, 'test_f1': 0.6440406922836941, 'test_runtime': 1.9699, 'test_samples_per_second': 118.788, 'test_steps_per_second': 4.061})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73395d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "probabilities = torch.softmax(torch.tensor(test_results.predictions).to(torch.float32), dim=-1)\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)\n",
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb603377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_save = []\n",
    "for idx in range(len(test_data)):\n",
    "    item = dataset['test'][idx]\n",
    "    actual_label = item['label']\n",
    "    predicted_label = predictions[idx]\n",
    "    claim = item['claim'] \n",
    "    premise = item['premise'] \n",
    "    category = item['category']\n",
    "    \n",
    "    # Append the information as a dictionary to the list\n",
    "    data_to_save.append({\n",
    "        'Claim': claim,\n",
    "        'Premise': premise,\n",
    "        'Actual Label': actual_label,\n",
    "        'Predicted Label': predicted_label,\n",
    "        'Category' : category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_to_save)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/home/elson/results/5.4.3_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c23339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correctly classified instances\n",
    "correctly_classified = df[df['Actual Label'] == df['Predicted Label']]\n",
    "\n",
    "# Calculate misclassified instances\n",
    "misclassified = df[df['Actual Label'] != df['Predicted Label']]\n",
    "\n",
    "# Count the number of correctly classified and misclassified by category\n",
    "correct_classification_counts = correctly_classified['Category'].value_counts()\n",
    "misclassification_counts = misclassified['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca0def77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           36\n",
       "Bone health              16\n",
       "Cancer                   12\n",
       "Fitness                  11\n",
       "Skin                      9\n",
       "Throat                    9\n",
       "Hair                      8\n",
       "Diabetes                  8\n",
       "Cardiovascular Health     8\n",
       "Neurological health       8\n",
       "Ear                       6\n",
       "COVID                     5\n",
       "Women' s Health           4\n",
       "Muscles                   3\n",
       "Mental Health             3\n",
       "Blood                     3\n",
       "Eye                       3\n",
       "Men's health              2\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0fddd944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Skin                     15\n",
       "General Health           15\n",
       "Blood                     6\n",
       "Eye                       6\n",
       "Bone health               5\n",
       "Cardiovascular Health     4\n",
       "Men's health              4\n",
       "Fitness                   4\n",
       "Diabetes                  4\n",
       "Hair                      4\n",
       "Muscles                   3\n",
       "Vascular                  3\n",
       "Dental Health             3\n",
       "Women' s Health           2\n",
       "COVID                     1\n",
       "Neurological health       1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38b899b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_counts = df['Category'].value_counts()\n",
    "\n",
    "# Calculate ratios\n",
    "correct_classification_ratios = correct_classification_counts / total_counts\n",
    "misclassification_ratios = misclassification_counts / total_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c3598b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blood                    0.333333\n",
      "Bone health              0.761905\n",
      "COVID                    0.833333\n",
      "Cancer                   1.000000\n",
      "Cardiovascular Health    0.666667\n",
      "Dental Health                 NaN\n",
      "Diabetes                 0.666667\n",
      "Ear                      1.000000\n",
      "Eye                      0.333333\n",
      "Fitness                  0.733333\n",
      "General Health           0.705882\n",
      "Hair                     0.666667\n",
      "Men's health             0.333333\n",
      "Mental Health            1.000000\n",
      "Muscles                  0.500000\n",
      "Neurological health      0.888889\n",
      "Skin                     0.375000\n",
      "Throat                   1.000000\n",
      "Vascular                      NaN\n",
      "Women' s Health          0.666667\n",
      "Name: Category, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(correct_classification_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27602a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blood                    0.666667\n",
      "Bone health              0.238095\n",
      "COVID                    0.166667\n",
      "Cancer                        NaN\n",
      "Cardiovascular Health    0.333333\n",
      "Dental Health            1.000000\n",
      "Diabetes                 0.333333\n",
      "Ear                           NaN\n",
      "Eye                      0.666667\n",
      "Fitness                  0.266667\n",
      "General Health           0.294118\n",
      "Hair                     0.333333\n",
      "Men's health             0.666667\n",
      "Mental Health                 NaN\n",
      "Muscles                  0.500000\n",
      "Neurological health      0.111111\n",
      "Skin                     0.625000\n",
      "Throat                        NaN\n",
      "Vascular                 1.000000\n",
      "Women' s Health          0.333333\n",
      "Name: Category, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(misclassification_ratios)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
