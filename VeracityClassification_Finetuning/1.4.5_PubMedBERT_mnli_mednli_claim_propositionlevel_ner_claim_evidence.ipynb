{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-022bc67e9c58e92d\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 227.51it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('csv',data_files='dataset_propositionattribution_nerfeatures.csv',delimiter=',',column_names=[\"claim\",\"premise\",\"label\",\"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\",\"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\",\"url\", \"entities\",\"entity_map\",\"entity_map_ev\",\"entities_ev\",\"gem_exp\",\"gem_label\",\"gpt_label\",\"gpt_exp\",\"gold_exp\",\"synonym\",\"voice\",\"split\"],skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "133f9357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-2b8e361375c0e153.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-0cc9bb699c2761fb.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-608a44ac65076739.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01252e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['claim', 'premise', 'label','category','count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat','counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat']\n",
    "all_columns = train_dataset.column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1623/1623 [00:00<00:00, 3117.71ex/s]\n",
      "100%|██████████| 465/465 [00:00<00:00, 3364.54ex/s]\n",
      "100%|██████████| 234/234 [00:00<00:00, 3370.75ex/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 0, 'entailment': 1, 'neutral': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 0,\n",
    "    \"entailment\": 1,\n",
    "    \"neutral\": 2\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='pritamdeka/PubMedBERT-MNLI-MedNLI'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "\n",
    "        claim = item['claim']\n",
    "        premise = item['premise'].replace('\\n', '').replace('[','').replace(']','')\n",
    "        \n",
    "        additional_features = [\n",
    "            \"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\"]\n",
    "    \n",
    "        for feature in additional_features:\n",
    "            if feature in item:\n",
    "                claim += \"[SEP]\" + str(item[feature])\n",
    "        \n",
    "        additional_features_ev = [\n",
    "            'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat']\n",
    "    \n",
    "        for feature_ev in additional_features_ev:\n",
    "            if feature_ev in item:\n",
    "                premise += \"[SEP]\" + str(item[feature])\n",
    "        item['claim']=claim\n",
    "        item['premise']=premise        \n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "             premise, claim,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "        item['input_ids'] = inputs['input_ids'].squeeze()  # Remove batch dimension\n",
    "        item['attention_mask']= inputs['attention_mask'].squeeze() # Remove batch dimension\n",
    "        \n",
    "        output_item = {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),  # Remove batch dimension\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),  # Remove batch dimension\n",
    "            'claim': claim,  # Include augmented claim text\n",
    "            'evidences': premise  # Include original evidence text\n",
    "        }\n",
    "        \n",
    "        if 'label' in item:\n",
    "            output_item['label'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return output_item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62421eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"pritamdeka/PubMedBERT-MNLI-MedNLI\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=512)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=3, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    return {\"accuracy\": acc, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f5cf584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([    2,  1920,  4415, 16984,  1927, 14542,  4006,  4480,  1930, 14227,\n",
       "          5004,  2760,  1920, 29555,  1927,  1920,  4486, 14269,  1922,  1920,\n",
       "         25420,  1930,  3185,  1920,  3238,  1954,  1930, 10472,  3170,  1942,\n",
       "          2760,  1920,  8828,  1927,  1920,  4407,  1930,  3714,  1920,  7104,\n",
       "          2495,    18,     3,    20,     3,    20,     3,    20,     3,    20,\n",
       "             3,    20,     3,    20,     3,    20,     3,    20,     3,    20,\n",
       "             3,    20,     3,    20,     3,    20,     3, 14227,  5004,  4415,\n",
       "          6691,  1977,  8929,  2251,  1922,  4407,  5715,  4461,  1942,  4087,\n",
       "          3326,  1920,  7818,  1927,  1920,  4407,    18,     3,    20,     3,\n",
       "            20,     3,    20,     3,    20,     3,    20,     3,    20,     3,\n",
       "            20,     3,    20,     3,    20,     3,    20,     3,    20,     3,\n",
       "            20,     3,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'claim': 'Myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0',\n",
       " 'evidences': 'The essential oils of frankincense and myrrh increase the fluidity of the lipid bilayer in the cuticle and change the orderly and dense structure to increase the permeability of the skin and decrease the barrier effect.[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0',\n",
       " 'label': tensor(1)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1530\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1530' max='1530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1530/1530 06:56, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.865800</td>\n",
       "      <td>0.755528</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.564864</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.587257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.642200</td>\n",
       "      <td>1.041447</td>\n",
       "      <td>0.565591</td>\n",
       "      <td>0.668382</td>\n",
       "      <td>0.565591</td>\n",
       "      <td>0.594135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.395800</td>\n",
       "      <td>1.105215</td>\n",
       "      <td>0.632258</td>\n",
       "      <td>0.640827</td>\n",
       "      <td>0.632258</td>\n",
       "      <td>0.636025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.173600</td>\n",
       "      <td>1.566556</td>\n",
       "      <td>0.608602</td>\n",
       "      <td>0.671090</td>\n",
       "      <td>0.608602</td>\n",
       "      <td>0.628544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.244000</td>\n",
       "      <td>1.709543</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.628030</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.629846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.149200</td>\n",
       "      <td>1.864890</td>\n",
       "      <td>0.604301</td>\n",
       "      <td>0.635379</td>\n",
       "      <td>0.604301</td>\n",
       "      <td>0.613524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.069000</td>\n",
       "      <td>2.338475</td>\n",
       "      <td>0.658065</td>\n",
       "      <td>0.660379</td>\n",
       "      <td>0.658065</td>\n",
       "      <td>0.659194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.052800</td>\n",
       "      <td>2.545588</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.649073</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.641123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.038500</td>\n",
       "      <td>2.586591</td>\n",
       "      <td>0.627957</td>\n",
       "      <td>0.642146</td>\n",
       "      <td>0.627957</td>\n",
       "      <td>0.631564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.025300</td>\n",
       "      <td>2.588058</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.651469</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.643858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>2.637238</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.672195</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.673541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>2.697036</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.670546</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.658204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>2.802956</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.673466</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.656191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>2.796018</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.671989</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.662655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>2.805071</td>\n",
       "      <td>0.658065</td>\n",
       "      <td>0.672421</td>\n",
       "      <td>0.658065</td>\n",
       "      <td>0.664038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/1.4.5_pubmedbert/checkpoint-102\n",
      "Configuration saved in /home/elson/1.4.5_pubmedbert/checkpoint-102/config.json\n",
      "Model weights saved in /home/elson/1.4.5_pubmedbert/checkpoint-102/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/1.4.5_pubmedbert/checkpoint-204\n",
      "Configuration saved in /home/elson/1.4.5_pubmedbert/checkpoint-204/config.json\n",
      "Model weights saved in /home/elson/1.4.5_pubmedbert/checkpoint-204/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/1.4.5_pubmedbert/checkpoint-306\n",
      "Configuration saved in /home/elson/1.4.5_pubmedbert/checkpoint-306/config.json\n",
      "Model weights saved in /home/elson/1.4.5_pubmedbert/checkpoint-306/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.5_pubmedbert/checkpoint-204] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/1.4.5_pubmedbert/checkpoint-408\n",
      "Configuration saved in /home/elson/1.4.5_pubmedbert/checkpoint-408/config.json\n",
      "Model weights saved in /home/elson/1.4.5_pubmedbert/checkpoint-408/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.5_pubmedbert/checkpoint-306] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/1.4.5_pubmedbert/checkpoint-510\n",
      "Configuration saved in /home/elson/1.4.5_pubmedbert/checkpoint-510/config.json\n",
      "Model weights saved in /home/elson/1.4.5_pubmedbert/checkpoint-510/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.5_pubmedbert/checkpoint-408] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/1.4.5_pubmedbert/checkpoint-612\n",
      "Configuration saved in /home/elson/1.4.5_pubmedbert/checkpoint-612/config.json\n",
      "Model weights saved in /home/elson/1.4.5_pubmedbert/checkpoint-612/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.5_pubmedbert/checkpoint-510] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/1.4.5_pubmedbert/checkpoint-714\n",
      "Configuration saved in /home/elson/1.4.5_pubmedbert/checkpoint-714/config.json\n",
      "Model weights saved in /home/elson/1.4.5_pubmedbert/checkpoint-714/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.5_pubmedbert/checkpoint-102] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/1.4.5_pubmedbert/checkpoint-612] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/1.4.5_pubmedbert/checkpoint-816\n",
      "Configuration saved in /home/elson/1.4.5_pubmedbert/checkpoint-816/config.json\n",
      "Model weights saved in /home/elson/1.4.5_pubmedbert/checkpoint-816/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/1.4.5_pubmedbert/checkpoint-918\n",
      "Configuration saved in /home/elson/1.4.5_pubmedbert/checkpoint-918/config.json\n",
      "Model weights saved in /home/elson/1.4.5_pubmedbert/checkpoint-918/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.5_pubmedbert/checkpoint-816] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/1.4.5_pubmedbert/checkpoint-1020\n",
      "Configuration saved in /home/elson/1.4.5_pubmedbert/checkpoint-1020/config.json\n",
      "Model weights saved in /home/elson/1.4.5_pubmedbert/checkpoint-1020/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.5_pubmedbert/checkpoint-918] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/1.4.5_pubmedbert/checkpoint-1122\n",
      "Configuration saved in /home/elson/1.4.5_pubmedbert/checkpoint-1122/config.json\n",
      "Model weights saved in /home/elson/1.4.5_pubmedbert/checkpoint-1122/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.5_pubmedbert/checkpoint-714] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/1.4.5_pubmedbert/checkpoint-1020] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/1.4.5_pubmedbert/checkpoint-1224\n",
      "Configuration saved in /home/elson/1.4.5_pubmedbert/checkpoint-1224/config.json\n",
      "Model weights saved in /home/elson/1.4.5_pubmedbert/checkpoint-1224/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/1.4.5_pubmedbert/checkpoint-1326\n",
      "Configuration saved in /home/elson/1.4.5_pubmedbert/checkpoint-1326/config.json\n",
      "Model weights saved in /home/elson/1.4.5_pubmedbert/checkpoint-1326/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.5_pubmedbert/checkpoint-1224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/1.4.5_pubmedbert/checkpoint-1428\n",
      "Configuration saved in /home/elson/1.4.5_pubmedbert/checkpoint-1428/config.json\n",
      "Model weights saved in /home/elson/1.4.5_pubmedbert/checkpoint-1428/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.5_pubmedbert/checkpoint-1326] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/1.4.5_pubmedbert/checkpoint-1530\n",
      "Configuration saved in /home/elson/1.4.5_pubmedbert/checkpoint-1530/config.json\n",
      "Model weights saved in /home/elson/1.4.5_pubmedbert/checkpoint-1530/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.5_pubmedbert/checkpoint-1428] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/elson/1.4.5_pubmedbert/checkpoint-1122 (score: 0.6752688172043011).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /home/elson/1.4.5_pubmedbert/best_model/config.json\n",
      "Model weights saved in /home/elson/1.4.5_pubmedbert/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/1.4.5_pubmedbert/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/1.4.5_pubmedbert/best_model/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/1.4.5_pubmedbert/best_model/tokenizer_config.json',\n",
       " '/home/elson/1.4.5_pubmedbert/best_model/special_tokens_map.json',\n",
       " '/home/elson/1.4.5_pubmedbert/best_model/vocab.txt',\n",
       " '/home/elson/1.4.5_pubmedbert/best_model/added_tokens.json',\n",
       " '/home/elson/1.4.5_pubmedbert/best_model/tokenizer.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/1.4.5_pubmedbert/',\n",
    "    num_train_epochs=20,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.1,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/1.4.5_pubmedbert/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/1.4.5_pubmedbert/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63deaea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/1.4.5_pubmedbert/best_model/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"/home/elson/1.4.5_pubmedbert/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"contradiction\",\n",
      "    \"1\": \"entailment\",\n",
      "    \"2\": \"neutral\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"contradiction\": 0,\n",
      "    \"entailment\": 1,\n",
      "    \"neutral\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file /home/elson/1.4.5_pubmedbert/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at /home/elson/1.4.5_pubmedbert/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 16\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/1.4.5_pubmedbert/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[-5.074  ,  4.887  , -0.9824 ],\n",
      "       [-3.521  ,  6.414  , -3.846  ],\n",
      "       [-3.523  ,  6.46   , -3.902  ],\n",
      "       [ 5.727  , -2.898  , -1.816  ],\n",
      "       [-3.145  ,  6.39   , -4.297  ],\n",
      "       [-2.926  ,  6.355  , -4.24   ],\n",
      "       [-3.756  ,  6.44   , -3.738  ],\n",
      "       [-4.82   ,  5.523  , -1.96   ],\n",
      "       [-3.354  ,  6.45   , -4.027  ],\n",
      "       [-3.213  ,  6.418  , -4.22   ],\n",
      "       [-2.959  ,  6.44   , -4.31   ],\n",
      "       [-3.428  ,  6.418  , -3.988  ],\n",
      "       [-3.678  ,  5.688  , -3.379  ],\n",
      "       [-3.426  ,  6.504  , -4.02   ],\n",
      "       [-3.54   ,  6.43   , -3.926  ],\n",
      "       [-0.02611, -3.682  ,  3.7    ],\n",
      "       [-3.578  ,  6.465  , -4.035  ],\n",
      "       [-3.31   ,  6.465  , -4.19   ],\n",
      "       [-3.559  ,  6.473  , -3.963  ],\n",
      "       [-3.729  ,  6.492  , -3.842  ],\n",
      "       [-5.387  ,  1.751  ,  2.578  ],\n",
      "       [-3.248  ,  5.453  , -3.586  ],\n",
      "       [-3.455  ,  6.504  , -4.08   ],\n",
      "       [ 5.6    , -1.459  , -3.54   ],\n",
      "       [ 5.867  , -2.809  , -1.925  ],\n",
      "       [ 5.484  , -3.957  , -0.2172 ],\n",
      "       [-3.271  ,  6.496  , -4.15   ],\n",
      "       [-4.254  ,  6.117  , -3.188  ],\n",
      "       [-3.42   ,  6.473  , -4.035  ],\n",
      "       [-3.537  ,  6.508  , -3.975  ],\n",
      "       [-3.809  , -1.156  ,  4.625  ],\n",
      "       [-3.178  ,  6.418  , -4.152  ],\n",
      "       [-4.043  ,  6.234  , -3.404  ],\n",
      "       [-3.08   ,  5.02   , -3.145  ],\n",
      "       [-4.05   ,  5.438  , -2.87   ],\n",
      "       [-3.465  ,  6.48   , -4.105  ],\n",
      "       [-3.244  ,  6.473  , -4.137  ],\n",
      "       [-3.414  ,  6.47   , -4.008  ],\n",
      "       [ 5.797  , -2.475  , -2.373  ],\n",
      "       [-3.65   ,  6.473  , -3.951  ],\n",
      "       [ 5.78   , -1.713  , -3.27   ],\n",
      "       [-4.69   ,  3.916  , -0.592  ],\n",
      "       [ 5.402  , -3.223  , -1.161  ],\n",
      "       [-3.32   , -2.64   ,  5.387  ],\n",
      "       [-4.51   ,  5.168  , -1.6875 ],\n",
      "       [-3.197  ,  6.438  , -4.113  ],\n",
      "       [ 1.27   ,  3.42   , -5.445  ],\n",
      "       [-3.074  ,  6.46   , -4.258  ],\n",
      "       [-3.115  ,  6.47   , -4.25   ],\n",
      "       [ 5.895  , -2.357  , -2.443  ],\n",
      "       [-4.406  ,  0.1519 ,  3.309  ],\n",
      "       [-3.121  , -1.86   ,  4.664  ],\n",
      "       [-3.336  ,  6.24   , -4.06   ],\n",
      "       [-4.016  ,  6.367  , -3.496  ],\n",
      "       [ 5.812  , -3.34   , -1.4375 ],\n",
      "       [-3.484  ,  6.49   , -4.01   ],\n",
      "       [-3.342  ,  6.375  , -4.15   ],\n",
      "       [-3.766  ,  6.258  , -3.797  ],\n",
      "       [-3.482  ,  6.48   , -4.047  ],\n",
      "       [-2.979  ,  6.402  , -4.395  ],\n",
      "       [-3.992  ,  6.19   , -3.512  ],\n",
      "       [ 5.414  , -2.44   , -2.086  ],\n",
      "       [-2.89   , -3.113  ,  6.105  ],\n",
      "       [-3.545  ,  6.17   , -3.867  ],\n",
      "       [-3.78   , -1.139  ,  4.67   ],\n",
      "       [-3.074  ,  6.434  , -4.32   ],\n",
      "       [-3.36   ,  6.504  , -4.086  ],\n",
      "       [-3.475  ,  6.47   , -3.975  ],\n",
      "       [-3.414  ,  6.496  , -3.988  ],\n",
      "       [ 5.71   , -2.393  , -2.324  ],\n",
      "       [-3.408  ,  6.36   , -4.133  ],\n",
      "       [-2.363  ,  5.73   , -4.504  ],\n",
      "       [-4.477  ,  4.566  , -1.554  ],\n",
      "       [-3.748  ,  6.137  , -3.662  ],\n",
      "       [-4.938  ,  0.09955,  3.916  ],\n",
      "       [ 1.997  ,  2.918  , -5.125  ],\n",
      "       [-3.562  ,  6.457  , -3.928  ],\n",
      "       [-2.447  ,  4.855  , -3.625  ],\n",
      "       [-3.266  ,  6.465  , -4.094  ],\n",
      "       [-4.184  ,  5.547  , -2.932  ],\n",
      "       [-3.498  ,  6.492  , -3.955  ],\n",
      "       [-3.533  ,  6.48   , -4.02   ],\n",
      "       [-3.832  ,  6.2    , -3.623  ],\n",
      "       [-3.08   ,  6.414  , -4.316  ],\n",
      "       [-3.145  ,  6.445  , -4.207  ],\n",
      "       [-4.32   ,  5.36   , -1.936  ],\n",
      "       [-3.205  ,  6.383  , -4.125  ],\n",
      "       [ 3.291  ,  1.194  , -4.625  ],\n",
      "       [-3.73   ,  6.383  , -3.885  ],\n",
      "       [-3.01   , -2.797  ,  5.918  ],\n",
      "       [-3.816  ,  6.41   , -3.697  ],\n",
      "       [-3.365  ,  6.44   , -4.027  ],\n",
      "       [ 5.598  , -2.096  , -2.645  ],\n",
      "       [-3.17   ,  6.473  , -4.207  ],\n",
      "       [-3.664  ,  5.31   , -3.094  ],\n",
      "       [-2.5    , -3.441  ,  6.023  ],\n",
      "       [ 5.34   , -1.706  , -2.773  ],\n",
      "       [-3.531  ,  4.168  , -1.73   ],\n",
      "       [-2.988  ,  6.367  , -4.223  ],\n",
      "       [-3.252  ,  6.457  , -4.22   ],\n",
      "       [ 5.688  , -2.266  , -2.508  ],\n",
      "       [-3.197  ,  6.453  , -4.22   ],\n",
      "       [-3.531  ,  6.496  , -3.957  ],\n",
      "       [-3.928  , -0.5093 ,  4.01   ],\n",
      "       [-3.979  ,  6.355  , -3.576  ],\n",
      "       [-3.45   ,  6.477  , -3.979  ],\n",
      "       [-3.123  ,  6.426  , -4.273  ],\n",
      "       [ 5.668  , -2.684  , -1.972  ],\n",
      "       [-3.338  ,  6.46   , -4.082  ],\n",
      "       [-4.81   ,  1.07   ,  2.893  ],\n",
      "       [-4.09   ,  6.17   , -3.086  ],\n",
      "       [-3.56   ,  6.504  , -3.955  ],\n",
      "       [-3.758  ,  6.36   , -3.707  ],\n",
      "       [-3.432  ,  6.473  , -3.998  ],\n",
      "       [-4.13   ,  6.027  , -3.22   ],\n",
      "       [-3.168  ,  6.426  , -4.082  ],\n",
      "       [-3.455  ,  6.46   , -3.99   ],\n",
      "       [-2.752  ,  6.195  , -4.46   ],\n",
      "       [-3.65   ,  6.426  , -3.697  ],\n",
      "       [-2.986  ,  6.406  , -4.324  ],\n",
      "       [-2.85   , -2.951  ,  5.89   ],\n",
      "       [-3.707  ,  6.477  , -3.805  ],\n",
      "       [-4.152  ,  5.777  , -3.12   ],\n",
      "       [-3.736  ,  0.1265 ,  2.328  ],\n",
      "       [-3.03   , -3.041  ,  6.176  ],\n",
      "       [-3.451  ,  6.477  , -4.05   ],\n",
      "       [-4.992  ,  1.314  ,  2.771  ],\n",
      "       [-2.885  ,  6.395  , -4.406  ],\n",
      "       [-2.838  ,  6.297  , -4.496  ],\n",
      "       [-3.629  ,  6.277  , -3.81   ],\n",
      "       [-3.197  ,  6.336  , -4.293  ],\n",
      "       [ 5.727  , -3.479  , -1.058  ],\n",
      "       [-3.44   ,  6.465  , -3.963  ],\n",
      "       [ 4.97   , -3.652  , -0.3943 ],\n",
      "       [-4.31   ,  5.97   , -2.984  ],\n",
      "       [-4.16   ,  5.906  , -3.24   ],\n",
      "       [-3.295  ,  6.25   , -4.043  ],\n",
      "       [-2.855  , -3.36   ,  6.332  ],\n",
      "       [-1.835  , -3.7    ,  5.785  ],\n",
      "       [-3.412  ,  6.5    , -4.043  ],\n",
      "       [-3.137  ,  6.426  , -4.133  ],\n",
      "       [ 0.10736,  3.38   , -4.508  ],\n",
      "       [ 0.1647 ,  3.018  , -3.617  ],\n",
      "       [-3.424  ,  6.5    , -4.098  ],\n",
      "       [-3.268  ,  6.383  , -4.11   ],\n",
      "       [-2.943  , -1.479  ,  4.28   ],\n",
      "       [ 5.74   , -3.389  , -1.364  ],\n",
      "       [ 5.355  , -3.617  , -0.6504 ],\n",
      "       [-3.514  ,  6.44   , -4.035  ],\n",
      "       [-3.     , -2.863  ,  5.99   ],\n",
      "       [-4.344  ,  5.87   , -2.824  ],\n",
      "       [-3.8    ,  6.406  , -3.715  ],\n",
      "       [-4.56   ,  5.562  , -2.158  ],\n",
      "       [-3.76   ,  6.32   , -3.799  ],\n",
      "       [-3.66   ,  6.4    , -3.844  ],\n",
      "       [-3.404  ,  6.48   , -4.105  ],\n",
      "       [-3.145  ,  6.457  , -4.242  ],\n",
      "       [-3.002  ,  6.344  , -4.37   ],\n",
      "       [ 5.02   , -1.466  , -2.732  ],\n",
      "       [ 5.63   , -3.41   , -1.364  ],\n",
      "       [ 6.08   , -3.031  , -1.991  ],\n",
      "       [ 6.05   , -3.04   , -1.974  ],\n",
      "       [-3.37   ,  6.418  , -4.15   ],\n",
      "       [ 5.945  , -2.742  , -2.29   ],\n",
      "       [ 4.02   , -3.295  , -0.203  ],\n",
      "       [-4.04   , -1.755  ,  5.51   ],\n",
      "       [-3.062  ,  6.355  , -4.3    ],\n",
      "       [ 0.4448 , -2.543  ,  2.295  ],\n",
      "       [ 4.31   , -4.133  ,  0.9326 ],\n",
      "       [-3.027  ,  5.582  , -3.805  ],\n",
      "       [ 5.97   , -3.367  , -1.405  ],\n",
      "       [-2.725  ,  5.742  , -4.258  ],\n",
      "       [ 6.027  , -2.695  , -2.373  ],\n",
      "       [-3.803  ,  6.42   , -3.8    ],\n",
      "       [-3.3    ,  6.508  , -4.06   ],\n",
      "       [-3.594  ,  5.348  , -2.906  ],\n",
      "       [-3.424  ,  6.504  , -4.05   ],\n",
      "       [ 5.613  , -3.31   , -1.094  ],\n",
      "       [-2.441  ,  6.242  , -4.637  ],\n",
      "       [-3.344  ,  6.24   , -4.117  ],\n",
      "       [-3.914  ,  0.882  ,  2.623  ],\n",
      "       [ 5.094  , -2.469  , -1.846  ],\n",
      "       [ 5.094  , -3.256  , -1.03   ],\n",
      "       [-4.168  ,  6.188  , -3.264  ],\n",
      "       [ 5.598  , -3.38   , -1.158  ],\n",
      "       [-3.438  ,  6.457  , -4.055  ],\n",
      "       [-3.453  ,  6.47   , -4.09   ],\n",
      "       [-3.555  ,  6.516  , -3.979  ],\n",
      "       [-4.164  ,  6.195  , -3.209  ],\n",
      "       [-4.15   ,  6.156  , -3.158  ],\n",
      "       [-3.959  ,  1.308  ,  1.186  ],\n",
      "       [-3.95   ,  6.414  , -3.426  ],\n",
      "       [-3.496  ,  6.523  , -3.969  ],\n",
      "       [-4.402  ,  1.291  ,  2.064  ],\n",
      "       [ 6.105  , -2.951  , -2.094  ],\n",
      "       [-3.203  ,  6.453  , -4.145  ],\n",
      "       [-4.656  ,  5.67   , -2.264  ],\n",
      "       [-3.426  ,  6.484  , -4.01   ],\n",
      "       [-3.346  ,  6.266  , -4.027  ],\n",
      "       [-4.645  ,  1.484  ,  2.531  ],\n",
      "       [-3.592  ,  6.53   , -3.914  ],\n",
      "       [-3.094  ,  6.41   , -4.21   ],\n",
      "       [-3.762  ,  5.76   , -3.3    ],\n",
      "       [-3.771  ,  6.402  , -3.764  ],\n",
      "       [-4.098  ,  6.023  , -3.188  ],\n",
      "       [-1.43   , -2.578  ,  3.512  ],\n",
      "       [-3.232  ,  6.484  , -4.195  ],\n",
      "       [-2.762  , -2.791  ,  5.574  ],\n",
      "       [-3.145  ,  6.44   , -4.133  ],\n",
      "       [-3.455  ,  6.383  , -4.066  ],\n",
      "       [-4.4    ,  5.324  , -2.05   ],\n",
      "       [-4.254  ,  0.1875 ,  3.656  ],\n",
      "       [-3.55   ,  6.457  , -4.004  ],\n",
      "       [-3.133  ,  6.41   , -4.16   ],\n",
      "       [-3.256  ,  6.477  , -4.12   ],\n",
      "       [ 5.81   , -3.027  , -1.747  ],\n",
      "       [ 5.508  , -2.217  , -2.396  ],\n",
      "       [-3.096  ,  6.145  , -4.098  ],\n",
      "       [-3.512  ,  6.477  , -3.93   ],\n",
      "       [-3.492  ,  6.473  , -4.02   ],\n",
      "       [-3.592  ,  6.414  , -3.959  ],\n",
      "       [-3.783  ,  6.42   , -3.715  ],\n",
      "       [ 5.54   , -2.117  , -2.496  ],\n",
      "       [-3.172  ,  6.47   , -4.152  ],\n",
      "       [-2.777  ,  6.383  , -4.39   ],\n",
      "       [-3.213  ,  6.42   , -4.086  ],\n",
      "       [-3.213  ,  6.477  , -4.125  ],\n",
      "       [-2.74   , -2.48   ,  4.69   ],\n",
      "       [-3.393  , -0.4126 ,  3.244  ],\n",
      "       [ 5.75   , -2.902  , -1.852  ],\n",
      "       [-3.246  ,  6.465  , -4.098  ],\n",
      "       [-3.96   ,  6.15   , -3.494  ],\n",
      "       [-0.8325 ,  2.557  , -2.516  ],\n",
      "       [ 5.336  , -2.688  , -1.795  ]], dtype=float16), label_ids=array([1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1,\n",
      "       1, 2, 0, 0, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 0, 1, 0, 2, 1, 1,\n",
      "       2, 0, 1, 1, 1, 0, 2, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 0, 2, 1, 2, 1,\n",
      "       1, 2, 0, 0, 1, 1, 2, 2, 2, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1,\n",
      "       1, 2, 1, 1, 2, 1, 2, 2, 0, 1, 1, 2, 0, 2, 1, 2, 1, 1, 1, 2, 1, 1,\n",
      "       2, 0, 1, 1, 2, 1, 1, 1, 2, 0, 2, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2,\n",
      "       1, 2, 1, 2, 1, 1, 2, 1, 0, 1, 1, 1, 2, 2, 0, 2, 1, 1, 1, 1, 2, 2,\n",
      "       0, 1, 1, 2, 1, 0, 0, 0, 2, 1, 1, 2, 1, 2, 0, 1, 0, 1, 2, 1, 1, 1,\n",
      "       1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 0, 0, 1, 2, 1,\n",
      "       1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 2, 0, 1, 1,\n",
      "       1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 0, 1, 1, 2]), metrics={'test_loss': 2.741118907928467, 'test_accuracy': 0.6623931623931624, 'test_precision': 0.6589474345783732, 'test_recall': 0.6623931623931624, 'test_f1': 0.6362566572500348, 'test_runtime': 1.2436, 'test_samples_per_second': 188.169, 'test_steps_per_second': 12.062})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d4e861c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "probabilities = torch.softmax(torch.tensor(test_results.predictions).to(torch.float32), dim=-1)\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)\n",
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1747566",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_save = []\n",
    "for idx in range(len(test_data)):\n",
    "    item = dataset['test'][idx]\n",
    "    actual_label = item['label']\n",
    "    predicted_label = predictions[idx]\n",
    "    claim = item['claim'] \n",
    "    premise = item['premise'] \n",
    "    category = item['category']\n",
    "    \n",
    "    # Append the information as a dictionary to the list\n",
    "    data_to_save.append({\n",
    "        'Claim': claim,\n",
    "        'Premise': premise,\n",
    "        'Actual Label': actual_label,\n",
    "        'Predicted Label': predicted_label,\n",
    "        'Category' : category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_to_save)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/home/elson/results/1.4.4_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f40c56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correctly classified instances\n",
    "correctly_classified = df[df['Actual Label'] == df['Predicted Label']]\n",
    "\n",
    "# Calculate misclassified instances\n",
    "misclassified = df[df['Actual Label'] != df['Predicted Label']]\n",
    "\n",
    "# Count the number of correctly classified and misclassified by category\n",
    "correct_classification_counts = correctly_classified['Category'].value_counts()\n",
    "misclassification_counts = misclassified['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61d30750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           41\n",
       "Bone health              13\n",
       "Fitness                  13\n",
       "Skin                     12\n",
       "Diabetes                 10\n",
       "Cardiovascular Health     9\n",
       "Cancer                    8\n",
       "Throat                    8\n",
       "Neurological health       7\n",
       "Ear                       6\n",
       "Hair                      5\n",
       "Women' s Health           4\n",
       "Blood                     4\n",
       "COVID                     4\n",
       "Men's health              3\n",
       "Mental Health             3\n",
       "Vascular                  2\n",
       "Eye                       2\n",
       "Muscles                   1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "670ffadf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Skin                     12\n",
       "General Health           10\n",
       "Bone health               8\n",
       "Eye                       7\n",
       "Hair                      7\n",
       "Blood                     5\n",
       "Muscles                   5\n",
       "Cancer                    4\n",
       "Cardiovascular Health     3\n",
       "Dental Health             3\n",
       "Men's health              3\n",
       "Fitness                   2\n",
       "Women' s Health           2\n",
       "Diabetes                  2\n",
       "COVID                     2\n",
       "Neurological health       2\n",
       "Vascular                  1\n",
       "Throat                    1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
