{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-022bc67e9c58e92d\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 183.05it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('csv',data_files='dataset_propositionattribution_nerfeatures.csv',delimiter=',',column_names=[\"claim\",\"premise\",\"label\",\"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\",\"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\",\"url\", \"entities\",\"entity_map\",\"entity_map_ev\",\"entities_ev\",\"gem_exp\",\"gem_label\",\"gpt_label\",\"gpt_exp\",\"gold_exp\",\"synonym\",\"voice\",\"split\"],skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "133f9357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-2b8e361375c0e153.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-0cc9bb699c2761fb.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-608a44ac65076739.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01252e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\"claim\", \"premise\", \"label\", \"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\"]\n",
    "all_columns = dataset[\"train\"].column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-18f96bf5c6176fc5.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-6db4f01ca05878d4.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-1a61e2b1bf2efa35.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 2, 'entailment': 0, 'neutral': 1}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 2,\n",
    "    \"entailment\": 0,\n",
    "    \"neutral\": 1\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e15010ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='bioformers/bioformer-8L-mnli'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "        # Extracting claim and evidence texts\n",
    "        claim = item['claim'] \n",
    "        evidences = item['premise']\n",
    "        item['premise']=evidences\n",
    "        item['claim']=claim\n",
    "        additional_features = [\n",
    "            \"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\"]\n",
    "    \n",
    "        for feature in additional_features:\n",
    "            if feature in item:\n",
    "                claim += \"[SEP]\" + str(item[feature])\n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "            evidences,claim,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "         # Construct the output item\n",
    "        output_item = {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),  # Remove batch dimension\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),  # Remove batch dimension\n",
    "            'claim': claim,  # Include augmented claim text\n",
    "            'evidences': evidences  # Include original evidence text\n",
    "        }\n",
    "        \n",
    "        if 'label' in item:\n",
    "            output_item['label'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return output_item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62421eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(32768, 512, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 512)\n",
       "      (token_type_embeddings): Embedding(2, 512)\n",
       "      (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=512, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"bioformers/bioformer-8L-mnli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=512)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=3, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    return {\"accuracy\": acc, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f5cf584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  101,  1480,  3720, 15658,  1431,  2132,  4765,  2848,  9507,  1111,\n",
       "          1435,  2573,  1109,  4258,  2161,  1425, 26267,  1431,  1425,  3460,\n",
       "         14360,  1427,  1425, 26669,  1435,  2731,  1425,  2784,  1456,  1435,\n",
       "         10036,  2700,  1446,  2161,  1425,  7805,  1431,  1425,  3550,  1435,\n",
       "          3026,  1425,  6245,  1997,   119,   102, 31487,  4258,  3720,  6187,\n",
       "          1478,  8811,  1822,  1427,  3550,  5183,  4030,  1446,  3346,  2520,\n",
       "          1425,  6875,  1431,  1425,  3550,   119,   102,   121,   102,   121,\n",
       "           102,   121,   102,   121,   102,   121,   102,   121,   102,   121,\n",
       "           102,   121,   102,   121,   102,   121,   102,   121,   102,   121,\n",
       "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'claim': 'Myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0',\n",
       " 'evidences': 'The essential oils of frankincense and myrrh increase the fluidity of the lipid bilayer in the cuticle and change the orderly and dense structure to increase the permeability of the skin and decrease the barrier effect.',\n",
       " 'label': tensor(0)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1530\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1530' max='1530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1530/1530 03:21, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.852500</td>\n",
       "      <td>0.816702</td>\n",
       "      <td>0.647312</td>\n",
       "      <td>0.607754</td>\n",
       "      <td>0.647312</td>\n",
       "      <td>0.610933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.614600</td>\n",
       "      <td>0.932138</td>\n",
       "      <td>0.602151</td>\n",
       "      <td>0.644016</td>\n",
       "      <td>0.602151</td>\n",
       "      <td>0.618093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.371300</td>\n",
       "      <td>1.184310</td>\n",
       "      <td>0.621505</td>\n",
       "      <td>0.634335</td>\n",
       "      <td>0.621505</td>\n",
       "      <td>0.619767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.230200</td>\n",
       "      <td>1.390831</td>\n",
       "      <td>0.606452</td>\n",
       "      <td>0.647973</td>\n",
       "      <td>0.606452</td>\n",
       "      <td>0.622399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.257700</td>\n",
       "      <td>1.463313</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>0.609967</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>0.612391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.136400</td>\n",
       "      <td>1.638386</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.634527</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.638385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.081700</td>\n",
       "      <td>1.859563</td>\n",
       "      <td>0.619355</td>\n",
       "      <td>0.630105</td>\n",
       "      <td>0.619355</td>\n",
       "      <td>0.624096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.091300</td>\n",
       "      <td>1.970165</td>\n",
       "      <td>0.615054</td>\n",
       "      <td>0.630833</td>\n",
       "      <td>0.615054</td>\n",
       "      <td>0.621267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.128400</td>\n",
       "      <td>2.032857</td>\n",
       "      <td>0.630108</td>\n",
       "      <td>0.641989</td>\n",
       "      <td>0.630108</td>\n",
       "      <td>0.632780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.024600</td>\n",
       "      <td>2.129369</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>0.636407</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>0.628262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.028400</td>\n",
       "      <td>2.108407</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.636895</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.641077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>2.196468</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.645153</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.639990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>2.213295</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.652091</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.649942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>2.221684</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.647595</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.647656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.010900</td>\n",
       "      <td>2.229402</td>\n",
       "      <td>0.658065</td>\n",
       "      <td>0.651493</td>\n",
       "      <td>0.658065</td>\n",
       "      <td>0.651727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.3_bioformer/checkpoint-102\n",
      "Configuration saved in /home/elson/11.4.3_bioformer/checkpoint-102/config.json\n",
      "Model weights saved in /home/elson/11.4.3_bioformer/checkpoint-102/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.3_bioformer/checkpoint-51] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/11.4.3_bioformer/checkpoint-765] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.3_bioformer/checkpoint-204\n",
      "Configuration saved in /home/elson/11.4.3_bioformer/checkpoint-204/config.json\n",
      "Model weights saved in /home/elson/11.4.3_bioformer/checkpoint-204/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.3_bioformer/checkpoint-306\n",
      "Configuration saved in /home/elson/11.4.3_bioformer/checkpoint-306/config.json\n",
      "Model weights saved in /home/elson/11.4.3_bioformer/checkpoint-306/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.3_bioformer/checkpoint-204] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.3_bioformer/checkpoint-408\n",
      "Configuration saved in /home/elson/11.4.3_bioformer/checkpoint-408/config.json\n",
      "Model weights saved in /home/elson/11.4.3_bioformer/checkpoint-408/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.3_bioformer/checkpoint-306] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.3_bioformer/checkpoint-510\n",
      "Configuration saved in /home/elson/11.4.3_bioformer/checkpoint-510/config.json\n",
      "Model weights saved in /home/elson/11.4.3_bioformer/checkpoint-510/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.3_bioformer/checkpoint-408] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.3_bioformer/checkpoint-612\n",
      "Configuration saved in /home/elson/11.4.3_bioformer/checkpoint-612/config.json\n",
      "Model weights saved in /home/elson/11.4.3_bioformer/checkpoint-612/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.3_bioformer/checkpoint-510] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.3_bioformer/checkpoint-714\n",
      "Configuration saved in /home/elson/11.4.3_bioformer/checkpoint-714/config.json\n",
      "Model weights saved in /home/elson/11.4.3_bioformer/checkpoint-714/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.3_bioformer/checkpoint-612] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.3_bioformer/checkpoint-816\n",
      "Configuration saved in /home/elson/11.4.3_bioformer/checkpoint-816/config.json\n",
      "Model weights saved in /home/elson/11.4.3_bioformer/checkpoint-816/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.3_bioformer/checkpoint-714] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.3_bioformer/checkpoint-918\n",
      "Configuration saved in /home/elson/11.4.3_bioformer/checkpoint-918/config.json\n",
      "Model weights saved in /home/elson/11.4.3_bioformer/checkpoint-918/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.3_bioformer/checkpoint-816] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.3_bioformer/checkpoint-1020\n",
      "Configuration saved in /home/elson/11.4.3_bioformer/checkpoint-1020/config.json\n",
      "Model weights saved in /home/elson/11.4.3_bioformer/checkpoint-1020/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.3_bioformer/checkpoint-918] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.3_bioformer/checkpoint-1122\n",
      "Configuration saved in /home/elson/11.4.3_bioformer/checkpoint-1122/config.json\n",
      "Model weights saved in /home/elson/11.4.3_bioformer/checkpoint-1122/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.3_bioformer/checkpoint-102] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/11.4.3_bioformer/checkpoint-1020] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.3_bioformer/checkpoint-1224\n",
      "Configuration saved in /home/elson/11.4.3_bioformer/checkpoint-1224/config.json\n",
      "Model weights saved in /home/elson/11.4.3_bioformer/checkpoint-1224/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.3_bioformer/checkpoint-1326\n",
      "Configuration saved in /home/elson/11.4.3_bioformer/checkpoint-1326/config.json\n",
      "Model weights saved in /home/elson/11.4.3_bioformer/checkpoint-1326/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.3_bioformer/checkpoint-1122] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/11.4.3_bioformer/checkpoint-1224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.3_bioformer/checkpoint-1428\n",
      "Configuration saved in /home/elson/11.4.3_bioformer/checkpoint-1428/config.json\n",
      "Model weights saved in /home/elson/11.4.3_bioformer/checkpoint-1428/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.3_bioformer/checkpoint-1530\n",
      "Configuration saved in /home/elson/11.4.3_bioformer/checkpoint-1530/config.json\n",
      "Model weights saved in /home/elson/11.4.3_bioformer/checkpoint-1530/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.3_bioformer/checkpoint-1326] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/11.4.3_bioformer/checkpoint-1428] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/elson/11.4.3_bioformer/checkpoint-1530 (score: 0.6580645161290323).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /home/elson/11.4.3_bioformer/best_model/config.json\n",
      "Model weights saved in /home/elson/11.4.3_bioformer/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/11.4.3_bioformer/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/11.4.3_bioformer/best_model/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/11.4.3_bioformer/best_model/tokenizer_config.json',\n",
       " '/home/elson/11.4.3_bioformer/best_model/special_tokens_map.json',\n",
       " '/home/elson/11.4.3_bioformer/best_model/vocab.txt',\n",
       " '/home/elson/11.4.3_bioformer/best_model/added_tokens.json',\n",
       " '/home/elson/11.4.3_bioformer/best_model/tokenizer.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/11.4.3_bioformer/',\n",
    "    num_train_epochs=15,\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.1,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/11.4.3_bioformer/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/11.4.3_bioformer/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63deaea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/11.4.3_bioformer/best_model/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"/home/elson/11.4.3_bioformer/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"finetuning_task\": \"mnli\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 512,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"entailment\",\n",
      "    \"1\": \"neutral\",\n",
      "    \"2\": \"contradiction\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2048,\n",
      "  \"label2id\": {\n",
      "    \"contradiction\": 2,\n",
      "    \"entailment\": 0,\n",
      "    \"neutral\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 8,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32768\n",
      "}\n",
      "\n",
      "loading weights file /home/elson/11.4.3_bioformer/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at /home/elson/11.4.3_bioformer/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 16\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/11.4.3_bioformer/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[ 5.65   , -2.533  , -3.121  ],\n",
      "       [ 0.4082 ,  4.176  , -4.535  ],\n",
      "       [ 5.62   , -3.062  , -2.594  ],\n",
      "       [-3.031  , -2.326  ,  5.67   ],\n",
      "       [ 5.62   , -2.912  , -2.617  ],\n",
      "       [ 5.785  , -3.078  , -2.668  ],\n",
      "       [ 5.74   , -3.213  , -2.553  ],\n",
      "       [ 5.664  , -2.482  , -3.145  ],\n",
      "       [ 3.547  , -0.4346 , -3.197  ],\n",
      "       [ 4.977  , -1.935  , -3.1    ],\n",
      "       [ 5.6    , -3.572  , -2.059  ],\n",
      "       [ 5.703  , -3.33   , -2.36   ],\n",
      "       [ 5.746  , -2.777  , -2.953  ],\n",
      "       [ 5.77   , -2.812  , -2.959  ],\n",
      "       [ 5.785  , -2.982  , -2.8    ],\n",
      "       [-2.777  , -1.356  ,  4.24   ],\n",
      "       [ 5.74   , -2.867  , -2.9    ],\n",
      "       [ 5.766  , -3.066  , -2.674  ],\n",
      "       [ 4.562  , -0.91   , -3.715  ],\n",
      "       [ 5.79   , -3.102  , -2.648  ],\n",
      "       [ 5.168  , -3.344  , -2.082  ],\n",
      "       [-0.841  ,  3.92   , -3.016  ],\n",
      "       [ 5.734  , -2.895  , -2.814  ],\n",
      "       [-2.973  , -2.275  ,  5.52   ],\n",
      "       [-0.509  , -2.988  ,  3.553  ],\n",
      "       [-3.516  ,  0.00597,  3.758  ],\n",
      "       [ 5.76   , -3.133  , -2.596  ],\n",
      "       [-2.953  ,  5.645  , -2.203  ],\n",
      "       [ 5.74   , -2.652  , -3.072  ],\n",
      "       [ 5.676  , -3.238  , -2.44   ],\n",
      "       [ 5.156  , -1.62   , -3.658  ],\n",
      "       [ 5.734  , -2.791  , -2.852  ],\n",
      "       [ 5.297  , -2.652  , -2.775  ],\n",
      "       [-2.012  , -1.714  ,  4.316  ],\n",
      "       [ 4.656  , -0.541  , -4.195  ],\n",
      "       [ 5.766  , -2.758  , -3.014  ],\n",
      "       [ 5.723  , -2.969  , -2.756  ],\n",
      "       [ 5.742  , -2.574  , -3.1    ],\n",
      "       [-0.4167 , -3.822  ,  4.5    ],\n",
      "       [ 5.72   , -2.592  , -3.172  ],\n",
      "       [-2.686  , -0.1748 ,  2.89   ],\n",
      "       [-1.631  ,  5.336  , -3.465  ],\n",
      "       [ 5.1    , -3.139  , -2.158  ],\n",
      "       [ 0.6865 , -4.04   ,  3.365  ],\n",
      "       [ 5.367  , -1.552  , -3.896  ],\n",
      "       [ 5.8    , -2.826  , -2.926  ],\n",
      "       [ 3.488  , -0.03738, -3.559  ],\n",
      "       [ 5.777  , -2.53   , -3.23   ],\n",
      "       [ 5.59   , -3.254  , -2.367  ],\n",
      "       [-2.617  , -2.37   ,  5.4    ],\n",
      "       [ 5.23   , -3.432  , -2.012  ],\n",
      "       [ 0.4004 ,  2.771  , -2.781  ],\n",
      "       [-0.3953 ,  1.712  , -1.069  ],\n",
      "       [-1.919  ,  5.285  , -3.033  ],\n",
      "       [-2.248  ,  0.7354 ,  1.538  ],\n",
      "       [ 2.254  ,  1.241  , -3.486  ],\n",
      "       [ 0.1783 ,  3.904  , -3.873  ],\n",
      "       [-0.712  ,  4.723  , -4.02   ],\n",
      "       [ 4.543  , -1.389  , -3.188  ],\n",
      "       [ 5.76   , -3.084  , -2.707  ],\n",
      "       [ 5.723  , -2.344  , -3.275  ],\n",
      "       [-2.117  , -2.684  ,  5.19   ],\n",
      "       [ 0.826  ,  3.945  , -4.723  ],\n",
      "       [ 5.242  , -1.732  , -3.389  ],\n",
      "       [ 5.562  , -1.811  , -3.805  ],\n",
      "       [ 5.664  , -3.092  , -2.502  ],\n",
      "       [ 5.754  , -3.115  , -2.613  ],\n",
      "       [ 5.707  , -3.152  , -2.535  ],\n",
      "       [ 5.62   , -3.54   , -2.127  ],\n",
      "       [ 3.207  , -1.999  , -1.21   ],\n",
      "       [ 5.707  , -2.928  , -2.775  ],\n",
      "       [ 5.117  , -1.803  , -3.346  ],\n",
      "       [ 5.76   , -2.809  , -2.99   ],\n",
      "       [ 5.715  , -2.299  , -3.361  ],\n",
      "       [ 3.842  , -0.7344 , -3.234  ],\n",
      "       [ 3.803  , -3.701  , -0.414  ],\n",
      "       [ 5.73   , -3.035  , -2.707  ],\n",
      "       [ 5.586  , -2.205  , -3.406  ],\n",
      "       [ 5.69   , -3.191  , -2.54   ],\n",
      "       [ 5.355  , -3.678  , -1.79   ],\n",
      "       [ 5.676  , -3.041  , -2.596  ],\n",
      "       [ 5.746  , -3.094  , -2.69   ],\n",
      "       [ 5.703  , -3.008  , -2.729  ],\n",
      "       [ 5.715  , -3.309  , -2.428  ],\n",
      "       [ 5.74   , -3.172  , -2.545  ],\n",
      "       [ 5.55   , -2.947  , -2.646  ],\n",
      "       [ 5.64   , -3.258  , -2.355  ],\n",
      "       [ 3.967  , -2.387  , -1.486  ],\n",
      "       [ 3.104  ,  1.766  , -4.85   ],\n",
      "       [-0.507  ,  4.797  , -4.2    ],\n",
      "       [ 5.633  , -3.148  , -2.537  ],\n",
      "       [ 5.79   , -2.723  , -3.045  ],\n",
      "       [-3.912  , -1.22   ,  5.47   ],\n",
      "       [ 5.797  , -2.768  , -3.025  ],\n",
      "       [-2.502  ,  2.174  ,  0.6333 ],\n",
      "       [ 1.435  ,  0.1843 , -1.848  ],\n",
      "       [-1.649  , -3.426  ,  4.867  ],\n",
      "       [ 5.527  , -2.71   , -2.91   ],\n",
      "       [ 5.598  , -1.896  , -3.656  ],\n",
      "       [ 5.74   , -2.807  , -2.91   ],\n",
      "       [ 0.05093, -4.28   ,  4.363  ],\n",
      "       [ 5.785  , -2.941  , -2.78   ],\n",
      "       [ 5.797  , -2.9    , -2.83   ],\n",
      "       [ 5.402  , -1.327  , -4.152  ],\n",
      "       [ 5.758  , -2.54   , -3.145  ],\n",
      "       [ 5.54   , -1.8    , -3.74   ],\n",
      "       [ 5.473  , -3.06   , -2.361  ],\n",
      "       [ 4.008  , -2.55   , -1.629  ],\n",
      "       [ 5.406  , -1.461  , -3.963  ],\n",
      "       [ 5.664  , -2.312  , -3.354  ],\n",
      "       [ 0.4094 ,  4.21   , -4.51   ],\n",
      "       [ 5.645  , -2.834  , -2.744  ],\n",
      "       [ 5.574  , -2.783  , -2.887  ],\n",
      "       [ 5.72   , -3.078  , -2.635  ],\n",
      "       [-1.219  ,  4.453  , -2.912  ],\n",
      "       [ 5.676  , -2.918  , -2.73   ],\n",
      "       [ 5.727  , -3.258  , -2.45   ],\n",
      "       [ 2.094  , -3.984  ,  2.277  ],\n",
      "       [ 5.645  , -3.264  , -2.42   ],\n",
      "       [ 5.723  , -2.775  , -2.967  ],\n",
      "       [-0.02563,  4.477  , -4.312  ],\n",
      "       [ 5.746  , -2.914  , -2.85   ],\n",
      "       [ 1.595  ,  3.305  , -4.98   ],\n",
      "       [-0.8926 ,  4.99   , -3.713  ],\n",
      "       [-2.18   ,  5.453  , -2.895  ],\n",
      "       [ 5.766  , -2.814  , -2.988  ],\n",
      "       [ 5.418  , -1.931  , -3.467  ],\n",
      "       [ 5.766  , -3.07   , -2.709  ],\n",
      "       [ 5.71   , -3.154  , -2.527  ],\n",
      "       [ 5.633  , -2.719  , -3.     ],\n",
      "       [ 1.309  , -0.7095 , -0.3577 ],\n",
      "       [-3.342  ,  4.188  , -0.269  ],\n",
      "       [ 5.773  , -2.756  , -2.94   ],\n",
      "       [ 3.385  , -1.676  , -2.006  ],\n",
      "       [ 5.312  , -2.133  , -3.19   ],\n",
      "       [ 5.74   , -2.977  , -2.709  ],\n",
      "       [ 5.69   , -3.086  , -2.596  ],\n",
      "       [-0.2433 ,  4.39   , -4.055  ],\n",
      "       [-2.602  ,  4.848  , -1.768  ],\n",
      "       [ 5.797  , -2.674  , -3.01   ],\n",
      "       [ 5.785  , -2.945  , -2.812  ],\n",
      "       [-2.79   , -1.039  ,  3.787  ],\n",
      "       [-3.121  ,  5.273  , -1.754  ],\n",
      "       [ 5.76   , -2.998  , -2.725  ],\n",
      "       [ 5.39   , -2.277  , -3.254  ],\n",
      "       [-3.748  ,  2.246  ,  1.682  ],\n",
      "       [-2.678  , -2.496  ,  5.547  ],\n",
      "       [ 1.574  , -0.02258, -1.204  ],\n",
      "       [ 5.78   , -2.922  , -2.81   ],\n",
      "       [ 3.932  ,  0.4272 , -4.297  ],\n",
      "       [ 5.73   , -2.523  , -3.146  ],\n",
      "       [ 5.633  , -3.082  , -2.605  ],\n",
      "       [ 5.414  , -2.22   , -3.184  ],\n",
      "       [ 5.668  , -3.209  , -2.49   ],\n",
      "       [ 5.77   , -2.85   , -2.873  ],\n",
      "       [ 5.73   , -3.133  , -2.6    ],\n",
      "       [ 5.707  , -3.314  , -2.365  ],\n",
      "       [ 5.766  , -2.959  , -2.768  ],\n",
      "       [-3.639  ,  4.586  , -0.566  ],\n",
      "       [-2.674  , -2.5    ,  5.516  ],\n",
      "       [-2.643  , -2.553  ,  5.64   ],\n",
      "       [-2.426  , -2.775  ,  5.6    ],\n",
      "       [ 5.152  , -1.728  , -3.525  ],\n",
      "       [-3.342  ,  1.599  ,  1.714  ],\n",
      "       [ 3.652  , -1.777  , -2.227  ],\n",
      "       [ 5.613  , -2.951  , -2.758  ],\n",
      "       [ 5.676  , -3.236  , -2.426  ],\n",
      "       [-1.926  , -1.159  ,  2.994  ],\n",
      "       [ 3.928  , -2.145  , -1.483  ],\n",
      "       [-0.3777 , -2.908  ,  3.58   ],\n",
      "       [-3.443  , -1.791  ,  5.63   ],\n",
      "       [-2.193  , -2.54   ,  5.15   ],\n",
      "       [ 3.752  , -3.365  , -0.4995 ],\n",
      "       [ 5.7    , -2.352  , -3.303  ],\n",
      "       [ 5.777  , -3.088  , -2.639  ],\n",
      "       [ 5.64   , -2.508  , -3.1    ],\n",
      "       [ 5.76   , -3.186  , -2.586  ],\n",
      "       [ 1.483  , -3.81   ,  2.584  ],\n",
      "       [ 5.57   , -3.107  , -2.383  ],\n",
      "       [-1.486  ,  4.65   , -2.61   ],\n",
      "       [ 1.611  , -0.709  , -1.1045 ],\n",
      "       [ 5.31   , -2.31   , -3.145  ],\n",
      "       [-3.021  , -1.941  ,  5.395  ],\n",
      "       [ 5.72   , -2.504  , -3.08   ],\n",
      "       [-4.137  ,  0.2573 ,  4.21   ],\n",
      "       [ 5.688  , -3.227  , -2.5    ],\n",
      "       [ 5.74   , -2.383  , -3.291  ],\n",
      "       [ 5.785  , -2.602  , -3.139  ],\n",
      "       [ 5.07   , -0.959  , -3.977  ],\n",
      "       [ 5.426  , -1.931  , -3.451  ],\n",
      "       [ 0.2197 ,  4.3    , -4.227  ],\n",
      "       [ 3.676  ,  0.8027 , -4.2    ],\n",
      "       [ 5.203  , -3.305  , -1.907  ],\n",
      "       [ 4.55   , -0.7026 , -3.871  ],\n",
      "       [-3.117  , -2.057  ,  5.55   ],\n",
      "       [ 5.758  , -3.094  , -2.61   ],\n",
      "       [ 5.652  , -2.766  , -2.93   ],\n",
      "       [ 5.793  , -3.055  , -2.668  ],\n",
      "       [ 5.688  , -3.322  , -2.342  ],\n",
      "       [ 2.914  ,  0.919  , -3.867  ],\n",
      "       [ 5.715  , -3.299  , -2.402  ],\n",
      "       [ 5.785  , -3.016  , -2.72   ],\n",
      "       [ 4.91   , -2.115  , -2.793  ],\n",
      "       [ 5.668  , -2.27   , -3.363  ],\n",
      "       [ 5.277  , -1.284  , -4.043  ],\n",
      "       [-0.4253 , -2.03   ,  2.146  ],\n",
      "       [ 5.773  , -3.078  , -2.695  ],\n",
      "       [ 2.996  ,  0.2441 , -3.145  ],\n",
      "       [ 5.69   , -2.82   , -2.877  ],\n",
      "       [ 5.676  , -3.     , -2.79   ],\n",
      "       [-1.078  ,  5.094  , -3.781  ],\n",
      "       [ 5.016  , -1.758  , -3.371  ],\n",
      "       [ 4.758  , -3.488  , -1.42   ],\n",
      "       [ 5.312  , -1.768  , -3.564  ],\n",
      "       [ 5.766  , -2.953  , -2.807  ],\n",
      "       [-2.307  , -2.754  ,  5.297  ],\n",
      "       [ 1.203  , -2.844  ,  1.478  ],\n",
      "       [ 5.316  , -2.777  , -2.646  ],\n",
      "       [ 5.734  , -2.979  , -2.732  ],\n",
      "       [-0.02992,  3.957  , -3.621  ],\n",
      "       [ 5.742  , -2.691  , -2.986  ],\n",
      "       [ 0.0671 ,  4.164  , -4.312  ],\n",
      "       [ 1.857  , -3.78   ,  1.592  ],\n",
      "       [ 5.668  , -3.16   , -2.486  ],\n",
      "       [ 5.6    , -2.969  , -2.574  ],\n",
      "       [ 5.793  , -2.965  , -2.781  ],\n",
      "       [ 5.703  , -3.225  , -2.463  ],\n",
      "       [-2.68   , -1.703  ,  4.45   ],\n",
      "       [ 1.778  ,  0.4924 , -2.266  ],\n",
      "       [-2.617  ,  2.139  ,  0.6914 ],\n",
      "       [ 5.79   , -2.945  , -2.797  ],\n",
      "       [ 5.656  , -2.291  , -3.324  ],\n",
      "       [ 5.37   , -3.47   , -1.77   ],\n",
      "       [ 1.343  , -0.83   , -0.1295 ]], dtype=float16), label_ids=array([0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
      "       0, 1, 2, 2, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 2, 0, 2, 1, 0, 0,\n",
      "       1, 2, 0, 0, 0, 2, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 2, 1, 0, 1, 0,\n",
      "       0, 1, 2, 2, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
      "       0, 1, 0, 0, 1, 0, 1, 1, 2, 0, 0, 1, 2, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "       1, 2, 0, 0, 1, 0, 0, 0, 1, 2, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
      "       0, 1, 0, 1, 0, 0, 1, 0, 2, 0, 0, 0, 1, 1, 2, 1, 0, 0, 0, 0, 1, 1,\n",
      "       2, 0, 0, 1, 0, 2, 2, 2, 1, 0, 0, 1, 0, 1, 2, 0, 2, 0, 1, 0, 0, 0,\n",
      "       0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 2, 2, 0, 1, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 2, 0, 0,\n",
      "       0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 2, 0, 0, 1]), metrics={'test_loss': 2.322758674621582, 'test_accuracy': 0.6495726495726496, 'test_precision': 0.6470085470085469, 'test_recall': 0.6495726495726496, 'test_f1': 0.6218110972209333, 'test_runtime': 0.5892, 'test_samples_per_second': 397.136, 'test_steps_per_second': 25.457})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "808dd68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48fb2163",
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = torch.softmax(torch.tensor(test_results.predictions).to(torch.float32), dim=-1)\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed6cfde2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")  # Adjust xticklabels and yticklabels as needed\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "346c6d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_save = []\n",
    "for idx in range(len(test_data)):\n",
    "    item = dataset['test'][idx]\n",
    "    actual_label = item['label']\n",
    "    predicted_label = predictions[idx]\n",
    "    claim = item['claim'] \n",
    "    premise = item['premise'] \n",
    "    category = item['category']\n",
    "    \n",
    "    # Append the information as a dictionary to the list\n",
    "    data_to_save.append({\n",
    "        'Claim': claim,\n",
    "        'Premise': premise,\n",
    "        'Actual Label': actual_label,\n",
    "        'Predicted Label': predicted_label,\n",
    "        'Category' : category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_to_save)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/home/elson/results/11.4.3_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4543aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correctly classified instances\n",
    "correctly_classified = df[df['Actual Label'] == df['Predicted Label']]\n",
    "\n",
    "# Calculate misclassified instances\n",
    "misclassified = df[df['Actual Label'] != df['Predicted Label']]\n",
    "\n",
    "# Count the number of correctly classified and misclassified by category\n",
    "correct_classification_counts = correctly_classified['Category'].value_counts()\n",
    "misclassification_counts = misclassified['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad099d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           40\n",
       "Fitness                  13\n",
       "Skin                     12\n",
       "Bone health              12\n",
       "Diabetes                  9\n",
       "Cancer                    9\n",
       "Cardiovascular Health     9\n",
       "Throat                    8\n",
       "Blood                     6\n",
       "Ear                       6\n",
       "Hair                      5\n",
       "Neurological health       5\n",
       "Women' s Health           4\n",
       "COVID                     3\n",
       "Men's health              3\n",
       "Mental Health             3\n",
       "Eye                       3\n",
       "Muscles                   1\n",
       "Vascular                  1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d45817c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Skin                     12\n",
       "General Health           11\n",
       "Bone health               9\n",
       "Hair                      7\n",
       "Eye                       6\n",
       "Muscles                   5\n",
       "Neurological health       4\n",
       "Blood                     3\n",
       "Men's health              3\n",
       "Cardiovascular Health     3\n",
       "COVID                     3\n",
       "Diabetes                  3\n",
       "Dental Health             3\n",
       "Cancer                    3\n",
       "Vascular                  2\n",
       "Women' s Health           2\n",
       "Fitness                   2\n",
       "Throat                    1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
