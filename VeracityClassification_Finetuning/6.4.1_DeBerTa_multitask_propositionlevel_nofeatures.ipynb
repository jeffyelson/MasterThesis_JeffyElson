{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-927ab0163adb9fdb\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-927ab0163adb9fdb/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 373.52it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('csv',data_files='dataset_propositionattribution_nerfeatures.csv',delimiter=',',column_names=[\"claim\",\"premise\",\"label\",\"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\",\"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\",\"url\", \"entities\",\"entity_map\",\"gem_exp\",\"gem_label\",\"gpt_label\",\"gpt_exp\",\"gold_exp\",\"entity_map_ev\",\"entity_ev\",\"split\"],skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "835b6a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-927ab0163adb9fdb/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-d013d5114fa105ab.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-927ab0163adb9fdb/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-16f9acbdd82fea07.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-927ab0163adb9fdb/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-47c7de469e4087a2.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01252e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\"claim\", \"premise\", \"label\"]\n",
    "all_columns = dataset[\"train\"].column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-927ab0163adb9fdb/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-c04f7e43468f969f.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-927ab0163adb9fdb/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-b4575673d3585192.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-927ab0163adb9fdb/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-bfd24c086ca7428f.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 2, 'entailment': 0, 'neutral': 1}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 2,\n",
    "    \"entailment\": 0,\n",
    "    \"neutral\": 1\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e15010ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='sileod/deberta-v3-small-tasksource-nli'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "        # Extracting claim and evidence texts\n",
    "\n",
    "        claim = item['claim']\n",
    "        evidences = item['premise']\n",
    "        item['premise']=evidences\n",
    "        item['claim']=claim\n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "            evidences,claim,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "        item['input_ids'] = inputs['input_ids'].squeeze()  # Remove batch dimension\n",
    "        item['attention_mask']= inputs['attention_mask'].squeeze() # Remove batch dimension\n",
    "        \n",
    "        if 'label' in item:\n",
    "            item['labels'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62421eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DebertaV2ForSequenceClassification(\n",
       "  (deberta): DebertaV2Model(\n",
       "    (embeddings): DebertaV2Embeddings(\n",
       "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaV2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (1): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (2): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (3): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (4): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (5): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (pooler): ContextPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): StableDropout()\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (dropout): StableDropout()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"sileod/deberta-v3-small-tasksource-nli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=512)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=3, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    return {\"accuracy\": acc, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f5cf584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'claim': 'Myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.',\n",
       " 'premise': 'The essential oils of frankincense and myrrh increase the fluidity of the lipid bilayer in the cuticle and change the orderly and dense structure to increase the permeability of the skin and decrease the barrier effect.',\n",
       " 'label': 0,\n",
       " 'input_ids': tensor([    1,   279,  1830,  6725,   265, 88609,   263, 98237,   993,   262,\n",
       "         49462,   265,   262, 22003, 96579,   267,   262, 61462,   263,   575,\n",
       "           262, 26217,   263,  9854,  1730,   264,   993,   262, 39632,   265,\n",
       "           262,  1158,   263,  4843,   262,  7275,  1290,   260,     2,   573,\n",
       "         52341,  1830,  1080,   269,  1359,   427,   267, 17847,   633,   264,\n",
       "           408,  1300,   262,  2658,   265,   262,  1158,   260,     2,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'labels': tensor(0)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 765\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='765' max='765' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [765/765 06:27, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.678600</td>\n",
       "      <td>0.722321</td>\n",
       "      <td>0.716129</td>\n",
       "      <td>0.678612</td>\n",
       "      <td>0.716129</td>\n",
       "      <td>0.696720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.297900</td>\n",
       "      <td>1.077634</td>\n",
       "      <td>0.683871</td>\n",
       "      <td>0.722520</td>\n",
       "      <td>0.683871</td>\n",
       "      <td>0.698553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.103800</td>\n",
       "      <td>1.510799</td>\n",
       "      <td>0.681720</td>\n",
       "      <td>0.718953</td>\n",
       "      <td>0.681720</td>\n",
       "      <td>0.694595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.023400</td>\n",
       "      <td>1.861397</td>\n",
       "      <td>0.664516</td>\n",
       "      <td>0.689090</td>\n",
       "      <td>0.664516</td>\n",
       "      <td>0.674163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>2.107094</td>\n",
       "      <td>0.670968</td>\n",
       "      <td>0.720954</td>\n",
       "      <td>0.670968</td>\n",
       "      <td>0.687739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.046600</td>\n",
       "      <td>2.287065</td>\n",
       "      <td>0.683871</td>\n",
       "      <td>0.719692</td>\n",
       "      <td>0.683871</td>\n",
       "      <td>0.696561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>2.468571</td>\n",
       "      <td>0.647312</td>\n",
       "      <td>0.715179</td>\n",
       "      <td>0.647312</td>\n",
       "      <td>0.666502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>2.302196</td>\n",
       "      <td>0.703226</td>\n",
       "      <td>0.731457</td>\n",
       "      <td>0.703226</td>\n",
       "      <td>0.711222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>2.418575</td>\n",
       "      <td>0.698925</td>\n",
       "      <td>0.729703</td>\n",
       "      <td>0.698925</td>\n",
       "      <td>0.709031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.599059</td>\n",
       "      <td>0.681720</td>\n",
       "      <td>0.731184</td>\n",
       "      <td>0.681720</td>\n",
       "      <td>0.696529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>2.491104</td>\n",
       "      <td>0.703226</td>\n",
       "      <td>0.728945</td>\n",
       "      <td>0.703226</td>\n",
       "      <td>0.711242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>2.714553</td>\n",
       "      <td>0.670968</td>\n",
       "      <td>0.729138</td>\n",
       "      <td>0.670968</td>\n",
       "      <td>0.689816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.693627</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.720859</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.689383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.693943</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.722138</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.691487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.666865</td>\n",
       "      <td>0.690323</td>\n",
       "      <td>0.727508</td>\n",
       "      <td>0.690323</td>\n",
       "      <td>0.702602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to /home/elson/6.4.1_deberta/checkpoint-51\n",
      "Configuration saved in /home/elson/6.4.1_deberta/checkpoint-51/config.json\n",
      "Model weights saved in /home/elson/6.4.1_deberta/checkpoint-51/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/6.4.1_deberta/checkpoint-203] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/6.4.1_deberta/checkpoint-406] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/6.4.1_deberta/checkpoint-102\n",
      "Configuration saved in /home/elson/6.4.1_deberta/checkpoint-102/config.json\n",
      "Model weights saved in /home/elson/6.4.1_deberta/checkpoint-102/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/6.4.1_deberta/checkpoint-153\n",
      "Configuration saved in /home/elson/6.4.1_deberta/checkpoint-153/config.json\n",
      "Model weights saved in /home/elson/6.4.1_deberta/checkpoint-153/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/6.4.1_deberta/checkpoint-102] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/6.4.1_deberta/checkpoint-204\n",
      "Configuration saved in /home/elson/6.4.1_deberta/checkpoint-204/config.json\n",
      "Model weights saved in /home/elson/6.4.1_deberta/checkpoint-204/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/6.4.1_deberta/checkpoint-153] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/6.4.1_deberta/checkpoint-255\n",
      "Configuration saved in /home/elson/6.4.1_deberta/checkpoint-255/config.json\n",
      "Model weights saved in /home/elson/6.4.1_deberta/checkpoint-255/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/6.4.1_deberta/checkpoint-204] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/6.4.1_deberta/checkpoint-306\n",
      "Configuration saved in /home/elson/6.4.1_deberta/checkpoint-306/config.json\n",
      "Model weights saved in /home/elson/6.4.1_deberta/checkpoint-306/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/6.4.1_deberta/checkpoint-255] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/6.4.1_deberta/checkpoint-357\n",
      "Configuration saved in /home/elson/6.4.1_deberta/checkpoint-357/config.json\n",
      "Model weights saved in /home/elson/6.4.1_deberta/checkpoint-357/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/6.4.1_deberta/checkpoint-306] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/6.4.1_deberta/checkpoint-408\n",
      "Configuration saved in /home/elson/6.4.1_deberta/checkpoint-408/config.json\n",
      "Model weights saved in /home/elson/6.4.1_deberta/checkpoint-408/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/6.4.1_deberta/checkpoint-357] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/6.4.1_deberta/checkpoint-459\n",
      "Configuration saved in /home/elson/6.4.1_deberta/checkpoint-459/config.json\n",
      "Model weights saved in /home/elson/6.4.1_deberta/checkpoint-459/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/6.4.1_deberta/checkpoint-408] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/6.4.1_deberta/checkpoint-510\n",
      "Configuration saved in /home/elson/6.4.1_deberta/checkpoint-510/config.json\n",
      "Model weights saved in /home/elson/6.4.1_deberta/checkpoint-510/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/6.4.1_deberta/checkpoint-459] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/6.4.1_deberta/checkpoint-561\n",
      "Configuration saved in /home/elson/6.4.1_deberta/checkpoint-561/config.json\n",
      "Model weights saved in /home/elson/6.4.1_deberta/checkpoint-561/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/6.4.1_deberta/checkpoint-510] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/6.4.1_deberta/checkpoint-612\n",
      "Configuration saved in /home/elson/6.4.1_deberta/checkpoint-612/config.json\n",
      "Model weights saved in /home/elson/6.4.1_deberta/checkpoint-612/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/6.4.1_deberta/checkpoint-561] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/6.4.1_deberta/checkpoint-663\n",
      "Configuration saved in /home/elson/6.4.1_deberta/checkpoint-663/config.json\n",
      "Model weights saved in /home/elson/6.4.1_deberta/checkpoint-663/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/6.4.1_deberta/checkpoint-612] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/6.4.1_deberta/checkpoint-714\n",
      "Configuration saved in /home/elson/6.4.1_deberta/checkpoint-714/config.json\n",
      "Model weights saved in /home/elson/6.4.1_deberta/checkpoint-714/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/6.4.1_deberta/checkpoint-663] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/6.4.1_deberta/checkpoint-765\n",
      "Configuration saved in /home/elson/6.4.1_deberta/checkpoint-765/config.json\n",
      "Model weights saved in /home/elson/6.4.1_deberta/checkpoint-765/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/6.4.1_deberta/checkpoint-714] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/elson/6.4.1_deberta/checkpoint-51 (score: 0.7161290322580646).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Configuration saved in /home/elson/6.4.1_deberta/best_model/config.json\n",
      "Model weights saved in /home/elson/6.4.1_deberta/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/6.4.1_deberta/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/6.4.1_deberta/best_model/special_tokens_map.json\n",
      "added tokens file saved in /home/elson/6.4.1_deberta/best_model/added_tokens.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/6.4.1_deberta/best_model/tokenizer_config.json',\n",
       " '/home/elson/6.4.1_deberta/best_model/special_tokens_map.json',\n",
       " '/home/elson/6.4.1_deberta/best_model/spm.model',\n",
       " '/home/elson/6.4.1_deberta/best_model/added_tokens.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/6.4.1_deberta/',\n",
    "    num_train_epochs=15,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.06,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/6.4.1_deberta/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/6.4.1_deberta/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63deaea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/6.4.1_deberta/best_model/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"/home/elson/6.4.1_deberta/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifiers_size\": [\n",
      "    3,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    1,\n",
      "    2,\n",
      "    3,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    1,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2,\n",
      "    3,\n",
      "    6,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    5,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    47,\n",
      "    23,\n",
      "    9,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    20,\n",
      "    50,\n",
      "    3,\n",
      "    3,\n",
      "    4,\n",
      "    2,\n",
      "    8,\n",
      "    3,\n",
      "    4,\n",
      "    2,\n",
      "    2,\n",
      "    20,\n",
      "    2,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    174,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    41,\n",
      "    51,\n",
      "    2,\n",
      "    3,\n",
      "    2,\n",
      "    2,\n",
      "    18,\n",
      "    2,\n",
      "    16,\n",
      "    8,\n",
      "    3,\n",
      "    17,\n",
      "    3,\n",
      "    2,\n",
      "    2,\n",
      "    11,\n",
      "    42,\n",
      "    12,\n",
      "    7,\n",
      "    3,\n",
      "    4,\n",
      "    3,\n",
      "    7,\n",
      "    100,\n",
      "    13,\n",
      "    100,\n",
      "    8,\n",
      "    1,\n",
      "    20,\n",
      "    2,\n",
      "    2,\n",
      "    4,\n",
      "    5,\n",
      "    3,\n",
      "    4,\n",
      "    14,\n",
      "    2,\n",
      "    6,\n",
      "    4,\n",
      "    2,\n",
      "    1,\n",
      "    3,\n",
      "    10,\n",
      "    3,\n",
      "    10,\n",
      "    4,\n",
      "    2,\n",
      "    7,\n",
      "    6,\n",
      "    28,\n",
      "    3,\n",
      "    6,\n",
      "    7,\n",
      "    6,\n",
      "    5,\n",
      "    4,\n",
      "    3,\n",
      "    2,\n",
      "    7,\n",
      "    2,\n",
      "    6,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    20,\n",
      "    2,\n",
      "    9,\n",
      "    13,\n",
      "    4,\n",
      "    2,\n",
      "    4,\n",
      "    3,\n",
      "    2,\n",
      "    2,\n",
      "    3,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    4,\n",
      "    1,\n",
      "    2,\n",
      "    1,\n",
      "    13,\n",
      "    3,\n",
      "    5,\n",
      "    11,\n",
      "    37,\n",
      "    2,\n",
      "    49,\n",
      "    40,\n",
      "    10,\n",
      "    4,\n",
      "    1,\n",
      "    2,\n",
      "    2,\n",
      "    1,\n",
      "    5,\n",
      "    2,\n",
      "    3,\n",
      "    2,\n",
      "    2,\n",
      "    12,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    19,\n",
      "    3,\n",
      "    1,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    1,\n",
      "    2,\n",
      "    2,\n",
      "    1,\n",
      "    1,\n",
      "    2,\n",
      "    3,\n",
      "    2,\n",
      "    1,\n",
      "    4,\n",
      "    3,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    2,\n",
      "    3,\n",
      "    2,\n",
      "    3,\n",
      "    1,\n",
      "    1,\n",
      "    2,\n",
      "    1,\n",
      "    3,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    3,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    1,\n",
      "    3,\n",
      "    2,\n",
      "    2,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    2,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    4,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    3,\n",
      "    1,\n",
      "    3,\n",
      "    1,\n",
      "    2,\n",
      "    2,\n",
      "    1,\n",
      "    2,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    1,\n",
      "    3,\n",
      "    1,\n",
      "    1,\n",
      "    3,\n",
      "    1,\n",
      "    3,\n",
      "    2,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    2,\n",
      "    50,\n",
      "    50,\n",
      "    50,\n",
      "    50,\n",
      "    2,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    77,\n",
      "    1,\n",
      "    3,\n",
      "    2,\n",
      "    2,\n",
      "    1,\n",
      "    1,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    3,\n",
      "    18,\n",
      "    13,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    4,\n",
      "    2,\n",
      "    24,\n",
      "    23,\n",
      "    67,\n",
      "    279,\n",
      "    3,\n",
      "    2,\n",
      "    2,\n",
      "    1,\n",
      "    2,\n",
      "    2,\n",
      "    3,\n",
      "    1,\n",
      "    2,\n",
      "    3,\n",
      "    2,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2,\n",
      "    4,\n",
      "    1,\n",
      "    17,\n",
      "    3,\n",
      "    2,\n",
      "    3,\n",
      "    2,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    1,\n",
      "    1,\n",
      "    3,\n",
      "    2,\n",
      "    9,\n",
      "    2,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    1,\n",
      "    2,\n",
      "    2,\n",
      "    3,\n",
      "    2,\n",
      "    2,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"entailment\",\n",
      "    \"1\": \"neutral\",\n",
      "    \"2\": \"contradiction\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"contradiction\": 2,\n",
      "    \"entailment\": 0,\n",
      "    \"neutral\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"tasks\": [\n",
      "    \"glue/mnli\",\n",
      "    \"glue/qnli\",\n",
      "    \"glue/rte\",\n",
      "    \"glue/wnli\",\n",
      "    \"glue/mrpc\",\n",
      "    \"glue/qqp\",\n",
      "    \"glue/stsb\",\n",
      "    \"super_glue/boolq\",\n",
      "    \"super_glue/cb\",\n",
      "    \"super_glue/multirc\",\n",
      "    \"super_glue/wic\",\n",
      "    \"super_glue/axg\",\n",
      "    \"anli/a1\",\n",
      "    \"anli/a2\",\n",
      "    \"anli/a3\",\n",
      "    \"sick/label\",\n",
      "    \"sick/relatedness\",\n",
      "    \"sick/entailment_AB\",\n",
      "    \"snli\",\n",
      "    \"scitail/snli_format\",\n",
      "    \"hans\",\n",
      "    \"WANLI\",\n",
      "    \"recast/recast_kg_relations\",\n",
      "    \"recast/recast_megaveridicality\",\n",
      "    \"recast/recast_ner\",\n",
      "    \"recast/recast_verbcorner\",\n",
      "    \"recast/recast_factuality\",\n",
      "    \"recast/recast_verbnet\",\n",
      "    \"recast/recast_puns\",\n",
      "    \"recast/recast_sentiment\",\n",
      "    \"probability_words_nli/reasoning_2hop\",\n",
      "    \"probability_words_nli/reasoning_1hop\",\n",
      "    \"probability_words_nli/usnli\",\n",
      "    \"nan-nli/joey234--nan-nli\",\n",
      "    \"nli_fever\",\n",
      "    \"breaking_nli\",\n",
      "    \"conj_nli\",\n",
      "    \"fracas\",\n",
      "    \"dialogue_nli\",\n",
      "    \"mpe\",\n",
      "    \"dnc\",\n",
      "    \"recast_white/fnplus\",\n",
      "    \"recast_white/sprl\",\n",
      "    \"recast_white/dpr\",\n",
      "    \"joci\",\n",
      "    \"robust_nli/IS_CS\",\n",
      "    \"robust_nli/LI_LI\",\n",
      "    \"robust_nli/ST_WO\",\n",
      "    \"robust_nli/PI_SP\",\n",
      "    \"robust_nli/PI_CD\",\n",
      "    \"robust_nli/ST_SE\",\n",
      "    \"robust_nli/ST_NE\",\n",
      "    \"robust_nli/ST_LM\",\n",
      "    \"robust_nli_is_sd\",\n",
      "    \"robust_nli_li_ts\",\n",
      "    \"add_one_rte\",\n",
      "    \"imppres/implicature_quantifiers/log\",\n",
      "    \"imppres/implicature_numerals_2_3/log\",\n",
      "    \"imppres/implicature_modals/log\",\n",
      "    \"imppres/implicature_gradable_adjective/log\",\n",
      "    \"imppres/implicature_connectives/log\",\n",
      "    \"imppres/implicature_numerals_10_100/log\",\n",
      "    \"imppres/implicature_gradable_verb/log\",\n",
      "    \"glue_diagnostics/diagnostics\",\n",
      "    \"hlgd\",\n",
      "    \"paws/labeled_final\",\n",
      "    \"paws/labeled_swap\",\n",
      "    \"medical_questions_pairs\",\n",
      "    \"conll2003/pos_tags\",\n",
      "    \"conll2003/chunk_tags\",\n",
      "    \"conll2003/ner_tags\",\n",
      "    \"model-written-evals\",\n",
      "    \"truthful_qa/multiple_choice\",\n",
      "    \"fig-qa\",\n",
      "    \"bigbench/contextual_parametric_knowledge_conflicts\",\n",
      "    \"bigbench/empirical_judgments\",\n",
      "    \"bigbench/hhh_alignment\",\n",
      "    \"bigbench/metaphor_boolean\",\n",
      "    \"bigbench/key_value_maps\",\n",
      "    \"bigbench/known_unknowns\",\n",
      "    \"bigbench/symbol_interpretation\",\n",
      "    \"bigbench/misconceptions\",\n",
      "    \"bigbench/bbq_lite_json\",\n",
      "    \"bigbench/navigate\",\n",
      "    \"bigbench/discourse_marker_prediction\",\n",
      "    \"bigbench/disambiguation_qa\",\n",
      "    \"bigbench/cifar10_classification\",\n",
      "    \"bigbench/real_or_fake_text\",\n",
      "    \"bigbench/moral_permissibility\",\n",
      "    \"bigbench/abstract_narrative_understanding\",\n",
      "    \"bigbench/physics\",\n",
      "    \"bigbench/logical_fallacy_detection\",\n",
      "    \"bigbench/code_line_description\",\n",
      "    \"bigbench/implicit_relations\",\n",
      "    \"bigbench/unit_interpretation\",\n",
      "    \"bigbench/logical_sequence\",\n",
      "    \"bigbench/mnist_ascii\",\n",
      "    \"bigbench/irony_identification\",\n",
      "    \"bigbench/mathematical_induction\",\n",
      "    \"bigbench/winowhy\",\n",
      "    \"bigbench/elementary_math_qa\",\n",
      "    \"bigbench/implicatures\",\n",
      "    \"bigbench/vitaminc_fact_verification\",\n",
      "    \"bigbench/play_dialog_same_or_different\",\n",
      "    \"bigbench/movie_dialog_same_or_different\",\n",
      "    \"bigbench/physical_intuition\",\n",
      "    \"bigbench/reasoning_about_colored_objects\",\n",
      "    \"bigbench/english_proverbs\",\n",
      "    \"bigbench/timedial\",\n",
      "    \"bigbench/conceptual_combinations\",\n",
      "    \"bigbench/suicide_risk\",\n",
      "    \"bigbench/movie_recommendation\",\n",
      "    \"bigbench/formal_fallacies_syllogisms_negation\",\n",
      "    \"bigbench/causal_judgment\",\n",
      "    \"bigbench/emoji_movie\",\n",
      "    \"bigbench/sports_understanding\",\n",
      "    \"bigbench/hindu_knowledge\",\n",
      "    \"bigbench/entailed_polarity\",\n",
      "    \"bigbench/fact_checker\",\n",
      "    \"bigbench/fantasy_reasoning\",\n",
      "    \"bigbench/logical_args\",\n",
      "    \"bigbench/evaluating_information_essentiality\",\n",
      "    \"bigbench/crass_ai\",\n",
      "    \"bigbench/identify_odd_metaphor\",\n",
      "    \"bigbench/cause_and_effect\",\n",
      "    \"bigbench/undo_permutation\",\n",
      "    \"bigbench/intent_recognition\",\n",
      "    \"bigbench/cs_algorithms\",\n",
      "    \"bigbench/identify_math_theorems\",\n",
      "    \"bigbench/strategyqa\",\n",
      "    \"bigbench/penguins_in_a_table\",\n",
      "    \"bigbench/nonsense_words_grammar\",\n",
      "    \"bigbench/logical_deduction\",\n",
      "    \"bigbench/phrase_relatedness\",\n",
      "    \"bigbench/gre_reading_comprehension\",\n",
      "    \"bigbench/understanding_fables\",\n",
      "    \"bigbench/question_selection\",\n",
      "    \"bigbench/ruin_names\",\n",
      "    \"bigbench/logic_grid_puzzle\",\n",
      "    \"bigbench/presuppositions_as_nli\",\n",
      "    \"bigbench/strange_stories\",\n",
      "    \"bigbench/general_knowledge\",\n",
      "    \"bigbench/geometric_shapes\",\n",
      "    \"bigbench/social_support\",\n",
      "    \"bigbench/color\",\n",
      "    \"bigbench/snarks\",\n",
      "    \"bigbench/odd_one_out\",\n",
      "    \"bigbench/epistemic_reasoning\",\n",
      "    \"bigbench/emojis_emotion_prediction\",\n",
      "    \"bigbench/metaphor_understanding\",\n",
      "    \"bigbench/human_organs_senses\",\n",
      "    \"bigbench/simple_ethical_questions\",\n",
      "    \"bigbench/crash_blossom\",\n",
      "    \"bigbench/authorship_verification\",\n",
      "    \"bigbench/dark_humor_detection\",\n",
      "    \"bigbench/analogical_similarity\",\n",
      "    \"bigbench/social_iqa\",\n",
      "    \"bigbench/figure_of_speech_detection\",\n",
      "    \"bigbench/sentence_ambiguity\",\n",
      "    \"bigbench/salient_translation_error_detection\",\n",
      "    \"bigbench/novel_concepts\",\n",
      "    \"bigbench/anachronisms\",\n",
      "    \"bigbench/arithmetic\",\n",
      "    \"bigbench/riddle_sense\",\n",
      "    \"bigbench/analytic_entailment\",\n",
      "    \"bigbench/date_understanding\",\n",
      "    \"bigbench/dyck_languages\",\n",
      "    \"bigbench/tracking_shuffled_objects\",\n",
      "    \"bigbench/temporal_sequences\",\n",
      "    \"bigbench/hyperbaton\",\n",
      "    \"bigbench/goal_step_wikihow\",\n",
      "    \"bigbench/international_phonetic_alphabet_nli\",\n",
      "    \"bigbench/similarities_abstraction\",\n",
      "    \"bigbench/checkmate_in_one\",\n",
      "    \"cos_e/v1.0\",\n",
      "    \"cosmos_qa\",\n",
      "    \"dream\",\n",
      "    \"openbookqa\",\n",
      "    \"qasc\",\n",
      "    \"quartz\",\n",
      "    \"quail\",\n",
      "    \"head_qa/en\",\n",
      "    \"sciq\",\n",
      "    \"social_i_qa\",\n",
      "    \"wiki_hop/original\",\n",
      "    \"wiqa\",\n",
      "    \"piqa\",\n",
      "    \"hellaswag\",\n",
      "    \"super_glue/copa\",\n",
      "    \"balanced-copa\",\n",
      "    \"e-CARE\",\n",
      "    \"art\",\n",
      "    \"winogrande/winogrande_xl\",\n",
      "    \"codah/codah\",\n",
      "    \"ai2_arc/ARC-Easy/challenge\",\n",
      "    \"ai2_arc/ARC-Challenge/challenge\",\n",
      "    \"definite_pronoun_resolution\",\n",
      "    \"swag/regular\",\n",
      "    \"math_qa\",\n",
      "    \"glue/cola\",\n",
      "    \"glue/sst2\",\n",
      "    \"utilitarianism\",\n",
      "    \"amazon_counterfactual/en\",\n",
      "    \"insincere-questions\",\n",
      "    \"toxic_conversations\",\n",
      "    \"TuringBench\",\n",
      "    \"trec\",\n",
      "    \"vitaminc/tals--vitaminc\",\n",
      "    \"hope_edi/english\",\n",
      "    \"rumoureval_2019/RumourEval2019\",\n",
      "    \"ethos/binary\",\n",
      "    \"ethos/multilabel\",\n",
      "    \"tweet_eval/sentiment\",\n",
      "    \"tweet_eval/emotion\",\n",
      "    \"tweet_eval/hate\",\n",
      "    \"tweet_eval/irony\",\n",
      "    \"tweet_eval/emoji\",\n",
      "    \"tweet_eval/offensive\",\n",
      "    \"tweet_eval/stance_abortion\",\n",
      "    \"tweet_eval/stance_atheism\",\n",
      "    \"tweet_eval/stance_climate\",\n",
      "    \"tweet_eval/stance_feminist\",\n",
      "    \"tweet_eval/stance_hillary\",\n",
      "    \"discovery/discovery\",\n",
      "    \"pragmeval/squinky-informativeness\",\n",
      "    \"pragmeval/squinky-implicature\",\n",
      "    \"pragmeval/emobank-arousal\",\n",
      "    \"pragmeval/squinky-formality\",\n",
      "    \"pragmeval/emobank-dominance\",\n",
      "    \"pragmeval/switchboard\",\n",
      "    \"pragmeval/mrda\",\n",
      "    \"pragmeval/emobank-valence\",\n",
      "    \"pragmeval/verifiability\",\n",
      "    \"pragmeval/persuasiveness-strength\",\n",
      "    \"pragmeval/sarcasm\",\n",
      "    \"pragmeval/stac\",\n",
      "    \"pragmeval/persuasiveness-relevance\",\n",
      "    \"pragmeval/pdtb\",\n",
      "    \"pragmeval/persuasiveness-premisetype\",\n",
      "    \"pragmeval/emergent\",\n",
      "    \"pragmeval/gum\",\n",
      "    \"pragmeval/persuasiveness-claimtype\",\n",
      "    \"pragmeval/persuasiveness-eloquence\",\n",
      "    \"pragmeval/persuasiveness-specificity\",\n",
      "    \"silicone/iemocap\",\n",
      "    \"silicone/oasis\",\n",
      "    \"silicone/maptask\",\n",
      "    \"silicone/meld_e\",\n",
      "    \"silicone/meld_s\",\n",
      "    \"silicone/dyda_da\",\n",
      "    \"silicone/sem\",\n",
      "    \"silicone/dyda_e\",\n",
      "    \"lex_glue/eurlex\",\n",
      "    \"lex_glue/scotus\",\n",
      "    \"lex_glue/ledgar\",\n",
      "    \"lex_glue/unfair_tos\",\n",
      "    \"lex_glue/case_hold\",\n",
      "    \"language-identification\",\n",
      "    \"imdb\",\n",
      "    \"rotten_tomatoes\",\n",
      "    \"ag_news\",\n",
      "    \"yelp_review_full/yelp_review_full\",\n",
      "    \"financial_phrasebank/sentences_allagree\",\n",
      "    \"poem_sentiment\",\n",
      "    \"dbpedia_14/dbpedia_14\",\n",
      "    \"amazon_polarity/amazon_polarity\",\n",
      "    \"app_reviews\",\n",
      "    \"hate_speech18\",\n",
      "    \"sms_spam\",\n",
      "    \"humicroedit/subtask-1\",\n",
      "    \"humicroedit/subtask-2\",\n",
      "    \"snips_built_in_intents\",\n",
      "    \"hate_speech_offensive\",\n",
      "    \"yahoo_answers_topics\",\n",
      "    \"stackoverflow-questions\",\n",
      "    \"hyperpartisan_news\",\n",
      "    \"sciie\",\n",
      "    \"citation_intent\",\n",
      "    \"go_emotions/simplified\",\n",
      "    \"scicite\",\n",
      "    \"liar\",\n",
      "    \"lexical_relation_classification/EVALution\",\n",
      "    \"lexical_relation_classification/BLESS\",\n",
      "    \"lexical_relation_classification/CogALexV\",\n",
      "    \"lexical_relation_classification/K&H+N\",\n",
      "    \"lexical_relation_classification/ROOT09\",\n",
      "    \"linguisticprobing/odd_man_out\",\n",
      "    \"linguisticprobing/tree_depth\",\n",
      "    \"linguisticprobing/coordination_inversion\",\n",
      "    \"linguisticprobing/sentence_length\",\n",
      "    \"linguisticprobing/obj_number\",\n",
      "    \"linguisticprobing/subj_number\",\n",
      "    \"linguisticprobing/bigram_shift\",\n",
      "    \"linguisticprobing/top_constituents\",\n",
      "    \"linguisticprobing/past_present\",\n",
      "    \"crowdflower/political-media-message\",\n",
      "    \"crowdflower/text_emotion\",\n",
      "    \"crowdflower/sentiment_nuclear_power\",\n",
      "    \"crowdflower/tweet_global_warming\",\n",
      "    \"crowdflower/corporate-messaging\",\n",
      "    \"crowdflower/airline-sentiment\",\n",
      "    \"crowdflower/political-media-audience\",\n",
      "    \"crowdflower/political-media-bias\",\n",
      "    \"crowdflower/economic-news\",\n",
      "    \"ethics/commonsense\",\n",
      "    \"ethics/deontology\",\n",
      "    \"ethics/justice\",\n",
      "    \"ethics/virtue\",\n",
      "    \"emo/emo2019\",\n",
      "    \"google_wellformed_query\",\n",
      "    \"tweets_hate_speech_detection\",\n",
      "    \"has_part\",\n",
      "    \"wnut_17/wnut_17\",\n",
      "    \"ncbi_disease/ncbi_disease\",\n",
      "    \"acronym_identification\",\n",
      "    \"jnlpba/jnlpba\",\n",
      "    \"ontonotes_english/SpeedOfMagic--ontonotes_english\",\n",
      "    \"blog_authorship_corpus/gender\",\n",
      "    \"blog_authorship_corpus/age\",\n",
      "    \"blog_authorship_corpus/job\",\n",
      "    \"open_question_type\",\n",
      "    \"health_fact\",\n",
      "    \"commonsense_qa\",\n",
      "    \"mc_taco\",\n",
      "    \"ade_corpus_v2/Ade_corpus_v2_classification\",\n",
      "    \"discosense\",\n",
      "    \"circa\",\n",
      "    \"phrase_similarity\",\n",
      "    \"scientific-exaggeration-detection\",\n",
      "    \"quarel\",\n",
      "    \"fever-evidence-related/mwong--fever-related\",\n",
      "    \"numer_sense\",\n",
      "    \"dynasent/dynabench.dynasent.r1.all/r1\",\n",
      "    \"dynasent/dynabench.dynasent.r2.all/r2\",\n",
      "    \"Sarcasm_News_Headline\",\n",
      "    \"sem_eval_2010_task_8\",\n",
      "    \"auditor_review/demo-org--auditor_review\",\n",
      "    \"medmcqa\",\n",
      "    \"Dynasent_Disagreement\",\n",
      "    \"Politeness_Disagreement\",\n",
      "    \"SBIC_Disagreement\",\n",
      "    \"SChem_Disagreement\",\n",
      "    \"Dilemmas_Disagreement\",\n",
      "    \"logiqa\",\n",
      "    \"wiki_qa\",\n",
      "    \"cycic_classification\",\n",
      "    \"cycic_multiplechoice\",\n",
      "    \"sts-companion\",\n",
      "    \"commonsense_qa_2.0\",\n",
      "    \"lingnli\",\n",
      "    \"monotonicity-entailment\",\n",
      "    \"arct\",\n",
      "    \"scinli\",\n",
      "    \"naturallogic\",\n",
      "    \"onestop_qa\",\n",
      "    \"moral_stories/full\",\n",
      "    \"prost\",\n",
      "    \"dynahate\",\n",
      "    \"syntactic-augmentation-nli\",\n",
      "    \"autotnli\",\n",
      "    \"CONDAQA\",\n",
      "    \"webgpt_comparisons\",\n",
      "    \"synthetic-instruct-gptj-pairwise\",\n",
      "    \"scruples\",\n",
      "    \"wouldyourather\",\n",
      "    \"attempto-nli\",\n",
      "    \"defeasible-nli/atomic\",\n",
      "    \"defeasible-nli/snli\",\n",
      "    \"help-nli\",\n",
      "    \"nli-veridicality-transitivity\",\n",
      "    \"natural-language-satisfiability\",\n",
      "    \"lonli\",\n",
      "    \"dadc-limit-nli\",\n",
      "    \"FLUTE\",\n",
      "    \"strategy-qa\",\n",
      "    \"summarize_from_feedback/comparisons\",\n",
      "    \"folio\",\n",
      "    \"tomi-nli\",\n",
      "    \"avicenna\",\n",
      "    \"SHP\",\n",
      "    \"MedQA-USMLE-4-options-hf\",\n",
      "    \"wikimedqa/medwiki\",\n",
      "    \"cicero\",\n",
      "    \"CREAK\",\n",
      "    \"mutual\",\n",
      "    \"NeQA\",\n",
      "    \"quote-repetition\",\n",
      "    \"redefine-math\",\n",
      "    \"puzzte\",\n",
      "    \"implicatures\",\n",
      "    \"race/middle\",\n",
      "    \"race/high\",\n",
      "    \"race-c\",\n",
      "    \"spartqa-yn\",\n",
      "    \"spartqa-mchoice\",\n",
      "    \"temporal-nli\",\n",
      "    \"riddle_sense\",\n",
      "    \"clcd-english\",\n",
      "    \"twentyquestions\",\n",
      "    \"reclor\",\n",
      "    \"counterfactually-augmented-imdb\",\n",
      "    \"counterfactually-augmented-snli\",\n",
      "    \"cnli\",\n",
      "    \"boolq-natural-perturbations\",\n",
      "    \"acceptability-prediction\",\n",
      "    \"equate\",\n",
      "    \"ScienceQA_text_only\",\n",
      "    \"ekar_english\",\n",
      "    \"implicit-hate-stg1\",\n",
      "    \"chaos-mnli-ambiguity\",\n",
      "    \"headline_cause/en_simple\",\n",
      "    \"logiqa-2.0-nli\",\n",
      "    \"oasst2_dense_flat/quality\",\n",
      "    \"oasst2_dense_flat/toxicity\",\n",
      "    \"oasst2_dense_flat/helpfulness\",\n",
      "    \"mindgames\",\n",
      "    \"universal_dependencies/en_gum/deprel\",\n",
      "    \"universal_dependencies/en_partut/deprel\",\n",
      "    \"universal_dependencies/en_ewt/deprel\",\n",
      "    \"universal_dependencies/en_lines/deprel\",\n",
      "    \"ambient\",\n",
      "    \"path-naturalness-prediction\",\n",
      "    \"civil_comments/toxicity\",\n",
      "    \"civil_comments/severe_toxicity\",\n",
      "    \"civil_comments/obscene\",\n",
      "    \"civil_comments/threat\",\n",
      "    \"civil_comments/insult\",\n",
      "    \"civil_comments/identity_attack\",\n",
      "    \"civil_comments/sexual_explicit\",\n",
      "    \"cloth\",\n",
      "    \"dgen\",\n",
      "    \"I2D2\",\n",
      "    \"args_me\",\n",
      "    \"Touche23-ValueEval\",\n",
      "    \"starcon\",\n",
      "    \"banking77\",\n",
      "    \"lsat_qa/all\",\n",
      "    \"ConTRoL-nli\",\n",
      "    \"tracie\",\n",
      "    \"sherliic\",\n",
      "    \"sen-making/1\",\n",
      "    \"sen-making/2\",\n",
      "    \"winowhy\",\n",
      "    \"mbib-base/cognitive-bias\",\n",
      "    \"mbib-base/fake-news\",\n",
      "    \"mbib-base/gender-bias\",\n",
      "    \"mbib-base/hate-speech\",\n",
      "    \"mbib-base/linguistic-bias\",\n",
      "    \"mbib-base/political-bias\",\n",
      "    \"mbib-base/racial-bias\",\n",
      "    \"mbib-base/text-level-bias\",\n",
      "    \"robustLR\",\n",
      "    \"v1/gen_train234_test2to10\",\n",
      "    \"logical-fallacy\",\n",
      "    \"parade\",\n",
      "    \"cladder\",\n",
      "    \"subjectivity\",\n",
      "    \"MOH\",\n",
      "    \"VUAC\",\n",
      "    \"TroFi\",\n",
      "    \"sharc_modified/mod\",\n",
      "    \"conceptrules_v2\",\n",
      "    \"disrpt/eng.dep.scidtb.rels\",\n",
      "    \"conll2000\",\n",
      "    \"few-nerd/supervised\",\n",
      "    \"finer-139\",\n",
      "    \"zero-shot-label-nli\",\n",
      "    \"com2sense\",\n",
      "    \"scone\",\n",
      "    \"winodict\",\n",
      "    \"fool-me-twice\",\n",
      "    \"monli\",\n",
      "    \"corr2cause\",\n",
      "    \"lsat_qa/all\",\n",
      "    \"apt\",\n",
      "    \"twitter-financial-news-sentiment\",\n",
      "    \"icl-symbol-tuning-instruct\",\n",
      "    \"SpaceNLI\",\n",
      "    \"propsegment/nli\",\n",
      "    \"HatemojiBuild\",\n",
      "    \"regset\",\n",
      "    \"esci\",\n",
      "    \"chatbot_arena_conversations\",\n",
      "    \"dnd_style_intents\",\n",
      "    \"FLD.v2\",\n",
      "    \"SDOH-NLI\",\n",
      "    \"scifact_entailment\",\n",
      "    \"feasibilityQA\",\n",
      "    \"simple_pair\",\n",
      "    \"AdjectiveScaleProbe-nli\",\n",
      "    \"resnli\",\n",
      "    \"SpaRTUN\",\n",
      "    \"ReSQ\",\n",
      "    \"semantic_fragments_nli\",\n",
      "    \"dataset_train_nli\",\n",
      "    \"stepgame\",\n",
      "    \"nlgraph\",\n",
      "    \"oasst2_pairwise_rlhf_reward\",\n",
      "    \"hh-rlhf/helpful-rejection-sampled\",\n",
      "    \"hh-rlhf/helpful-base\",\n",
      "    \"hh-rlhf/helpful-online\",\n",
      "    \"hh-rlhf/harmless-base\",\n",
      "    \"ruletaker\",\n",
      "    \"PARARULE-Plus\",\n",
      "    \"proofwriter\",\n",
      "    \"logical-entailment\",\n",
      "    \"babi_nli\",\n",
      "    \"gen_debiased_nli\",\n",
      "    \"imppres/presupposition\",\n",
      "    \"/prag\",\n",
      "    \"blimp-2\",\n",
      "    \"mmlu-4\"\n",
      "  ],\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file /home/elson/6.4.1_deberta/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at /home/elson/6.4.1_deberta/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 32\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/6.4.1_deberta/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[ 6.2744e-01, -7.3584e-01, -2.1985e-01],\n",
      "       [ 1.2070e+00, -6.5918e-01, -7.6270e-01],\n",
      "       [ 2.3340e+00, -1.4180e+00, -1.3223e+00],\n",
      "       [-9.4287e-01, -1.2998e+00,  1.8828e+00],\n",
      "       [ 1.4688e+00, -9.7998e-01, -1.0938e+00],\n",
      "       [ 2.6211e+00, -9.0869e-01, -2.2363e+00],\n",
      "       [ 1.0830e+00, -1.1240e+00, -3.3130e-01],\n",
      "       [ 1.5762e+00, -6.4014e-01, -1.4180e+00],\n",
      "       [ 1.5059e+00, -1.2441e+00, -1.0137e+00],\n",
      "       [ 1.4033e+00, -1.0693e+00, -5.9521e-01],\n",
      "       [ 1.8330e+00, -1.3877e+00, -8.9893e-01],\n",
      "       [ 2.2188e+00, -9.2188e-01, -1.8867e+00],\n",
      "       [ 8.0957e-01, -7.4219e-01, -5.4785e-01],\n",
      "       [ 2.1504e+00, -7.6074e-01, -1.8037e+00],\n",
      "       [ 1.1816e+00, -2.9346e-01, -9.7803e-01],\n",
      "       [-1.2219e-01, -1.0283e+00,  8.2129e-01],\n",
      "       [ 1.4375e+00, -5.6055e-01, -1.1973e+00],\n",
      "       [ 1.8135e+00, -5.6885e-01, -1.6172e+00],\n",
      "       [ 2.5195e+00, -1.1123e+00, -1.9326e+00],\n",
      "       [ 2.4355e+00, -1.1504e+00, -1.7188e+00],\n",
      "       [ 5.3772e-02, -7.9492e-01,  5.3467e-01],\n",
      "       [ 9.7656e-01, -8.2080e-01, -4.8315e-01],\n",
      "       [ 1.3809e+00, -1.0078e+00, -6.4453e-01],\n",
      "       [-5.8447e-01, -1.2559e+00,  1.5420e+00],\n",
      "       [-6.4014e-01, -9.7070e-01,  1.4707e+00],\n",
      "       [-1.1709e+00, -2.8735e-01,  1.3047e+00],\n",
      "       [ 2.7734e+00, -1.2090e+00, -2.1387e+00],\n",
      "       [ 7.6416e-01, -4.6289e-01, -5.2783e-01],\n",
      "       [ 1.6553e+00, -6.1182e-01, -1.6553e+00],\n",
      "       [ 1.9619e+00, -1.1787e+00, -1.2041e+00],\n",
      "       [ 2.7441e-01, -6.6357e-01,  1.2488e-01],\n",
      "       [ 2.0137e+00, -7.9736e-01, -1.6777e+00],\n",
      "       [ 1.0078e+00, -6.9189e-01, -6.1816e-01],\n",
      "       [ 8.7891e-01, -8.5547e-01, -5.9863e-01],\n",
      "       [-1.8750e-01, -6.8652e-01,  8.4229e-01],\n",
      "       [ 1.5674e+00, -4.8926e-01, -1.3271e+00],\n",
      "       [ 6.8262e-01, -8.6475e-01, -3.2910e-01],\n",
      "       [ 2.1816e+00, -8.9453e-01, -1.6406e+00],\n",
      "       [-1.3359e+00, -1.1689e+00,  2.2695e+00],\n",
      "       [ 1.7529e+00, -7.2607e-01, -1.3848e+00],\n",
      "       [-3.6523e-01, -1.0820e+00,  1.1191e+00],\n",
      "       [ 2.1152e+00, -7.6660e-01, -1.8896e+00],\n",
      "       [ 7.5928e-01, -7.7637e-01, -2.2180e-01],\n",
      "       [ 6.0986e-01, -8.2129e-01, -5.6763e-02],\n",
      "       [-4.0625e-01, -6.0986e-01,  1.0488e+00],\n",
      "       [ 1.8828e+00, -9.4238e-01, -1.3408e+00],\n",
      "       [ 6.0889e-01, -8.6621e-01, -1.0433e-03],\n",
      "       [ 2.4590e+00, -9.4824e-01, -1.9502e+00],\n",
      "       [ 2.0684e+00, -1.1475e+00, -1.2051e+00],\n",
      "       [-7.9395e-01, -7.9102e-01,  1.3721e+00],\n",
      "       [ 1.7224e-01, -6.2305e-01,  3.3887e-01],\n",
      "       [ 4.2944e-01, -5.1514e-01, -3.3594e-01],\n",
      "       [ 7.0801e-01, -8.6377e-01, -2.1863e-01],\n",
      "       [ 1.9658e+00, -7.2559e-01, -1.7188e+00],\n",
      "       [-1.1517e-01, -5.0781e-01,  4.4263e-01],\n",
      "       [ 2.5449e+00, -1.1748e+00, -2.0059e+00],\n",
      "       [ 4.6753e-01, -5.4102e-01, -9.1309e-02],\n",
      "       [ 2.1484e+00, -6.7285e-01, -2.0664e+00],\n",
      "       [ 2.3164e+00, -1.1533e+00, -1.6455e+00],\n",
      "       [ 2.0977e+00, -9.3457e-01, -1.5195e+00],\n",
      "       [ 9.3213e-01, -7.7930e-01, -6.5820e-01],\n",
      "       [-7.9492e-01, -1.0146e+00,  1.5332e+00],\n",
      "       [ 1.1553e+00, -5.5762e-01, -9.5264e-01],\n",
      "       [ 1.5498e+00, -8.5352e-01, -1.3701e+00],\n",
      "       [ 1.2314e+00, -2.6758e-01, -1.0830e+00],\n",
      "       [ 1.1787e+00, -8.6182e-01, -8.1104e-01],\n",
      "       [ 2.5020e+00, -1.1094e+00, -1.9873e+00],\n",
      "       [ 2.1699e+00, -1.1416e+00, -1.3467e+00],\n",
      "       [ 1.5361e+00, -1.3486e+00, -6.2451e-01],\n",
      "       [-2.6929e-01, -1.1396e+00,  1.4834e+00],\n",
      "       [ 1.5400e+00, -9.3994e-01, -1.1982e+00],\n",
      "       [ 1.1523e+00, -5.4443e-01, -9.7461e-01],\n",
      "       [ 1.1143e+00, -4.1846e-01, -9.1650e-01],\n",
      "       [ 1.3447e+00, -6.0938e-01, -1.2148e+00],\n",
      "       [ 5.4834e-01, -7.2510e-01, -7.6447e-03],\n",
      "       [ 1.7393e+00, -8.5010e-01, -1.2012e+00],\n",
      "       [ 7.6660e-01, -7.5342e-01, -3.5400e-01],\n",
      "       [ 1.2451e+00, -8.8867e-01, -8.7256e-01],\n",
      "       [ 1.7930e+00, -1.2959e+00, -8.1006e-01],\n",
      "       [ 6.9238e-01, -8.7354e-01, -1.1401e-01],\n",
      "       [ 2.0918e+00, -1.2617e+00, -1.1172e+00],\n",
      "       [ 1.8311e+00, -9.4873e-01, -1.2051e+00],\n",
      "       [ 7.6318e-01, -3.2642e-01, -6.7334e-01],\n",
      "       [ 1.8613e+00, -1.2754e+00, -9.4336e-01],\n",
      "       [ 2.6348e+00, -1.2354e+00, -1.9590e+00],\n",
      "       [ 1.3306e-01, -6.0938e-01,  3.1079e-01],\n",
      "       [ 7.4561e-01, -6.8604e-01, -4.0869e-01],\n",
      "       [ 5.4443e-01, -9.4482e-01,  8.3313e-02],\n",
      "       [ 1.1396e+00, -7.6562e-01, -7.4561e-01],\n",
      "       [ 1.2402e+00, -6.2451e-01, -1.0020e+00],\n",
      "       [ 2.4727e+00, -1.3965e+00, -1.5283e+00],\n",
      "       [ 2.0625e+00, -1.2266e+00, -1.4326e+00],\n",
      "       [-7.0215e-01, -1.2939e+00,  1.6201e+00],\n",
      "       [ 2.2949e+00, -9.4385e-01, -1.7246e+00],\n",
      "       [-8.0444e-02, -6.7578e-01,  5.3955e-01],\n",
      "       [ 7.3242e-01, -7.1924e-01, -3.0737e-01],\n",
      "       [ 3.7427e-01, -1.2598e+00,  7.7588e-01],\n",
      "       [ 8.1543e-01, -5.1318e-01, -4.4629e-01],\n",
      "       [ 1.5693e+00, -1.1885e+00, -7.4316e-01],\n",
      "       [ 1.0459e+00, -6.6943e-01, -7.7393e-01],\n",
      "       [-7.4609e-01, -9.4336e-01,  1.6084e+00],\n",
      "       [ 1.8877e+00, -4.6558e-01, -1.7559e+00],\n",
      "       [ 2.4023e+00, -8.0420e-01, -1.9336e+00],\n",
      "       [ 1.3135e+00, -4.6582e-01, -1.0234e+00],\n",
      "       [ 2.0586e+00, -8.7305e-01, -1.4170e+00],\n",
      "       [ 2.0742e+00, -1.3408e+00, -1.2744e+00],\n",
      "       [ 1.1875e+00, -1.1758e+00, -3.1860e-01],\n",
      "       [ 4.6948e-01, -9.5068e-01,  2.0703e-01],\n",
      "       [ 1.7402e+00, -1.2129e+00, -1.1504e+00],\n",
      "       [ 1.1855e+00, -1.1270e+00, -7.9443e-01],\n",
      "       [ 2.2559e+00, -6.3965e-01, -2.1426e+00],\n",
      "       [ 1.8770e+00, -8.5303e-01, -1.4121e+00],\n",
      "       [ 1.3955e+00, -6.9922e-01, -9.4092e-01],\n",
      "       [ 8.4180e-01, -8.2617e-01, -3.9771e-01],\n",
      "       [ 1.9648e+00, -7.3975e-01, -1.8008e+00],\n",
      "       [ 1.5762e+00, -1.0166e+00, -1.0498e+00],\n",
      "       [ 2.3730e+00, -1.0469e+00, -1.7920e+00],\n",
      "       [ 2.1802e-01, -7.7576e-02, -2.2888e-01],\n",
      "       [ 1.6318e+00, -1.2432e+00, -9.3848e-01],\n",
      "       [ 7.1338e-01, -7.5342e-01, -3.2129e-01],\n",
      "       [ 1.2754e+00, -6.6016e-01, -9.3799e-01],\n",
      "       [ 2.5762e+00, -1.2012e+00, -2.1797e+00],\n",
      "       [ 1.9062e+00, -6.5723e-01, -1.7686e+00],\n",
      "       [ 6.1426e-01, -5.9277e-01, -2.3584e-01],\n",
      "       [ 1.0488e+00, -9.9316e-01, -5.3418e-01],\n",
      "       [ 1.5762e+00, -6.3184e-01, -1.2305e+00],\n",
      "       [ 2.7393e-01, -8.1348e-01,  1.3269e-01],\n",
      "       [ 2.3359e+00, -1.0400e+00, -1.6152e+00],\n",
      "       [ 1.5127e+00, -9.1016e-01, -1.2139e+00],\n",
      "       [ 1.4336e+00, -4.8218e-01, -1.1758e+00],\n",
      "       [ 8.9355e-01, -7.2852e-01, -5.4834e-01],\n",
      "       [-8.4229e-01, -1.0596e+00,  1.8486e+00],\n",
      "       [ 1.6602e+00, -1.0234e+00, -1.0391e+00],\n",
      "       [ 5.2930e-01, -9.5703e-01, -1.9455e-02],\n",
      "       [ 1.2422e+00, -9.0186e-01, -7.4463e-01],\n",
      "       [ 3.7329e-01, -9.2090e-01,  2.7271e-01],\n",
      "       [ 8.0371e-01, -8.8281e-01, -6.7749e-02],\n",
      "       [ 7.4707e-01, -8.3154e-01, -1.5674e-01],\n",
      "       [ 9.1431e-02, -5.0342e-01,  1.3550e-01],\n",
      "       [ 2.3438e+00, -7.6855e-01, -1.9219e+00],\n",
      "       [ 2.0117e+00, -9.4971e-01, -1.4619e+00],\n",
      "       [ 4.2383e-01, -8.0859e-01,  6.7444e-02],\n",
      "       [ 7.8369e-01, -8.8721e-01, -5.3076e-01],\n",
      "       [ 2.3945e+00, -1.0518e+00, -1.9463e+00],\n",
      "       [ 5.1367e-01, -7.4170e-01, -1.7502e-02],\n",
      "       [ 7.0898e-01, -7.8369e-01, -1.3745e-01],\n",
      "       [-6.6602e-01, -7.7930e-01,  1.0928e+00],\n",
      "       [-3.0859e-01, -8.2031e-01,  1.0605e+00],\n",
      "       [ 8.6768e-01, -8.8477e-01, -3.8428e-01],\n",
      "       [ 4.1260e-01, -6.3086e-01,  9.6741e-03],\n",
      "       [ 7.2217e-01, -8.0566e-01, -3.1104e-01],\n",
      "       [ 2.5098e+00, -1.3965e+00, -1.5586e+00],\n",
      "       [ 1.7246e+00, -7.9102e-01, -1.4453e+00],\n",
      "       [ 1.1777e+00, -3.9453e-01, -9.6680e-01],\n",
      "       [ 1.3555e+00, -9.3604e-01, -8.9062e-01],\n",
      "       [ 2.2617e+00, -1.3232e+00, -1.3330e+00],\n",
      "       [ 2.6426e+00, -1.3076e+00, -1.7100e+00],\n",
      "       [ 7.2949e-01, -1.0508e+00,  1.2500e-01],\n",
      "       [ 1.8265e-02, -2.6215e-02,  3.3630e-02],\n",
      "       [-1.0117e+00, -1.0723e+00,  1.5117e+00],\n",
      "       [-1.1709e+00, -6.2988e-01,  1.5117e+00],\n",
      "       [-1.2490e+00, -1.3027e+00,  2.1191e+00],\n",
      "       [ 1.4189e+00, -5.7520e-01, -1.3027e+00],\n",
      "       [ 3.9966e-01, -1.2490e+00,  3.2153e-01],\n",
      "       [ 7.7393e-01, -8.0127e-01, -3.4131e-01],\n",
      "       [ 3.1934e-01, -7.1680e-01,  3.0542e-01],\n",
      "       [ 1.5225e+00, -1.0127e+00, -1.1045e+00],\n",
      "       [-6.4880e-02, -1.0049e+00,  8.8672e-01],\n",
      "       [-5.7471e-01, -8.9844e-01,  1.4844e+00],\n",
      "       [ 4.6118e-01, -1.2266e+00,  4.6631e-01],\n",
      "       [-5.5273e-01, -3.4424e-01,  8.3203e-01],\n",
      "       [ 7.6562e-01, -1.1553e+00,  1.4758e-01],\n",
      "       [ 2.7856e-01, -8.8135e-01,  3.0664e-01],\n",
      "       [ 2.0371e+00, -9.6240e-01, -1.2285e+00],\n",
      "       [ 2.4980e+00, -1.0000e+00, -2.0664e+00],\n",
      "       [ 2.1423e-01, -5.5273e-01,  2.1948e-01],\n",
      "       [ 1.7119e+00, -1.1982e+00, -1.0420e+00],\n",
      "       [-1.6516e-01, -6.6992e-01,  9.9414e-01],\n",
      "       [ 1.8057e+00, -8.4863e-01, -1.5967e+00],\n",
      "       [ 7.6709e-01, -1.2188e+00,  7.8674e-02],\n",
      "       [-1.7700e-01, -1.0908e+00,  9.4336e-01],\n",
      "       [ 4.1333e-01, -1.0752e+00,  2.9370e-01],\n",
      "       [-1.3047e+00, -1.0449e+00,  2.1074e+00],\n",
      "       [ 4.9146e-01, -3.7012e-01, -3.4644e-01],\n",
      "       [-6.4453e-01, -4.6362e-01,  1.1680e+00],\n",
      "       [ 2.5176e+00, -1.2324e+00, -1.9512e+00],\n",
      "       [ 2.0059e+00, -7.3682e-01, -1.7881e+00],\n",
      "       [ 1.8770e+00, -7.4756e-01, -1.7354e+00],\n",
      "       [ 1.4502e+00, -8.6719e-01, -1.2412e+00],\n",
      "       [ 1.2793e+00, -6.7480e-01, -9.3604e-01],\n",
      "       [ 4.2773e-01, -7.6514e-01,  1.7041e-01],\n",
      "       [ 1.1494e+00, -7.6318e-01, -6.8457e-01],\n",
      "       [ 1.6826e+00, -1.2656e+00, -8.3203e-01],\n",
      "       [ 4.0845e-01, -5.4834e-01, -4.8279e-02],\n",
      "       [-1.2656e+00, -1.0469e+00,  1.9902e+00],\n",
      "       [ 2.1777e+00, -9.4971e-01, -1.6758e+00],\n",
      "       [ 1.1777e+00, -5.8936e-01, -1.0117e+00],\n",
      "       [ 2.0605e+00, -6.4258e-01, -1.6982e+00],\n",
      "       [ 2.0801e+00, -1.1709e+00, -1.2041e+00],\n",
      "       [ 1.2021e+00, -6.4551e-01, -9.6289e-01],\n",
      "       [ 1.3896e+00, -1.0156e+00, -6.9092e-01],\n",
      "       [ 2.6680e+00, -8.3887e-01, -2.4395e+00],\n",
      "       [ 4.3872e-01, -5.0146e-01, -1.6760e-01],\n",
      "       [ 1.3486e+00, -7.6855e-01, -6.9482e-01],\n",
      "       [-3.9282e-01, -5.8350e-01,  1.1025e+00],\n",
      "       [-2.8271e-01, -1.0244e+00,  1.1523e+00],\n",
      "       [ 2.3105e+00, -1.0234e+00, -1.6201e+00],\n",
      "       [ 7.6660e-01, -7.8906e-01, -1.3037e-01],\n",
      "       [ 2.3691e+00, -1.2324e+00, -1.7842e+00],\n",
      "       [ 1.0586e+00, -5.4834e-01, -6.4746e-01],\n",
      "       [ 9.7754e-01, -8.4668e-01, -4.3457e-01],\n",
      "       [ 1.2324e+00, -6.4307e-01, -9.5557e-01],\n",
      "       [ 1.4287e+00, -1.0742e+00, -7.5098e-01],\n",
      "       [ 1.5635e+00, -1.0869e+00, -1.2334e+00],\n",
      "       [ 2.6914e+00, -1.1592e+00, -2.0703e+00],\n",
      "       [ 5.4736e-01, -9.0967e-01, -6.5002e-02],\n",
      "       [ 8.2812e-01, -9.2090e-01, -3.1543e-01],\n",
      "       [ 4.5117e-01, -8.0420e-01,  9.2102e-02],\n",
      "       [ 2.1465e+00, -9.0771e-01, -1.6279e+00],\n",
      "       [ 1.0654e+00, -1.1025e+00, -2.8711e-01],\n",
      "       [ 2.5508e+00, -8.9355e-01, -2.2598e+00],\n",
      "       [ 1.7119e+00, -7.6611e-01, -1.1611e+00],\n",
      "       [ 6.3232e-01, -9.9512e-01,  5.7129e-02],\n",
      "       [ 1.9395e+00, -1.1836e+00, -1.1152e+00],\n",
      "       [ 1.5234e+00, -9.3652e-01, -1.0586e+00],\n",
      "       [ 2.7598e+00, -6.4111e-01, -2.7461e+00],\n",
      "       [ 2.7344e+00, -1.3076e+00, -1.9072e+00],\n",
      "       [-2.8833e-01, -1.0566e+00,  1.1934e+00],\n",
      "       [ 5.1392e-02, -1.3438e+00,  8.1934e-01],\n",
      "       [-2.4402e-01,  1.9989e-02,  1.8408e-01],\n",
      "       [ 2.0410e+00, -9.8779e-01, -1.4521e+00],\n",
      "       [ 1.3984e+00, -7.3047e-01, -1.0918e+00],\n",
      "       [ 9.8682e-01, -9.3213e-01, -4.7363e-01],\n",
      "       [-3.6084e-01, -6.8799e-01,  1.0029e+00]], dtype=float16), label_ids=array([0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 2,\n",
      "       0, 1, 2, 2, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 2, 1, 0, 0,\n",
      "       0, 2, 0, 0, 2, 2, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 2, 1, 0, 1, 2,\n",
      "       0, 0, 2, 2, 0, 0, 1, 1, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "       2, 1, 0, 0, 2, 0, 0, 0, 2, 0, 0, 1, 2, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "       1, 0, 1, 0, 1, 0, 0, 0, 2, 2, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2,\n",
      "       0, 1, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 2, 2, 0, 0, 0, 0, 1, 1,\n",
      "       0, 0, 0, 1, 0, 2, 2, 2, 0, 0, 0, 1, 0, 0, 2, 0, 2, 0, 1, 0, 0, 0,\n",
      "       0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 1, 0, 0, 0, 0, 1, 1, 2, 0, 0,\n",
      "       0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 2]), metrics={'test_loss': 0.8250848650932312, 'test_accuracy': 0.6709401709401709, 'test_precision': 0.5462216795550129, 'test_recall': 0.6709401709401709, 'test_f1': 0.6016708006332662, 'test_runtime': 1.1676, 'test_samples_per_second': 200.404, 'test_steps_per_second': 6.851})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
