{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score,balanced_accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-31dfe7adddcf5ced\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 223.76it/s]\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-ad71be204b279b28.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-e7b6b615907c24ca.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-bee802838a3bfaea.arrow\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset from the CSV file\n",
    "dataset = load_dataset(\n",
    "    'csv',\n",
    "    data_files='dataset_semanticattribution_nerfeatures_split.csv',\n",
    "    delimiter=',',\n",
    "    column_names=[\n",
    "        \"claim\", \"premise\", \"label\", \"category\", \"count_bf\", \"count_ca\", \"count_dis\",\n",
    "        \"count_food\", \"count_lipid\", \"count_treat\", \"pres_bf\", \"pres_ca\", \"pres_dis\",\n",
    "        \"pres_food\", \"pres_lipid\", \"pres_treat\", \"counte_bf\", \"counte_ca\", \"counte_dis\",\n",
    "        \"counte_food\", \"counte_lipid\", \"counte_treat\", \"prese_bf\", \"prese_ca\", \"prese_dis\",\n",
    "        \"prese_food\", \"prese_lipid\", \"prese_treat\", \"url\", \"entities\", \"entity_map\",\n",
    "        \"gold_exp\", \"gemini_exp\", \"gemini_label\",\"entity_ev\",\"entity_map_ev\", \"split\"\n",
    "    ],\n",
    "    skiprows=1\n",
    ")\n",
    "\n",
    "\n",
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'gold_exp', 'gemini_exp', 'gemini_label', 'entity_ev', 'entity_map_ev', 'split'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'gold_exp', 'gemini_exp', 'gemini_label', 'entity_ev', 'entity_map_ev', 'split'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'gold_exp', 'gemini_exp', 'gemini_label', 'entity_ev', 'entity_map_ev', 'split'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41f1db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\"claim\", \"premise\", \"label\",\"category\"]\n",
    "all_columns = dataset[\"train\"].column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-50595ddd17286cb3.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-cf2be768746ce61a.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-9f1a3115a6b3b289.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 2, 'entailment': 0, 'neutral': 1}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 2,\n",
    "    \"entailment\": 0,\n",
    "    \"neutral\": 1\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "        # Extracting claim and evidence texts\n",
    "\n",
    "        claim = item['claim']\n",
    "        premise = item['premise'].replace('\\n', '').replace('[','').replace(']','')\n",
    "        item['claim']=claim\n",
    "        item['premise']=premise\n",
    "        \n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "            claim, premise,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "        item['input_ids'] = inputs['input_ids'].squeeze()  # Remove batch dimension\n",
    "        item['attention_mask']= inputs['attention_mask'].squeeze() # Remove batch dimension\n",
    "        \n",
    "        if 'label' in item:\n",
    "            item['labels'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62421eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DebertaV2ForSequenceClassification(\n",
       "  (deberta): DebertaV2Model(\n",
       "    (embeddings): DebertaV2Embeddings(\n",
       "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaV2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (1): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (2): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (3): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (4): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (5): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (6): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (7): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (8): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (9): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (10): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (11): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (pooler): ContextPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): StableDropout()\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (dropout): StableDropout()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=3, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    bal_accuracy = balanced_accuracy_score(labels,preds)\n",
    "\n",
    "    return {\"accuracy\": acc, \"balanced_accuracy\":bal_accuracy, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17c5e0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'claim': 'Myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.',\n",
       " 'premise': '; UnkoviÄ‡, N.; DimkiÄ‡, I.; JanaÄ‡koviÄ‡, P.; GavriloviÄ‡, M.; StanojeviÄ‡, O.; VukojeviÄ‡, J. Frankincense and myrrh essential oils and burn incense fume against micro-inhabitants of sacral ambients.Shameem, I. Phytochemical & therapeutic potentials of Murr makki (.Oxidative stress and immunotoxic effects of lead and their amelioration with myrrh (Commiphora molmol) emulsion.Essential Oils: Magical Ingredients for Skin Care.Chakravarty, N.; Kellogg, C.; Alvarez, J.; Equils, O.; Morgan, M. UV Protection by Natural Products: C. myrrha Oil Versus Sunscreen.Hamidpour, R.; Hamidpour, S.; Hamidpour, M.; Shahlari, M. Frankincense (ä¹³é¦™ RÇ” XiÄ\\x81ng;.species): From the selection of traditional applications to the novel phytotherapy for the prevention and treatment of serious diseases.Chemistry and immunomodulatory activity of frankincense oil.Compositions containing Boswellia extracts.; Cooper, E. Frankincense and myrrh as remedies in children.',\n",
       " 'label': 0,\n",
       " 'category': 'General Health',\n",
       " 'input_ids': tensor([     1,    573,  52341,   1830,   1080,    269,   1359,    427,    267,\n",
       "          17847,    633,    264,    408,   1300,    262,   2658,    265,    262,\n",
       "           1158,    260,      2,   2600,   3405,  16876,    667,  37198,  61593,\n",
       "            261,   1149,    260,    346,  29597,   6848,  37198,  61593,    261,\n",
       "            273,    260,    346,  37741,  37198,  61593,  16876,    667,  37198,\n",
       "          61593,    261,    916,    260,    346, 117259,  34984,  37198,  61593,\n",
       "            261,    749,    260,    346,  10490,  73907,   8007,  37198,  61593,\n",
       "            261,   1130,    260,    346,   1407,   3359,  73907,   8007,  37198,\n",
       "          61593,    261,    851,    260, 100066,    263,  98237,   1830,   6725,\n",
       "            263,   5134,  30055,  77487,    532,   4014,    271,    547,  52263,\n",
       "          16224,    265,  86207,  14178,    268,    260,  97818,   4379,    261,\n",
       "            273,    260,  43923,  23399,    429,   8068,   1068,    268,    265,\n",
       "          88327,   1917, 110269,    287,    260,  57909,   4765,  12100,   2148,\n",
       "            263,  25348,  20413,   1563,    265,    917,    263,    308,    266,\n",
       "          84530,  62542,    275,  98237,    287,  41462,    667,  65073,  44845,\n",
       "          22317,    285,  36774,    260,  70298,  40149,    294,  32799,  22280,\n",
       "            270,   9560,   2926,    260,  29466,  32531,  11238,   5750,    261,\n",
       "           1149,    260,    346,  35339,    261,    716,    260,    346,  29700,\n",
       "            261,    851,    260,    346,  43713,  15150,    261,   1130,    260,\n",
       "            346,   5794,    261,    749,    260,   9048,   5341,    293,   4613,\n",
       "           4950,    294,    716,    260,  98237,    452,   4366,  52114,  72408,\n",
       "            260,  44233,   4765,  39151,    261,    909,    260,    346,  42595,\n",
       "          39151,    261,    662,    260,    346,  42595,  39151,    261,    749,\n",
       "            260,    346,  11209,  60641,    261,    749,    260, 100066,    287,\n",
       "          15726,   2209,   5858,  25499,   3004,    909,  74742,    318,  13238,\n",
       "          37198,    198,    133,   5900,    346,    260,  43427,    285,    294,\n",
       "           1007,    262,   1857,    265,   1471,   1567,    264,    262,   2626,\n",
       "          41529,  28479,    270,    262,   5937,    263,   1035,    265,   1721,\n",
       "           4253,    260,  95126,    263, 121470,   1506,    265,  88609,   1080,\n",
       "            260,  12768,  19573,    268,   4086,  60761,   2767,  15808,    260,\n",
       "            346,   7413,    261,    829,    260, 100066,    263,  98237,    283,\n",
       "          11882,    267,    572,    260,      2,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'labels': tensor(0)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 765\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='765' max='765' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [765/765 11:32, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.655500</td>\n",
       "      <td>0.830846</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.502576</td>\n",
       "      <td>0.659940</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.649869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.492900</td>\n",
       "      <td>0.861763</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.539868</td>\n",
       "      <td>0.715354</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.669247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.354800</td>\n",
       "      <td>0.987491</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.549804</td>\n",
       "      <td>0.706009</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.683059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.198800</td>\n",
       "      <td>1.189234</td>\n",
       "      <td>0.673118</td>\n",
       "      <td>0.522349</td>\n",
       "      <td>0.684015</td>\n",
       "      <td>0.673118</td>\n",
       "      <td>0.673464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.114400</td>\n",
       "      <td>1.490838</td>\n",
       "      <td>0.696774</td>\n",
       "      <td>0.586177</td>\n",
       "      <td>0.709364</td>\n",
       "      <td>0.696774</td>\n",
       "      <td>0.702405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.115100</td>\n",
       "      <td>1.619665</td>\n",
       "      <td>0.673118</td>\n",
       "      <td>0.538130</td>\n",
       "      <td>0.686028</td>\n",
       "      <td>0.673118</td>\n",
       "      <td>0.673888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.062200</td>\n",
       "      <td>1.785531</td>\n",
       "      <td>0.683871</td>\n",
       "      <td>0.583191</td>\n",
       "      <td>0.713010</td>\n",
       "      <td>0.683871</td>\n",
       "      <td>0.695306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.025400</td>\n",
       "      <td>2.025014</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.557470</td>\n",
       "      <td>0.692739</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.682154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>2.334387</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.555170</td>\n",
       "      <td>0.699912</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.673851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>2.355283</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.571718</td>\n",
       "      <td>0.710936</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.684208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>2.461880</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.552116</td>\n",
       "      <td>0.693132</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.683203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>2.511760</td>\n",
       "      <td>0.660215</td>\n",
       "      <td>0.544638</td>\n",
       "      <td>0.688070</td>\n",
       "      <td>0.660215</td>\n",
       "      <td>0.672229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>2.544021</td>\n",
       "      <td>0.662366</td>\n",
       "      <td>0.548632</td>\n",
       "      <td>0.691111</td>\n",
       "      <td>0.662366</td>\n",
       "      <td>0.674859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>2.538841</td>\n",
       "      <td>0.668817</td>\n",
       "      <td>0.545020</td>\n",
       "      <td>0.689222</td>\n",
       "      <td>0.668817</td>\n",
       "      <td>0.678015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>2.545783</td>\n",
       "      <td>0.673118</td>\n",
       "      <td>0.552511</td>\n",
       "      <td>0.693090</td>\n",
       "      <td>0.673118</td>\n",
       "      <td>0.682019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.2.1_deberta/checkpoint-51\n",
      "Configuration saved in /home/elson/2.2.1_deberta/checkpoint-51/config.json\n",
      "Model weights saved in /home/elson/2.2.1_deberta/checkpoint-51/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.1_deberta/checkpoint-102] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/2.2.1_deberta/checkpoint-765] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.2.1_deberta/checkpoint-102\n",
      "Configuration saved in /home/elson/2.2.1_deberta/checkpoint-102/config.json\n",
      "Model weights saved in /home/elson/2.2.1_deberta/checkpoint-102/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.2.1_deberta/checkpoint-153\n",
      "Configuration saved in /home/elson/2.2.1_deberta/checkpoint-153/config.json\n",
      "Model weights saved in /home/elson/2.2.1_deberta/checkpoint-153/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.1_deberta/checkpoint-51] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/2.2.1_deberta/checkpoint-102] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.2.1_deberta/checkpoint-204\n",
      "Configuration saved in /home/elson/2.2.1_deberta/checkpoint-204/config.json\n",
      "Model weights saved in /home/elson/2.2.1_deberta/checkpoint-204/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.1_deberta/checkpoint-153] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.2.1_deberta/checkpoint-255\n",
      "Configuration saved in /home/elson/2.2.1_deberta/checkpoint-255/config.json\n",
      "Model weights saved in /home/elson/2.2.1_deberta/checkpoint-255/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.1_deberta/checkpoint-204] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.2.1_deberta/checkpoint-306\n",
      "Configuration saved in /home/elson/2.2.1_deberta/checkpoint-306/config.json\n",
      "Model weights saved in /home/elson/2.2.1_deberta/checkpoint-306/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.2.1_deberta/checkpoint-357\n",
      "Configuration saved in /home/elson/2.2.1_deberta/checkpoint-357/config.json\n",
      "Model weights saved in /home/elson/2.2.1_deberta/checkpoint-357/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.1_deberta/checkpoint-306] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.2.1_deberta/checkpoint-408\n",
      "Configuration saved in /home/elson/2.2.1_deberta/checkpoint-408/config.json\n",
      "Model weights saved in /home/elson/2.2.1_deberta/checkpoint-408/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.1_deberta/checkpoint-357] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.2.1_deberta/checkpoint-459\n",
      "Configuration saved in /home/elson/2.2.1_deberta/checkpoint-459/config.json\n",
      "Model weights saved in /home/elson/2.2.1_deberta/checkpoint-459/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.1_deberta/checkpoint-408] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.2.1_deberta/checkpoint-510\n",
      "Configuration saved in /home/elson/2.2.1_deberta/checkpoint-510/config.json\n",
      "Model weights saved in /home/elson/2.2.1_deberta/checkpoint-510/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.1_deberta/checkpoint-459] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.2.1_deberta/checkpoint-561\n",
      "Configuration saved in /home/elson/2.2.1_deberta/checkpoint-561/config.json\n",
      "Model weights saved in /home/elson/2.2.1_deberta/checkpoint-561/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.1_deberta/checkpoint-510] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.2.1_deberta/checkpoint-612\n",
      "Configuration saved in /home/elson/2.2.1_deberta/checkpoint-612/config.json\n",
      "Model weights saved in /home/elson/2.2.1_deberta/checkpoint-612/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.1_deberta/checkpoint-561] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.2.1_deberta/checkpoint-663\n",
      "Configuration saved in /home/elson/2.2.1_deberta/checkpoint-663/config.json\n",
      "Model weights saved in /home/elson/2.2.1_deberta/checkpoint-663/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.1_deberta/checkpoint-612] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.2.1_deberta/checkpoint-714\n",
      "Configuration saved in /home/elson/2.2.1_deberta/checkpoint-714/config.json\n",
      "Model weights saved in /home/elson/2.2.1_deberta/checkpoint-714/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.1_deberta/checkpoint-663] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.2.1_deberta/checkpoint-765\n",
      "Configuration saved in /home/elson/2.2.1_deberta/checkpoint-765/config.json\n",
      "Model weights saved in /home/elson/2.2.1_deberta/checkpoint-765/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.1_deberta/checkpoint-714] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/elson/2.2.1_deberta/checkpoint-255 (score: 0.6967741935483871).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /home/elson/2.2.1_deberta/best_model/config.json\n",
      "Model weights saved in /home/elson/2.2.1_deberta/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/2.2.1_deberta/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/2.2.1_deberta/best_model/special_tokens_map.json\n",
      "added tokens file saved in /home/elson/2.2.1_deberta/best_model/added_tokens.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/2.2.1_deberta/best_model/tokenizer_config.json',\n",
       " '/home/elson/2.2.1_deberta/best_model/special_tokens_map.json',\n",
       " '/home/elson/2.2.1_deberta/best_model/spm.model',\n",
       " '/home/elson/2.2.1_deberta/best_model/added_tokens.json')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/2.2.1_deberta/',\n",
    "    num_train_epochs=15,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.06,\n",
    "    weight_decay=0.1,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/2.2.1_deberta/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/2.2.1_deberta/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63deaea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/2.2.1_deberta/best_model/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"/home/elson/2.2.1_deberta/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"entailment\",\n",
      "    \"1\": \"neutral\",\n",
      "    \"2\": \"contradiction\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"contradiction\": 2,\n",
      "    \"entailment\": 0,\n",
      "    \"neutral\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file /home/elson/2.2.1_deberta/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at /home/elson/2.2.1_deberta/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 32\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/2.2.1_deberta/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[ 4.4961e+00, -1.2891e+00, -2.9902e+00],\n",
      "       [ 3.8086e-02,  1.8926e+00, -1.9805e+00],\n",
      "       [ 5.4141e+00, -2.2148e+00, -2.9492e+00],\n",
      "       [-1.0840e+00, -2.0977e+00,  3.4258e+00],\n",
      "       [ 4.7344e+00, -2.1992e+00, -2.3926e+00],\n",
      "       [ 5.6484e+00, -1.1328e+00, -4.2422e+00],\n",
      "       [ 5.4727e+00, -1.3721e+00, -3.7832e+00],\n",
      "       [ 5.5859e+00, -2.0176e+00, -3.2793e+00],\n",
      "       [ 6.0430e+00, -1.9922e+00, -3.6641e+00],\n",
      "       [ 5.0078e+00, -1.7939e+00, -3.0293e+00],\n",
      "       [ 5.7812e+00, -2.0664e+00, -3.3633e+00],\n",
      "       [ 5.9805e+00, -1.9023e+00, -3.7090e+00],\n",
      "       [ 4.2109e+00, -1.0388e-01, -4.0000e+00],\n",
      "       [ 4.6719e+00, -1.8994e+00, -2.5273e+00],\n",
      "       [ 4.2109e+00,  1.0956e-01, -4.3594e+00],\n",
      "       [-2.7070e+00, -4.2944e-01,  3.4238e+00],\n",
      "       [ 4.0430e+00,  2.4780e-01, -4.3281e+00],\n",
      "       [ 7.2705e-01,  2.8848e+00, -3.3828e+00],\n",
      "       [ 6.1133e+00, -1.7383e+00, -3.9805e+00],\n",
      "       [ 5.8086e+00, -1.9297e+00, -3.5625e+00],\n",
      "       [-3.0059e+00,  2.9922e+00,  3.4961e-01],\n",
      "       [ 8.4521e-01,  3.1616e-01, -1.0400e+00],\n",
      "       [ 1.3301e+00,  1.9619e+00, -3.1660e+00],\n",
      "       [-2.8750e+00,  9.3701e-01,  2.4023e+00],\n",
      "       [ 1.4482e+00, -3.1133e+00,  1.6084e+00],\n",
      "       [-3.3457e+00, -6.4697e-01,  4.2500e+00],\n",
      "       [ 5.5430e+00, -2.4277e+00, -2.9004e+00],\n",
      "       [ 5.8359e+00, -1.4961e+00, -4.0938e+00],\n",
      "       [ 5.1953e+00, -1.6221e+00, -3.2461e+00],\n",
      "       [ 5.9258e+00, -2.3008e+00, -3.2852e+00],\n",
      "       [ 1.7061e+00, -9.4727e-01, -7.1191e-01],\n",
      "       [ 6.0234e+00, -1.5283e+00, -4.1641e+00],\n",
      "       [ 6.0469e+00, -1.8945e+00, -3.8379e+00],\n",
      "       [ 5.5000e+00, -2.3691e+00, -2.8965e+00],\n",
      "       [ 2.5293e+00, -5.2738e-04, -2.2969e+00],\n",
      "       [ 5.0586e+00, -1.2344e+00, -3.6660e+00],\n",
      "       [ 1.8721e+00, -1.8340e+00,  4.0558e-02],\n",
      "       [ 5.9414e+00, -2.0430e+00, -3.5410e+00],\n",
      "       [-2.5078e+00, -5.8154e-01,  3.3867e+00],\n",
      "       [ 5.8672e+00, -1.6182e+00, -3.9727e+00],\n",
      "       [ 1.8030e-01,  9.7217e-01, -1.0693e+00],\n",
      "       [ 5.6914e+00, -1.3701e+00, -3.9844e+00],\n",
      "       [ 2.5586e+00, -1.8545e+00, -6.5771e-01],\n",
      "       [-2.9434e+00, -2.0332e+00,  4.9922e+00],\n",
      "       [ 4.0312e+00, -1.0098e+00, -2.8672e+00],\n",
      "       [ 5.5156e+00, -1.2158e+00, -4.0625e+00],\n",
      "       [ 4.6719e+00, -1.0098e+00, -3.5059e+00],\n",
      "       [ 6.0469e+00, -2.2949e+00, -3.4043e+00],\n",
      "       [ 5.8672e+00, -1.8018e+00, -3.7012e+00],\n",
      "       [-9.5996e-01, -2.3594e+00,  3.4277e+00],\n",
      "       [-7.0117e-01,  1.7151e-01,  1.0049e+00],\n",
      "       [ 2.0059e+00, -3.1348e+00,  1.0635e+00],\n",
      "       [-1.1631e+00, -4.5068e-01,  1.9834e+00],\n",
      "       [ 4.7422e+00, -1.1676e-01, -4.4609e+00],\n",
      "       [-5.8740e-01,  2.7812e+00, -2.2109e+00],\n",
      "       [ 5.0625e+00, -2.3086e+00, -2.5449e+00],\n",
      "       [-2.6465e+00, -1.8721e+00,  4.5312e+00],\n",
      "       [ 5.0742e+00, -5.8887e-01, -4.3008e+00],\n",
      "       [ 5.7500e+00, -2.0098e+00, -3.4238e+00],\n",
      "       [ 5.5000e+00, -2.5195e+00, -2.7129e+00],\n",
      "       [ 5.4844e+00, -1.4717e+00, -3.7559e+00],\n",
      "       [-1.9482e-01, -2.3457e+00,  2.6309e+00],\n",
      "       [ 5.4062e+00, -9.1797e-01, -4.2227e+00],\n",
      "       [ 4.7227e+00, -2.5801e+00, -2.0312e+00],\n",
      "       [ 1.8584e+00,  9.4141e-01, -2.9395e+00],\n",
      "       [ 5.5234e+00, -1.9102e+00, -3.2871e+00],\n",
      "       [ 5.6797e+00, -1.6895e+00, -3.6816e+00],\n",
      "       [ 5.7305e+00, -2.1387e+00, -3.2480e+00],\n",
      "       [ 5.1680e+00, -2.2266e+00, -2.6445e+00],\n",
      "       [-7.2314e-01, -2.3477e+00,  3.1094e+00],\n",
      "       [ 7.0850e-01, -2.4316e+00,  1.7383e+00],\n",
      "       [ 3.6504e+00,  5.7178e-01, -4.0781e+00],\n",
      "       [ 4.7461e+00, -1.8140e-01, -4.4297e+00],\n",
      "       [ 5.3711e+00, -2.4648e+00, -2.6602e+00],\n",
      "       [ 1.5781e+00, -7.1680e-01, -9.5459e-01],\n",
      "       [ 4.8047e+00, -2.8887e+00, -1.7256e+00],\n",
      "       [ 5.7969e+00, -1.9385e+00, -3.5840e+00],\n",
      "       [ 6.0625e+00, -1.6709e+00, -4.0391e+00],\n",
      "       [ 5.5352e+00, -1.4238e+00, -3.8438e+00],\n",
      "       [ 1.4014e+00, -2.5293e+00,  1.1631e+00],\n",
      "       [ 9.7070e-01, -2.4062e+00,  1.4375e+00],\n",
      "       [ 6.0469e+00, -1.8174e+00, -3.8691e+00],\n",
      "       [ 5.8633e+00, -1.6641e+00, -3.8906e+00],\n",
      "       [ 5.4336e+00, -1.8350e+00, -3.3203e+00],\n",
      "       [ 1.0225e+00,  5.9912e-01, -1.5693e+00],\n",
      "       [ 5.3086e+00, -1.8779e+00, -3.1367e+00],\n",
      "       [ 5.8984e+00, -2.0410e+00, -3.5469e+00],\n",
      "       [ 4.2031e+00, -1.7871e+00, -2.2148e+00],\n",
      "       [-1.3291e+00, -2.6289e+00,  4.0469e+00],\n",
      "       [ 5.9297e+00, -1.6826e+00, -3.9238e+00],\n",
      "       [ 5.1133e+00, -2.5234e+00, -2.3867e+00],\n",
      "       [ 5.2031e+00, -1.1914e+00, -3.7324e+00],\n",
      "       [ 1.7749e-01,  3.7036e-01, -4.9829e-01],\n",
      "       [ 4.9219e+00, -1.7012e+00, -2.9980e+00],\n",
      "       [ 1.9531e+00,  7.2559e-01, -2.7480e+00],\n",
      "       [ 3.9258e+00, -9.1113e-01, -3.0059e+00],\n",
      "       [ 4.8750e+00, -2.5430e+00, -2.0820e+00],\n",
      "       [-4.3262e-01,  3.3398e+00, -2.9219e+00],\n",
      "       [ 5.5977e+00, -2.3359e+00, -3.0059e+00],\n",
      "       [ 3.2891e+00,  1.0928e+00, -4.3672e+00],\n",
      "       [-1.5781e+00, -2.2129e+00,  3.8965e+00],\n",
      "       [ 1.8408e+00,  2.0664e+00, -3.9922e+00],\n",
      "       [ 5.8242e+00, -1.6045e+00, -3.9219e+00],\n",
      "       [ 1.3955e+00,  1.2607e+00, -2.8242e+00],\n",
      "       [ 4.7852e+00, -1.4082e+00, -3.1309e+00],\n",
      "       [ 5.4805e+00, -1.3857e+00, -3.8281e+00],\n",
      "       [ 2.8125e+00,  6.5308e-02, -2.8047e+00],\n",
      "       [-7.8711e-01,  2.7988e+00, -1.8389e+00],\n",
      "       [ 4.3594e+00, -1.8193e+00, -2.3398e+00],\n",
      "       [ 5.7227e+00, -2.0762e+00, -3.3594e+00],\n",
      "       [ 4.8164e+00, -1.3828e+00, -3.2969e+00],\n",
      "       [ 5.4141e+00, -2.1113e+00, -3.0410e+00],\n",
      "       [ 4.3672e+00, -5.9967e-02, -4.2031e+00],\n",
      "       [ 5.6445e+00, -1.9678e+00, -3.3945e+00],\n",
      "       [ 5.3828e+00, -4.8926e-01, -4.6953e+00],\n",
      "       [ 5.8047e+00, -1.4814e+00, -4.0078e+00],\n",
      "       [ 5.9336e+00, -2.2520e+00, -3.3203e+00],\n",
      "       [ 4.0742e+00,  3.0078e-01, -4.2109e+00],\n",
      "       [ 5.5664e+00, -1.6279e+00, -3.6191e+00],\n",
      "       [ 5.1172e+00, -1.3154e+00, -3.5293e+00],\n",
      "       [ 6.0781e+00, -1.8057e+00, -3.9277e+00],\n",
      "       [ 3.7910e+00, -1.1260e+00, -2.5723e+00],\n",
      "       [ 4.9844e+00, -3.3911e-01, -4.4727e+00],\n",
      "       [-5.2246e-01,  1.0000e+00, -4.3311e-01],\n",
      "       [ 6.0820e+00, -2.4297e+00, -3.2754e+00],\n",
      "       [ 6.0469e+00, -1.9561e+00, -3.7227e+00],\n",
      "       [-1.4951e+00, -3.2715e-02,  1.9258e+00],\n",
      "       [ 5.5898e+00, -2.0371e+00, -3.2812e+00],\n",
      "       [ 4.1250e+00, -2.1191e+00, -1.8438e+00],\n",
      "       [ 4.7734e+00, -3.4717e-01, -4.3477e+00],\n",
      "       [-1.9316e+00,  2.8652e+00, -5.6592e-01],\n",
      "       [ 2.0312e+00, -2.3320e+00,  3.0615e-01],\n",
      "       [ 5.6133e+00, -1.5625e+00, -3.7422e+00],\n",
      "       [-2.0781e+00, -1.4150e+00,  3.7090e+00],\n",
      "       [ 1.9053e+00, -8.4521e-01, -1.0156e+00],\n",
      "       [-2.6055e+00,  2.0039e+00,  1.3350e+00],\n",
      "       [ 4.3125e+00, -2.2969e+00, -1.9062e+00],\n",
      "       [-3.3047e+00,  2.6367e+00,  1.3262e+00],\n",
      "       [-2.4355e+00,  3.7949e+00, -1.2461e+00],\n",
      "       [-1.9766e+00,  4.3320e+00, -2.2520e+00],\n",
      "       [ 5.8438e+00, -1.4600e+00, -4.0898e+00],\n",
      "       [ 3.3047e+00,  2.4048e-01, -3.4805e+00],\n",
      "       [ 2.3516e+00, -3.2461e+00,  7.8760e-01],\n",
      "       [ 6.0508e+00, -1.9873e+00, -3.7402e+00],\n",
      "       [-1.8857e+00, -2.5859e+00,  4.5273e+00],\n",
      "       [-3.0200e-01,  2.4473e+00, -2.1230e+00],\n",
      "       [ 2.6504e+00, -1.1709e+00, -1.4990e+00],\n",
      "       [ 5.4883e+00, -1.9043e+00, -3.3555e+00],\n",
      "       [ 6.0312e+00, -1.8184e+00, -3.8398e+00],\n",
      "       [-2.1035e+00, -1.5254e+00,  3.8379e+00],\n",
      "       [ 5.1328e+00, -2.0098e+00, -2.9238e+00],\n",
      "       [ 5.3594e+00, -2.3789e+00, -2.7383e+00],\n",
      "       [ 6.1367e+00, -1.8809e+00, -3.8633e+00],\n",
      "       [ 5.6016e+00, -1.2969e+00, -4.0781e+00],\n",
      "       [ 5.4609e+00, -1.1191e+00, -4.1211e+00],\n",
      "       [ 5.5586e+00, -1.9746e+00, -3.3008e+00],\n",
      "       [ 5.5586e+00, -1.7598e+00, -3.5215e+00],\n",
      "       [-1.3809e+00,  7.1289e-01,  1.1836e+00],\n",
      "       [ 4.9570e+00, -1.0117e+00, -3.7520e+00],\n",
      "       [ 2.1167e-01, -1.8525e+00,  1.7090e+00],\n",
      "       [-3.2773e+00, -2.1680e-01,  3.7969e+00],\n",
      "       [-1.8984e+00, -2.4648e+00,  4.4609e+00],\n",
      "       [ 6.0195e+00, -1.8730e+00, -3.7637e+00],\n",
      "       [-1.6523e+00, -1.2671e-01,  2.0215e+00],\n",
      "       [ 2.3965e+00, -1.8447e+00, -5.2588e-01],\n",
      "       [ 4.0664e+00, -1.3486e+00, -2.6230e+00],\n",
      "       [ 5.2188e+00, -2.4238e+00, -2.4922e+00],\n",
      "       [ 1.2168e+00, -2.1562e+00,  9.7705e-01],\n",
      "       [ 3.4414e+00, -2.5820e+00, -8.1982e-01],\n",
      "       [ 4.7578e+00, -2.1641e+00, -2.4355e+00],\n",
      "       [-3.0703e+00, -7.3242e-01,  4.0469e+00],\n",
      "       [ 5.4141e+00, -2.5859e+00, -2.5547e+00],\n",
      "       [-2.5586e+00,  3.6758e+00, -6.6504e-01],\n",
      "       [ 5.5352e+00, -1.1211e+00, -4.1641e+00],\n",
      "       [ 6.0664e+00, -1.7676e+00, -3.9746e+00],\n",
      "       [-5.1465e-01,  5.0342e-01,  2.3645e-01],\n",
      "       [ 4.9141e+00, -1.4092e+00, -3.3164e+00],\n",
      "       [ 2.6904e-01, -2.9375e+00,  2.6172e+00],\n",
      "       [ 5.2305e+00, -2.5195e+00, -2.4570e+00],\n",
      "       [ 2.5293e+00, -3.5684e+00,  9.5166e-01],\n",
      "       [-2.4375e+00, -1.1108e-01,  2.9160e+00],\n",
      "       [-2.4258e+00, -1.0762e+00,  3.5957e+00],\n",
      "       [-1.7129e+00,  1.0156e+00,  1.2490e+00],\n",
      "       [ 4.8125e+00, -1.1191e+00, -3.4004e+00],\n",
      "       [ 3.2188e+00, -1.7908e-01, -2.9258e+00],\n",
      "       [ 6.0312e+00, -1.7764e+00, -3.8906e+00],\n",
      "       [ 5.5664e+00, -1.7852e+00, -3.5039e+00],\n",
      "       [ 5.4219e+00, -1.3877e+00, -3.8027e+00],\n",
      "       [ 3.5586e+00, -1.5742e+00, -1.8838e+00],\n",
      "       [ 6.1211e+00, -1.9727e+00, -3.8145e+00],\n",
      "       [ 2.0547e+00, -9.9805e-01, -9.3799e-01],\n",
      "       [ 4.7695e+00, -1.8428e+00, -2.7695e+00],\n",
      "       [ 5.7070e+00, -2.6133e+00, -2.7988e+00],\n",
      "       [ 1.9736e+00,  1.7959e+00, -3.7812e+00],\n",
      "       [-2.3828e+00, -1.6133e+00,  4.0859e+00],\n",
      "       [ 6.0352e+00, -1.7041e+00, -3.9824e+00],\n",
      "       [ 4.5195e+00, -2.4238e+00, -1.9990e+00],\n",
      "       [ 5.8984e+00, -1.8574e+00, -3.7441e+00],\n",
      "       [ 4.8594e+00, -1.5234e+00, -3.1543e+00],\n",
      "       [-7.2217e-01,  3.3535e+00, -2.5176e+00],\n",
      "       [ 5.8125e+00, -2.3105e+00, -3.1914e+00],\n",
      "       [ 5.9609e+00, -1.3447e+00, -4.3281e+00],\n",
      "       [ 4.3594e+00, -1.3760e+00, -2.8086e+00],\n",
      "       [ 5.0859e+00, -8.4375e-01, -4.0391e+00],\n",
      "       [ 4.0938e+00, -1.6582e+00, -2.1914e+00],\n",
      "       [-1.4229e+00,  9.8340e-01,  8.3936e-01],\n",
      "       [ 6.0508e+00, -2.0684e+00, -3.6562e+00],\n",
      "       [-1.3857e+00,  2.8984e+00, -1.3555e+00],\n",
      "       [ 5.9688e+00, -1.5537e+00, -4.0469e+00],\n",
      "       [-1.0625e+00,  3.3672e+00, -2.3242e+00],\n",
      "       [ 1.3398e+00,  2.3496e+00, -3.5527e+00],\n",
      "       [-2.0469e+00,  9.2651e-02,  2.4766e+00],\n",
      "       [ 6.1133e+00, -2.0508e+00, -3.6680e+00],\n",
      "       [ 5.0273e+00, -1.3047e+00, -3.4727e+00],\n",
      "       [ 1.3096e+00, -1.5996e+00,  3.8013e-01],\n",
      "       [-2.2480e+00,  8.5876e-02,  2.5801e+00],\n",
      "       [-1.4092e+00,  3.4595e-01,  1.4199e+00],\n",
      "       [-1.7021e+00, -2.7031e+00,  4.3984e+00],\n",
      "       [ 6.0742e+00, -1.7139e+00, -4.0195e+00],\n",
      "       [ 3.3125e+00, -3.3125e+00, -1.2062e-02],\n",
      "       [ 6.1016e+00, -1.8633e+00, -3.8965e+00],\n",
      "       [ 6.0039e+00, -2.0957e+00, -3.6113e+00],\n",
      "       [ 4.5859e+00, -2.8359e+00, -1.5215e+00],\n",
      "       [ 5.9727e+00, -1.9453e+00, -3.6680e+00],\n",
      "       [ 3.0977e+00, -2.7402e+00, -2.6074e-01],\n",
      "       [ 5.9180e+00, -1.4971e+00, -4.1484e+00],\n",
      "       [ 5.7734e+00, -1.7109e+00, -3.7441e+00],\n",
      "       [-2.8887e+00, -1.2705e+00,  4.4336e+00],\n",
      "       [ 4.6211e+00, -1.0439e+00, -3.3965e+00],\n",
      "       [ 2.3145e+00,  2.5684e-01, -2.5195e+00],\n",
      "       [ 5.8594e+00, -1.4541e+00, -4.1289e+00],\n",
      "       [ 5.5508e+00, -1.6250e+00, -3.6523e+00],\n",
      "       [ 4.8984e+00, -2.4199e+00, -2.2051e+00],\n",
      "       [-1.8818e+00, -3.2207e+00,  4.9102e+00]], dtype=float16), label_ids=array([0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
      "       0, 1, 2, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 2, 1, 0, 0,\n",
      "       0, 1, 0, 0, 0, 2, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 2, 1, 0, 1, 2,\n",
      "       0, 0, 2, 2, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       2, 1, 0, 1, 2, 0, 0, 0, 0, 0, 0, 1, 2, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "       1, 0, 1, 0, 1, 0, 0, 0, 2, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2,\n",
      "       0, 1, 0, 1, 0, 0, 0, 1, 2, 1, 0, 0, 2, 2, 2, 2, 0, 0, 0, 0, 1, 1,\n",
      "       0, 0, 0, 1, 0, 2, 2, 2, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "       0, 2, 0, 0, 0, 0, 2, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0,\n",
      "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 2, 0, 0,\n",
      "       0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2]), metrics={'test_loss': 1.667681097984314, 'test_accuracy': 0.6709401709401709, 'test_balanced_accuracy': 0.5387849979842063, 'test_precision': 0.645677065352708, 'test_recall': 0.6709401709401709, 'test_f1': 0.6437158252800215, 'test_runtime': 2.1077, 'test_samples_per_second': 111.019, 'test_steps_per_second': 3.796})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1cd75bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "probabilities = torch.softmax(torch.tensor(test_results.predictions).to(torch.float32), dim=-1)\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)\n",
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "766c4460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_save = []\n",
    "for idx in range(len(test_data)):\n",
    "    item = dataset['test'][idx]\n",
    "    actual_label = item['label']\n",
    "    predicted_label = predictions[idx]\n",
    "    claim = item['claim'] \n",
    "    premise = item['premise'] \n",
    "    category = item['category']\n",
    "    \n",
    "    # Append the information as a dictionary to the list\n",
    "    data_to_save.append({\n",
    "        'Claim': claim,\n",
    "        'Premise': premise,\n",
    "        'Actual Label': actual_label,\n",
    "        'Predicted Label': predicted_label,\n",
    "        'Category' : category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_to_save)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/home/elson/results/2.2.1_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3e1cc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correctly classified instances\n",
    "correctly_classified = df[df['Actual Label'] == df['Predicted Label']]\n",
    "\n",
    "# Calculate misclassified instances\n",
    "misclassified = df[df['Actual Label'] != df['Predicted Label']]\n",
    "\n",
    "# Count the number of correctly classified and misclassified by category\n",
    "correct_classification_counts = correctly_classified['Category'].value_counts()\n",
    "misclassification_counts = misclassified['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "afd884e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           35\n",
       "Bone health              13\n",
       "Diabetes                 11\n",
       "Cancer                   11\n",
       "Cardiovascular Health    10\n",
       "Fitness                  10\n",
       "Neurological health       9\n",
       "Throat                    9\n",
       "Skin                      7\n",
       "Hair                      6\n",
       "COVID                     6\n",
       "Ear                       6\n",
       "Men's health              5\n",
       "Blood                     5\n",
       "Eye                       4\n",
       "Women' s Health           4\n",
       "Mental Health             2\n",
       "Dental Health             2\n",
       "Muscles                   2\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6477f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Skin                     17\n",
       "General Health           16\n",
       "Bone health               8\n",
       "Hair                      6\n",
       "Fitness                   5\n",
       "Eye                       5\n",
       "Muscles                   4\n",
       "Blood                     4\n",
       "Vascular                  3\n",
       "Cardiovascular Health     2\n",
       "Women' s Health           2\n",
       "Diabetes                  1\n",
       "Men's health              1\n",
       "Dental Health             1\n",
       "Mental Health             1\n",
       "Cancer                    1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
