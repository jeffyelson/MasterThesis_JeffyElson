{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score,balanced_accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82806f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr 11 20:36:46 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:61:00.0 Off |                    0 |\n",
      "| N/A   38C    P0    55W / 300W |   3333MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  Off  | 00000000:62:00.0 Off |                    0 |\n",
      "| N/A   40C    P0    68W / 300W |  14325MiB / 32768MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  Off  | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   37C    P0    58W / 300W |   3253MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  Off  | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   37C    P0    58W / 300W |   3269MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     11098      C   ...A-AVD/venv_ava/bin/python     1665MiB |\n",
      "|    0   N/A  N/A     17092      C   ...A-AVD/venv_ava/bin/python     1665MiB |\n",
      "|    1   N/A  N/A     11098      C   ...A-AVD/venv_ava/bin/python     1711MiB |\n",
      "|    1   N/A  N/A     11099      C   ...A-AVD/venv_ava/bin/python     2027MiB |\n",
      "|    1   N/A  N/A     11102      C   ...A-AVD/venv_ava/bin/python     1711MiB |\n",
      "|    1   N/A  N/A     11110      C   ...A-AVD/venv_ava/bin/python     1711MiB |\n",
      "|    1   N/A  N/A     17092      C   ...A-AVD/venv_ava/bin/python     1711MiB |\n",
      "|    1   N/A  N/A     17093      C   ...A-AVD/venv_ava/bin/python     2027MiB |\n",
      "|    1   N/A  N/A     17096      C   ...A-AVD/venv_ava/bin/python     1711MiB |\n",
      "|    1   N/A  N/A     17099      C   ...A-AVD/venv_ava/bin/python     1711MiB |\n",
      "|    2   N/A  N/A     11102      C   ...A-AVD/venv_ava/bin/python     1625MiB |\n",
      "|    2   N/A  N/A     17096      C   ...A-AVD/venv_ava/bin/python     1625MiB |\n",
      "|    3   N/A  N/A     11110      C   ...A-AVD/venv_ava/bin/python     1633MiB |\n",
      "|    3   N/A  N/A     17099      C   ...A-AVD/venv_ava/bin/python     1633MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-9ed78e0185729396\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-9ed78e0185729396/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 225.67it/s]\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-9ed78e0185729396/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-d8a73572c5526b09.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-9ed78e0185729396/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-71c34de47dd068c7.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-9ed78e0185729396/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-9e4fe1ebeeeb9fd4.arrow\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset from the CSV file\n",
    "dataset = load_dataset(\n",
    "    'csv',\n",
    "    data_files='dataset_semanticattribution_nerfeatures_split.csv',\n",
    "    delimiter=',',\n",
    "    column_names=[\n",
    "        \"claim\", \"premise\", \"label\", \"category\", \"count_bf\", \"count_ca\", \"count_dis\",\n",
    "        \"count_food\", \"count_lipid\", \"count_treat\", \"pres_bf\", \"pres_ca\", \"pres_dis\",\n",
    "        \"pres_food\", \"pres_lipid\", \"pres_treat\", \"counte_bf\", \"counte_ca\", \"counte_dis\",\n",
    "        \"counte_food\", \"counte_lipid\", \"counte_treat\", \"prese_bf\", \"prese_ca\", \"prese_dis\",\n",
    "        \"prese_food\", \"prese_lipid\", \"prese_treat\", \"url\", \"entities\", \"entity_map\",\n",
    "        \"gold_exp\", \"gemini_exp\", \"gemini_label\",\"entity_ev\",\"entity_map_ev\", \"split\"\n",
    "    ],\n",
    "    skiprows=1\n",
    ")\n",
    "\n",
    "# Assuming 'split' column contains strings 'train', 'validation', 'test'\n",
    "# Filter the loaded dataset into subsets\n",
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'gold_exp', 'gemini_exp', 'gemini_label', 'entity_ev', 'entity_map_ev', 'split'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f3e71be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41f1db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\"claim\", \"premise\", \"label\",\"category\"]\n",
    "all_columns = train_dataset.column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-9ed78e0185729396/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-f56a0271a09887b4.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-9ed78e0185729396/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-80cde756ccac5cc2.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-9ed78e0185729396/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-4a220ab4c7e19e55.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 0, 'entailment': 1, 'neutral': 2}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 0,\n",
    "    \"entailment\": 1,\n",
    "    \"neutral\": 2\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b5bb17f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "465"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['val']['claim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "        # Extracting claim and evidence texts\n",
    "        category = item['category']\n",
    "\n",
    "        claim = item['claim']+ \"[\" + category + \"]\"\n",
    "        premise = item['premise'].replace('\\n', '').replace('[','').replace(']','')\n",
    "        item['claim']=claim\n",
    "        item['premise']=premise\n",
    "        item['category']=category\n",
    "        \n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "             premise, claim,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "        item['input_ids'] = inputs['input_ids'].squeeze()  # Remove batch dimension\n",
    "        item['attention_mask']= inputs['attention_mask'].squeeze() # Remove batch dimension\n",
    "        \n",
    "        if 'label' in item:\n",
    "            item['labels'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62421eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=3, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f72c5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model is on device: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    bal_accuracy = balanced_accuracy_score(labels,preds)\n",
    "\n",
    "    return {\"accuracy\": acc, \"balanced_accuracy\":bal_accuracy, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17c5e0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'claim': 'Myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.[General Health]',\n",
       " 'premise': '; Unković, N.; Dimkić, I.; Janaćković, P.; Gavrilović, M.; Stanojević, O.; Vukojević, J. Frankincense and myrrh essential oils and burn incense fume against micro-inhabitants of sacral ambients.Shameem, I. Phytochemical & therapeutic potentials of Murr makki (.Oxidative stress and immunotoxic effects of lead and their amelioration with myrrh (Commiphora molmol) emulsion.Essential Oils: Magical Ingredients for Skin Care.Chakravarty, N.; Kellogg, C.; Alvarez, J.; Equils, O.; Morgan, M. UV Protection by Natural Products: C. myrrha Oil Versus Sunscreen.Hamidpour, R.; Hamidpour, S.; Hamidpour, M.; Shahlari, M. Frankincense (乳香 Rǔ Xiāng;.species): From the selection of traditional applications to the novel phytotherapy for the prevention and treatment of serious diseases.Chemistry and immunomodulatory activity of frankincense oil.Compositions containing Boswellia extracts.; Cooper, E. Frankincense and myrrh as remedies in children.',\n",
       " 'label': 1,\n",
       " 'category': 'General Health',\n",
       " 'input_ids': tensor([     1,   2600,   3405,  94326,    261,   1149,    260,    346,  29597,\n",
       "           1165,  32453,    261,    273,    260,    346,   2846,  91581,  94326,\n",
       "            261,    916,    260,    346, 117259,  47587,    261,    749,    260,\n",
       "            346,  10490,  73907,   2179,  32453,    261,   1130,    260,    346,\n",
       "           1407,   3359,  73907,   2179,  32453,    261,    851,    260, 100066,\n",
       "            263,  98237,   1830,   6725,    263,   5134,  30055,  77487,    532,\n",
       "           4014,    271,    547,  52263,  16224,    265,  86207,  14178,    268,\n",
       "            260,  97818,   4379,    261,    273,    260,  43923,  23399,    429,\n",
       "           8068,   1068,    268,    265,  88327,   1917, 110269,    287,    260,\n",
       "          57909,   4765,  12100,   2148,    263,  25348,  20413,   1563,    265,\n",
       "            917,    263,    308,    266,  84530,  62542,    275,  98237,    287,\n",
       "          41462,    667,  65073,  44845,  22317,    285,  36774,    260,  70298,\n",
       "          40149,    294,  32799,  22280,    270,   9560,   2926,    260,  29466,\n",
       "          32531,  11238,   5750,    261,   1149,    260,    346,  35339,    261,\n",
       "            716,    260,    346,  29700,    261,    851,    260,    346,  43713,\n",
       "          15150,    261,   1130,    260,    346,   5794,    261,    749,    260,\n",
       "           9048,   5341,    293,   4613,   4950,    294,    716,    260,  98237,\n",
       "            452,   4366,  52114,  72408,    260,  44233,   4765,  39151,    261,\n",
       "            909,    260,    346,  42595,  39151,    261,    662,    260,    346,\n",
       "          42595,  39151,    261,    749,    260,    346,  11209,  60641,    261,\n",
       "            749,    260, 100066,    287, 123771, 123100,    909, 122987,  13238,\n",
       "          37986,    948,    346,    260,  43427,    285,    294,   1007,    262,\n",
       "           1857,    265,   1471,   1567,    264,    262,   2626,  41529,  28479,\n",
       "            270,    262,   5937,    263,   1035,    265,   1721,   4253,    260,\n",
       "          95126,    263, 121470,   1506,    265,  88609,   1080,    260,  12768,\n",
       "          19573,    268,   4086,  60761,   2767,  15808,    260,    346,   7413,\n",
       "            261,    829,    260, 100066,    263,  98237,    283,  11882,    267,\n",
       "            572,    260,      2,    573,  52341,   1830,   1080,    269,   1359,\n",
       "            427,    267,  17847,    633,    264,    408,   1300,    262,   2658,\n",
       "            265,    262,   1158,    260,   2550,  12082,   1516,    592,      2,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'labels': tensor(1)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on device: cuda:0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2040' max='2040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2040/2040 16:54, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.838200</td>\n",
       "      <td>0.680624</td>\n",
       "      <td>0.711828</td>\n",
       "      <td>0.407088</td>\n",
       "      <td>0.643111</td>\n",
       "      <td>0.711828</td>\n",
       "      <td>0.664956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.380600</td>\n",
       "      <td>0.904103</td>\n",
       "      <td>0.705376</td>\n",
       "      <td>0.472295</td>\n",
       "      <td>0.684879</td>\n",
       "      <td>0.705376</td>\n",
       "      <td>0.693723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.173000</td>\n",
       "      <td>1.446730</td>\n",
       "      <td>0.696774</td>\n",
       "      <td>0.573972</td>\n",
       "      <td>0.718314</td>\n",
       "      <td>0.696774</td>\n",
       "      <td>0.703082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>1.916572</td>\n",
       "      <td>0.707527</td>\n",
       "      <td>0.487819</td>\n",
       "      <td>0.695166</td>\n",
       "      <td>0.707527</td>\n",
       "      <td>0.698565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.047600</td>\n",
       "      <td>2.390321</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.519557</td>\n",
       "      <td>0.707825</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.662165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.064100</td>\n",
       "      <td>2.377330</td>\n",
       "      <td>0.664516</td>\n",
       "      <td>0.552076</td>\n",
       "      <td>0.708976</td>\n",
       "      <td>0.664516</td>\n",
       "      <td>0.682715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>2.751919</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.481180</td>\n",
       "      <td>0.685437</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.664765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>2.652335</td>\n",
       "      <td>0.679570</td>\n",
       "      <td>0.458503</td>\n",
       "      <td>0.681793</td>\n",
       "      <td>0.679570</td>\n",
       "      <td>0.676863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>2.730944</td>\n",
       "      <td>0.683871</td>\n",
       "      <td>0.481828</td>\n",
       "      <td>0.687394</td>\n",
       "      <td>0.683871</td>\n",
       "      <td>0.683939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>2.902352</td>\n",
       "      <td>0.681720</td>\n",
       "      <td>0.478535</td>\n",
       "      <td>0.688571</td>\n",
       "      <td>0.681720</td>\n",
       "      <td>0.681456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.875590</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.481295</td>\n",
       "      <td>0.685377</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.678197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.760823</td>\n",
       "      <td>0.690323</td>\n",
       "      <td>0.481322</td>\n",
       "      <td>0.687746</td>\n",
       "      <td>0.690323</td>\n",
       "      <td>0.688269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.976181</td>\n",
       "      <td>0.673118</td>\n",
       "      <td>0.473014</td>\n",
       "      <td>0.684685</td>\n",
       "      <td>0.673118</td>\n",
       "      <td>0.678024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.049482</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.477674</td>\n",
       "      <td>0.687416</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.680153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.038085</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.474053</td>\n",
       "      <td>0.683808</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.678736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.063000</td>\n",
       "      <td>0.673118</td>\n",
       "      <td>0.473014</td>\n",
       "      <td>0.682485</td>\n",
       "      <td>0.673118</td>\n",
       "      <td>0.676898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.083454</td>\n",
       "      <td>0.673118</td>\n",
       "      <td>0.473014</td>\n",
       "      <td>0.682485</td>\n",
       "      <td>0.673118</td>\n",
       "      <td>0.676898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.091965</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.474053</td>\n",
       "      <td>0.683808</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.678736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.098523</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.474053</td>\n",
       "      <td>0.683808</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.678736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.102321</td>\n",
       "      <td>0.673118</td>\n",
       "      <td>0.473014</td>\n",
       "      <td>0.682485</td>\n",
       "      <td>0.673118</td>\n",
       "      <td>0.676898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to /home/elson/2.2.2_deberta/checkpoint-102\n",
      "Configuration saved in /home/elson/2.2.2_deberta/checkpoint-102/config.json\n",
      "Model weights saved in /home/elson/2.2.2_deberta/checkpoint-102/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.2.2_deberta/checkpoint-204\n",
      "Configuration saved in /home/elson/2.2.2_deberta/checkpoint-204/config.json\n",
      "Model weights saved in /home/elson/2.2.2_deberta/checkpoint-204/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.2.2_deberta/checkpoint-306\n",
      "Configuration saved in /home/elson/2.2.2_deberta/checkpoint-306/config.json\n",
      "Model weights saved in /home/elson/2.2.2_deberta/checkpoint-306/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.2_deberta/checkpoint-204] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.2.2_deberta/checkpoint-408\n",
      "Configuration saved in /home/elson/2.2.2_deberta/checkpoint-408/config.json\n",
      "Model weights saved in /home/elson/2.2.2_deberta/checkpoint-408/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.2_deberta/checkpoint-306] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.2.2_deberta/checkpoint-510\n",
      "Configuration saved in /home/elson/2.2.2_deberta/checkpoint-510/config.json\n",
      "Model weights saved in /home/elson/2.2.2_deberta/checkpoint-510/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.2_deberta/checkpoint-408] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.2.2_deberta/checkpoint-612\n",
      "Configuration saved in /home/elson/2.2.2_deberta/checkpoint-612/config.json\n",
      "Model weights saved in /home/elson/2.2.2_deberta/checkpoint-612/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.2_deberta/checkpoint-510] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.2.2_deberta/checkpoint-714\n",
      "Configuration saved in /home/elson/2.2.2_deberta/checkpoint-714/config.json\n",
      "Model weights saved in /home/elson/2.2.2_deberta/checkpoint-714/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.2_deberta/checkpoint-612] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.2.2_deberta/checkpoint-816\n",
      "Configuration saved in /home/elson/2.2.2_deberta/checkpoint-816/config.json\n",
      "Model weights saved in /home/elson/2.2.2_deberta/checkpoint-816/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.2_deberta/checkpoint-714] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.2.2_deberta/checkpoint-918\n",
      "Configuration saved in /home/elson/2.2.2_deberta/checkpoint-918/config.json\n",
      "Model weights saved in /home/elson/2.2.2_deberta/checkpoint-918/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.2_deberta/checkpoint-816] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.2.2_deberta/checkpoint-1020\n",
      "Configuration saved in /home/elson/2.2.2_deberta/checkpoint-1020/config.json\n",
      "Model weights saved in /home/elson/2.2.2_deberta/checkpoint-1020/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.2_deberta/checkpoint-918] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.2.2_deberta/checkpoint-1122\n",
      "Configuration saved in /home/elson/2.2.2_deberta/checkpoint-1122/config.json\n",
      "Model weights saved in /home/elson/2.2.2_deberta/checkpoint-1122/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.2_deberta/checkpoint-1020] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.2.2_deberta/checkpoint-1224\n",
      "Configuration saved in /home/elson/2.2.2_deberta/checkpoint-1224/config.json\n",
      "Model weights saved in /home/elson/2.2.2_deberta/checkpoint-1224/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.2_deberta/checkpoint-1122] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.2.2_deberta/checkpoint-1326\n",
      "Configuration saved in /home/elson/2.2.2_deberta/checkpoint-1326/config.json\n",
      "Model weights saved in /home/elson/2.2.2_deberta/checkpoint-1326/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.2_deberta/checkpoint-1224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.2.2_deberta/checkpoint-1428\n",
      "Configuration saved in /home/elson/2.2.2_deberta/checkpoint-1428/config.json\n",
      "Model weights saved in /home/elson/2.2.2_deberta/checkpoint-1428/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.2_deberta/checkpoint-1326] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.2.2_deberta/checkpoint-1530\n",
      "Configuration saved in /home/elson/2.2.2_deberta/checkpoint-1530/config.json\n",
      "Model weights saved in /home/elson/2.2.2_deberta/checkpoint-1530/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.2_deberta/checkpoint-1428] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.2.2_deberta/checkpoint-1632\n",
      "Configuration saved in /home/elson/2.2.2_deberta/checkpoint-1632/config.json\n",
      "Model weights saved in /home/elson/2.2.2_deberta/checkpoint-1632/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.2_deberta/checkpoint-1530] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.2.2_deberta/checkpoint-1734\n",
      "Configuration saved in /home/elson/2.2.2_deberta/checkpoint-1734/config.json\n",
      "Model weights saved in /home/elson/2.2.2_deberta/checkpoint-1734/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.2_deberta/checkpoint-1632] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.2.2_deberta/checkpoint-1836\n",
      "Configuration saved in /home/elson/2.2.2_deberta/checkpoint-1836/config.json\n",
      "Model weights saved in /home/elson/2.2.2_deberta/checkpoint-1836/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.2_deberta/checkpoint-1734] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.2.2_deberta/checkpoint-1938\n",
      "Configuration saved in /home/elson/2.2.2_deberta/checkpoint-1938/config.json\n",
      "Model weights saved in /home/elson/2.2.2_deberta/checkpoint-1938/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.2_deberta/checkpoint-1836] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.2.2_deberta/checkpoint-2040\n",
      "Configuration saved in /home/elson/2.2.2_deberta/checkpoint-2040/config.json\n",
      "Model weights saved in /home/elson/2.2.2_deberta/checkpoint-2040/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.2_deberta/checkpoint-1938] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/elson/2.2.2_deberta/checkpoint-102 (score: 0.7118279569892473).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Configuration saved in /home/elson/2.2.2_deberta/best_model/config.json\n",
      "Model weights saved in /home/elson/2.2.2_deberta/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/2.2.2_deberta/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/2.2.2_deberta/best_model/special_tokens_map.json\n",
      "added tokens file saved in /home/elson/2.2.2_deberta/best_model/added_tokens.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/2.2.2_deberta/best_model/tokenizer_config.json',\n",
       " '/home/elson/2.2.2_deberta/best_model/special_tokens_map.json',\n",
       " '/home/elson/2.2.2_deberta/best_model/spm.model',\n",
       " '/home/elson/2.2.2_deberta/best_model/added_tokens.json')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/2.2.2_deberta/',\n",
    "    num_train_epochs=20,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.06,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(\"cuda:0\"),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "print(f\"Model is on device: {next(model.parameters()).device}\")\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/2.2.2_deberta/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/2.2.2_deberta/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cdee1665",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/2.2.2_deberta/best_model/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"/home/elson/2.2.2_deberta/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"entailment\",\n",
      "    \"1\": \"neutral\",\n",
      "    \"2\": \"contradiction\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"contradiction\": 2,\n",
      "    \"entailment\": 0,\n",
      "    \"neutral\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file /home/elson/2.2.2_deberta/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at /home/elson/2.2.2_deberta/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 16\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/2.2.2_deberta/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[ 3.1372e-01,  8.9160e-01, -1.3945e+00],\n",
      "       [-1.5283e-01,  9.8926e-01, -9.7070e-01],\n",
      "       [-2.7246e-01,  1.8047e+00, -1.8047e+00],\n",
      "       [ 1.1401e-01,  1.1113e+00, -1.4268e+00],\n",
      "       [ 4.0552e-01,  7.4854e-01, -1.3867e+00],\n",
      "       [-5.8398e-01,  1.9814e+00, -1.6631e+00],\n",
      "       [-5.5811e-01,  1.6445e+00, -1.3652e+00],\n",
      "       [-4.1650e-01,  1.7920e+00, -1.6592e+00],\n",
      "       [-3.0591e-01,  1.8643e+00, -1.7891e+00],\n",
      "       [-7.5989e-02,  1.3223e+00, -1.4521e+00],\n",
      "       [-5.4297e-01,  2.0332e+00, -1.7246e+00],\n",
      "       [-3.7598e-01,  1.7412e+00, -1.6465e+00],\n",
      "       [-1.1066e-01,  1.2568e+00, -1.3711e+00],\n",
      "       [-4.8022e-01,  1.9297e+00, -1.7500e+00],\n",
      "       [-2.0654e-01,  1.1436e+00, -1.1328e+00],\n",
      "       [ 3.5327e-01,  7.5439e-01, -1.3232e+00],\n",
      "       [-3.0591e-01,  1.0039e+00, -8.9502e-01],\n",
      "       [-2.5806e-01,  1.4551e+00, -1.4287e+00],\n",
      "       [-4.1455e-01,  1.8203e+00, -1.6465e+00],\n",
      "       [-3.0005e-01,  1.7822e+00, -1.7959e+00],\n",
      "       [-6.5674e-02,  1.1279e+00, -1.2803e+00],\n",
      "       [ 1.9791e-02,  1.1660e+00, -1.4219e+00],\n",
      "       [-2.4011e-01,  1.4531e+00, -1.4404e+00],\n",
      "       [ 4.1431e-01,  5.7959e-01, -1.2246e+00],\n",
      "       [ 3.5547e-01,  6.7529e-01, -1.2402e+00],\n",
      "       [ 7.8076e-01, -1.0614e-01, -8.9062e-01],\n",
      "       [-4.4336e-01,  1.9307e+00, -1.7227e+00],\n",
      "       [ 6.3965e-02,  7.8174e-01, -1.0264e+00],\n",
      "       [-5.4541e-01,  1.8613e+00, -1.5889e+00],\n",
      "       [-4.0869e-01,  1.9814e+00, -1.8545e+00],\n",
      "       [ 4.9146e-01,  5.0098e-01, -1.1982e+00],\n",
      "       [-4.7729e-01,  2.0234e+00, -1.8301e+00],\n",
      "       [-4.6533e-01,  1.8672e+00, -1.6396e+00],\n",
      "       [ 7.3853e-02,  1.3340e+00, -1.6221e+00],\n",
      "       [ 1.5881e-01,  7.3193e-01, -1.1074e+00],\n",
      "       [-2.3328e-01,  1.0762e+00, -1.0361e+00],\n",
      "       [-3.3813e-02,  1.2754e+00, -1.5195e+00],\n",
      "       [-3.0078e-01,  1.5127e+00, -1.4492e+00],\n",
      "       [ 5.0586e-01,  5.5029e-01, -1.2578e+00],\n",
      "       [ 6.8045e-04,  7.7441e-01, -9.7900e-01],\n",
      "       [ 1.8860e-02,  1.1006e+00, -1.3311e+00],\n",
      "       [-4.1577e-01,  1.7021e+00, -1.5850e+00],\n",
      "       [-4.4281e-02,  1.2695e+00, -1.4521e+00],\n",
      "       [-3.4473e-01,  1.4600e+00, -1.3340e+00],\n",
      "       [ 2.0166e-01,  8.0518e-01, -1.2314e+00],\n",
      "       [-4.4336e-01,  1.7031e+00, -1.5146e+00],\n",
      "       [-5.5029e-01,  1.8857e+00, -1.5518e+00],\n",
      "       [ 1.5572e-02,  1.0811e+00, -1.3135e+00],\n",
      "       [-3.5938e-01,  1.8125e+00, -1.7031e+00],\n",
      "       [ 4.6240e-01,  6.4697e-01, -1.2822e+00],\n",
      "       [ 4.1089e-01,  7.1582e-01, -1.3613e+00],\n",
      "       [ 9.5581e-02,  1.1855e+00, -1.4941e+00],\n",
      "       [-1.9684e-03,  1.1924e+00, -1.3936e+00],\n",
      "       [-5.5713e-01,  1.9033e+00, -1.6201e+00],\n",
      "       [ 1.0590e-01,  1.0117e+00, -1.3330e+00],\n",
      "       [-4.1577e-01,  1.7891e+00, -1.6719e+00],\n",
      "       [ 3.6060e-01,  7.9736e-01, -1.3584e+00],\n",
      "       [-3.4741e-01,  1.5869e+00, -1.5225e+00],\n",
      "       [-3.6914e-01,  1.8213e+00, -1.7207e+00],\n",
      "       [-8.8867e-02,  1.3369e+00, -1.4902e+00],\n",
      "       [-2.9077e-01,  1.3652e+00, -1.3174e+00],\n",
      "       [ 3.5913e-01,  9.3945e-01, -1.4756e+00],\n",
      "       [-3.5645e-01,  1.1309e+00, -1.0127e+00],\n",
      "       [ 5.3271e-01,  5.1318e-01, -1.2627e+00],\n",
      "       [ 1.7029e-02,  8.0371e-01, -1.0273e+00],\n",
      "       [-1.1230e-01,  1.5381e+00, -1.6670e+00],\n",
      "       [-6.6748e-01,  2.0566e+00, -1.6729e+00],\n",
      "       [-4.5361e-01,  1.7793e+00, -1.5811e+00],\n",
      "       [-5.8545e-01,  2.0488e+00, -1.7158e+00],\n",
      "       [ 2.9327e-02,  1.0713e+00, -1.3418e+00],\n",
      "       [-3.5840e-01,  1.6885e+00, -1.5645e+00],\n",
      "       [-6.6260e-01,  1.6836e+00, -1.2578e+00],\n",
      "       [-2.4353e-01,  9.3213e-01, -8.9844e-01],\n",
      "       [-2.9980e-01,  1.3730e+00, -1.3066e+00],\n",
      "       [ 2.6025e-01,  7.8271e-01, -1.2607e+00],\n",
      "       [ 2.4390e-01,  8.1494e-01, -1.2646e+00],\n",
      "       [ 2.7222e-01,  9.1016e-01, -1.3799e+00],\n",
      "       [-2.5220e-01,  1.4824e+00, -1.4805e+00],\n",
      "       [-2.8467e-01,  1.8750e+00, -1.9053e+00],\n",
      "       [ 2.2998e-01,  7.7881e-01, -1.2412e+00],\n",
      "       [-4.5581e-01,  1.9424e+00, -1.7783e+00],\n",
      "       [-5.0244e-01,  1.9277e+00, -1.6758e+00],\n",
      "       [-4.1455e-01,  1.5654e+00, -1.4092e+00],\n",
      "       [-4.0112e-01,  1.8428e+00, -1.6748e+00],\n",
      "       [-4.1064e-01,  1.8047e+00, -1.6191e+00],\n",
      "       [ 2.2778e-01,  1.0498e+00, -1.4893e+00],\n",
      "       [ 4.9976e-01,  6.9043e-01, -1.3916e+00],\n",
      "       [-3.6890e-01,  1.5479e+00, -1.3633e+00],\n",
      "       [ 9.9365e-02,  8.2764e-01, -1.1523e+00],\n",
      "       [-2.9199e-01,  1.2119e+00, -1.1484e+00],\n",
      "       [-1.0364e-01,  1.5986e+00, -1.7676e+00],\n",
      "       [-5.5127e-01,  1.8730e+00, -1.6162e+00],\n",
      "       [-2.6489e-01,  1.4492e+00, -1.4023e+00],\n",
      "       [-1.3770e-01,  1.1719e+00, -1.2412e+00],\n",
      "       [-2.0630e-01,  1.2646e+00, -1.2578e+00],\n",
      "       [-1.7120e-02,  1.2432e+00, -1.4453e+00],\n",
      "       [ 1.0510e-01,  1.0342e+00, -1.3828e+00],\n",
      "       [-2.4500e-01,  1.3105e+00, -1.2432e+00],\n",
      "       [-2.4426e-01,  1.7002e+00, -1.7461e+00],\n",
      "       [-3.5938e-01,  1.6807e+00, -1.5859e+00],\n",
      "       [ 3.0762e-01,  7.0068e-01, -1.1924e+00],\n",
      "       [-3.1714e-01,  1.5840e+00, -1.5420e+00],\n",
      "       [-5.0732e-01,  1.8994e+00, -1.6250e+00],\n",
      "       [-2.1826e-01,  1.0527e+00, -1.0293e+00],\n",
      "       [ 3.6914e-01,  3.6230e-01, -8.7793e-01],\n",
      "       [-3.4839e-01,  1.8330e+00, -1.7080e+00],\n",
      "       [-3.9404e-01,  1.6777e+00, -1.4668e+00],\n",
      "       [ 6.4148e-02,  1.2842e+00, -1.6201e+00],\n",
      "       [-4.8340e-01,  1.8535e+00, -1.6611e+00],\n",
      "       [-6.1377e-01,  2.1309e+00, -1.7949e+00],\n",
      "       [-5.2832e-01,  1.7266e+00, -1.4443e+00],\n",
      "       [-3.9355e-01,  1.8418e+00, -1.7393e+00],\n",
      "       [-2.7710e-01,  1.4258e+00, -1.4131e+00],\n",
      "       [ 4.4409e-01,  7.1777e-01, -1.3418e+00],\n",
      "       [-5.7910e-01,  1.8994e+00, -1.5811e+00],\n",
      "       [-3.5107e-01,  1.5439e+00, -1.4072e+00],\n",
      "       [-4.3042e-01,  1.9102e+00, -1.7451e+00],\n",
      "       [ 5.8105e-01,  1.4551e-01, -9.5361e-01],\n",
      "       [-6.2793e-01,  2.1328e+00, -1.7578e+00],\n",
      "       [-1.6370e-01,  1.5635e+00, -1.6221e+00],\n",
      "       [-3.5571e-01,  1.4512e+00, -1.3701e+00],\n",
      "       [-4.5654e-01,  2.0020e+00, -1.8145e+00],\n",
      "       [-5.4785e-01,  1.7295e+00, -1.5039e+00],\n",
      "       [-1.2244e-01,  1.0322e+00, -1.1572e+00],\n",
      "       [-5.2051e-01,  2.0098e+00, -1.7656e+00],\n",
      "       [-3.6304e-01,  1.6689e+00, -1.5879e+00],\n",
      "       [-9.0088e-02,  1.0098e+00, -1.1465e+00],\n",
      "       [-2.4121e-01,  1.3613e+00, -1.3662e+00],\n",
      "       [-3.0493e-01,  1.6182e+00, -1.5713e+00],\n",
      "       [-9.5276e-02,  1.1514e+00, -1.2803e+00],\n",
      "       [-1.3196e-01,  1.2051e+00, -1.2900e+00],\n",
      "       [ 1.9519e-01,  6.6260e-01, -1.0928e+00],\n",
      "       [-2.9248e-01,  1.4971e+00, -1.3896e+00],\n",
      "       [-3.6353e-01,  1.5322e+00, -1.3945e+00],\n",
      "       [-2.0862e-01,  1.2666e+00, -1.3271e+00],\n",
      "       [ 2.4988e-01,  6.8311e-01, -1.1396e+00],\n",
      "       [ 2.3389e-01,  7.7344e-01, -1.2197e+00],\n",
      "       [-1.5332e-01,  1.3477e+00, -1.4355e+00],\n",
      "       [ 2.2986e-01,  8.4473e-01, -1.2881e+00],\n",
      "       [-6.1328e-01,  2.1152e+00, -1.7441e+00],\n",
      "       [-4.2725e-01,  1.7354e+00, -1.5840e+00],\n",
      "       [-1.8018e-01,  1.3301e+00, -1.3623e+00],\n",
      "       [ 1.5173e-01,  1.1592e+00, -1.5400e+00],\n",
      "       [-3.5645e-01,  1.8125e+00, -1.7266e+00],\n",
      "       [ 1.8176e-01,  7.5635e-01, -1.0830e+00],\n",
      "       [-8.1848e-02,  6.2012e-01, -6.6455e-01],\n",
      "       [ 1.1743e-01,  1.2402e+00, -1.5537e+00],\n",
      "       [ 9.5154e-02,  6.6357e-01, -9.7412e-01],\n",
      "       [-1.9189e-01,  1.4336e+00, -1.4824e+00],\n",
      "       [-2.4841e-01,  1.4062e+00, -1.3906e+00],\n",
      "       [-1.0828e-01,  1.0703e+00, -1.2178e+00],\n",
      "       [-1.5125e-01,  1.6270e+00, -1.7314e+00],\n",
      "       [-5.8057e-01,  1.9580e+00, -1.6670e+00],\n",
      "       [-2.0203e-01,  1.1670e+00, -1.1660e+00],\n",
      "       [-5.9229e-01,  1.9492e+00, -1.5723e+00],\n",
      "       [-4.5093e-01,  1.8340e+00, -1.6807e+00],\n",
      "       [-5.9961e-01,  1.8398e+00, -1.4795e+00],\n",
      "       [-7.5722e-03,  1.1836e+00, -1.3994e+00],\n",
      "       [ 4.6216e-01,  5.1562e-01, -1.2158e+00],\n",
      "       [ 1.8103e-01,  1.0488e+00, -1.3887e+00],\n",
      "       [ 9.5703e-01, -4.5312e-01, -7.2705e-01],\n",
      "       [ 8.8318e-02,  1.1318e+00, -1.4336e+00],\n",
      "       [-5.0098e-01,  1.8447e+00, -1.6084e+00],\n",
      "       [ 2.4731e-01,  9.9365e-01, -1.4932e+00],\n",
      "       [ 2.1472e-01,  8.1885e-01, -1.2305e+00],\n",
      "       [ 3.8330e-01,  5.4834e-01, -1.1270e+00],\n",
      "       [-1.3574e-01,  1.5576e+00, -1.6660e+00],\n",
      "       [ 6.2622e-02,  1.1084e+00, -1.4141e+00],\n",
      "       [-2.8753e-04,  8.3691e-01, -1.0566e+00],\n",
      "       [-2.1179e-01,  1.5703e+00, -1.6201e+00],\n",
      "       [ 8.7451e-01, -2.4622e-01, -8.2715e-01],\n",
      "       [-1.3867e-01,  1.4775e+00, -1.5850e+00],\n",
      "       [ 5.3467e-01,  5.6494e-01, -1.3135e+00],\n",
      "       [-2.9712e-01,  1.5107e+00, -1.4844e+00],\n",
      "       [-6.4600e-01,  1.8857e+00, -1.4902e+00],\n",
      "       [ 3.6963e-01,  5.1953e-01, -1.0859e+00],\n",
      "       [-5.6348e-01,  2.1191e+00, -1.8379e+00],\n",
      "       [ 2.3682e-01,  8.3447e-01, -1.2871e+00],\n",
      "       [-1.1902e-01,  1.2471e+00, -1.3193e+00],\n",
      "       [ 3.0930e-02,  1.1445e+00, -1.3701e+00],\n",
      "       [ 2.7222e-01,  8.0762e-01, -1.3018e+00],\n",
      "       [ 1.5326e-03,  1.2744e+00, -1.5010e+00],\n",
      "       [ 4.2212e-01,  7.1387e-01, -1.3750e+00],\n",
      "       [ 2.0105e-01,  1.0713e+00, -1.4590e+00],\n",
      "       [ 2.3169e-01,  6.1523e-01, -1.0771e+00],\n",
      "       [-4.9390e-01,  1.9092e+00, -1.6514e+00],\n",
      "       [-2.2852e-01,  1.2627e+00, -1.2891e+00],\n",
      "       [-2.8394e-01,  1.4414e+00, -1.3682e+00],\n",
      "       [ 4.9976e-01,  4.6655e-01, -1.1689e+00],\n",
      "       [-5.5322e-01,  1.9150e+00, -1.6084e+00],\n",
      "       [ 5.6763e-02,  8.4766e-01, -1.1348e+00],\n",
      "       [-2.3706e-01,  1.6738e+00, -1.6904e+00],\n",
      "       [-1.7236e-01,  1.3955e+00, -1.4590e+00],\n",
      "       [-2.1362e-01,  1.1953e+00, -1.1631e+00],\n",
      "       [ 5.1416e-01,  6.8311e-01, -1.4268e+00],\n",
      "       [-3.8599e-01,  1.9141e+00, -1.7998e+00],\n",
      "       [ 1.6541e-01,  1.0498e+00, -1.4648e+00],\n",
      "       [-5.9082e-01,  2.0898e+00, -1.7275e+00],\n",
      "       [-7.1777e-01,  2.0938e+00, -1.6484e+00],\n",
      "       [-3.5010e-01,  1.1553e+00, -9.7314e-01],\n",
      "       [-2.0813e-01,  1.3223e+00, -1.3291e+00],\n",
      "       [-5.9473e-01,  1.9775e+00, -1.6602e+00],\n",
      "       [ 1.1682e-01,  1.1768e+00, -1.5244e+00],\n",
      "       [-3.3984e-01,  1.4561e+00, -1.3486e+00],\n",
      "       [ 5.8289e-02,  9.5947e-01, -1.2471e+00],\n",
      "       [ 3.8452e-01,  6.4062e-01, -1.2461e+00],\n",
      "       [-3.6011e-01,  1.6221e+00, -1.5146e+00],\n",
      "       [-1.6980e-01,  9.0967e-01, -9.0576e-01],\n",
      "       [-6.6992e-01,  2.2383e+00, -1.8613e+00],\n",
      "       [-3.9600e-01,  1.5059e+00, -1.3203e+00],\n",
      "       [-4.4629e-01,  1.8613e+00, -1.6465e+00],\n",
      "       [ 5.0110e-02,  6.4746e-01, -8.9355e-01],\n",
      "       [-4.9805e-01,  1.9434e+00, -1.6973e+00],\n",
      "       [-3.3447e-01,  1.8848e+00, -1.7148e+00],\n",
      "       [-3.7036e-01,  1.7568e+00, -1.6172e+00],\n",
      "       [-8.1116e-02,  1.1191e+00, -1.2207e+00],\n",
      "       [ 1.2230e-02,  9.6924e-01, -1.1680e+00],\n",
      "       [-8.8928e-02,  1.3955e+00, -1.5391e+00],\n",
      "       [-5.2441e-01,  2.0391e+00, -1.7812e+00],\n",
      "       [-2.6001e-01,  1.5430e+00, -1.5127e+00],\n",
      "       [-4.1968e-01,  1.8633e+00, -1.7051e+00],\n",
      "       [-4.4653e-01,  1.8232e+00, -1.6250e+00],\n",
      "       [ 1.1853e-01,  8.1445e-01, -1.1387e+00],\n",
      "       [-4.9756e-01,  2.0195e+00, -1.8252e+00],\n",
      "       [-2.1301e-01,  1.4414e+00, -1.4463e+00],\n",
      "       [-6.0059e-01,  1.9971e+00, -1.6689e+00],\n",
      "       [-3.2739e-01,  1.6885e+00, -1.6387e+00],\n",
      "       [ 4.0234e-01,  4.9463e-01, -1.1064e+00],\n",
      "       [ 2.1851e-01,  8.6719e-01, -1.3311e+00],\n",
      "       [ 6.7236e-01, -1.6785e-01, -7.3730e-01],\n",
      "       [-4.0747e-01,  1.8555e+00, -1.7207e+00],\n",
      "       [ 1.0944e-01,  9.9805e-01, -1.3330e+00],\n",
      "       [-1.6895e-01,  1.3242e+00, -1.4121e+00],\n",
      "       [ 1.1926e-01,  9.2236e-01, -1.2139e+00]], dtype=float16), label_ids=array([1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 0,\n",
      "       1, 2, 0, 0, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 0, 2, 1, 1,\n",
      "       1, 0, 1, 1, 0, 0, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 0, 2, 1, 2, 0,\n",
      "       1, 1, 0, 0, 1, 1, 2, 2, 1, 0, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1,\n",
      "       0, 2, 1, 1, 0, 1, 1, 1, 0, 1, 1, 2, 0, 2, 1, 2, 1, 1, 1, 2, 1, 1,\n",
      "       2, 1, 2, 1, 2, 1, 1, 1, 0, 0, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 2, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2,\n",
      "       1, 1, 1, 2, 1, 0, 0, 0, 1, 1, 1, 2, 1, 1, 0, 1, 0, 1, 2, 1, 1, 1,\n",
      "       1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 1, 2, 1, 1, 1, 1, 2, 2, 0, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 0, 1, 1, 0]), metrics={'test_loss': 0.9538682699203491, 'test_accuracy': 0.6324786324786325, 'test_balanced_accuracy': 0.3460317460317461, 'test_precision': 0.47858520535511684, 'test_recall': 0.6324786324786325, 'test_f1': 0.5159465357337699, 'test_runtime': 2.3593, 'test_samples_per_second': 99.183, 'test_steps_per_second': 6.358})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be81d0c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjQAAAG5CAYAAACZTa6YAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAApCUlEQVR4nO3deZhcdZXw8e9JAkKQXdIgCYuTiGziwuCCIIsLKCMwoKCMRibSguLuyzL6wojiOqPiimEzuCCijKAwIC8Dg7KZsAhhGckghkBIICyyJ9057x91g0VIujtFVVfde78fnvuk7lL3ngr9VJ+c8/vdG5mJJElSmY3pdgCSJEnPlwmNJEkqPRMaSZJUeiY0kiSp9ExoJElS6ZnQSJKk0jOhkUoiItaMiF9HxCMRcc7zOM8hEfHbdsbWDRHxnxExtdtxSOoNJjRSm0XEeyJiVkQ8FhHzi1+8b2jDqQ8E+oANM/OdrZ4kM3+SmW9pQzzPEhG7RURGxH8st32HYvvlIzzPv0bEj4c7LjP3zswZLYYrqWJMaKQ2iohPAt8Evkgj+dgM+B6wbxtOvznwp8wcaMO5OuV+4HURsWHTtqnAn9p1gWjwu0vSs/ilILVJRKwLnAB8ODPPzczHM3NJZv46M/9PccwLIuKbEXFvsXwzIl5Q7NstIuZFxKciYmFR3Tm02Pc54DjgoKLyM235SkZEbFFUQsYV6++PiDsj4tGI+HNEHNK0/fdN73t9RMwsWlkzI+L1Tfsuj4jPR8SVxXl+GxEvGuKvYTHwK+Dg4v1jgYOAnyz3d3VSRNwdEX+NiOsiYpdi+17AvzR9zj82xXFiRFwJPAG8pNj2gWL/9yPil03n/0pEXBoRMdL/f5LKzYRGap/XAWsA/zHEMZ8BXgu8AtgB2An4bNP+jYF1gU2BacB3I2L9zDyeRtXn7Mx8YWaeNlQgEbEW8C1g78xcG3g9cOMKjtsAuKA4dkPg68AFy1VY3gMcCkwAVgc+PdS1gTOB9xWv3wrMBu5d7piZNP4ONgB+CpwTEWtk5kXLfc4dmt7zXqAfWBv4y3Ln+xSwfZGs7ULj725q+mwXqTZMaKT22RB4YJiW0CHACZm5MDPvBz5H4xf1MkuK/Usy80LgMWCrFuNZCmwXEWtm5vzMvGUFx7wduCMzf5SZA5l5FnA78A9Nx5yRmX/KzCeBn9NIRFYqM68CNoiIrWgkNmeu4JgfZ+ai4pr/DryA4T/nDzPzluI9S5Y73xM0/h6/DvwY+EhmzhvmfJIqxIRGap9FwIuWtXxW4sU8u7rwl2LbM+dYLiF6AnjhqgaSmY/TaPUcDsyPiAsi4mUjiGdZTJs2rd/XQjw/Ao4EdmcFFauI+HRE3Fa0uR6mUZUaqpUFcPdQOzPzWuBOIGgkXpJqxIRGap+rgaeB/YY45l4ag3uX2YzntmNG6nFgfNP6xs07M/PizHwzsAmNqsspI4hnWUz3tBjTMj8CPgRcWFRPnlG0hI4C3gWsn5nrAY/QSEQAVtYmGrJ9FBEfplHpubc4v6QaMaGR2iQzH6ExcPe7EbFfRIyPiNUiYu+I+Gpx2FnAZyNio2Jw7XE0WiStuBHYNSI2KwYkH7tsR0T0RcS+xViap2m0rpau4BwXAi8tppqPi4iDgG2A37QYEwCZ+WfgjTTGDC1vbWCAxoyocRFxHLBO0/4FwBarMpMpIl4KfAH4Jxqtp6Mi4hWtRS+pjExopDYqxoN8ksZA3/tptEmOpDHzBxq/dGcBNwE3A9cX21q51iXA2cW5ruPZSciYIo57gQdpJBdHrOAci4B9aAyqXUSjsrFPZj7QSkzLnfv3mbmi6tPFwEU0pnL/BXiKZ7eTlt00cFFEXD/cdYoW34+Br2TmHzPzDhozpX60bAaZpOoLJwFIkqSys0IjSZJKz4RGkiSVngmNJEkqPRMaSZJUekPdAKyrHnva0cpqr+v/8lC3Q1CF7PSSDbodgipojXGM6vPH1nzlkW37XfvkDd/p6rPTrNBIkqTS69kKjSRJ6rCR37+y51Xnk0iSpNqyQiNJUl1FV4e9tJUJjSRJdWXLSZIkqXdYoZEkqa5sOUmSpNKz5SRJktQ7TGgkSaqriPYtw14qTo+IhRExewX7PhURGREvKtYjIr4VEXMi4qaIeNVw5zehkSSprmJM+5bh/RDY6zkhREwC3gLMbdq8NzClWPqB7w93chMaSZLUcZl5BfDgCnZ9AzgKaH6u1L7AmdlwDbBeRGwy1PlNaCRJqqs2tpwioj8iZjUt/cNfPvYF7snMPy63a1Pg7qb1ecW2lXKWkyRJddXGWU6ZOR2YPuJLR4wH/oVGu+l5M6GRJEnd8HfAlsAfozGoeCJwfUTsBNwDTGo6dmKxbaVMaCRJqqsu3lgvM28GJvwtlLgL2DEzH4iI84EjI+JnwGuARzJz/lDncwyNJEl1NYqznCLiLOBqYKuImBcR04Y4/ELgTmAOcArwoeHOb4VGkiR1XGa+e5j9WzS9TuDDq3J+ExpJkurKZzlJkqTS81lOkiRJvcMKjSRJdVWhCo0JjSRJdTWmOmNoqpOaSZKk2rJCI0lSXdlykiRJpVehadvVSc0kSVJtWaGRJKmubDlJkqTSs+UkSZLUO6zQSJJUV7acJElS6VWo5WRCI0lSXVWoQlOdTyJJkmrLCo0kSXVly0mSJJWeLSdJkqTeYYVGkqS6suUkSZJKz5aTJElS77BCI0lSXVWoQmNCI0lSXVVoDE11UjNJklRbVmgkSaorW06SJKn0bDlJkiT1Dis0kiTVlS0nSZJUeracJEmSeocVGkmSaioqVKExoZEkqaaqlNDYcpIkSaVnhUaSpLqqToHGhEaSpLqy5SRJktRDrNBIklRTVarQmNBIklRTVUpobDlJkqTSs0IjSVJNValCY0JTUk8//TSHHfpPLF68mMHBQfZ801s4/MMf7XZYKpkli5/mq8ccwcCSJQwODvLqnXdn30MO47Y/zuIXp3+bgYEBNp+8FVM/+i+MHevXhVbdlb+7gq98+USWDi5l/wPeybTD+rsdkppVJ58xoSmr1VdfnZNP/SHjx6/FkiVLmDb1EHZ+w65sv8Mruh2aSmTcaqvzqRO/wxprjmdgYICvHv1Btn3Vazjjm5/nk1/4Nhtvuhnn/Xg6V116Ibu85R3dDlclMzg4yBdPPIEfnHIGfX19vOegA9lt9z34u8mTux2aKsgxNCUVEYwfvxYAAwMDDAwMVOqpqRodEcEaa44HYHBggMGBAcaMGcu4caux8aabAbD1K3fi+qsu72KUKqvZN9/EpEmbM3HSJFZbfXX2etvbufyyS7sdlppERNuWbutYhSYiXgbsC2xabLoHOD8zb+vUNetmcHCQfzr4AO6eO5d3Hfwetn/5Dt0OSSW0dHCQz3/iUO6fP4/d3n4AW750GwYHB7nrjtvYYsrWXH/lZTz0wIJuh6kSWrhgARtvsvEz6xP6+rj5ppu6GJGWN5qJSEScDuwDLMzM7YptXwP+AVgM/C9waGY+XOw7FpgGDAIfzcyLhzp/Ryo0EXE08DMa3bk/FEsAZ0XEMUO8rz8iZkXErNNPnd6J0Cpl7NixnHXOr/jPSy5n9uybmHPHn7odkkpozNixHP+tM/nqGedx159u5d65d9J/1AmcfepJnPjJf+YFa44nxoztdpiSyu+HwF7LbbsE2C4zXw78CTgWICK2AQ4Gti3e872IGPKLqFMVmmnAtpm5pHljRHwduAX48orelJnTgekAjz2d2aHYKmftddZhx79/DVdd+TsmT3lpt8NRSY1/4dpstf2rmH3dNbz1Hw/h6K+cDMAt11/Lgnvmdjk6ldGEvj7um3/fM+sLFyygr6+vixFpeaNZocnMKyJii+W2/bZp9RrgwOL1vsDPMvNp4M8RMQfYCbh6Zefv1BiapcCLV7B9k2KfnqeHHnyQR//6VwCeeuoprr36KrbY8iVdjkpl8+gjD/HEY48CsPjpp7j1xplsPHFz/vrwgwAsWbKYi375I9649/7dDFMlte122zN37l3Mm3c3SxYv5qILL+CNu+/R7bDUpJ1jaJq7LMWyqlPa/hn4z+L1psDdTfvm8bchLCvUqQrNx4FLI+KOpoA2AyYDR3bomrXywAP3c/xnj2FwcJBcmrzprXux6xt373ZYKplHHlzE6d88gaVLl5JLkx3fsAc77PQGzjn929w080oyk9323p+td9ix26GqhMaNG8exnzmOI/o/wNKlg+y3/wFMnjyl22GpQ5q7LKsqIj4DDAA/afX6kR3q7ETEGBrloeZBwTMzc3Ak77flpHa7/i8PdTsEVchOL9mg2yGogtYYN7p3htlw6llt+127aMa7h429aDn9Ztmg4GLb+4EPAntm5hPFtmMBMvNLxfrFwL9m5kpbTh2b5ZSZS2n0wyRJUg/q9nTriNgLOAp447JkpnA+8NNi7O2LgSk0JhitlDfWkyRJHRcRZwG7AS+KiHnA8TRmNb0AuKRIrq7JzMMz85aI+DlwK41W1IeH6/CY0EiSVFOjPMvp3SvYfNoQx58InDjS85vQSJJUU91uObWTjz6QJEmlZ4VGkqS6qk6BxoRGkqS6suUkSZLUQ6zQSJJUU1Wq0JjQSJJUU1VKaGw5SZKk0rNCI0lSTVWpQmNCI0lSXVUnn7HlJEmSys8KjSRJNWXLSZIklV6VEhpbTpIkqfSs0EiSVFNVqtCY0EiSVFfVyWdMaCRJqqsqVWgcQyNJkkrPCo0kSTVVpQqNCY0kSTVVpYTGlpMkSSo9KzSSJNVUlSo0JjSSJNVVdfIZW06SJKn8rNBIklRTtpwkSVLpVSmhseUkSZJKzwqNJEk1VaECjQmNJEl1ZctJkiSph1ihkSSppipUoDGhkSSprmw5SZIk9RArNJIk1VSFCjQmNJIk1dWYMdXJaGw5SZKk0rNCI0lSTdlykiRJpecsJ0mSpB5ihUaSpJqqUIHGhEaSpLqy5SRJktRDrNBIklRTVmgkSVLpRbRvGf5acXpELIyI2U3bNoiISyLijuLP9YvtERHfiog5EXFTRLxquPOb0EiSpNHwQ2Cv5bYdA1yamVOAS4t1gL2BKcXSD3x/uJOb0EiSVFMR0bZlOJl5BfDgcpv3BWYUr2cA+zVtPzMbrgHWi4hNhjq/CY0kSTXVzpZTRPRHxKympX8EIfRl5vzi9X1AX/F6U+DupuPmFdtWykHBkiTpecvM6cD05/H+jIhs9f0mNJIk1VQPzHJaEBGbZOb8oqW0sNh+DzCp6biJxbaVsuUkSVJNjeYsp5U4H5havJ4KnNe0/X3FbKfXAo80taZWyAqNJEnquIg4C9gNeFFEzAOOB74M/DwipgF/Ad5VHH4h8DZgDvAEcOhw5zehkSSppkaz5ZSZ717Jrj1XcGwCH16V85vQSJJUU90fQtM+jqGRJEmlZ4VGkqSa6oFZTm3TswnN0mx5Krq0Qm896Lhuh6AKeWjmd7odgvS8VSifseUkSZLKr2crNJIkqbNsOUmSpNKrUD5jy0mSJJWfFRpJkmrKlpMkSSq9CuUztpwkSVL5WaGRJKmmbDlJkqTSq1JCY8tJkiSVnhUaSZJqqkIFGhMaSZLqypaTJElSD7FCI0lSTVWoQGNCI0lSXVWp5WRCI0lSTVUon3EMjSRJKj8rNJIk1dSYCpVoTGgkSaqpCuUztpwkSVL5WaGRJKmmnOUkSZJKb0x18hlbTpIkqfys0EiSVFO2nCRJUulVKJ+x5SRJksrPCo0kSTUVVKdEY0IjSVJNOctJkiSph1ihkSSpppzlJEmSSq9C+YwtJ0mSVH5WaCRJqqkxFSrRmNBIklRTFcpnVp7QRMS3gVzZ/sz8aEcikiRJWkVDVWhmjVoUkiRp1NVillNmzmhej4jxmflE50OSJEmjoUL5zPCznCLidRFxK3B7sb5DRHyv45FJkiSN0EgGBX8TeCtwPkBm/jEidu1kUJIkqfNqN8spM+9ers822JlwJEnSaKlOOjOyG+vdHRGvBzIiVouITwO3dTguSZJUIRHxiYi4JSJmR8RZEbFGRGwZEddGxJyIODsiVm/1/CNJaA4HPgxsCtwLvKJYlyRJJRYRbVuGuc6mwEeBHTNzO2AscDDwFeAbmTkZeAiY1upnGbbllJkPAIe0egFJktSbxoxuz2kcsGZELAHGA/OBPYD3FPtnAP8KfL+Vk49kltNLIuLXEXF/RCyMiPMi4iWtXEySJFVTRPRHxKympX/Zvsy8B/g3YC6NROYR4Drg4cwcKA6bR6Mb1JKRDAr+KfBdYP9i/WDgLOA1rV5UkiR1XztvrJeZ04HpK7nO+sC+wJbAw8A5wF5tuzgjG0MzPjN/lJkDxfJjYI12BiFJkkZfRPuWYbwJ+HNm3p+ZS4BzgZ2B9SJiWXFlInBPq59lpQlNRGwQERsA/xkRx0TEFhGxeUQcBVzY6gUlSVLtzAVeGxHjo1EW2hO4FbgMOLA4ZipwXqsXGKrldB2Nh1Muy7s+2LQvgWNbvagkSeq+0XqWU2ZeGxG/AK4HBoAbaLSnLgB+FhFfKLad1uo1hnqW05atnlSSJPW+0ZzllJnHA8cvt/lOYKd2nH9EdwqOiO2AbWgaO5OZZ7YjAEmSpOdr2IQmIo4HdqOR0FwI7A38HjChkSSpxEar5TQaRjLL6UAag3fuy8xDgR2AdTsalSRJ6rho49JtI0lonszMpcBARKwDLAQmdTYsSZKkkRvJGJpZEbEecAqNmU+PAVd3MihJktR5YyrUchrJs5w+VLw8OSIuAtYBHuhoVJIkqeMqlM+MbJbTMpl5F0BEzAU260RAkiRJq2qVEpomFcrpJEmqpyrNcmo1ocm2RiFJkkZdhfKZlSc0EfFtVpy4BLBepwLSyL1j7z0ZP34txowdy7ixYznzrF90OySVwMnHH8Leu27H/Q8+yo7v/OKz9n3svXvw5U/+IxN3P5pFDz/OLq+ewjnf6OeuexcBcN5/3ciXpl/UjbBVUlf+7gq+8uUTWTq4lP0PeCfTDuvvdkiqqKEqNLNa3KdRdPKpM1hv/fW7HYZK5Ee/voaTz/5vTv38+561fWLfeuz52q2ZO//BZ22/8ob/5YCPnTyaIaoiBgcH+eKJJ/CDU86gr6+P9xx0ILvtvgd/N3lyt0NToRaznDJzxmgGIml0XHn9/7LZJhs8Z/tXP30AnznpV5zzDf8FrfaYffNNTJq0ORMnNW5dttfb3s7ll11qQtNDKpTPjOjGeupRQXDk4dN478EHcO4vft7tcFRi++y2PfcufJib/3TPc/a95uVbcu3Zx/Cr7xzB1i/ZuAvRqawWLljAxpv87WdmQl8fCxYs6GJEqrJWBwWrB5zyw58woa+PBxct4sjDp7HFllvyqlf/fbfDUsmsucZqHPXPb2WfD33nOftuvP1utnrb/+XxJxfz1jdsw8+/0c/2+57QhSgldUKVZjmNeoUmIg4dYl9/RMyKiFlnnDZ9NMMqpQl9fQBssOGG7LbHm7hl9s1djkhl9JKJG7H5phvyh7OP5fYLPsemE9bj6p8eTd+Ga/Po40/x+JOLAbj497ey2rixbLjeWl2OWGUxoa+P++bf98z6wgUL6Cu+t9QbxrRx6bZWZjkBkJkfbfGanwPOWMk5pwPTAf761FKnhg/hySeeYGkma621Fk8+8QTXXH0lH/jgh4Z/o7ScW+bcy+Z7HvvM+u0XfI6dD/kqix5+nL4N12bBokcB2HHbzRkTwaKHH+9WqCqZbbfbnrlz72LevLvpm9DHRRdewJe+9u/dDksV1eospyFFxE0r2wWYnrfBogcXcdQnPgLAwMAAe71tH16/8y5djkplMONL72eXV0/hReu9kDkXfZ7Pn3whM3614sez7f+mV3LYO3dhYHCQp55awvuOXeG/RaQVGjduHMd+5jiO6P8AS5cOst/+BzB58pRuh6UmVWo5RWb7CyERsQB4K/DQ8ruAqzLzxcOdwwqN2q3vda0WFaXnemjmc8ccSc/XGuNG9078Hz/v9rb9rv3mvi/ranY07KDgiNgIOBrYBlhj2fbM3GOIt/0GeGFm3riC812+ylFKkqS2G1OdAs2IxvH8BLgN2JLG+Je7gJlDvSEzp2Xm71ey7z2rGKMkSdKQRpLQbJiZpwFLMvO/M/OfgaGqM5IkqQQiom1Lt43kPjRLij/nR8TbgXuB595mVJIklUqVWk4jSWi+EBHrAp8Cvg2sA3yio1FJkiStgmETmsz8TfHyEWD3zoYjSZJGSw90itpmJLOczmAFN9grxtJIkqSSqsXTtpv8pun1GsD+NMbRSJIk9YSRtJx+2bweEWcBK5ySLUmSyqMXnsHULq08bXsKMKHdgUiSpNFVoY7TiMbQPMqzx9DcR+POwZIkST1hJC2ntUcjEEmSNLqqNCh42PZZRFw6km2SJKlcItq3dNtKKzQRsQYwHnhRRKwPzzwBdB1g01GITZIkaUSGajl9EPg48GLgOv6W0PwV+E5nw5IkSZ1Wi0cfZOZJwEkR8ZHM/PYoxiRJkkZBrcbQAEsjYr1lKxGxfkR8qHMhSZIkrZqRJDSHZebDy1Yy8yHgsI5FJEmSRkUtBgU3GRsRkZkJEBFjgdU7G5YkSeq0WoyhaXIRcHZE/KBY/2CxTZIkqSeMJKE5GugHjijWLwFO6VhEkiRpVATVKdEMO4YmM5dm5smZeWBmHgjcCjjrSZKkkhsT7Vu6bUQPp4yIVwLvBt4F/Bk4t5NBSZIkrYqh7hT8UhpJzLuBB4CzgcjM3UcpNkmS1EG9UFlpl6EqNLcDvwP2ycw5ABHxiVGJSpIkdVz0wnzrNhlqDM0/AvOByyLilIjYEyo0ekiSJI2aiFgvIn4REbdHxG0R8bqI2CAiLomIO4o/12/1/CtNaDLzV5l5MPAy4DIaz3WaEBHfj4i3tHpBSZLUG0Z5UPBJwEWZ+TJgB+A24Bjg0sycAlxarLf2WYY7IDMfz8yfZuY/ABOBG2hM5ZYkSSU2WncKjoh1gV2B0wAyc3HxFIJ9gRnFYTOA/Vr9LCN59MEzMvOhzJyemXu2ekFJklQ9EdEfEbOalv6m3VsC9wNnRMQNEXFqRKwF9GXm/OKY+4C+Vq8/omnbkiSpetr5tO3MnA5MX8nuccCrgI9k5rURcRLLtZcyMyMiW73+KlVoJElSdYziGJp5wLzMvLZY/wWNBGdBRGwCUPy5sOXP0uobJUmSRiIz7wPujoitik170njywPnA1GLbVOC8Vq9hy0mSpJoa5dvQfAT4SUSsDtwJHEqjsPLziJgG/IXGEwlaYkIjSVJNjRnF28tl5o3AjivY1ZaJRracJElS6VmhkSSppir05AMTGkmS6qpKD6e05SRJkkrPCo0kSTXVzhvrdZsJjSRJNVWhfMaWkyRJKj8rNJIk1ZQtJ0mSVHoVymdsOUmSpPKzQiNJUk1VqaphQiNJUk1FhXpOVUrOJElSTVmhkSSppqpTnzGhkSSptqo0bduWkyRJKj0rNJIk1VR16jMmNJIk1VaFOk62nCRJUvlZoZEkqaaqdB8aExpJkmqqSm0aExpJkmqqShWaKiVnkiSppqzQSJJUU9Wpz/RwQrP6OItHaq/zfnp8t0OQpJ5iy0mSJKmH9GyFRpIkdVaVqhomNJIk1ZQtJ0mSpB5ihUaSpJqqTn3GhEaSpNqqUMfJlpMkSSo/KzSSJNXUmAo1nUxoJEmqKVtOkiRJPcQKjSRJNRW2nCRJUtnZcpIkSeohVmgkSaopZzlJkqTSs+UkSZLUQ6zQSJJUU1Wq0JjQSJJUU1Watm3LSZIklZ4JjSRJNTUm2reMRESMjYgbIuI3xfqWEXFtRMyJiLMjYvWWP0urb5QkSeUWbfxvhD4G3Na0/hXgG5k5GXgImNbqZzGhkSRJHRcRE4G3A6cW6wHsAfyiOGQGsF+r5zehkSSppiLauUR/RMxqWvqXu9w3gaOApcX6hsDDmTlQrM8DNm31szjLSZKkmmrnLKfMnA5MX+F1IvYBFmbmdRGxW9su2sSERpIkddrOwDsi4m3AGsA6wEnAehExrqjSTATuafUCtpwkSaqp0ZrllJnHZubEzNwCOBj4r8w8BLgMOLA4bCpwXsufpdU3SpKkcuvCLKflHQ18MiLm0BhTc1qrJ7LlJEmSRk1mXg5cXry+E9ipHec1oZEkqaZ8lpMkSSq9CuUzjqGRJEnlZ4VGkqSaGlOhnpMJjSRJNVWddMaWkyRJqgArNJIk1VWFSjQmNJIk1VQ7n+XUbbacJElS6VmhkSSppio0ycmERpKkuqpQPmPLSZIklZ8VGkmS6qpCJRoTGkmSaspZTpIkST3ECo0kSTXlLCdJklR6FcpnbDlJkqTys0IjSVJdVahEY0IjSVJNOctJkiSph1ihkSSpppzlJEmSSq9C+YwJjSRJtVWhjMYxNJIkqfSs0EiSVFNVmuVkQiNJUk1VaVCwLSdJklR6VmgkSaqpChVoTGgkSaqtCmU0tpwkSVLpWaEpsSt/dwVf+fKJLB1cyv4HvJNph/V3OySV1NLBQb726Q+w7oYbcfhnv8qMr3+OuXNuZ+y4cWw+ZWsOPuIoxo7z60Krzu+p3lalWU5WaEpqcHCQL554At87+VT+4/wLuOjC3/C/c+Z0OyyV1OW/OYe+iZs/s77jrm/hs9/9KceedCaLFz/NVZf8uovRqaz8nup9Ee1bus2EpqRm33wTkyZtzsRJk1ht9dXZ621v5/LLLu12WCqhhx5YyC2zruZ1b/6HZ7Ztu+PriAgigs2nbMPDixZ2MUKVld9TGk0dS2gi4mURsWdEvHC57Xt16pp1snDBAjbeZONn1if09bFgwYIuRqSyOve0b7Hv1CMYs4J/Yg0ODDDz8ovZ+pWv7UJkKju/p3pftHHpto4kNBHxUeA84CPA7IjYt2n3F4d4X39EzIqIWaedMr0ToUlqMnvmlbxw3fXYbPLLVrj/7B/8O5O32YHJ2+4wypFJGhUVymg6NcrvMODVmflYRGwB/CIitsjMkxjiY2fmdGA6wFMDZIdiq4QJfX3cN/++Z9YXLlhAX19fFyNSGd15+83Mnnklt153DUuWLOapJx5nxjdOYOonjuPCn53OY488zMHHnNjtMFVSfk9pNHUqoRmTmY8BZOZdEbEbjaRmc3oijyu/bbfbnrlz72LevLvpm9DHRRdewJe+9u/dDksl8473Hs473ns4AHfcfD2Xnvczpn7iOK665NfcfsMfOPKEkxgzxqF2ao3fU72vSrOcOpXQLIiIV2TmjQBFpWYf4HRg+w5ds1bGjRvHsZ85jiP6P8DSpYPst/8BTJ48pdthqSLO/v6/scFGfXz96A8CsMPr3sjeBx3a5ahUNn5P9b5emJ3ULpHZ/s5OREwEBjLzvhXs2zkzrxzuHLac1G5X3HF/t0NQhew6ZaNuh6AKWmPc6JZM/ue+J9r2u3arjcd3NT3qSIUmM+cNsW/YZEaSJHVehQo03ilYkqTaqlBG42g/SZJUeiY0kiTVVLTxvyGvEzEpIi6LiFsj4paI+FixfYOIuCQi7ij+XL/Vz2JCI0lSTY3is5wGgE9l5jbAa4EPR8Q2wDHApZk5Bbi0WG+JCY0kSeqozJyfmdcXrx8FbgM2BfYFZhSHzQD2a/UaJjSSJNVUO5980Pz4omLpX+E1G08QeCVwLdCXmfOLXfcBLd9K2llOkiTVVRtnOTU/vmill2s8sPqXwMcz86/R1KvKzIyIlu+LY4VGkiR1XESsRiOZ+UlmnltsXhARmxT7NwEWtnp+ExpJkmpqFGc5BXAacFtmfr1p1/nA1OL1VOC8Vj+LLSdJkmpqFJ/ltDPwXuDmiLix2PYvwJeBn0fENOAvwLtavYAJjSRJ6qjM/D0rH7GzZzuuYUIjSVJNVejJByY0kiTVVoUyGgcFS5Kk0rNCI0lSTQ03O6lMTGgkSaqpUZzl1HG2nCRJUulZoZEkqaYqVKAxoZEkqa5sOUmSJPUQKzSSJNVWdUo0JjSSJNWULSdJkqQeYoVGkqSaqlCBxoRGkqS6suUkSZLUQ6zQSJJUUz7LSZIklV918hlbTpIkqfys0EiSVFMVKtCY0EiSVFfOcpIkSeohVmgkSaopZzlJkqTyq04+Y8tJkiSVnxUaSZJqqkIFGhMaSZLqqkqznExoJEmqqSoNCnYMjSRJKj0rNJIk1VSVWk5WaCRJUumZ0EiSpNKz5SRJUk1VqeVkQiNJUk05y0mSJKmHWKGRJKmmbDlJkqTSq1A+Y8tJkiSVnxUaSZLqqkIlGhMaSZJqyllOkiRJPcQKjSRJNeUsJ0mSVHoVymdsOUmSpPKzQiNJUl1VqERjhUaSpJqKNv437LUi9oqI/4mIORFxTLs/iwmNJEnqqIgYC3wX2BvYBnh3RGzTzmuY0EiSVFMR7VuGsRMwJzPvzMzFwM+Afdv5WXp2DM0a46rU2eusiOjPzOndjqPXvWXrjbodQin486R282eqd7Xzd21E9AP9TZumN/1/3xS4u2nfPOA17bo2WKGpiv7hD5FGzJ8ntZs/UzWQmdMzc8emZVSTWBMaSZLUafcAk5rWJxbb2saERpIkddpMYEpEbBkRqwMHA+e38wI9O4ZGq8TetNrJnye1mz9TNZeZAxFxJHAxMBY4PTNvaec1IjPbeT5JkqRRZ8tJkiSVngmNJEkqPROaEuv0baRVLxFxekQsjIjZ3Y5F1RARkyLisoi4NSJuiYiPdTsmVZdjaEqquI30n4A307hB0Uzg3Zl5a1cDU2lFxK7AY8CZmbldt+NR+UXEJsAmmXl9RKwNXAfs5/eUOsEKTXl1/DbSqpfMvAJ4sNtxqDoyc35mXl+8fhS4jcYdY6W2M6EprxXdRtovCkk9KSK2AF4JXNvlUFRRJjSSpI6KiBcCvwQ+npl/7XY8qiYTmvLq+G2kJen5iojVaCQzP8nMc7sdj6rLhKa8On4baUl6PiIigNOA2zLz692OR9VmQlNSmTkALLuN9G3Az9t9G2nVS0ScBVwNbBUR8yJiWrdjUuntDLwX2CMibiyWt3U7KFWT07YlSVLpWaGRJEmlZ0IjSZJKz4RGkiSVngmNJEkqPRMaSZJUeiY0UhdFxGAxlXV2RJwTEeOfx7l+GBEHFq9PjYhthjh2t4h4fQvXuCsiXjTS7Ss5x/sj4jvtuK4kLWNCI3XXk5n5iuLp1ouBw5t3RsS4Vk6amR8Y5onGuwGrnNBIUq8yoZF6x++AyUX15HcRcT5wa0SMjYivRcTMiLgpIj4IjbuwRsR3IuJ/IuL/AROWnSgiLo+IHYvXe0XE9RHxx4i4tHhI4OHAJ4rq0C4RsVFE/LK4xsyI2Ll474YR8duIuCUiTgVipB8mInaKiKsj4oaIuCoitmraPamI8Y6IOL7pPf8UEX8o4vpBRIxt/a9TUp209K8/Se1VVGL2Bi4qNr0K2C4z/xwR/cAjmfn3EfEC4MqI+C2NJxdvBWwD9AG3Aqcvd96NgFOAXYtzbZCZD0bEycBjmflvxXE/Bb6Rmb+PiM1o3IF6a+B44PeZeUJEvB1YlbsH3w7skpkDEfEm4IvAAcW+nYDtgCeAmRFxAfA4cBCwc2YuiYjvAYcAZ67CNSXVlAmN1F1rRsSNxevf0XjuzeuBP2Tmn4vtbwFevmx8DLAuMAXYFTgrMweBeyPiv1Zw/tcCVyw7V2Y+uJI43gRs03j0DgDrFE9I3hX4x+K9F0TEQ6vw2dYFZkTEFCCB1Zr2XZKZiwAi4lzgDcAA8GoaCQ7AmsDCVbiepBozoZG668nMfEXzhuKX+ePNm4CPZObFyx3XzmfijAFem5lPrSCWVn0euCwz9y/aXJc37Vv+mStJ43POyMxjn89FJdWTY2ik3ncxcERErAYQES+NiLWAK4CDijE2mwC7r+C91wC7RsSWxXs3KLY/CqzddNxvgY8sW4mIVxQvrwDeU2zbG1h/FeJeF7ineP3+5fa9OSI2iIg1gf2AK4FLgQMjYsKyWCNi81W4nqQaM6GRet+pNMbHXB8Rs4Ef0Kiu/gdwR7HvTBpPyn6WzLwf6AfOjYg/AmcXu34N7L9sUDDwUWDHYtDxrfxtttXnaCREt9BoPc0dIs6biqd0z4uIrwNfBb4UETfw3GrwH4BfAjcBv8zMWcWsrM8Cv42Im4BLgE1G+HckqeZ82rYkSSo9KzSSJKn0TGgkSVLpmdBIkqTSM6GRJEmlZ0IjSZJKz4RGkiSVngmNJEkqvf8PIVPK1A0ScP0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "probabilities = torch.softmax(torch.tensor(test_results.predictions).to(torch.float32), dim=-1)\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)\n",
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef4c67fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_save = []\n",
    "for idx in range(len(test_data)):\n",
    "    item = dataset['test'][idx]\n",
    "    actual_label = item['label']\n",
    "    predicted_label = predictions[idx]\n",
    "    claim = item['claim'] \n",
    "    premise = item['premise'] \n",
    "    category = item['category']\n",
    "    \n",
    "    # Append the information as a dictionary to the list\n",
    "    data_to_save.append({\n",
    "        'Claim': claim,\n",
    "        'Premise': premise,\n",
    "        'Actual Label': actual_label,\n",
    "        'Predicted Label': predicted_label,\n",
    "        'Category' : category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_to_save)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/home/elson/results/2.2.2_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a1a63a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correctly classified instances\n",
    "correctly_classified = df[df['Actual Label'] == df['Predicted Label']]\n",
    "\n",
    "# Calculate misclassified instances\n",
    "misclassified = df[df['Actual Label'] != df['Predicted Label']]\n",
    "\n",
    "# Count the number of correctly classified and misclassified by category\n",
    "correct_classification_counts = correctly_classified['Category'].value_counts()\n",
    "misclassification_counts = misclassified['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c4055e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           35\n",
       "Fitness                  13\n",
       "Cancer                   12\n",
       "Bone health              12\n",
       "Skin                      9\n",
       "Hair                      9\n",
       "Neurological health       9\n",
       "Diabetes                  9\n",
       "Throat                    9\n",
       "Ear                       6\n",
       "Eye                       6\n",
       "Cardiovascular Health     6\n",
       "COVID                     4\n",
       "Muscles                   3\n",
       "Blood                     3\n",
       "Mental Health             3\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "117a1d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           16\n",
       "Skin                     15\n",
       "Bone health               9\n",
       "Women' s Health           6\n",
       "Cardiovascular Health     6\n",
       "Blood                     6\n",
       "Men's health              6\n",
       "Muscles                   3\n",
       "Hair                      3\n",
       "Vascular                  3\n",
       "Diabetes                  3\n",
       "Eye                       3\n",
       "Dental Health             3\n",
       "COVID                     2\n",
       "Fitness                   2\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
