{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification,AutoConfig\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score,precision_recall_fscore_support\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-cfbf7584a6bb7c13\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 312.84it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('csv',data_files='dataset_sentenceattribution_nerfeatures_split.csv',delimiter=',',column_names=[\"claim\",\"premise\",\"label\",\"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\",\"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\",\"url\", \"entities\",\"entity_map\",\"gem_exp\",\"gem_label\",\"gpt_label\",\"gpt_exp\",\"gold_exp\",\"entity_map_ev\",\"entity_ev\",\"synonym\",\"voice\",\"split\"],skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ae13160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'gem_exp', 'gem_label', 'gpt_label', 'gpt_exp', 'gold_exp', 'entity_map_ev', 'entity_ev', 'synonym', 'voice', 'split'],\n",
       "        num_rows: 2322\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "133f9357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-aa1fd4d2889f655e.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-9cd628f4430f2ace.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-df968f39da4ad12a.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01252e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\"claim\", \"premise\", \"label\", \"category\",\"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\"]\n",
    "all_columns = dataset[\"train\"].column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1623/1623 [00:00<00:00, 4251.83ex/s]\n",
      "100%|██████████| 465/465 [00:00<00:00, 4732.86ex/s]\n",
      "100%|██████████| 234/234 [00:00<00:00, 4625.24ex/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 2, 'entailment': 0, 'neutral': 1}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 2,\n",
    "    \"entailment\": 0,\n",
    "    \"neutral\": 1\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e15010ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='sjrhuschlee/flan-t5-base-mnli'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "        # Extracting claim and evidence texts\n",
    "        claim = item['claim'] \n",
    "        evidences = item['premise']\n",
    "        item['premise']=evidences\n",
    "        item['claim']=claim\n",
    "        additional_features = [\n",
    "            \"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\"]\n",
    "    \n",
    "        for feature in additional_features:\n",
    "            if feature in item:\n",
    "                evidences += \"[SEP]\" + str(item[feature])\n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "            evidences, claim,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "         # Construct the output item\n",
    "        output_item = {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),  # Remove batch dimension\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),  # Remove batch dimension\n",
    "            'claim': claim,  # Include augmented claim text\n",
    "            'evidences': evidences  # Include original evidence text\n",
    "        }\n",
    "        \n",
    "        if 'label' in item:\n",
    "            output_item['label'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return output_item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62421eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "T5ForSequenceClassification(\n",
       "  (transformer): T5Model(\n",
       "    (shared): Embedding(32128, 768)\n",
       "    (encoder): T5Stack(\n",
       "      (embed_tokens): Embedding(32128, 768)\n",
       "      (block): ModuleList(\n",
       "        (0): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 12)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (6): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (7): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (8): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (9): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (10): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (11): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): T5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (decoder): T5Stack(\n",
       "      (embed_tokens): Embedding(32128, 768)\n",
       "      (block): ModuleList(\n",
       "        (0): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 12)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (6): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (7): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (8): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (9): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (10): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (11): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): T5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (classification_head): T5ClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"sjrhuschlee/flan-t5-base-mnli\"\n",
    "config = AutoConfig.from_pretrained(\n",
    "    model_name, num_labels=len(label2id), id2label=id2label, label2id=label2id\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=512)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,ignore_mismatched_sizes=True,config=config, trust_remote_code=True)\n",
    "device = \"cuda:0\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    if isinstance(\n",
    "        logits, tuple\n",
    "    ):  # if the model also returns hidden_states or attentions\n",
    "        logits = logits[0]\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, predictions, average=\"weighted\"\n",
    "    )\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "\n",
    "\n",
    "    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f5cf584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([ 5433,     6,  6124,   103,  1572,  1171,  1717,  2537,  9753,  3217,\n",
       "            24,     8,     3,  6296,  2917,    75,  5167,    11,    82,    52,\n",
       "            52,   107,  1832,  1043, 12771,   228,  2519,     8, 23458,    13,\n",
       "           212, 12851,   725,    45,  1133,  9241,   588,    51,   159,    12,\n",
       "            74,    51,   159,    57,  3094,  1133,  1717,  2537,     5,  6306,\n",
       "           134,  8569,   908,   632,  6306,   134,  8569,   908,   632,  6306,\n",
       "           134,  8569,   908,   632,  6306,   134,  8569,   908,   632,  6306,\n",
       "           134,  8569,   908,   632,  6306,   134,  8569,   908,   632,  6306,\n",
       "           134,  8569,   908,   632,  6306,   134,  8569,   908,   632,  6306,\n",
       "           134,  8569,   908,   632,  6306,   134,  8569,   908,   632,  6306,\n",
       "           134,  8569,   908,   632,  6306,   134,  8569,   908,   632,     1,\n",
       "           499,    52,    52,   107,  1832,  1043,    19,  1664,   261,    16,\n",
       "         26309,   494,    12,   199,  1172,     8,  3179,    13,     8,  1133,\n",
       "             5,     1,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'claim': 'Myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.',\n",
       " 'evidences': 'Additionally, laser doppler blood flow measurement showed that the frankincense and myrrh essential oil compound could promote the elimination of capillaries from skin epidermis to dermis by increasing skin blood flow.[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0',\n",
       " 'label': tensor(1)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3045\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3045' max='3045' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3045/3045 41:56, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.575300</td>\n",
       "      <td>0.897926</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.660371</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.619133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.557400</td>\n",
       "      <td>1.156040</td>\n",
       "      <td>0.647312</td>\n",
       "      <td>0.671907</td>\n",
       "      <td>0.647312</td>\n",
       "      <td>0.655406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.396400</td>\n",
       "      <td>1.506697</td>\n",
       "      <td>0.608602</td>\n",
       "      <td>0.645270</td>\n",
       "      <td>0.608602</td>\n",
       "      <td>0.617223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.269000</td>\n",
       "      <td>1.773481</td>\n",
       "      <td>0.608602</td>\n",
       "      <td>0.628332</td>\n",
       "      <td>0.608602</td>\n",
       "      <td>0.615092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>2.235270</td>\n",
       "      <td>0.608602</td>\n",
       "      <td>0.626877</td>\n",
       "      <td>0.608602</td>\n",
       "      <td>0.615823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.051300</td>\n",
       "      <td>3.100508</td>\n",
       "      <td>0.604301</td>\n",
       "      <td>0.622659</td>\n",
       "      <td>0.604301</td>\n",
       "      <td>0.611851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.027800</td>\n",
       "      <td>2.473220</td>\n",
       "      <td>0.617204</td>\n",
       "      <td>0.626951</td>\n",
       "      <td>0.617204</td>\n",
       "      <td>0.621549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.222200</td>\n",
       "      <td>2.515115</td>\n",
       "      <td>0.634409</td>\n",
       "      <td>0.645618</td>\n",
       "      <td>0.634409</td>\n",
       "      <td>0.638894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.081800</td>\n",
       "      <td>2.830160</td>\n",
       "      <td>0.634409</td>\n",
       "      <td>0.643810</td>\n",
       "      <td>0.634409</td>\n",
       "      <td>0.638412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.059300</td>\n",
       "      <td>3.032275</td>\n",
       "      <td>0.619355</td>\n",
       "      <td>0.622822</td>\n",
       "      <td>0.619355</td>\n",
       "      <td>0.620973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>3.240668</td>\n",
       "      <td>0.602151</td>\n",
       "      <td>0.616575</td>\n",
       "      <td>0.602151</td>\n",
       "      <td>0.608223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>3.594950</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.614596</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.613479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.050800</td>\n",
       "      <td>3.717959</td>\n",
       "      <td>0.623656</td>\n",
       "      <td>0.627123</td>\n",
       "      <td>0.623656</td>\n",
       "      <td>0.625274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.799794</td>\n",
       "      <td>0.623656</td>\n",
       "      <td>0.628125</td>\n",
       "      <td>0.623656</td>\n",
       "      <td>0.625754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>3.836570</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>0.629633</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>0.627620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/10.1.4_flant5/checkpoint-203\n",
      "Configuration saved in /home/elson/10.1.4_flant5/checkpoint-203/config.json\n",
      "Model weights saved in /home/elson/10.1.4_flant5/checkpoint-203/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/10.1.4_flant5/checkpoint-406\n",
      "Configuration saved in /home/elson/10.1.4_flant5/checkpoint-406/config.json\n",
      "Model weights saved in /home/elson/10.1.4_flant5/checkpoint-406/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/10.1.4_flant5/checkpoint-609\n",
      "Configuration saved in /home/elson/10.1.4_flant5/checkpoint-609/config.json\n",
      "Model weights saved in /home/elson/10.1.4_flant5/checkpoint-609/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/10.1.4_flant5/checkpoint-406] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/10.1.4_flant5/checkpoint-812\n",
      "Configuration saved in /home/elson/10.1.4_flant5/checkpoint-812/config.json\n",
      "Model weights saved in /home/elson/10.1.4_flant5/checkpoint-812/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/10.1.4_flant5/checkpoint-609] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/10.1.4_flant5/checkpoint-1015\n",
      "Configuration saved in /home/elson/10.1.4_flant5/checkpoint-1015/config.json\n",
      "Model weights saved in /home/elson/10.1.4_flant5/checkpoint-1015/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/10.1.4_flant5/checkpoint-812] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/10.1.4_flant5/checkpoint-1218\n",
      "Configuration saved in /home/elson/10.1.4_flant5/checkpoint-1218/config.json\n",
      "Model weights saved in /home/elson/10.1.4_flant5/checkpoint-1218/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/10.1.4_flant5/checkpoint-1015] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/10.1.4_flant5/checkpoint-1421\n",
      "Configuration saved in /home/elson/10.1.4_flant5/checkpoint-1421/config.json\n",
      "Model weights saved in /home/elson/10.1.4_flant5/checkpoint-1421/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/10.1.4_flant5/checkpoint-1218] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/10.1.4_flant5/checkpoint-1624\n",
      "Configuration saved in /home/elson/10.1.4_flant5/checkpoint-1624/config.json\n",
      "Model weights saved in /home/elson/10.1.4_flant5/checkpoint-1624/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/10.1.4_flant5/checkpoint-1421] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/10.1.4_flant5/checkpoint-1827\n",
      "Configuration saved in /home/elson/10.1.4_flant5/checkpoint-1827/config.json\n",
      "Model weights saved in /home/elson/10.1.4_flant5/checkpoint-1827/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/10.1.4_flant5/checkpoint-1624] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/10.1.4_flant5/checkpoint-2030\n",
      "Configuration saved in /home/elson/10.1.4_flant5/checkpoint-2030/config.json\n",
      "Model weights saved in /home/elson/10.1.4_flant5/checkpoint-2030/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/10.1.4_flant5/checkpoint-1827] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/10.1.4_flant5/checkpoint-2233\n",
      "Configuration saved in /home/elson/10.1.4_flant5/checkpoint-2233/config.json\n",
      "Model weights saved in /home/elson/10.1.4_flant5/checkpoint-2233/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/10.1.4_flant5/checkpoint-2030] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/10.1.4_flant5/checkpoint-2436\n",
      "Configuration saved in /home/elson/10.1.4_flant5/checkpoint-2436/config.json\n",
      "Model weights saved in /home/elson/10.1.4_flant5/checkpoint-2436/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/10.1.4_flant5/checkpoint-2233] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/10.1.4_flant5/checkpoint-2639\n",
      "Configuration saved in /home/elson/10.1.4_flant5/checkpoint-2639/config.json\n",
      "Model weights saved in /home/elson/10.1.4_flant5/checkpoint-2639/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/10.1.4_flant5/checkpoint-2436] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/10.1.4_flant5/checkpoint-2842\n",
      "Configuration saved in /home/elson/10.1.4_flant5/checkpoint-2842/config.json\n",
      "Model weights saved in /home/elson/10.1.4_flant5/checkpoint-2842/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/10.1.4_flant5/checkpoint-2639] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/10.1.4_flant5/checkpoint-3045\n",
      "Configuration saved in /home/elson/10.1.4_flant5/checkpoint-3045/config.json\n",
      "Model weights saved in /home/elson/10.1.4_flant5/checkpoint-3045/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/10.1.4_flant5/checkpoint-2842] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/elson/10.1.4_flant5/checkpoint-203 (score: 0.6559139784946236).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='89' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [59/59 16:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /home/elson/10.1.4_flant5/best_model/config.json\n",
      "Model weights saved in /home/elson/10.1.4_flant5/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/10.1.4_flant5/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/10.1.4_flant5/best_model/special_tokens_map.json\n",
      "Copy vocab file to /home/elson/10.1.4_flant5/best_model/spiece.model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/10.1.4_flant5/best_model/tokenizer_config.json',\n",
       " '/home/elson/10.1.4_flant5/best_model/special_tokens_map.json',\n",
       " '/home/elson/10.1.4_flant5/best_model/spiece.model',\n",
       " '/home/elson/10.1.4_flant5/best_model/added_tokens.json',\n",
       " '/home/elson/10.1.4_flant5/best_model/tokenizer.json')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/10.1.4_flant5/',\n",
    "    num_train_epochs=15,\n",
    "    learning_rate=3e-4,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=False,\n",
    "    logging_steps=10,\n",
    "    warmup_ratio=0.06,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/10.1.4_flant5/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/10.1.4_flant5/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63deaea8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/10.1.4_flant5/best_model/config.json\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"/home/elson/10.1.4_flant5/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForSequenceClassification\"\n",
      "  ],\n",
      "  \"auto_map\": {\n",
      "    \"AutoModelForSequenceClassification\": \"modeling_t5seq.T5ForSequenceClassification\"\n",
      "  },\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"finetuning_task\": \"mnli\",\n",
      "  \"id2label\": {\n",
      "    \"0\": \"entailment\",\n",
      "    \"1\": \"neutral\",\n",
      "    \"2\": \"contradiction\"\n",
      "  },\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"label2id\": {\n",
      "    \"contradiction\": 2,\n",
      "    \"entailment\": 0,\n",
      "    \"neutral\": 1\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "loading weights file /home/elson/10.1.4_flant5/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing T5ForSequenceClassification.\n",
      "\n",
      "All the weights of T5ForSequenceClassification were initialized from the model checkpoint at /home/elson/10.1.4_flant5/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 8\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/10.1.4_flant5/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path,trust_remote_code=True).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=(array([[ 9.05254483e-01,  9.88592148e-01, -1.89857233e+00],\n",
      "       [ 2.70199466e+00, -2.60176986e-01, -2.03809953e+00],\n",
      "       [ 2.27216911e+00, -4.28435266e-01, -1.61690092e+00],\n",
      "       [ 6.50078714e-01, -5.08101881e-01, -1.50825754e-01],\n",
      "       [ 1.68281353e+00, -1.19193606e-01, -1.45861149e+00],\n",
      "       [ 3.59723735e+00, -4.57520783e-01, -2.55257607e+00],\n",
      "       [ 2.24427390e+00, -5.98018289e-01, -1.36671638e+00],\n",
      "       [ 3.26429439e+00, -4.14171815e-01, -2.32761240e+00],\n",
      "       [ 2.78300643e+00, -8.16163421e-02, -2.47271681e+00],\n",
      "       [ 1.11630726e+00, -3.80923927e-01, -6.24553323e-01],\n",
      "       [ 1.77088940e+00, -7.90289164e-01, -7.23446608e-01],\n",
      "       [ 3.35289073e+00, -5.54798782e-01, -2.22642756e+00],\n",
      "       [-1.13420558e+00, -2.63647497e-01,  1.08159053e+00],\n",
      "       [ 3.30104876e+00, -4.43424046e-01, -2.31164885e+00],\n",
      "       [ 1.03901887e+00, -1.93476036e-01, -7.00220287e-01],\n",
      "       [-6.91905916e-01, -4.34703827e-01,  8.94850254e-01],\n",
      "       [ 3.09761167e+00, -2.35536575e-01, -2.29140306e+00],\n",
      "       [ 9.00030673e-01, -4.99297231e-01, -3.66789371e-01],\n",
      "       [ 3.22551394e+00, -4.38598275e-01, -2.22612691e+00],\n",
      "       [ 2.46793222e+00,  7.82457143e-02, -2.22289729e+00],\n",
      "       [ 1.81308342e-03, -4.85740304e-02, -1.00953884e-01],\n",
      "       [ 2.16868985e-02, -3.70325804e-01,  3.03324640e-01],\n",
      "       [ 1.34931147e+00,  2.97578752e-01, -1.63436699e+00],\n",
      "       [ 3.01618665e-01, -9.89021808e-02, -3.59857649e-01],\n",
      "       [ 4.41905260e-01, -5.38437784e-01,  3.76869999e-02],\n",
      "       [-1.62499106e+00, -3.82258326e-01,  1.67044878e+00],\n",
      "       [ 3.20979500e+00, -6.21161014e-02, -2.61272860e+00],\n",
      "       [ 6.92059875e-01, -1.72568619e-01, -4.21431243e-01],\n",
      "       [ 1.94821799e+00, -5.97847402e-01, -1.08272171e+00],\n",
      "       [ 1.78564861e-01, -4.94042158e-01,  1.52989015e-01],\n",
      "       [ 1.06736934e+00, -1.55162215e-01, -7.78784752e-01],\n",
      "       [ 3.04948401e+00, -1.29728496e-01, -2.45975614e+00],\n",
      "       [ 2.61927223e+00, -4.32082951e-01, -1.77782273e+00],\n",
      "       [ 1.43994832e+00, -3.18906128e-01, -9.30930316e-01],\n",
      "       [ 3.01069170e-01,  4.27100122e-01, -8.90491426e-01],\n",
      "       [ 2.05506301e+00,  1.02436505e-01, -1.87892067e+00],\n",
      "       [ 3.89981717e-01,  1.10674649e-01, -5.89666903e-01],\n",
      "       [ 2.51435161e+00, -1.35697842e-01, -2.12635899e+00],\n",
      "       [-6.16056144e-01, -6.42457962e-01,  1.03252721e+00],\n",
      "       [ 2.21037984e+00,  8.15312192e-02, -1.97109199e+00],\n",
      "       [ 1.07822442e+00,  1.68233544e-01, -1.27296925e+00],\n",
      "       [ 2.85225272e+00, -2.58145928e-01, -2.16177011e+00],\n",
      "       [ 8.94512594e-01, -1.57310501e-01, -6.83163047e-01],\n",
      "       [-1.25389159e+00, -1.16855145e-01,  9.85911489e-01],\n",
      "       [-5.24994075e-01, -4.81930003e-02,  3.14030707e-01],\n",
      "       [ 1.78579044e+00, -1.76803753e-01, -1.34032631e+00],\n",
      "       [ 9.14608479e-01,  3.01577568e-01, -1.35115063e+00],\n",
      "       [ 2.44615722e+00, -4.43654150e-01, -1.71115088e+00],\n",
      "       [ 2.43435693e+00, -1.34659961e-01, -2.05577064e+00],\n",
      "       [ 1.07067898e-01, -7.07989812e-01,  4.98985529e-01],\n",
      "       [ 1.68962300e+00, -5.81014007e-02, -1.49047744e+00],\n",
      "       [ 9.34319019e-01, -5.56696653e-02, -8.41486275e-01],\n",
      "       [ 1.56388474e+00,  2.77725518e-01, -1.73222625e+00],\n",
      "       [-1.39935672e+00, -6.70686007e-01,  1.70000124e+00],\n",
      "       [ 1.50386408e-01,  1.19898379e-01, -3.60954612e-01],\n",
      "       [ 3.05563426e+00, -1.52440980e-01, -2.42105889e+00],\n",
      "       [-1.81882107e+00, -7.06882179e-01,  2.07919741e+00],\n",
      "       [ 2.21098948e+00,  2.46946082e-01, -2.15000319e+00],\n",
      "       [ 1.57571149e+00,  4.62123379e-02, -1.49045670e+00],\n",
      "       [ 2.91507649e+00, -4.11227942e-01, -2.10673976e+00],\n",
      "       [ 1.61994886e+00, -3.80699545e-01, -1.11688328e+00],\n",
      "       [-6.64653182e-01, -8.45755517e-01,  1.20854270e+00],\n",
      "       [ 3.17247725e+00, -4.26522344e-01, -2.16572452e+00],\n",
      "       [ 3.97164136e-01,  8.65774453e-01, -1.55421960e+00],\n",
      "       [ 7.71387696e-01,  1.98286012e-01, -9.85328376e-01],\n",
      "       [ 3.36760688e+00, -3.79954159e-01, -2.54018497e+00],\n",
      "       [ 1.25690830e+00,  1.39383912e-01, -1.39376342e+00],\n",
      "       [ 3.21596241e+00, -4.07240182e-01, -2.29571986e+00],\n",
      "       [ 8.71184289e-01, -4.66197357e-02, -8.09331715e-01],\n",
      "       [-3.27629596e-01, -8.61707449e-01,  1.08838916e+00],\n",
      "       [ 2.07753301e+00, -8.29847515e-01, -9.70997214e-01],\n",
      "       [ 1.38643932e+00,  1.93103060e-01, -1.49618161e+00],\n",
      "       [ 1.18736875e+00,  4.18754481e-02, -1.12180257e+00],\n",
      "       [-1.08611500e+00, -1.57043219e-01,  9.17135358e-01],\n",
      "       [ 1.03739226e+00, -2.26249829e-01, -6.58530891e-01],\n",
      "       [ 1.05164480e+00,  2.08123550e-01, -1.29995489e+00],\n",
      "       [ 1.39477193e+00, -2.97241539e-01, -9.57787812e-01],\n",
      "       [ 1.20108807e+00, -1.11910209e-01, -9.81959105e-01],\n",
      "       [ 3.77218366e+00, -7.10104823e-01, -2.42133355e+00],\n",
      "       [ 2.48125482e+00, -3.53571773e-01, -1.81360865e+00],\n",
      "       [ 3.11327434e+00, -6.51232839e-01, -1.94497108e+00],\n",
      "       [ 1.43700027e+00, -3.34940046e-01, -1.01302564e+00],\n",
      "       [ 2.45517778e+00, -3.25871825e-01, -1.76649714e+00],\n",
      "       [ 1.65779924e+00, -5.09542108e-01, -9.01225686e-01],\n",
      "       [ 2.71610713e+00, -1.21160522e-01, -2.34157944e+00],\n",
      "       [ 1.38224840e+00,  2.13421360e-01, -1.46438003e+00],\n",
      "       [ 2.78521633e+00, -3.73279750e-01, -2.06343603e+00],\n",
      "       [ 5.82199730e-02,  6.99885786e-01, -1.11040401e+00],\n",
      "       [ 2.09777570e+00, -8.73099640e-02, -1.84847689e+00],\n",
      "       [ 2.94903350e+00, -4.60328877e-01, -1.98413289e+00],\n",
      "       [ 2.11706519e+00, -4.13597047e-01, -1.49419904e+00],\n",
      "       [ 2.74459434e+00, -6.55058265e-01, -1.79539573e+00],\n",
      "       [-6.18299365e-01, -5.06385505e-01,  8.32256854e-01],\n",
      "       [ 2.39143467e+00, -2.92815298e-01, -1.79418528e+00],\n",
      "       [ 8.51393700e-01,  4.41495888e-02, -8.56076181e-01],\n",
      "       [ 1.20902634e+00, -2.12420031e-01, -8.85088384e-01],\n",
      "       [ 3.00091386e-01,  5.50193191e-02, -4.56706911e-01],\n",
      "       [ 1.01610994e+00, -3.64697501e-02, -8.71359825e-01],\n",
      "       [ 3.84811282e+00, -6.41213238e-01, -2.58282876e+00],\n",
      "       [ 3.16890860e+00, -4.95658755e-01, -2.15506935e+00],\n",
      "       [-1.17807555e+00, -1.22608495e+00,  2.06081843e+00],\n",
      "       [ 2.84684491e+00, -3.30731988e-01, -2.04090595e+00],\n",
      "       [ 3.15858388e+00, -6.40315831e-01, -2.04577422e+00],\n",
      "       [ 1.54006088e+00,  2.64058799e-01, -1.70420575e+00],\n",
      "       [ 1.35441387e+00, -1.34163424e-01, -1.13739836e+00],\n",
      "       [ 1.72693837e+00, -5.01180947e-01, -1.20748198e+00],\n",
      "       [ 6.96561456e-01,  1.06588030e+00, -1.98275936e+00],\n",
      "       [-7.86123276e-02,  1.22310661e-01, -2.13351503e-01],\n",
      "       [ 2.48895073e+00, -6.81262374e-01, -1.55557489e+00],\n",
      "       [ 2.22726083e+00, -6.16744161e-01, -1.42249286e+00],\n",
      "       [-7.88758218e-01, -2.33492672e-01,  7.49276459e-01],\n",
      "       [ 3.31193948e+00, -4.74784732e-01, -2.33706045e+00],\n",
      "       [ 2.94502211e+00, -5.06320417e-01, -1.97850204e+00],\n",
      "       [ 9.34235394e-01, -1.89791873e-01, -6.66297317e-01],\n",
      "       [ 3.02766943e+00, -3.77779841e-01, -2.18265414e+00],\n",
      "       [ 2.34233451e+00,  2.76082940e-03, -2.14176297e+00],\n",
      "       [ 3.52397037e+00, -5.02779901e-01, -2.37153339e+00],\n",
      "       [ 2.77653170e+00, -2.54311711e-01, -2.15177345e+00],\n",
      "       [ 2.31848955e+00, -4.74311352e-01, -1.54249167e+00],\n",
      "       [ 2.78705883e+00, -1.94208305e-02, -2.40939927e+00],\n",
      "       [ 3.37230039e+00, -3.10941815e-01, -2.46174121e+00],\n",
      "       [ 6.61458194e-01, -2.72697598e-01, -4.24575746e-01],\n",
      "       [ 2.71272874e+00, -3.80359471e-01, -1.95894873e+00],\n",
      "       [ 2.04428411e+00,  6.24492407e-01, -2.46068525e+00],\n",
      "       [ 6.36319876e-01, -3.91838938e-01, -3.41413617e-01],\n",
      "       [ 1.40914071e+00, -1.57353625e-01, -1.13262367e+00],\n",
      "       [ 5.88446736e-01, -2.98067499e-02, -5.58339119e-01],\n",
      "       [ 2.98909521e+00, -3.77901435e-01, -2.21052861e+00],\n",
      "       [ 9.50978696e-01, -9.58671987e-01,  2.52902787e-02],\n",
      "       [ 2.65753031e+00, -5.12732446e-01, -1.73010945e+00],\n",
      "       [ 1.34451842e+00, -1.06553935e-01, -1.10380709e+00],\n",
      "       [-2.94373661e-01, -2.60725617e-01,  3.37165534e-01],\n",
      "       [ 2.62491870e+00, -1.75324231e-01, -2.11860943e+00],\n",
      "       [-1.93798408e-01,  1.02937236e-01, -1.65007398e-01],\n",
      "       [ 1.77992022e+00, -8.98736119e-02, -1.47156918e+00],\n",
      "       [ 4.17779565e-01,  3.03637952e-01, -8.50119948e-01],\n",
      "       [ 2.66796327e+00, -3.66152525e-01, -1.95591545e+00],\n",
      "       [-4.01046604e-01,  3.00831467e-01, -1.77301019e-01],\n",
      "       [ 1.63845465e-01,  3.04069579e-01, -5.77294230e-01],\n",
      "       [ 3.29746485e+00, -5.46439886e-01, -2.28833413e+00],\n",
      "       [ 1.46020532e+00, -2.14607254e-01, -1.08550620e+00],\n",
      "       [ 1.46655214e+00, -1.71999261e-01, -1.24935973e+00],\n",
      "       [ 1.55975878e+00,  1.10904403e-01, -1.61542809e+00],\n",
      "       [ 3.20860887e+00, -2.50542879e-01, -2.43358827e+00],\n",
      "       [ 2.47155309e+00, -5.76763213e-01, -1.59160924e+00],\n",
      "       [ 2.55387068e+00, -4.07811642e-01, -1.76217914e+00],\n",
      "       [ 1.57341480e+00,  4.55337882e-01, -1.97380006e+00],\n",
      "       [-2.39078715e-01, -3.91454220e-01,  3.84407580e-01],\n",
      "       [ 2.26135802e+00, -2.59132177e-01, -1.74040437e+00],\n",
      "       [ 3.35006237e-01, -1.85085952e-01, -2.43301228e-01],\n",
      "       [ 4.46196869e-02,  5.24030030e-01, -7.97164679e-01],\n",
      "       [ 2.15608907e+00, -4.53930795e-01, -1.47272623e+00],\n",
      "       [ 3.23057246e+00, -4.40710902e-01, -2.26842785e+00],\n",
      "       [ 2.59963775e+00, -3.17489952e-01, -1.87850785e+00],\n",
      "       [ 2.89874291e+00, -2.25772768e-01, -2.31522703e+00],\n",
      "       [ 2.72507977e+00, -7.09317803e-01, -1.66011572e+00],\n",
      "       [ 1.04927731e+00, -8.15814257e-01, -1.34547919e-01],\n",
      "       [ 1.07626641e+00,  3.45499933e-01, -1.42738628e+00],\n",
      "       [ 2.21210647e+00, -1.11058488e-01, -1.88143635e+00],\n",
      "       [-1.74175155e+00, -6.67739272e-01,  1.89813590e+00],\n",
      "       [-9.42907274e-01, -3.32575887e-01,  1.05954206e+00],\n",
      "       [-2.03289223e+00, -1.35439742e+00,  2.97009563e+00],\n",
      "       [ 3.07963252e+00, -5.84308624e-01, -1.93020439e+00],\n",
      "       [-1.96181500e+00, -9.99074221e-01,  2.55662084e+00],\n",
      "       [ 1.09356320e+00, -1.89086035e-01, -8.68093729e-01],\n",
      "       [ 2.15851212e+00, -9.41891670e-02, -1.80849886e+00],\n",
      "       [ 9.05813336e-01, -7.62276828e-01, -8.51281807e-02],\n",
      "       [-1.14678872e+00, -8.34746510e-02,  8.57393801e-01],\n",
      "       [-2.01480889e+00, -7.51981497e-01,  2.18633890e+00],\n",
      "       [-1.06590509e+00, -9.67932343e-01,  1.70240510e+00],\n",
      "       [-1.64881134e+00, -3.73882085e-01,  1.69842815e+00],\n",
      "       [ 1.74041700e+00, -2.03839436e-01, -1.35442090e+00],\n",
      "       [ 3.74072492e-01,  3.06976140e-01, -8.07109535e-01],\n",
      "       [ 3.39990044e+00, -4.08953011e-01, -2.49260640e+00],\n",
      "       [ 2.19243121e+00, -2.55693197e-01, -1.65065980e+00],\n",
      "       [-1.81383654e-01,  2.68232822e-01, -2.49250397e-01],\n",
      "       [ 2.69178939e+00, -6.38362229e-01, -1.65793180e+00],\n",
      "       [ 6.23918548e-02, -6.01083457e-01,  4.10394907e-01],\n",
      "       [ 2.61539054e+00, -2.36601278e-01, -2.13274622e+00],\n",
      "       [-1.52569667e-01, -3.88139397e-01,  4.00812984e-01],\n",
      "       [-3.15809727e-01, -3.33794296e-01,  5.08156955e-01],\n",
      "       [ 2.59098679e-01, -5.62328637e-01,  2.71375060e-01],\n",
      "       [ 2.64918566e-01, -5.39183140e-01,  1.35522485e-01],\n",
      "       [ 1.51070631e+00,  1.22049677e+00, -2.65933514e+00],\n",
      "       [ 1.40201306e+00,  3.93286347e-01, -1.68419969e+00],\n",
      "       [ 3.10105062e+00, -5.19123554e-01, -2.06050777e+00],\n",
      "       [ 1.36171103e+00, -2.62891334e-02, -1.23367369e+00],\n",
      "       [ 2.63643241e+00,  8.19608755e-03, -2.34180856e+00],\n",
      "       [ 1.05442345e+00,  1.47800818e-01, -1.15912271e+00],\n",
      "       [ 2.38272071e+00, -4.52964842e-01, -1.59030044e+00],\n",
      "       [-2.66987324e-01, -9.62910950e-02,  1.96141273e-01],\n",
      "       [ 1.54314804e+00,  2.21475467e-01, -1.71482635e+00],\n",
      "       [ 1.97840643e+00, -3.67678881e-01, -1.34393251e+00],\n",
      "       [ 2.34541750e+00, -4.01333511e-01, -1.68508053e+00],\n",
      "       [-3.87170881e-01, -1.11738491e+00,  1.28433514e+00],\n",
      "       [ 3.48855853e+00, -5.09700418e-01, -2.39507174e+00],\n",
      "       [ 2.50912404e+00, -3.17904532e-01, -1.93057275e+00],\n",
      "       [ 3.23229361e+00, -4.95743513e-01, -2.22437263e+00],\n",
      "       [ 1.89613497e+00, -3.33853960e-01, -1.35151613e+00],\n",
      "       [ 1.91065216e+00, -5.10226488e-02, -1.65575337e+00],\n",
      "       [ 2.73183370e+00, -5.65044284e-01, -1.70489752e+00],\n",
      "       [ 3.28973508e+00, -3.07607085e-01, -2.46894741e+00],\n",
      "       [ 1.50441253e+00,  7.44813085e-01, -2.20710444e+00],\n",
      "       [ 3.35825968e+00, -4.40025210e-01, -2.44880438e+00],\n",
      "       [-2.70387493e-02,  1.01836421e-01, -2.69189149e-01],\n",
      "       [ 1.84088364e-01, -9.60375667e-02, -1.91115364e-01],\n",
      "       [ 2.48748541e+00,  1.86877310e-01, -2.43380785e+00],\n",
      "       [ 2.29263306e+00, -3.99712414e-01, -1.56953168e+00],\n",
      "       [ 3.40690970e+00, -3.27586949e-01, -2.65057039e+00],\n",
      "       [ 2.10230970e+00, -4.18434888e-02, -1.74115908e+00],\n",
      "       [ 1.05411696e+00, -1.87720194e-01, -8.02857339e-01],\n",
      "       [ 1.71996605e+00, -2.04236671e-01, -1.30995369e+00],\n",
      "       [ 3.00589395e+00, -4.79512155e-01, -2.03973389e+00],\n",
      "       [ 1.37909508e+00,  3.19717526e-01, -1.74024177e+00],\n",
      "       [ 3.17483926e+00, -4.06960189e-01, -2.34039140e+00],\n",
      "       [-7.26738870e-02, -1.09581277e-01,  8.08317773e-03],\n",
      "       [ 4.09634382e-01,  1.89499538e-02, -5.11277378e-01],\n",
      "       [-5.94876945e-01, -9.72058833e-01,  1.28714085e+00],\n",
      "       [ 3.58850026e+00, -4.37436581e-01, -2.50923228e+00],\n",
      "       [-1.13654554e+00, -1.07739046e-01,  7.90045202e-01],\n",
      "       [ 3.07861114e+00, -3.14163446e-01, -2.30275965e+00],\n",
      "       [ 2.20594788e+00, -2.64361560e-01, -1.61875308e+00],\n",
      "       [ 8.63622844e-01,  1.91785581e-03, -7.78722584e-01],\n",
      "       [ 3.68682194e+00, -7.53145337e-01, -2.29111195e+00],\n",
      "       [ 2.50588632e+00, -1.66711789e-02, -2.27640343e+00],\n",
      "       [ 3.75499105e+00, -4.04562742e-01, -2.68520021e+00],\n",
      "       [ 3.17159557e+00, -5.59776843e-01, -2.13233685e+00],\n",
      "       [-8.91218483e-01, -1.56236246e-01,  8.35738540e-01],\n",
      "       [-3.71986300e-01, -4.74878699e-01,  6.85119629e-01],\n",
      "       [ 2.78799129e+00, -2.77190506e-01, -2.14624429e+00],\n",
      "       [ 8.00895333e-01, -3.44988525e-01, -4.04588342e-01],\n",
      "       [ 2.94471860e+00, -3.48564923e-01, -2.26042628e+00],\n",
      "       [ 2.54743743e+00,  1.14029378e-01, -2.43056035e+00],\n",
      "       [ 8.94072533e-01, -6.87516987e-01, -2.07700059e-01]], dtype=float32), array([[[-7.91156068e-02,  4.37218733e-02, -1.76006351e-02, ...,\n",
      "          2.13428251e-02, -3.41308936e-02,  1.03742160e-01],\n",
      "        [-6.43375292e-02,  8.87587387e-03, -1.51931673e-01, ...,\n",
      "          5.06131388e-02, -5.72197065e-02, -3.41124646e-02],\n",
      "        [ 3.31833474e-02, -6.45279363e-02, -3.78873833e-02, ...,\n",
      "         -6.20577671e-02, -4.23155092e-02,  2.57606362e-03],\n",
      "        ...,\n",
      "        [ 1.27554193e-01,  1.27121001e-01, -2.36688033e-01, ...,\n",
      "          3.45720261e-01, -1.47813991e-01,  1.08979098e-01],\n",
      "        [ 1.27554193e-01,  1.27121001e-01, -2.36688033e-01, ...,\n",
      "          3.45720261e-01, -1.47813991e-01,  1.08979098e-01],\n",
      "        [ 1.27554193e-01,  1.27121001e-01, -2.36688033e-01, ...,\n",
      "          3.45720261e-01, -1.47813991e-01,  1.08979098e-01]],\n",
      "\n",
      "       [[-1.29195407e-01,  1.63458902e-02, -1.33809850e-01, ...,\n",
      "         -5.90312928e-02, -9.69452187e-02, -9.49298497e-03],\n",
      "        [ 3.03782411e-02, -3.07098508e-01, -7.67051429e-02, ...,\n",
      "         -1.29959792e-01, -4.92403954e-02,  7.45335072e-02],\n",
      "        [-3.03979144e-02, -1.61172539e-01, -1.75798431e-01, ...,\n",
      "          1.61092356e-01,  1.32810205e-01, -2.08185967e-02],\n",
      "        ...,\n",
      "        [ 4.73381430e-02,  8.77401829e-02, -2.53610581e-01, ...,\n",
      "          2.88722456e-01, -3.38746198e-02, -3.17895610e-04],\n",
      "        [ 4.73381430e-02,  8.77401829e-02, -2.53610581e-01, ...,\n",
      "          2.88722456e-01, -3.38746198e-02, -3.17895610e-04],\n",
      "        [ 4.73381430e-02,  8.77401829e-02, -2.53610581e-01, ...,\n",
      "          2.88722456e-01, -3.38746198e-02, -3.17895610e-04]],\n",
      "\n",
      "       [[-2.01145619e-01, -3.78696411e-03, -1.65884227e-01, ...,\n",
      "          1.52650282e-01,  2.36092396e-02, -7.89264888e-02],\n",
      "        [-6.60356432e-02,  2.98242792e-02, -1.30159125e-01, ...,\n",
      "          1.52206793e-01,  1.01222992e-01,  9.65890847e-03],\n",
      "        [-2.07106799e-01, -6.39136359e-02, -9.74260643e-02, ...,\n",
      "          8.01110491e-02, -7.63722286e-02, -6.63282871e-02],\n",
      "        ...,\n",
      "        [ 6.49172068e-02,  7.11734742e-02, -1.22516483e-01, ...,\n",
      "          3.13264519e-01,  1.60507280e-02,  4.81770886e-03],\n",
      "        [ 6.49172068e-02,  7.11734742e-02, -1.22516483e-01, ...,\n",
      "          3.13264519e-01,  1.60507280e-02,  4.81770886e-03],\n",
      "        [ 6.49172068e-02,  7.11734742e-02, -1.22516483e-01, ...,\n",
      "          3.13264519e-01,  1.60507280e-02,  4.81770886e-03]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-1.92939378e-02,  1.11864964e-02, -1.16050988e-01, ...,\n",
      "         -5.17769679e-02,  2.59461552e-02,  3.38166691e-02],\n",
      "        [ 9.19635966e-03, -1.05954014e-01,  1.58629827e-02, ...,\n",
      "          3.92546728e-02,  4.22791094e-02,  1.74481124e-01],\n",
      "        [ 1.16174527e-01, -2.44627103e-01,  4.99432087e-02, ...,\n",
      "         -5.67141250e-02, -1.69065267e-01,  2.49728352e-01],\n",
      "        ...,\n",
      "        [ 6.41902536e-02,  3.28862518e-02, -2.30692439e-02, ...,\n",
      "          4.04654562e-01, -7.56964087e-02,  6.09008633e-02],\n",
      "        [ 6.41902536e-02,  3.28862518e-02, -2.30692439e-02, ...,\n",
      "          4.04654562e-01, -7.56964087e-02,  6.09008633e-02],\n",
      "        [ 6.41902536e-02,  3.28862518e-02, -2.30692439e-02, ...,\n",
      "          4.04654562e-01, -7.56964087e-02,  6.09008633e-02]],\n",
      "\n",
      "       [[-1.02287538e-01,  3.92680429e-02, -1.27106816e-01, ...,\n",
      "          1.80100113e-01, -1.17063977e-01, -1.02603473e-01],\n",
      "        [-9.18158591e-02,  4.82404372e-03, -5.90493158e-03, ...,\n",
      "          1.67383254e-01, -1.52504165e-02,  7.53441527e-02],\n",
      "        [ 2.00756714e-02, -6.39998317e-02, -3.25295888e-02, ...,\n",
      "          6.41207397e-02,  2.51006912e-02,  5.70439622e-02],\n",
      "        ...,\n",
      "        [ 1.70891151e-01,  1.98330334e-03, -2.11713016e-01, ...,\n",
      "          3.28313023e-01, -2.32937440e-01,  1.06023893e-01],\n",
      "        [ 1.70891151e-01,  1.98330334e-03, -2.11713016e-01, ...,\n",
      "          3.28313023e-01, -2.32937440e-01,  1.06023893e-01],\n",
      "        [ 1.70891151e-01,  1.98330334e-03, -2.11713016e-01, ...,\n",
      "          3.28313023e-01, -2.32937440e-01,  1.06023893e-01]],\n",
      "\n",
      "       [[-6.88854828e-02, -8.22831765e-02, -2.37108529e-01, ...,\n",
      "          2.51196045e-03,  9.17659923e-02, -2.88391590e-01],\n",
      "        [ 6.51863515e-02,  7.71759152e-02, -2.12413847e-01, ...,\n",
      "         -1.19892739e-01,  2.76065012e-03, -1.52023481e-02],\n",
      "        [ 7.42685841e-03,  5.11200689e-02, -1.99419498e-01, ...,\n",
      "         -2.02334657e-01, -1.44693814e-03, -8.85888338e-02],\n",
      "        ...,\n",
      "        [-5.85509744e-03,  1.86540663e-01, -3.13636452e-01, ...,\n",
      "          1.67261675e-01, -1.74383625e-01, -2.21357904e-02],\n",
      "        [-5.85509744e-03,  1.86540663e-01, -3.13636452e-01, ...,\n",
      "          1.67261675e-01, -1.74383625e-01, -2.21357904e-02],\n",
      "        [-5.85509744e-03,  1.86540663e-01, -3.13636452e-01, ...,\n",
      "          1.67261675e-01, -1.74383625e-01, -2.21357904e-02]]],\n",
      "      dtype=float32)), label_ids=array([1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 2, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n",
      "       1, 1, 1, 2, 0, 2, 1, 0, 0, 0, 0, 0, 1, 1, 2, 0, 2, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 2, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 2, 1, 0, 1, 0,\n",
      "       1, 0, 2, 1, 0, 1, 1, 1, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "       1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 2, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
      "       1, 0, 0, 0, 1, 0, 0, 0, 2, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
      "       0, 1, 0, 1, 0, 0, 1, 0, 2, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
      "       0, 0, 0, 1, 0, 0, 2, 2, 0, 2, 0, 1, 0, 1, 1, 0, 2, 0, 1, 0, 0, 1,\n",
      "       0, 1, 0, 0, 1, 2, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 2,\n",
      "       0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 2, 0, 0, 2]), metrics={'test_loss': 0.9517315030097961, 'test_accuracy': 0.5897435897435898, 'test_precision': 0.6495841995841997, 'test_recall': 0.5897435897435898, 'test_f1': 0.504040584162288, 'test_runtime': 7.6653, 'test_samples_per_second': 30.527, 'test_steps_per_second': 3.914})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "808dd68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48fb2163",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions_array = np.array(test_results.predictions[0])\n",
    "\n",
    "predictions_tensor = torch.tensor(predictions_array).to(torch.float32)\n",
    "probabilities = torch.softmax(predictions_tensor, dim=-1)\n",
    "\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed6cfde2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")  # Adjust xticklabels and yticklabels as needed\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "346c6d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_save = []\n",
    "for idx in range(len(test_data)):\n",
    "    item = dataset['test'][idx]\n",
    "    actual_label = item['label']\n",
    "    predicted_label = predictions[idx]\n",
    "    claim = item['claim'] \n",
    "    premise = item['premise'] \n",
    "    category = item['category']\n",
    "    \n",
    "    # Append the information as a dictionary to the list\n",
    "    data_to_save.append({\n",
    "        'Claim': claim,\n",
    "        'Premise': premise,\n",
    "        'Actual Label': actual_label,\n",
    "        'Predicted Label': predicted_label,\n",
    "        'Category' : category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_to_save)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/home/elson/results/10.1.4_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4543aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correctly classified instances\n",
    "correctly_classified = df[df['Actual Label'] == df['Predicted Label']]\n",
    "\n",
    "# Calculate misclassified instances\n",
    "misclassified = df[df['Actual Label'] != df['Predicted Label']]\n",
    "\n",
    "# Count the number of correctly classified and misclassified by category\n",
    "correct_classification_counts = correctly_classified['Category'].value_counts()\n",
    "misclassification_counts = misclassified['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad099d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           36\n",
       "Diabetes                 12\n",
       "Cancer                   12\n",
       "Fitness                  10\n",
       "Hair                      9\n",
       "Bone health               9\n",
       "COVID                     6\n",
       "Neurological health       6\n",
       "Cardiovascular Health     6\n",
       "Throat                    6\n",
       "Ear                       6\n",
       "Skin                      5\n",
       "Blood                     4\n",
       "Mental Health             3\n",
       "Eye                       3\n",
       "Vascular                  2\n",
       "Women' s Health           2\n",
       "Men's health              1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d45817c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Skin                     19\n",
       "General Health           15\n",
       "Bone health              12\n",
       "Muscles                   6\n",
       "Eye                       6\n",
       "Cardiovascular Health     6\n",
       "Men's health              5\n",
       "Fitness                   5\n",
       "Blood                     5\n",
       "Women' s Health           4\n",
       "Hair                      3\n",
       "Dental Health             3\n",
       "Neurological health       3\n",
       "Throat                    3\n",
       "Vascular                  1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7fa0ad3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:HfApi.login: This method is deprecated in favor of `set_access_token`.\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "404 Client Error: Not Found for url: https://huggingface.co/api/login",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-42bb60433b92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Logging to HuggingFace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhuggingface_hub\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlogin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"jeffyelson03\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Ovgujeff03#\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/factcheck/lib/python3.6/site-packages/huggingface_hub/hf_api.py\u001b[0m in \u001b[0;36mlogin\u001b[0;34m(self, username, password)\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{self.endpoint}/api/login\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"username\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0musername\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"password\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpassword\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m         \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/factcheck/lib/python3.6/site-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://huggingface.co/api/login"
     ]
    }
   ],
   "source": [
    "#Logging to HuggingFace\n",
    "from huggingface_hub import login\n",
    "login(\"jeffyelson03\",\"Ovgujeff03#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9f7cd62a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'HfApi' object has no attribute 'upload_folder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-af4272c879bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Upload the files to the Hugging Face repository\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m#Upload Model folder from Local to HuggingFace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m api.upload_folder(\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mfolder_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mrepo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'HfApi' object has no attribute 'upload_folder'"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfApi, HfFolder,Repository\n",
    "\n",
    "\n",
    "# Define the model and tokenizer names or paths\n",
    "model_name = model_path\n",
    "\n",
    "# Define your Hugging Face model repository id\n",
    "repo_id = \"jeffyelson03/FLANT5_SentenceLevel_NER_Evidence\"\n",
    "# Initialize the Hugging Face API\n",
    "api = HfApi()\n",
    "\n",
    "# Log in using your Hugging Face credentials\n",
    "username = \"jeffyelson03\"\n",
    "api_token = HfFolder.save_token(\"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\")\n",
    "\n",
    "\n",
    "# Create the repository on Hugging Face\n",
    "#api.create_repo(name=repo_id)\n",
    "\n",
    "# Upload the files to the Hugging Face repository\n",
    "#Upload Model folder from Local to HuggingFace \n",
    "api.upload_folder(\n",
    "    folder_path=model_path,\n",
    "    repo_id=repo_id\n",
    ")\n",
    "\n",
    "# Publish Model Tokenizer on Hugging Face\n",
    "tokenizer.push_to_hub(model_repo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd1ecc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
