{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45f1f111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/nvidia-modprobe: unrecognized option: \"-s\"\n",
      "\n",
      "ERROR: Invalid commandline, please run `/usr/bin/nvidia-modprobe --help` for\n",
      "       usage information.\n",
      "\n",
      "/usr/bin/nvidia-modprobe: unrecognized option: \"-s\"\n",
      "\n",
      "ERROR: Invalid commandline, please run `/usr/bin/nvidia-modprobe --help` for\n",
      "       usage information.\n",
      "\n",
      "Sun Aug  4 17:37:20 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.29.06              Driver Version: 545.29.06    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-SXM2-32GB           Off | 00000000:61:00.0 Off |                    0 |\n",
      "| N/A   36C    P0              57W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2-32GB           Off | 00000000:62:00.0 Off |                    0 |\n",
      "| N/A   55C    P0             248W / 300W |  25897MiB / 32768MiB |     93%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2-32GB           Off | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   63C    P0             261W / 300W |  15153MiB / 32768MiB |     89%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2-32GB           Off | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   39C    P0              59W / 300W |      0MiB / 32768MiB |      2%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    1   N/A  N/A     44521      C   /home/elson/factcheck/bin/python3         25894MiB |\n",
      "|    2   N/A  N/A     43641      C   /home/elson/factcheck/bin/python3         15150MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-47509a4ace11a992\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-47509a4ace11a992/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 253.89it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('csv',data_files='dataset_sentenceattribution_nerfeatures_split.csv',delimiter=',',column_names=[\"claim\",\"premise\",\"label\",\"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\",\"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\",\"url\", \"entities\",\"entity_map\",\"entity_map_ev\",\"entity_ev\",\"gem_exp\",\"gem_label\",\"gpt_exp\",\"gpt_label\",\"gold_exp\",\"synonym\",\"voice\",\"split\"],skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e2914c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'entity_map_ev', 'entity_ev', 'gem_exp', 'gem_label', 'gpt_exp', 'gpt_label', 'gold_exp', 'synonym', 'voice', 'split'],\n",
       "        num_rows: 2322\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57d56e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'test',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['split']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ce96b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-47509a4ace11a992/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-cd7ed25d4d332523.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-47509a4ace11a992/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-caadbcafda8de4b1.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-47509a4ace11a992/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-9e929b5a7841f440.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'entity_map_ev', 'entity_ev', 'gem_exp', 'gem_label', 'gpt_exp', 'gpt_label', 'gold_exp', 'synonym', 'voice', 'split'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'entity_map_ev', 'entity_ev', 'gem_exp', 'gem_label', 'gpt_exp', 'gpt_label', 'gold_exp', 'synonym', 'voice', 'split'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'entity_map_ev', 'entity_ev', 'gem_exp', 'gem_label', 'gpt_exp', 'gpt_label', 'gold_exp', 'synonym', 'voice', 'split'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41f1db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\"claim\", \"premise\", \"label\", \"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\"]\n",
    "all_columns = dataset[\"train\"].column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-47509a4ace11a992/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-73f2ab8bfe66828e.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-47509a4ace11a992/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-b3c3298c42898a00.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-47509a4ace11a992/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-4b891ab422a84f19.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 1, 'entailment': 0, 'neutral': 1}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 1,\n",
    "    \"entailment\": 0,\n",
    "    \"neutral\": 1\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='MoritzLaurer/DeBERTa-v3-base-mnli-fever-docnli-ling-2c'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "        # Extracting claim and evidence texts\n",
    "        claim = item['claim'] \n",
    "        evidences = item['premise']\n",
    "        item['premise']=evidences\n",
    "        item['claim']=claim\n",
    "        additional_features = [\n",
    "            \"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\"]\n",
    "    \n",
    "        for feature in additional_features:\n",
    "            if feature in item:\n",
    "                claim += \"[SEP]\" + str(item[feature])\n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "            evidences,claim,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "         # Construct the output item\n",
    "        output_item = {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),  # Remove batch dimension\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),  # Remove batch dimension\n",
    "            'claim': claim,  # Include augmented claim text\n",
    "            'evidences': evidences  # Include original evidence text\n",
    "        }\n",
    "        \n",
    "        if 'label' in item:\n",
    "            output_item['label'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return output_item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62421eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at MoritzLaurer/DeBERTa-v3-base-mnli-fever-docnli-ling-2c and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([3, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([2]) in the checkpoint and torch.Size([3]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DebertaV2ForSequenceClassification(\n",
       "  (deberta): DebertaV2Model(\n",
       "    (embeddings): DebertaV2Embeddings(\n",
       "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaV2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (1): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (2): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (3): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (4): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (5): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (6): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (7): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (8): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (9): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (10): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (11): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (pooler): ContextPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): StableDropout()\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (dropout): StableDropout()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"MoritzLaurer/DeBERTa-v3-base-mnli-fever-docnli-ling-2c\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=3, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    bal_accuracy = balanced_accuracy_score(labels,preds)\n",
    "\n",
    "    return {\"accuracy\": acc, \"balanced_accuracy\":bal_accuracy, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17c5e0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([    1,  4081,   261,  5042,   333, 73325,  1452,  2155,  6116,  1938,\n",
       "           272,   262, 88609,   263, 98237,  1830,  1080,  7355,   387,  2655,\n",
       "           262, 12682,   265, 65008,   292,  1158, 53245,   264, 75840,   293,\n",
       "          2376,  1158,  1452,  2155,   260,     2,   573, 52341,  1830,  1080,\n",
       "           269,  1359,   427,   267, 17847,   633,   264,   408,  1300,   262,\n",
       "          2658,   265,   262,  1158,   260,     2,   767,     2,   767,     2,\n",
       "           767,     2,   767,     2,   767,     2,   767,     2,   767,     2,\n",
       "           767,     2,   767,     2,   767,     2,   767,     2,   767,     2,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'claim': 'Myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0',\n",
       " 'evidences': 'Additionally, laser doppler blood flow measurement showed that the frankincense and myrrh essential oil compound could promote the elimination of capillaries from skin epidermis to dermis by increasing skin blood flow.',\n",
       " 'label': tensor(1)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 765\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='765' max='765' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [765/765 11:27, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.599100</td>\n",
       "      <td>0.649030</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.620270</td>\n",
       "      <td>0.681161</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.645670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.471900</td>\n",
       "      <td>0.648453</td>\n",
       "      <td>0.722581</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.719380</td>\n",
       "      <td>0.722581</td>\n",
       "      <td>0.719987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.259700</td>\n",
       "      <td>0.805879</td>\n",
       "      <td>0.720430</td>\n",
       "      <td>0.728427</td>\n",
       "      <td>0.739138</td>\n",
       "      <td>0.720430</td>\n",
       "      <td>0.723367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.181600</td>\n",
       "      <td>0.983223</td>\n",
       "      <td>0.726882</td>\n",
       "      <td>0.709025</td>\n",
       "      <td>0.724296</td>\n",
       "      <td>0.726882</td>\n",
       "      <td>0.725007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.142900</td>\n",
       "      <td>1.143240</td>\n",
       "      <td>0.722581</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.719380</td>\n",
       "      <td>0.722581</td>\n",
       "      <td>0.719987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.098000</td>\n",
       "      <td>1.369809</td>\n",
       "      <td>0.713978</td>\n",
       "      <td>0.712983</td>\n",
       "      <td>0.722819</td>\n",
       "      <td>0.713978</td>\n",
       "      <td>0.716347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>1.414202</td>\n",
       "      <td>0.718280</td>\n",
       "      <td>0.718388</td>\n",
       "      <td>0.727983</td>\n",
       "      <td>0.718280</td>\n",
       "      <td>0.720724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.044900</td>\n",
       "      <td>1.668571</td>\n",
       "      <td>0.716129</td>\n",
       "      <td>0.696429</td>\n",
       "      <td>0.712922</td>\n",
       "      <td>0.716129</td>\n",
       "      <td>0.713657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.074500</td>\n",
       "      <td>1.619888</td>\n",
       "      <td>0.729032</td>\n",
       "      <td>0.718147</td>\n",
       "      <td>0.729545</td>\n",
       "      <td>0.729032</td>\n",
       "      <td>0.729275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.023900</td>\n",
       "      <td>1.668205</td>\n",
       "      <td>0.729032</td>\n",
       "      <td>0.720898</td>\n",
       "      <td>0.731273</td>\n",
       "      <td>0.729032</td>\n",
       "      <td>0.729936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.015400</td>\n",
       "      <td>1.718237</td>\n",
       "      <td>0.716129</td>\n",
       "      <td>0.702847</td>\n",
       "      <td>0.715623</td>\n",
       "      <td>0.716129</td>\n",
       "      <td>0.715863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>1.716368</td>\n",
       "      <td>0.729032</td>\n",
       "      <td>0.719064</td>\n",
       "      <td>0.730089</td>\n",
       "      <td>0.729032</td>\n",
       "      <td>0.729507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>1.774390</td>\n",
       "      <td>0.726882</td>\n",
       "      <td>0.719112</td>\n",
       "      <td>0.729452</td>\n",
       "      <td>0.726882</td>\n",
       "      <td>0.727894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>1.804430</td>\n",
       "      <td>0.729032</td>\n",
       "      <td>0.720898</td>\n",
       "      <td>0.731273</td>\n",
       "      <td>0.729032</td>\n",
       "      <td>0.729936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.017600</td>\n",
       "      <td>1.814571</td>\n",
       "      <td>0.729032</td>\n",
       "      <td>0.720898</td>\n",
       "      <td>0.731273</td>\n",
       "      <td>0.729032</td>\n",
       "      <td>0.729936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.3_deberta_docnli/checkpoint-51\n",
      "Configuration saved in /home/elson/5.1.3_deberta_docnli/checkpoint-51/config.json\n",
      "Model weights saved in /home/elson/5.1.3_deberta_docnli/checkpoint-51/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.3_deberta_docnli/checkpoint-102\n",
      "Configuration saved in /home/elson/5.1.3_deberta_docnli/checkpoint-102/config.json\n",
      "Model weights saved in /home/elson/5.1.3_deberta_docnli/checkpoint-102/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.3_deberta_docnli/checkpoint-51] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.3_deberta_docnli/checkpoint-153\n",
      "Configuration saved in /home/elson/5.1.3_deberta_docnli/checkpoint-153/config.json\n",
      "Model weights saved in /home/elson/5.1.3_deberta_docnli/checkpoint-153/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.3_deberta_docnli/checkpoint-102] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.3_deberta_docnli/checkpoint-204\n",
      "Configuration saved in /home/elson/5.1.3_deberta_docnli/checkpoint-204/config.json\n",
      "Model weights saved in /home/elson/5.1.3_deberta_docnli/checkpoint-204/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.3_deberta_docnli/checkpoint-153] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.3_deberta_docnli/checkpoint-255\n",
      "Configuration saved in /home/elson/5.1.3_deberta_docnli/checkpoint-255/config.json\n",
      "Model weights saved in /home/elson/5.1.3_deberta_docnli/checkpoint-255/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.3_deberta_docnli/checkpoint-306\n",
      "Configuration saved in /home/elson/5.1.3_deberta_docnli/checkpoint-306/config.json\n",
      "Model weights saved in /home/elson/5.1.3_deberta_docnli/checkpoint-306/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.3_deberta_docnli/checkpoint-255] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.3_deberta_docnli/checkpoint-357\n",
      "Configuration saved in /home/elson/5.1.3_deberta_docnli/checkpoint-357/config.json\n",
      "Model weights saved in /home/elson/5.1.3_deberta_docnli/checkpoint-357/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.3_deberta_docnli/checkpoint-306] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.3_deberta_docnli/checkpoint-408\n",
      "Configuration saved in /home/elson/5.1.3_deberta_docnli/checkpoint-408/config.json\n",
      "Model weights saved in /home/elson/5.1.3_deberta_docnli/checkpoint-408/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.3_deberta_docnli/checkpoint-357] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.3_deberta_docnli/checkpoint-459\n",
      "Configuration saved in /home/elson/5.1.3_deberta_docnli/checkpoint-459/config.json\n",
      "Model weights saved in /home/elson/5.1.3_deberta_docnli/checkpoint-459/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.3_deberta_docnli/checkpoint-204] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/5.1.3_deberta_docnli/checkpoint-408] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.3_deberta_docnli/checkpoint-510\n",
      "Configuration saved in /home/elson/5.1.3_deberta_docnli/checkpoint-510/config.json\n",
      "Model weights saved in /home/elson/5.1.3_deberta_docnli/checkpoint-510/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.3_deberta_docnli/checkpoint-459] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.3_deberta_docnli/checkpoint-561\n",
      "Configuration saved in /home/elson/5.1.3_deberta_docnli/checkpoint-561/config.json\n",
      "Model weights saved in /home/elson/5.1.3_deberta_docnli/checkpoint-561/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.3_deberta_docnli/checkpoint-612\n",
      "Configuration saved in /home/elson/5.1.3_deberta_docnli/checkpoint-612/config.json\n",
      "Model weights saved in /home/elson/5.1.3_deberta_docnli/checkpoint-612/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.3_deberta_docnli/checkpoint-561] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.3_deberta_docnli/checkpoint-663\n",
      "Configuration saved in /home/elson/5.1.3_deberta_docnli/checkpoint-663/config.json\n",
      "Model weights saved in /home/elson/5.1.3_deberta_docnli/checkpoint-663/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.3_deberta_docnli/checkpoint-612] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.3_deberta_docnli/checkpoint-714\n",
      "Configuration saved in /home/elson/5.1.3_deberta_docnli/checkpoint-714/config.json\n",
      "Model weights saved in /home/elson/5.1.3_deberta_docnli/checkpoint-714/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.3_deberta_docnli/checkpoint-663] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.1.3_deberta_docnli/checkpoint-765\n",
      "Configuration saved in /home/elson/5.1.3_deberta_docnli/checkpoint-765/config.json\n",
      "Model weights saved in /home/elson/5.1.3_deberta_docnli/checkpoint-765/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.1.3_deberta_docnli/checkpoint-714] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/elson/5.1.3_deberta_docnli/checkpoint-510 (score: 0.7299361072152095).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /home/elson/5.1.3_deberta_docnli/best_model/config.json\n",
      "Model weights saved in /home/elson/5.1.3_deberta_docnli/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/5.1.3_deberta_docnli/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/5.1.3_deberta_docnli/best_model/special_tokens_map.json\n",
      "added tokens file saved in /home/elson/5.1.3_deberta_docnli/best_model/added_tokens.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/5.1.3_deberta_docnli/best_model/tokenizer_config.json',\n",
       " '/home/elson/5.1.3_deberta_docnli/best_model/special_tokens_map.json',\n",
       " '/home/elson/5.1.3_deberta_docnli/best_model/spm.model',\n",
       " '/home/elson/5.1.3_deberta_docnli/best_model/added_tokens.json')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/5.1.3_deberta_docnli/',\n",
    "    num_train_epochs=15,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.06,\n",
    "    weight_decay=0.1,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/5.1.3_deberta_docnli/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/5.1.3_deberta_docnli/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63deaea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/5.1.3_deberta_docnli/best_model/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"/home/elson/5.1.3_deberta_docnli/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file /home/elson/5.1.3_deberta_docnli/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at /home/elson/5.1.3_deberta_docnli/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 32\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/5.1.3_deberta_docnli/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[ 1.1611e+00,  3.6211e+00, -5.4258e+00],\n",
      "       [ 6.0898e+00, -1.1006e+00, -4.6875e+00],\n",
      "       [ 5.9492e+00, -9.4629e-01, -4.7070e+00],\n",
      "       [-2.1426e+00,  5.6953e+00, -4.4805e+00],\n",
      "       [ 5.6875e+00, -9.5264e-01, -4.3320e+00],\n",
      "       [ 6.3164e+00, -1.6445e+00, -4.1836e+00],\n",
      "       [ 5.8555e+00, -1.1240e+00, -4.2891e+00],\n",
      "       [ 6.2461e+00, -1.6934e+00, -4.0820e+00],\n",
      "       [ 6.2109e+00, -1.2412e+00, -4.5820e+00],\n",
      "       [-6.1621e-01,  4.6211e+00, -4.6250e+00],\n",
      "       [ 6.0078e+00, -1.2432e+00, -4.4180e+00],\n",
      "       [ 6.2617e+00, -1.5850e+00, -4.2266e+00],\n",
      "       [ 5.3516e+00,  1.5210e-01, -5.4375e+00],\n",
      "       [ 6.3047e+00, -1.7041e+00, -4.1016e+00],\n",
      "       [-2.0879e+00,  5.3477e+00, -4.1406e+00],\n",
      "       [-2.0645e+00,  5.6289e+00, -4.5430e+00],\n",
      "       [ 5.3086e+00, -1.5125e-01, -5.1211e+00],\n",
      "       [ 4.8281e+00, -1.6748e-01, -4.6836e+00],\n",
      "       [ 6.2734e+00, -1.6045e+00, -4.2109e+00],\n",
      "       [ 6.0664e+00, -9.5801e-01, -4.8164e+00],\n",
      "       [-1.5645e+00,  5.5430e+00, -4.7422e+00],\n",
      "       [ 5.8477e+00, -5.2832e-01, -5.1055e+00],\n",
      "       [-7.5586e-01,  4.3359e+00, -4.0781e+00],\n",
      "       [-1.3535e+00,  5.3789e+00, -4.7031e+00],\n",
      "       [-7.5146e-01,  5.1289e+00, -5.0898e+00],\n",
      "       [-2.4199e+00,  5.8086e+00, -4.3711e+00],\n",
      "       [ 6.2500e+00, -1.6484e+00, -4.1406e+00],\n",
      "       [-1.5293e+00,  5.5508e+00, -4.7578e+00],\n",
      "       [ 4.3203e+00,  5.7080e-01, -4.9805e+00],\n",
      "       [ 6.2852e+00, -1.5176e+00, -4.2891e+00],\n",
      "       [-1.5742e+00,  5.5859e+00, -4.7773e+00],\n",
      "       [ 5.9531e+00, -7.8809e-01, -4.8945e+00],\n",
      "       [ 5.6328e+00, -7.3340e-01, -4.5938e+00],\n",
      "       [ 4.5312e+00,  1.0322e+00, -5.6914e+00],\n",
      "       [-1.8926e+00,  5.7148e+00, -4.6719e+00],\n",
      "       [-1.2344e+00,  5.0703e+00, -4.4648e+00],\n",
      "       [ 5.6367e+00, -2.7612e-01, -5.2344e+00],\n",
      "       [ 6.1836e+00, -1.2422e+00, -4.5703e+00],\n",
      "       [-2.2715e+00,  5.8398e+00, -4.5312e+00],\n",
      "       [-4.0039e-01,  4.8086e+00, -5.0078e+00],\n",
      "       [-1.8506e+00,  5.3438e+00, -4.2773e+00],\n",
      "       [ 6.2266e+00, -1.4746e+00, -4.2656e+00],\n",
      "       [ 4.0977e+00,  4.6143e-01, -4.4297e+00],\n",
      "       [-2.1992e+00,  5.8594e+00, -4.6055e+00],\n",
      "       [-2.1172e+00,  5.9258e+00, -4.7070e+00],\n",
      "       [-3.7891e-01,  4.5078e+00, -4.6914e+00],\n",
      "       [ 1.7637e+00,  3.2773e+00, -5.5547e+00],\n",
      "       [ 4.2383e+00,  1.0547e+00, -5.3984e+00],\n",
      "       [ 5.7891e+00, -5.5518e-01, -5.0625e+00],\n",
      "       [-1.6836e+00,  5.1133e+00, -4.1289e+00],\n",
      "       [-1.8965e+00,  5.4180e+00, -4.2773e+00],\n",
      "       [-7.0679e-02,  4.7891e+00, -5.3555e+00],\n",
      "       [-7.4268e-01,  4.8828e+00, -4.7773e+00],\n",
      "       [-1.1116e-02,  4.7812e+00, -5.4766e+00],\n",
      "       [-2.3223e+00,  5.5859e+00, -4.2969e+00],\n",
      "       [ 6.3242e+00, -1.7158e+00, -4.1016e+00],\n",
      "       [-9.2236e-01,  4.1367e+00, -3.7363e+00],\n",
      "       [ 5.7578e+00, -7.7441e-01, -4.6523e+00],\n",
      "       [ 5.7344e+00, -4.0161e-01, -5.1719e+00],\n",
      "       [ 6.2930e+00, -1.5342e+00, -4.2656e+00],\n",
      "       [ 6.1406e+00, -1.0918e+00, -4.6758e+00],\n",
      "       [-2.0469e+00,  5.5312e+00, -4.3516e+00],\n",
      "       [ 6.1680e+00, -1.2080e+00, -4.5547e+00],\n",
      "       [ 4.7148e+00,  4.7754e-01, -5.1172e+00],\n",
      "       [ 3.8672e-01,  3.9590e+00, -4.8320e+00],\n",
      "       [ 6.2578e+00, -1.5498e+00, -4.2773e+00],\n",
      "       [ 1.4014e+00,  3.5410e+00, -5.5938e+00],\n",
      "       [ 6.0625e+00, -1.3467e+00, -4.2266e+00],\n",
      "       [ 4.8672e+00, -2.1240e-01, -4.6172e+00],\n",
      "       [-7.8906e-01,  4.9102e+00, -4.7695e+00],\n",
      "       [ 5.3398e+00, -1.5833e-01, -5.0625e+00],\n",
      "       [-5.4102e-01,  4.2422e+00, -4.2070e+00],\n",
      "       [ 2.3496e+00,  2.8379e+00, -5.5859e+00],\n",
      "       [ 1.7666e+00,  3.4238e+00, -5.7344e+00],\n",
      "       [-4.2212e-01,  4.7812e+00, -5.0547e+00],\n",
      "       [ 5.1074e-01,  3.8926e+00, -4.9102e+00],\n",
      "       [ 2.5039e+00,  2.5273e+00, -5.4766e+00],\n",
      "       [ 6.1641e+00, -1.2422e+00, -4.4883e+00],\n",
      "       [ 6.2656e+00, -1.6533e+00, -4.1445e+00],\n",
      "       [ 5.7812e+00, -4.9683e-01, -5.1016e+00],\n",
      "       [ 6.2930e+00, -1.5732e+00, -4.2266e+00],\n",
      "       [ 6.0742e+00, -1.2256e+00, -4.4297e+00],\n",
      "       [ 6.2383e+00, -1.4346e+00, -4.3906e+00],\n",
      "       [ 6.2656e+00, -1.5605e+00, -4.1992e+00],\n",
      "       [ 6.2773e+00, -1.6279e+00, -4.1328e+00],\n",
      "       [-2.1348e+00,  5.8711e+00, -4.6406e+00],\n",
      "       [ 6.2578e+00, -1.4609e+00, -4.3633e+00],\n",
      "       [ 6.0078e+00, -8.6914e-01, -4.8320e+00],\n",
      "       [ 4.9336e+00,  4.3408e-01, -5.3438e+00],\n",
      "       [ 6.1992e+00, -1.2715e+00, -4.5117e+00],\n",
      "       [ 6.1758e+00, -1.1582e+00, -4.6602e+00],\n",
      "       [ 6.2891e+00, -1.6152e+00, -4.2031e+00],\n",
      "       [-2.0703e+00,  5.7344e+00, -4.5938e+00],\n",
      "       [ 6.2070e+00, -1.2744e+00, -4.5469e+00],\n",
      "       [ 5.9102e+00, -7.4658e-01, -4.9375e+00],\n",
      "       [ 5.0195e+00, -1.0016e-01, -4.7031e+00],\n",
      "       [-1.5488e+00,  5.6250e+00, -4.8242e+00],\n",
      "       [ 7.5342e-01,  4.0469e+00, -5.4570e+00],\n",
      "       [ 6.2969e+00, -1.6182e+00, -4.2031e+00],\n",
      "       [ 6.2930e+00, -1.6826e+00, -4.1289e+00],\n",
      "       [-9.6558e-02,  4.1406e+00, -4.5625e+00],\n",
      "       [ 5.0625e+00,  1.7566e-01, -5.1367e+00],\n",
      "       [ 6.2930e+00, -1.5820e+00, -4.2344e+00],\n",
      "       [ 1.5127e+00,  3.5312e+00, -5.5625e+00],\n",
      "       [ 6.1953e+00, -1.1816e+00, -4.6133e+00],\n",
      "       [ 6.2617e+00, -1.4766e+00, -4.3398e+00],\n",
      "       [ 5.8320e+00, -5.5371e-01, -5.0391e+00],\n",
      "       [-1.7959e+00,  5.0742e+00, -4.0859e+00],\n",
      "       [ 6.3086e+00, -1.6729e+00, -4.1328e+00],\n",
      "       [ 5.7773e+00, -4.2871e-01, -5.1445e+00],\n",
      "       [-2.0776e-01,  4.8867e+00, -5.3984e+00],\n",
      "       [ 6.3242e+00, -1.7031e+00, -4.1016e+00],\n",
      "       [ 6.1406e+00, -1.1865e+00, -4.6211e+00],\n",
      "       [-6.8799e-01,  5.0586e+00, -4.9609e+00],\n",
      "       [ 6.3008e+00, -1.6162e+00, -4.2070e+00],\n",
      "       [ 4.7500e+00,  4.8584e-01, -5.3398e+00],\n",
      "       [ 6.2773e+00, -1.6211e+00, -4.1836e+00],\n",
      "       [ 6.2773e+00, -1.5244e+00, -4.3008e+00],\n",
      "       [ 5.9062e+00, -6.5869e-01, -5.0078e+00],\n",
      "       [ 6.2070e+00, -1.3320e+00, -4.4766e+00],\n",
      "       [ 6.3164e+00, -1.5654e+00, -4.2656e+00],\n",
      "       [ 5.9727e+00, -7.6318e-01, -4.9492e+00],\n",
      "       [ 6.2617e+00, -1.4570e+00, -4.3828e+00],\n",
      "       [ 1.2783e+00,  3.6270e+00, -5.4414e+00],\n",
      "       [-1.6553e+00,  3.7734e+00, -3.1055e+00],\n",
      "       [-2.2129e+00,  5.1719e+00, -4.0234e+00],\n",
      "       [-1.4971e+00,  5.0938e+00, -4.2734e+00],\n",
      "       [ 6.2812e+00, -1.5205e+00, -4.2578e+00],\n",
      "       [ 6.2461e+00, -1.3525e+00, -4.5117e+00],\n",
      "       [ 5.1406e+00,  2.5171e-01, -5.3477e+00],\n",
      "       [ 4.8789e+00,  5.3076e-01, -5.4141e+00],\n",
      "       [-2.1113e+00,  5.6367e+00, -4.4297e+00],\n",
      "       [ 3.9746e+00,  7.6367e-01, -4.9141e+00],\n",
      "       [-1.7617e+00,  3.6836e+00, -2.9961e+00],\n",
      "       [ 9.0771e-01,  3.6113e+00, -4.9297e+00],\n",
      "       [-1.9805e+00,  5.1367e+00, -4.0898e+00],\n",
      "       [ 5.7109e+00, -4.3042e-01, -5.1211e+00],\n",
      "       [ 2.4102e+00,  2.7148e+00, -5.5703e+00],\n",
      "       [-2.0117e+00,  5.8203e+00, -4.6758e+00],\n",
      "       [ 6.2812e+00, -1.6172e+00, -4.1914e+00],\n",
      "       [ 5.9727e+00, -1.0498e+00, -4.5586e+00],\n",
      "       [ 2.6973e+00,  2.6602e+00, -5.7344e+00],\n",
      "       [ 5.9883e+00, -8.0469e-01, -4.9023e+00],\n",
      "       [ 6.0664e+00, -1.4111e+00, -4.2852e+00],\n",
      "       [ 5.7109e+00, -3.3350e-01, -5.2070e+00],\n",
      "       [ 5.7578e+00, -6.2256e-01, -4.9766e+00],\n",
      "       [-1.8955e+00,  5.6484e+00, -4.5469e+00],\n",
      "       [-1.8770e+00,  5.6953e+00, -4.6406e+00],\n",
      "       [ 1.4131e+00,  3.5391e+00, -5.5156e+00],\n",
      "       [-9.8438e-01,  5.2539e+00, -4.9531e+00],\n",
      "       [-2.3184e+00,  5.4023e+00, -4.1719e+00],\n",
      "       [ 6.1094e+00, -1.2051e+00, -4.5547e+00],\n",
      "       [ 6.3008e+00, -1.6484e+00, -4.1562e+00],\n",
      "       [ 5.9922e+00, -9.5020e-01, -4.7969e+00],\n",
      "       [ 6.2656e+00, -1.4521e+00, -4.3750e+00],\n",
      "       [ 6.2109e+00, -1.6650e+00, -4.0820e+00],\n",
      "       [ 6.2383e+00, -1.3271e+00, -4.4727e+00],\n",
      "       [-1.8770e+00,  5.2812e+00, -4.2500e+00],\n",
      "       [ 5.4102e+00,  3.5034e-02, -5.3750e+00],\n",
      "       [-2.3340e+00,  5.5352e+00, -4.3516e+00],\n",
      "       [-2.4805e+00,  5.7148e+00, -4.2695e+00],\n",
      "       [-2.2969e+00,  5.1094e+00, -3.9473e+00],\n",
      "       [ 6.2188e+00, -1.6006e+00, -4.1797e+00],\n",
      "       [-1.3848e+00,  5.4688e+00, -4.8398e+00],\n",
      "       [ 5.3906e+00, -1.9763e-01, -5.0234e+00],\n",
      "       [ 5.9570e+00, -8.0420e-01, -4.8867e+00],\n",
      "       [ 5.9648e+00, -7.9590e-01, -4.9102e+00],\n",
      "       [-2.2539e+00,  5.5859e+00, -4.3359e+00],\n",
      "       [-2.0820e+00,  4.9570e+00, -3.9316e+00],\n",
      "       [ 4.9844e+00,  4.7510e-01, -5.5039e+00],\n",
      "       [-2.3906e+00,  5.8633e+00, -4.4414e+00],\n",
      "       [ 4.0312e+00,  1.5010e+00, -5.6445e+00],\n",
      "       [-1.7285e+00,  4.0234e+00, -3.2559e+00],\n",
      "       [ 6.2734e+00, -1.6475e+00, -4.1641e+00],\n",
      "       [ 6.1914e+00, -1.2686e+00, -4.5469e+00],\n",
      "       [-2.0508e+00,  5.8008e+00, -4.6172e+00],\n",
      "       [ 6.2227e+00, -1.3467e+00, -4.4922e+00],\n",
      "       [ 5.6133e+00, -3.7451e-01, -5.0312e+00],\n",
      "       [ 4.6836e+00,  8.3008e-01, -5.5938e+00],\n",
      "       [-1.9463e+00,  5.7305e+00, -4.6172e+00],\n",
      "       [-1.8438e+00,  4.9805e+00, -4.0156e+00],\n",
      "       [-3.3618e-01,  4.7930e+00, -5.1484e+00],\n",
      "       [-1.9863e+00,  5.7578e+00, -4.5859e+00],\n",
      "       [ 8.6426e-01,  3.8516e+00, -5.3984e+00],\n",
      "       [-1.9277e+00,  5.5000e+00, -4.4648e+00],\n",
      "       [ 6.2305e+00, -1.5273e+00, -4.2852e+00],\n",
      "       [ 5.9727e+00, -9.7607e-01, -4.6484e+00],\n",
      "       [ 5.5664e+00, -3.4985e-01, -5.1367e+00],\n",
      "       [ 5.0586e+00,  2.1863e-01, -5.1992e+00],\n",
      "       [ 5.4570e+00, -3.8110e-01, -4.8203e+00],\n",
      "       [-2.1094e+00,  5.8633e+00, -4.6523e+00],\n",
      "       [-8.8525e-01,  4.6133e+00, -4.2617e+00],\n",
      "       [-1.0498e+00,  4.2031e+00, -3.6387e+00],\n",
      "       [ 1.0449e+00,  3.7891e+00, -5.4570e+00],\n",
      "       [-2.2676e+00,  5.8477e+00, -4.5273e+00],\n",
      "       [ 6.2656e+00, -1.5908e+00, -4.1602e+00],\n",
      "       [ 6.2188e+00, -1.2441e+00, -4.5781e+00],\n",
      "       [ 6.2852e+00, -1.5723e+00, -4.2461e+00],\n",
      "       [ 6.2383e+00, -1.4736e+00, -4.2852e+00],\n",
      "       [ 3.3711e+00,  1.7148e+00, -5.2383e+00],\n",
      "       [ 6.2070e+00, -1.4023e+00, -4.3906e+00],\n",
      "       [ 6.1289e+00, -1.0566e+00, -4.7383e+00],\n",
      "       [ 4.8242e+00,  4.2236e-01, -5.3125e+00],\n",
      "       [ 6.3008e+00, -1.5303e+00, -4.2852e+00],\n",
      "       [-2.0918e+00,  5.2617e+00, -4.1602e+00],\n",
      "       [-2.4121e+00,  5.7070e+00, -4.3750e+00],\n",
      "       [ 6.0156e+00, -9.6191e-01, -4.6562e+00],\n",
      "       [ 5.2461e+00, -6.0806e-03, -5.2383e+00],\n",
      "       [ 6.3086e+00, -1.7246e+00, -4.0938e+00],\n",
      "       [ 6.0703e+00, -1.0205e+00, -4.7227e+00],\n",
      "       [-9.7412e-01,  5.3281e+00, -5.0938e+00],\n",
      "       [ 3.5547e+00,  1.3467e+00, -4.9492e+00],\n",
      "       [ 6.2812e+00, -1.5586e+00, -4.2578e+00],\n",
      "       [ 2.5820e+00,  2.5488e+00, -5.5156e+00],\n",
      "       [ 6.2969e+00, -1.6533e+00, -4.1250e+00],\n",
      "       [-1.6406e+00,  5.3633e+00, -4.5156e+00],\n",
      "       [-1.7031e+00,  5.0000e+00, -4.1406e+00],\n",
      "       [ 4.2891e+00,  1.2334e+00, -5.7070e+00],\n",
      "       [ 6.3008e+00, -1.6875e+00, -4.0859e+00],\n",
      "       [-1.5547e+00,  5.2656e+00, -4.4102e+00],\n",
      "       [ 6.2930e+00, -1.6406e+00, -4.1836e+00],\n",
      "       [ 5.4180e+00, -4.2114e-01, -4.7695e+00],\n",
      "       [ 2.8477e+00,  1.9062e+00, -5.1289e+00],\n",
      "       [ 6.2891e+00, -1.4854e+00, -4.3477e+00],\n",
      "       [ 5.9961e+00, -8.8086e-01, -4.7617e+00],\n",
      "       [ 6.3008e+00, -1.6934e+00, -4.0781e+00],\n",
      "       [ 6.3086e+00, -1.6768e+00, -4.1250e+00],\n",
      "       [-2.3105e+00,  5.4141e+00, -4.2266e+00],\n",
      "       [-9.9561e-01,  5.3359e+00, -5.0781e+00],\n",
      "       [ 6.2734e+00, -1.5127e+00, -4.3047e+00],\n",
      "       [ 6.2656e+00, -1.4697e+00, -4.3711e+00],\n",
      "       [ 6.2812e+00, -1.5361e+00, -4.2695e+00],\n",
      "       [ 6.1719e+00, -1.1455e+00, -4.6484e+00],\n",
      "       [ 6.0391e+00, -9.5264e-01, -4.7812e+00]], dtype=float16), label_ids=array([1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n",
      "       1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n",
      "       1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "       1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
      "       1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
      "       0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
      "       0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n",
      "       0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1,\n",
      "       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1]), metrics={'test_loss': 1.4208879470825195, 'test_accuracy': 0.7606837606837606, 'test_balanced_accuracy': 0.7556580971215118, 'test_precision': 0.7664899203360742, 'test_recall': 0.7606837606837606, 'test_f1': 0.757833273205863, 'test_runtime': 1.9769, 'test_samples_per_second': 118.365, 'test_steps_per_second': 4.047})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73395d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjQAAAG5CAYAAACZTa6YAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAmFklEQVR4nO3de7xcdXnv8c83XAwotwSIEUGwIpZDBStFlEJVRMXqAT0UtdpGmxovaL1RBWvFWy20HNCqVaOoURTBCoeLFqERtHgBIiBXEUSRSyDchYBAwnP+mBXcpMnOzjCzZ8+sz9vXeu1Zl1m/Z7Yv2A/P8/vNSlUhSZI0zKYNOgBJkqRHy4RGkiQNPRMaSZI09ExoJEnS0DOhkSRJQ8+ERpIkDT0TGmlIJNkgyalJ7kryzUdxn9ckOaOXsQ1Ckv9MMmfQcUiaGkxopB5L8pdJFiW5J8ni5g/vn/bg1gcAs4CZVfUX3d6kqr5WVS/sQTyPkOS5SSrJSSsd37k5fvYE7/PBJMeu6bqq2reqFnQZrqQRY0Ij9VCSdwEfBz5GJ/nYBvh3YL8e3P5JwC+qalkP7tUvtwDPTjJzzLE5wC96NUA6/HeXpEfwXwpSjyTZBPgwcFBVnVhVS6vqwao6tar+vrnmMUk+nuTGZvt4ksc0556b5Pok706ypKnuvL459yHgA8Arm8rP3JUrGUm2bSoh6zb7r0tyTZK7k/wqyWvGHD9nzPuek+T8ppV1fpLnjDl3dpKPJPlhc58zkmw+zq/hAeD/Aa9q3r8O8Ergayv9rj6R5Lokv03y0yR7NsdfDLxvzOf82Zg4/inJD4F7gSc3x/62Of+ZJN8ac/8jkixMkon+/ydpuJnQSL3zbGA6cNI41/wDsDuwC7AzsBvw/jHnHw9sAmwFzAU+nWSzqjqMTtXn+Kp6XFUdM14gSR4L/Buwb1VtBDwHuGgV180Avt1cOxM4Cvj2ShWWvwReD2wJrA8cPN7YwFeAv25evwi4FLhxpWvOp/M7mAF8HfhmkulVdfpKn3PnMe/5K2AesBFw7Ur3ezfwR02ytied392c8tkuUmuY0Ei9MxO4dQ0todcAH66qJVV1C/AhOn+oV3iwOf9gVX0HuAfYoct4HgJ2SrJBVS2uqstWcc2fA1dV1VerallVHQf8HHjZmGu+VFW/qKr7gBPoJCKrVVU/AmYk2YFOYvOVVVxzbFXd1oz5f4HHsObP+eWquqx5z4Mr3e9eOr/Ho4BjgbdV1fVruJ+kEWJCI/XObcDmK1o+q/EEHllduLY59vA9VkqI7gUet7aBVNVSOq2eNwGLk3w7ydMmEM+KmLYas39TF/F8FXgr8DxWUbFKcnCSK5o21510qlLjtbIArhvvZFWdC1wDhE7iJalFTGik3vkxcD+w/zjX3Ehncu8K2/A/2zETtRTYcMz+48eerKrvVtU+wGw6VZfPTyCeFTHd0GVMK3wVeAvwnaZ68rCmJfQe4EBgs6raFLiLTiICsLo20bjtoyQH0an03NjcX1KLmNBIPVJVd9GZuPvpJPsn2TDJekn2TfIvzWXHAe9PskUzufYDdFok3bgI2CvJNs2E5ENXnEgyK8l+zVya++m0rh5axT2+Azy1WWq+bpJXAjsCp3UZEwBV9Svgz+jMGVrZRsAyOiui1k3yAWDjMedvBrZdm5VMSZ4KfBR4LZ3W03uS7NJd9JKGkQmN1EPNfJB30ZnoewudNslb6az8gc4f3UXAxcAlwAXNsW7GOhM4vrnXT3lkEjKtieNG4HY6ycWbV3GP24CX0plUexudysZLq+rWbmJa6d7nVNWqqk/fBU6ns5T7WuB3PLKdtOJLA29LcsGaxmlafMcCR1TVz6rqKjorpb66YgWZpNEXFwFIkqRhZ4VGkiQNPRMaSZI09ExoJEnS0DOhkSRJQ2+8LwAbqA2e8VZnK0sDcMf5nxp0CFJrTV+XSX3+WC//1t534acG+uw0KzSSJGnoTdkKjSRJ6rOJf3/llDc6n0SSJLWWFRpJktoqA5320lMmNJIktZUtJ0mSpKnDCo0kSW1ly0mSJA09W06SJElThxUaSZLaypaTJEkaeracJEmSpg4rNJIktZUtJ0mSNPRsOUmSJE0dVmgkSWorW06SJGno2XKSJEmaOkxoJElqq6R32xqHyheTLEly6ZhjM5KcmeSq5udmzfEk+bckVye5OMkfr+n+JjSSJLVVpvVuW7MvAy9e6dghwMKq2h5Y2OwD7Ats32zzgM+s6eYmNJIkqe+q6gfA7Ssd3g9Y0LxeAOw/5vhXquMnwKZJZo93fxMaSZLaqocVmiTzkiwas82bQASzqmpx8/omYFbzeivgujHXXd8cWy1XOUmS1FbTerdsu6rmA/MfxfsrSXX7fis0kiRpUG5e0Upqfi5pjt8AbD3muic2x1bLhEaSpLaa3EnBq3IKMKd5PQc4eczxv25WO+0O3DWmNbVKtpwkSWqrSfym4CTHAc8FNk9yPXAYcDhwQpK5wLXAgc3l3wFeAlwN3Au8fk33N6GRJEl9V1WvXs2pvVdxbQEHrc39TWgkSWqrEXr0gQmNJEltNUIPpxyd1EySJLWWFRpJktrKlpMkSRp6I9RyMqGRJKmtRqhCMzqfRJIktZYVGkmS2sqWkyRJGnq2nCRJkqYOKzSSJLWVLSdJkjT0bDlJkiRNHVZoJElqqxGq0JjQSJLUViM0h2Z0UjNJktRaVmgkSWorW06SJGno2XKSJEmaOqzQSJLUVracJEnS0LPlJEmSNHVYoZEkqaUyQhUaExpJklpqlBIaW06SJGnoWaGRJKmtRqdAY0IjSVJb2XKSJEmaQqzQSJLUUqNUoTGhkSSppUYpobHlJEmShp4VGkmSWmqUKjQmNJIktdXo5DO2nCRJ0vCzQiNJUkuNUsvJCo0kSS2VpGfbBMZ6e5JLk1yW5B3NsRlJzkxyVfNzs24/iwmNJEnqqyQ7AW8AdgN2Bl6a5CnAIcDCqtoeWNjsd8WERpKklprECs0fAudW1b1VtQz4PvAKYD9gQXPNAmD/bj+LCY0kSS3Vy4Qmybwki8Zs88YMdSmwZ5KZSTYEXgJsDcyqqsXNNTcBs7r9LE4KliRJj1pVzQfmr+bcFUmOAM4AlgIXActXuqaSVLfjW6GRJKmt0sNtDarqmKp6ZlXtBdwB/AK4OclsgObnkm4/igmNJEktNcmrnLZsfm5DZ/7M14FTgDnNJXOAk7v9LLacJEnSZPhWkpnAg8BBVXVnksOBE5LMBa4FDuz25iY0kiS11GR+sV5V7bmKY7cBe/fi/iY0kiS1lN8ULEmSNIVYoZEkqa1Gp0BjQiNJUlvZcpIkSZpCrNBIktRSo1ShMaGRJKmlRimhseUkSZKGnhUaSZJaapQqNCY0kiS11ejkM7acJEnS8LNCI0lSS9lykiRJQ2+UEhpbTpIkaehZoZEkqaVGqUJjQiNJUluNTj5jQiNJUluNUoXGOTSSJGnoWaGRJKmlRqlCY0KjtfbZw17DvnvtxC23382uf/ExADbbeEO+esTf8KQnzODaG2/nte85hjvvvo89n7k93zx6Hr++8TYATv7eRfzz/NMHGb40Mj7w/kP5wffPZsaMmZx48mkA/PyKK/johw/jgfvvZ5111+F97/8gf/T0pw84Uk1Vo5TQ2HLSWvvqqT9hv4M+/YhjB79+H84+70r+aL8Pc/Z5V3Lw61/48LkfXvhLdn/V4ez+qsNNZqQe2m//V/CZz33hEceOPupfedNbDuKEE0/mLW99Ox8/6l8HFJ00uUxotNZ+eMEvuf2uex9x7KXPfTrHnnouAMeeei4ve57/RSj12zN3/RM23mSTRxwL4Z57lgJwz913s8UWWw4iNA2JJD3bBq1vLackTwP2A7ZqDt0AnFJVV/RrTA3OljM34qZbfwvATbf+li1nbvTwuWc9fTvOPf4QFt9yF4cedRJXXHPToMKURt57Dnkfb543l6OOPIKHHnqIr3ztG4MOSVPZ4POQnulLhSbJe4Fv0PlVnddsAY5Lcsg475uXZFGSRctuvawfoWmSVHV+XvTz69jhJf/Is155OJ/5xvc54eh5gw1MGnEnHH8cf//eQzlj4ff5+/ceygf/8R8GHZI0KfrVcpoL/ElVHV5Vxzbb4cBuzblVqqr5VbVrVe267ub/q0+hqR+W3HY3j998YwAev/nG3HL73QDcvfR3LL3vAQC+e87lrLfuOszc9LEDi1MadaeefBJ779OZw/bCF+3LpZdcPOCINJWNUsupXwnNQ8ATVnF8dnNOI+bb37+E177sWQC89mXP4rSzO/8SnTWm9bTr/3oS0xJuu3PpQGKU2mCLLbdk0fnnAXDeuT9hmydtO9iANKWNUkLTrzk07wAWJrkKuK45tg3wFOCtfRpTk2TBP7+OPZ+5PZtv+jiuPv0jfOSz3+HIL53JsUf8DXP2fza/WXw7r33PFwF4+QuewRv+Yk+WLV/O7373IH996JcGHL00Ot578LtYdP553HnnHezz/L1480Fv4wMf/Aj/cvjHWL5sGes/5jF84IMfHnSY0qRIrZjs0OsbJ9PotJjGTgo+v6qWT+T9Gzzjrf0JTNK47jj/U4MOQWqt6etO7jTdpxz8nz37W3v1kfsOtEzTt1VOVfUQ8JN+3V+SJD06U6FV1Ct+D40kSRp6PvpAkqSWGqECjQmNJEltZctJkiRpCrFCI0lSS41QgcaERpKktpo2bXQyGltOkiSp75K8M8llSS5NclyS6Um2S3JukquTHJ9k/W7vb0IjSVJLJb3bxh8nWwF/B+xaVTsB6wCvAo4Ajq6qpwB3MM7zHtfEhEaSpJaa5Gc5rQtskGRdYENgMfB84D+a8wuA/bv9LCY0kiTpUUsyL8miMdu8Feeq6gbgSOA3dBKZu4CfAndW1bLmsuv5/eOS1pqTgiVJaqlernKqqvnA/FWPk82A/YDtgDuBbwIv7t3oJjSSJLXWJH6x3guAX1XVLc24JwJ7AJsmWbep0jyRzoOsu2LLSZIk9dtvgN2TbJhOFrU3cDlwFnBAc80c4ORuBzChkSSppSZrUnBVnUtn8u8FwCV08o/5wHuBdyW5GpgJHNPtZ7HlJElSS03mNwVX1WHAYSsdvgbYrRf3t0IjSZKGnhUaSZJaapSetm1CI0lSS41QPmPLSZIkDT8rNJIktZQtJ0mSNPRGKJ+x5SRJkoafFRpJklrKlpMkSRp6I5TP2HKSJEnDzwqNJEktZctJkiQNvRHKZ2w5SZKk4WeFRpKklrLlJEmSht4I5TO2nCRJ0vCzQiNJUkvZcpIkSUNvhPIZW06SJGn4WaGRJKmlbDlJkqShN0oJjS0nSZI09KzQSJLUUiNUoDGhkSSprWw5SZIkTSFWaCRJaqkRKtCY0EiS1Faj1HIyoZEkqaVGKJ9xDo0kSRp+VmgkSWqpaSNUojGhkSSppUYon7HlJEmShp8VGkmSWspVTpIkaehNG518xpaTJEnqryQ7JLlozPbbJO9IMiPJmUmuan5u1u0YJjSSJLVUkp5t46mqK6tql6raBXgmcC9wEnAIsLCqtgcWNvtdMaGRJKmlkt5ta2Fv4JdVdS2wH7CgOb4A2L/bz2JCI0mSHrUk85IsGrPNW82lrwKOa17PqqrFzeubgFndju+kYEmSWir0blZwVc0H5o87XrI+8L+BQ1fx/kpS3Y5vQiNJUksNYJXTvsAFVXVzs39zktlVtTjJbGBJtze25SRJkibLq/l9uwngFGBO83oOcHK3N7ZCI0lSS03mF+sleSywD/DGMYcPB05IMhe4Fjiw2/ub0EiS1FKT+UXBVbUUmLnSsdvorHp61Gw5SZKkoWeFRpKklprms5wkSdKwG6F8ZvUJTZJPAqtdD15Vf9eXiCRJktbSeBWaRZMWhSRJmnSTucqp31ab0FTVgrH7STasqnv7H5IkSZoMI5TPrHmVU5JnJ7kc+Hmzv3OSf+97ZJIkSRM0kUnBHwdeROfb/KiqnyXZq59BSZKk/mvdKqequm6lPtvy/oQjSZImy+ikMxNLaK5L8hygkqwHvB24or9hSZIkTdxEEpo3AZ8AtgJuBL4LHNTPoCRJUv+1YpXTClV1K/CaSYhFkiRNommjk89MaJXTk5OcmuSWJEuSnJzkyZMRnCRJ0kRM5OGUXwdOAGYDTwC+CRzXz6AkSVL/JenZNmgTSWg2rKqvVtWyZjsWmN7vwCRJUn8lvdsGbbxnOc1oXv5nkkOAb9B5ttMrge9MQmySJEkTMt6k4J/SSWBW5F1vHHOugEP7FZQkSeq/qdAq6pXxnuW03WQGIkmSJtcorXKa0DcFJ9kJ2JExc2eq6iv9CkqSJGltrDGhSXIY8Fw6Cc13gH2BcwATGkmShtgotZwmssrpAGBv4Kaqej2wM7BJX6OSJEl9lx5ugzaRhOa+qnoIWJZkY2AJsHV/w5IkSZq4icyhWZRkU+DzdFY+3QP8uJ9BSZKk/ps2Qi2niTzL6S3Ny88mOR3YGLi1r1FJkqS+G6F8ZmKrnFaoql8DJPkNsE0/ApIkSVpba5XQjDFCOZ0kSe00Squcuk1oqqdRSJKkSTdC+cy4z3L6JKtOXAJs2q+AJEmS1tZ4FZpFXZ6TJElDoBWrnKpqwWQGIkmSJtcI5TMT+mI9SZKkKa3bScF994MT/2nQIUittO+nfzToEKTWOuvtz5nU8VzlJEmSht4otWm6WeUEQFX9XV8ikiRJWkvdrnKSJElDrhUtJ1c5SZI02qZNYj7TPOj6C8BOdDpAfwNcCRwPbAv8Gjiwqu7o5v5rbJ8l2SLJkUm+k+R7K7ZuBpMkSVPHtPRum4BPAKdX1dOAnYErgEOAhVW1PbCw2e/us0zgmq81g24HfIhOBnV+twNKkqR2SbIJsBdwDEBVPVBVdwL7ASs6QguA/bsdYyIJzcyqOgZ4sKq+X1V/Azy/2wElSdLUkKSX27wki8Zs88YMtR1wC/ClJBcm+UKSxwKzqmpxc81NwKxuP8tElm0/2PxcnOTPgRuBGd0OKEmSpoZezqGpqvnA/NWcXhf4Y+BtVXVukk+wUnupqipJ1w+/nkiF5qNNqejdwMF0JvS8s9sBJUlS61wPXF9V5zb7/0Enwbk5yWyA5ueSbgdYY4Wmqk5rXt4FPK/bgSRJ0tQyWau2q+qmJNcl2aGqrgT2Bi5vtjnA4c3Pk7sdY40JTZIvsYov2Gvm0kiSpCE1yU/bfhvwtSTrA9cAr6fTKTohyVzgWuDAbm8+kTk0p415PR14OZ15NJIkSRNSVRcBu67i1N69uP9EWk7fGruf5DjgnF4MLkmSBqcVz3Iax/bAlr0ORJIkTa4RevLBhObQ3M0j59DcBLy3bxFJkiStpYm0nDaajEAkSdLkmuRJwX01kWc5LZzIMUmSNFyS3m2DttoKTZLpwIbA5kk2A1aEuzGw1STEJkmSNCHjtZzeCLwDeALwU36f0PwW+FR/w5IkSf3Wy0cfDNpqE5qq+gTwiSRvq6pPTmJMkiRpErRqDg3wUJJNV+wk2SzJW/oXkiRJ0tqZSELzhqq6c8VOVd0BvKFvEUmSpEnRiknBY6yTJFVVAEnWAdbvb1iSJKnfWjGHZozTgeOTfK7Zf2NzTJIkaUqYSELzXmAe8OZm/0zg832LSJIkTYowOiWaNc6hqaqHquqzVXVAVR0AXA646kmSpCE3Lb3bBm1CD6dM8gzg1cCBwK+AE/sZlCRJ0toY75uCn0oniXk1cCtwPJCqet4kxSZJkvpoKlRWemW8Cs3Pgf8GXlpVVwMkeeekRCVJkvouU2G9dY+MN4fmFcBi4Kwkn0+yN4zQ7CFJkjQyVpvQVNX/q6pXAU8DzqLzXKctk3wmyQsnKT5JktQnozQpeCKrnJZW1der6mXAE4EL6SzlliRJQ2yUvil4Io8+eFhV3VFV86tq734FJEmStLYmtGxbkiSNnlF62rYJjSRJLTUV5r70ylq1nCRJkqYiKzSSJLXUCHWcTGgkSWqraSP09XK2nCRJ0tCzQiNJUkvZcpIkSUPPVU6SJElTiBUaSZJayi/WkyRJQ2+E8hlbTpIkafhZoZEkqaVsOUmSpKE3QvmMCY0kSeq/JL8G7gaWA8uqatckM4DjgW2BXwMHVtUd3dzfOTSSJLXUtB5uE/S8qtqlqnZt9g8BFlbV9sDCZr/rzyJJklooSc+2Lu0HLGheLwD27/ZGJjSSJOlRSzIvyaIx27yVLingjCQ/HXNuVlUtbl7fBMzqdnzn0EiS1FK9nBNcVfOB+eNc8qdVdUOSLYEzk/x8pfdXkup2fBMaSZJaajKXbVfVDc3PJUlOAnYDbk4yu6oWJ5kNLOn2/racJElSXyV5bJKNVrwGXghcCpwCzGkumwOc3O0YVmgkSWqpSfwamlnASc3k4XWBr1fV6UnOB05IMhe4Fjiw2wFMaCRJaqnJ6jhV1TXAzqs4fhuwdy/GsOUkSZKGnhUaSZJa6lF8f8yUY0IjSVJLjVKbxoRGkqSWGqUKzSglZ5IkqaWs0EiS1FKjU58xoZEkqbVsOUmSJE0hVmgkSWqpUapqmNBIktRStpwkSZKmECs0kiS11OjUZ0xoJElqrRHqONlykiRJw88KjSRJLTVthJpOJjSSJLWULSdJkqQpxAqNJEktFVtOkiRp2NlykiRJmkKs0EiS1FKucpIkSUPPlpMkSdIUYoVGkqSWGqUKjQmNJEktNUrLtm05SZKkoWeFRpKklpo2OgUaExpJktrKlpMkSdIUYoVGkqSWcpWTJEkaeracJEmSphArNJIktZSrnCRJ0tCz5SRJkrSWkqyT5MIkpzX72yU5N8nVSY5Psn6397ZCo0flgQfu56MHv5FlDz7A8uXL2W3Pvfk/fzWPSy88j+O+8EmqHmL69A2Zd/AHePwTth50uNJI2XrT6XzgJTs8vD9748fwpZ9cx8bT12WPP5hBFdxx74McceZV3Lb0wQFGqqlqAKuc3g5cAWzc7B8BHF1V30jyWWAu8Jlubpyq6k2IPXb+r+6amoHpEaqK+393H9M32JBly5bxkXe/gb9607v47JEf5J2HHclW22zHmaf+B9dceRlvPPiwQYerCXjPKZcNOgR1YVrgm3N35S3HX8Ld9y/j3geWA/CKnR/Pk2ZuyNHfu2bAEWoiznr7cyY1xfjhVXf07G/tHttvNm7sSZ4ILAD+CXgX8DLgFuDxVbUsybOBD1bVi7oZ3wqNHpUkTN9gQwCWL1vGsmXLmpQ/3HfvUgDuW3oPm87cYoBRSqPvj7fehBvv+h03333/I45PX28dpuh/t6p9Pg68B9io2Z8J3FlVy5r964Gtur25CY0etYeWL+f9b/trbr7xevZ52QE85Wk78bfv/AeO/Md3sN5jprPBho/lg0cfM+gwpZH2/KduzsIrb314f+6zt+GFf7gFS+9fzjtPvHSAkWkqm9bDnlOSecC8MYfmV9X85txLgSVV9dMkz+3ZoGNM+qTgJK8f59y8JIuSLDrpuC9PYlR6NKatsw4f+/ev8W/HnsYvr7yc6379S04/8TgO/sjH+eSxp7HXPi/la/M/PugwpZG17rTwnCfP4PtX3/bwsWN+/Bte+cWf8l9X3sLLd549wOg0laWHW1XNr6pdx2zzxwy1B/C/k/wa+AbwfOATwKZJVhRXngjc0O1nGcQqpw+t7sTYX8bLX/26SQxJvfDYx23Ejjs/k5+d/yN+86ureMrTdgJg9z/bh6uuuGTA0Umj61nbbsovlizljnv/58Tf/7ryFvb6g5kDiEr6vao6tKqeWFXbAq8CvldVrwHOAg5oLpsDnNztGH1JaJJcvJrtEmBWP8bUYPz2zjtYes/dADxw/++45IJz2Wqbbbl36T0svv5aAC694Fy22nrbAUYpjbbnP3ULvveL37ebttp0+sOv93jyDH5zx32DCEvDoJclmu68F3hXkqvpzKnpen5Cv+bQzAJeBNyx0vEAP+rTmBqAO2+/lc/93w/x0PKHqHqIZ+31Ap7xrD2Z+/b38YmPHsK0hA0ftzHz3vWPgw5VGknT153GM7fZhKO+98uHj83b40lsvekGPERx82/vd4WTVmsQX6xXVWcDZzevrwF268V9+7JsO8kxwJeq6pxVnPt6Vf3lmu7hsm1pMFy2LQ3OZC/bPveXvftb+6w/2GSgXzvclwpNVc0d59wakxlJktR/A/hivb5x2bYkSS01QvmMz3KSJEnDzwqNJEltNUIlGhMaSZJaahCrnPrFlpMkSRp6VmgkSWopVzlJkqShN0L5jC0nSZI0/KzQSJLUViNUojGhkSSppVzlJEmSNIVYoZEkqaVc5SRJkobeCOUzJjSSJLXWCGU0zqGRJElDzwqNJEktNUqrnExoJElqqVGaFGzLSZIkDT0rNJIktdQIFWhMaCRJaq0RymhsOUmSpKFnhUaSpJZylZMkSRp6rnKSJEmaQqzQSJLUUiNUoDGhkSSptUYoo7HlJEmShp4VGkmSWspVTpIkaei5ykmSJGkKsUIjSVJLjVCBxoRGkqTWGqGMxpaTJEkaeiY0kiS1VHr4v3HHSaYnOS/Jz5JcluRDzfHtkpyb5OokxydZv9vPYkIjSVJLJb3b1uB+4PlVtTOwC/DiJLsDRwBHV9VTgDuAud1+FhMaSZLUV9VxT7O7XrMV8HzgP5rjC4D9ux3DhEaSpJZKL7dkXpJFY7Z5jxgrWSfJRcAS4Ezgl8CdVbWsueR6YKtuP4urnCRJaqsernKqqvnA/HHOLwd2SbIpcBLwtN6NboVGkiRNoqq6EzgLeDawaZIVxZUnAjd0e18TGkmSWmoSVzlt0VRmSLIBsA9wBZ3E5oDmsjnAyd1+FltOkiS11CQ+y2k2sCDJOnSKKSdU1WlJLge+keSjwIXAMd0OYEIjSZL6qqouBp6xiuPXALv1YgwTGkmSWmqEnnxgQiNJUmuNUEbjpGBJkjT0rNBIktRSa1qdNExMaCRJaqlJXOXUd7acJEnS0LNCI0lSS41QgcaERpKktrLlJEmSNIVYoZEkqbVGp0RjQiNJUkvZcpIkSZpCrNBIktRSI1SgMaGRJKmtbDlJkiRNIVZoJElqKZ/lJEmSht/o5DO2nCRJ0vCzQiNJUkuNUIHGhEaSpLZylZMkSdIUYoVGkqSWcpWTJEkafqOTz9hykiRJw88KjSRJLTVCBRoTGkmS2mqUVjmZ0EiS1FKjNCnYOTSSJGnoWaGRJKmlRqnlZIVGkiQNPRMaSZI09Gw5SZLUUqPUcjKhkSSppVzlJEmSNIVYoZEkqaVGqeVkhUaSpJZKD7dxx0m2TnJWksuTXJbk7c3xGUnOTHJV83Ozbj+LCY0kSeq3ZcC7q2pHYHfgoCQ7AocAC6tqe2Bhs98VExpJktpqkko0VbW4qi5oXt8NXAFsBewHLGguWwDs3+1HMaGRJKml0sv/JfOSLBqzzVvlmMm2wDOAc4FZVbW4OXUTMKvbz+KkYEmS9KhV1Xxg/njXJHkc8C3gHVX124yZlVxVlaS6Hd+ERpKklprMVU5J1qOTzHytqk5sDt+cZHZVLU4yG1jS7f1tOUmS1FKTuMopwDHAFVV11JhTpwBzmtdzgJO7/SxWaCRJUr/tAfwVcEmSi5pj7wMOB05IMhe4Fjiw2wFMaCRJaqtJajlV1TnjjLZ3L8YwoZEkqaV8lpMkSdIUYoVGkqSWGqVnOaWq6yXf0molmdd8J4GkSeQ/e2orW07ql1V+Q6SkvvOfPbWSCY0kSRp6JjSSJGnomdCoX+zhS4PhP3tqJScFS5KkoWeFRpIkDT0TGkmSNPRMaNRTSV6c5MokVyc5ZNDxSG2R5ItJliS5dNCxSINgQqOeSbIO8GlgX2BH4NVJdhxsVFJrfBl48aCDkAbFhEa9tBtwdVVdU1UPAN8A9htwTFIrVNUPgNsHHYc0KCY06qWtgOvG7F/fHJMkqa9MaCRJ0tAzoVEv3QBsPWb/ic0xSZL6yoRGvXQ+sH2S7ZKsD7wKOGXAMUmSWsCERj1TVcuAtwLfBa4ATqiqywYbldQOSY4DfgzskOT6JHMHHZM0mXz0gSRJGnpWaCRJ0tAzoZEkSUPPhEaSJA09ExpJkjT0TGgkSdLQM6GRBijJ8iQXJbk0yTeTbPgo7vXlJAc0r78w3oNBkzw3yXO6GOPXSTaf6PHV3ON1ST7Vi3ElaQUTGmmw7quqXapqJ+AB4E1jTyZZt5ubVtXfVtXl41zyXGCtExpJmqpMaKSp47+BpzTVk/9OcgpweZJ1kvxrkvOTXJzkjQDp+FSSK5P8F7DlihslOTvJrs3rFye5IMnPkixMsi2dxOmdTXVozyRbJPlWM8b5SfZo3jszyRlJLkvyBSAT/TBJdkvy4yQXJvlRkh3GnN66ifGqJIeNec9rk5zXxPW5JOt0/+uU1CZd/defpN5qKjH7Aqc3h/4Y2KmqfpVkHnBXVf1JkscAP0xyBvAMYAdgR2AWcDnwxZXuuwXweWCv5l4zqur2JJ8F7qmqI5vrvg4cXVXnJNmGzrc9/yFwGHBOVX04yZ8Da/Ptsz8H9qyqZUleAHwM+D/Nud2AnYB7gfOTfBtYCrwS2KOqHkzy78BrgK+sxZiSWsqERhqsDZJc1Lz+b+AYOq2g86rqV83xFwJPXzE/BtgE2B7YCziuqpYDNyb53iruvzvwgxX3qqrbVxPHC4Adk4cLMBsneVwzxiua9347yR1r8dk2ARYk2R4oYL0x586sqtsAkpwI/CmwDHgmnQQHYANgyVqMJ6nFTGikwbqvqnYZe6D5Y7507CHgbVX13ZWue0kP45gG7F5Vv1tFLN36CHBWVb28aXOdPebcys9cKTqfc0FVHfpoBpXUTs6hkaa+7wJvTrIeQJKnJnks8APglc0cm9nA81bx3p8AeyXZrnnvjOb43cBGY647A3jbip0kuzQvfwD8ZXNsX2CztYh7E+CG5vXrVjq3T5IZSTYA9gd+CCwEDkiy5YpYkzxpLcaT1GImNNLU9wU682MuSHIp8Dk61dWTgKuac1+h86TlR6iqW4B5wIlJfgYc35w6FXj5iknBwN8BuzaTji/n96utPkQnIbqMTuvpN+PEeXHzlOfrkxwF/Avwz0ku5H9Wg88DvgVcDHyrqhY1q7LeD5yR5GLgTGD2BH9HklrOp21LkqShZ4VGkiQNPRMaSZI09ExoJEnS0DOhkSRJQ8+ERpIkDT0TGkmSNPRMaCRJ0tD7/1WL1GQIQuigAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "probabilities = torch.softmax(torch.tensor(test_results.predictions).to(torch.float32), dim=-1)\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)\n",
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb603377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_save = []\n",
    "for idx in range(len(test_data)):\n",
    "    item = dataset['test'][idx]\n",
    "    actual_label = item['label']\n",
    "    predicted_label = predictions[idx]\n",
    "    claim = item['claim'] \n",
    "    premise = item['premise'] \n",
    "    category = item['category']\n",
    "    \n",
    "    # Append the information as a dictionary to the list\n",
    "    data_to_save.append({\n",
    "        'Claim': claim,\n",
    "        'Premise': premise,\n",
    "        'Actual Label': actual_label,\n",
    "        'Predicted Label': predicted_label,\n",
    "        'Category' : category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_to_save)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/home/elson/results/5.1.3_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c23339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correctly classified instances\n",
    "correctly_classified = df[df['Actual Label'] == df['Predicted Label']]\n",
    "\n",
    "# Calculate misclassified instances\n",
    "misclassified = df[df['Actual Label'] != df['Predicted Label']]\n",
    "\n",
    "# Count the number of correctly classified and misclassified by category\n",
    "correct_classification_counts = correctly_classified['Category'].value_counts()\n",
    "misclassification_counts = misclassified['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca0def77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           43\n",
       "Bone health              16\n",
       "Skin                     13\n",
       "Fitness                  12\n",
       "Cancer                   12\n",
       "Hair                      8\n",
       "Neurological health       8\n",
       "Eye                       8\n",
       "Diabetes                  7\n",
       "Cardiovascular Health     7\n",
       "Throat                    6\n",
       "Blood                     6\n",
       "Ear                       6\n",
       "Women' s Health           6\n",
       "Men's health              5\n",
       "COVID                     5\n",
       "Muscles                   4\n",
       "Vascular                  3\n",
       "Mental Health             3\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0fddd944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Skin                     11\n",
       "General Health            8\n",
       "Cardiovascular Health     5\n",
       "Bone health               5\n",
       "Diabetes                  5\n",
       "Hair                      4\n",
       "Dental Health             3\n",
       "Throat                    3\n",
       "Blood                     3\n",
       "Fitness                   3\n",
       "Muscles                   2\n",
       "COVID                     1\n",
       "Men's health              1\n",
       "Neurological health       1\n",
       "Eye                       1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38b899b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_counts = df['Category'].value_counts()\n",
    "\n",
    "# Calculate ratios\n",
    "correct_classification_ratios = correct_classification_counts / total_counts\n",
    "misclassification_ratios = misclassification_counts / total_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3598b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blood                    0.666667\n",
      "Bone health              0.761905\n",
      "COVID                    0.833333\n",
      "Cancer                   1.000000\n",
      "Cardiovascular Health    0.583333\n",
      "Dental Health                 NaN\n",
      "Diabetes                 0.583333\n",
      "Ear                      1.000000\n",
      "Eye                      0.888889\n",
      "Fitness                  0.800000\n",
      "General Health           0.843137\n",
      "Hair                     0.666667\n",
      "Men's health             0.833333\n",
      "Mental Health            1.000000\n",
      "Muscles                  0.666667\n",
      "Neurological health      0.888889\n",
      "Skin                     0.541667\n",
      "Throat                   0.666667\n",
      "Vascular                 1.000000\n",
      "Women' s Health          1.000000\n",
      "Name: Category, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(correct_classification_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27602a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blood                    0.333333\n",
      "Bone health              0.238095\n",
      "COVID                    0.166667\n",
      "Cancer                        NaN\n",
      "Cardiovascular Health    0.416667\n",
      "Dental Health            1.000000\n",
      "Diabetes                 0.416667\n",
      "Ear                           NaN\n",
      "Eye                      0.111111\n",
      "Fitness                  0.200000\n",
      "General Health           0.156863\n",
      "Hair                     0.333333\n",
      "Men's health             0.166667\n",
      "Mental Health                 NaN\n",
      "Muscles                  0.333333\n",
      "Neurological health      0.111111\n",
      "Skin                     0.458333\n",
      "Throat                   0.333333\n",
      "Vascular                      NaN\n",
      "Women' s Health               NaN\n",
      "Name: Category, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(misclassification_ratios)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
