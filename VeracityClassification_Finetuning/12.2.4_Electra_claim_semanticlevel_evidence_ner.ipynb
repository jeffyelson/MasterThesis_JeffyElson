{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score,balanced_accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82806f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jul 31 16:38:33 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:61:00.0 Off |                    0 |\n",
      "| N/A   43C    P0    57W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  Off  | 00000000:62:00.0 Off |                    0 |\n",
      "| N/A   44C    P0    58W / 300W |      0MiB / 32768MiB |      2%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  Off  | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   44C    P0   204W / 300W |  10258MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  Off  | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   58C    P0   247W / 300W |  23156MiB / 32768MiB |     45%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    2   N/A  N/A      8994      C   ...son/factcheck/bin/python3    14743MiB |\n",
      "|    3   N/A  N/A      8403      C   ...son/factcheck/bin/python3    23153MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-31dfe7adddcf5ced\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 210.92it/s]\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-ad71be204b279b28.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-e7b6b615907c24ca.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-bee802838a3bfaea.arrow\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset from the CSV file\n",
    "dataset = load_dataset(\n",
    "    'csv',\n",
    "    data_files='dataset_semanticattribution_nerfeatures_split.csv',\n",
    "    delimiter=',',\n",
    "    column_names=[\n",
    "        \"claim\", \"premise\", \"label\", \"category\", \"count_bf\", \"count_ca\", \"count_dis\",\n",
    "        \"count_food\", \"count_lipid\", \"count_treat\", \"pres_bf\", \"pres_ca\", \"pres_dis\",\n",
    "        \"pres_food\", \"pres_lipid\", \"pres_treat\", \"counte_bf\", \"counte_ca\", \"counte_dis\",\n",
    "        \"counte_food\", \"counte_lipid\", \"counte_treat\", \"prese_bf\", \"prese_ca\", \"prese_dis\",\n",
    "        \"prese_food\", \"prese_lipid\", \"prese_treat\", \"url\", \"entities\", \"entity_map\",\n",
    "        \"gold_exp\", \"gemini_exp\", \"gemini_label\",\"entity_ev\",\"entity_map_ev\", \"split\"\n",
    "    ],\n",
    "    skiprows=1\n",
    ")\n",
    "\n",
    "# Assuming 'split' column contains strings 'train', 'validation', 'test'\n",
    "# Filter the loaded dataset into subsets\n",
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'gold_exp', 'gemini_exp', 'gemini_label', 'entity_ev', 'entity_map_ev', 'split'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f3e71be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41f1db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['claim', 'premise', 'label','category','counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat']\n",
    "all_columns = train_dataset.column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-192f7cd55308f437.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-628e09c96e321cd1.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-1df942f735662e2b.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 0, 'entailment': 1, 'neutral': 2}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 0,\n",
    "    \"entailment\": 1,\n",
    "    \"neutral\": 2\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b5bb17f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "465"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['val']['claim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='TehranNLP-org/electra-base-mnli'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "        # Extracting claim and evidence texts\n",
    "\n",
    "        claim = item['claim']\n",
    "        premise = item['premise'].replace('\\n', '').replace('[','').replace(']','')\n",
    "        additional_features = [\n",
    "            'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat']\n",
    "    \n",
    "        for feature in additional_features:\n",
    "            if feature in item:\n",
    "                premise += \"[SEP]\" + str(item[feature])\n",
    "        item['claim']=claim\n",
    "        item['premise']=premise        \n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "             premise, claim,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "        item['input_ids'] = inputs['input_ids'].squeeze()  # Remove batch dimension\n",
    "        item['attention_mask']= inputs['attention_mask'].squeeze() # Remove batch dimension\n",
    "        \n",
    "        output_item = {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),  # Remove batch dimension\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),  # Remove batch dimension\n",
    "            'claim': claim,  # Include augmented claim text\n",
    "            'evidences': premise  # Include original evidence text\n",
    "        }\n",
    "        \n",
    "        if 'label' in item:\n",
    "            output_item['label'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return output_item\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62421eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"TehranNLP-org/electra-base-mnli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=3, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f72c5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model is on device: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    bal_accuracy = balanced_accuracy_score(labels,preds)\n",
    "\n",
    "    return {\"accuracy\": acc, \"balanced_accuracy\":bal_accuracy, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17c5e0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  101,  1025,  4895,  7724,  2401,  1527,  1010,  1050,  1012,  1025,\n",
       "         11737, 21128,  1527,  1010,  1045,  1012,  1025, 23341,  2050,  1527,\n",
       "         12849,  9035,  1527,  1010,  1052,  1012,  1025, 11721, 19716, 22360,\n",
       "          9035,  1527,  1010,  1049,  1012,  1025,  9761, 29147,  6777,  2401,\n",
       "          1527,  1010,  1051,  1012,  1025, 24728,  3683,  6460,  9035,  1527,\n",
       "          1010,  1046,  1012,  3581,  2378, 19023,  2063,  1998,  2026, 12171,\n",
       "          2232,  6827, 20631,  1998,  6402, 28647, 11865,  4168,  2114, 12702,\n",
       "          1011,  4864,  1997, 17266,  7941, 17093,  2015,  1012,  9467,  6633,\n",
       "          1010,  1045,  1012,  6887, 22123, 23555,  7712,  2389,  1004, 17261,\n",
       "          4022,  2015,  1997, 14163, 12171,  5003, 24103,  1006,  1012, 23060,\n",
       "          8524,  6024,  6911,  1998, 10047, 23041, 11439,  9048,  2278,  3896,\n",
       "          1997,  2599,  1998,  2037,  2572, 20806, 21223,  2007,  2026, 12171,\n",
       "          2232,  1006,  4012,  4328,  8458,  6525,  9587, 13728,  4747,  1007,\n",
       "          7861, 23316,  1012,  6827, 20631,  1024,  8687, 12760,  2005,  3096,\n",
       "          2729,  1012, 15775, 22272, 10755,  3723,  1010,  1050,  1012,  1025,\n",
       "         26129,  1010,  1039,  1012,  1025, 16309,  1010,  1046,  1012,  1025,\n",
       "          1041, 26147,  2015,  1010,  1051,  1012,  1025,  5253,  1010,  1049,\n",
       "          1012, 23068,  3860,  2011,  3019,  3688,  1024,  1039,  1012,  2026,\n",
       "         12171,  3270,  3514,  6431, 19352, 24410,  1012, 24811, 27757,  1010,\n",
       "          1054,  1012,  1025, 24811, 27757,  1010,  1055,  1012,  1025, 24811,\n",
       "         27757,  1010,  1049,  1012,  1025,  7890,  8017,  2072,  1010,  1049,\n",
       "          1012,  3581,  2378, 19023,  2063,  1006,  1037, 27904, 18107,  2063,\n",
       "         29649, 30108, 22110,  1524, 27735,  1025,  1012,  2427,  1007,  1024,\n",
       "          2013,  1996,  4989,  1997,  3151,  5097,  2000,  1996,  3117,  6887,\n",
       "         22123, 14573,  6906,  7685,  2005,  1996,  9740,  1998,  3949,  1997,\n",
       "          3809,  7870,  1012,  6370,  1998, 10047, 23041, 19506,  8566, 20051,\n",
       "         10253,  4023,  1997,  3581,  2378, 19023,  2063,  3514,  1012,  9265,\n",
       "          4820,  8945, 19228,  2401, 27059,  1012,  1025,  6201,  1010,  1041,\n",
       "          1012,  3581,  2378, 19023,  2063,  1998,  2026, 12171,  2232,  2004,\n",
       "          2128,  7583,  3111,  1999,  2336,  1012,   102,  1014,   102,  1014,\n",
       "           102,  1014,   102,  1014,   102,  1014,   102,  1014,   102,  1014,\n",
       "           102,  1014,   102,  1014,   102,  1014,   102,  1014,   102,  1014,\n",
       "           102,  2026, 12171,  2232,  6827,  3514,  2003,  2823,  2109,  1999,\n",
       "          3096, 16302,  3688,  2000,  2393,  5335,  1996,  3311,  1997,  1996,\n",
       "          3096,  1012,   102,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'claim': 'Myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.',\n",
       " 'evidences': '; UnkoviÄ‡, N.; DimkiÄ‡, I.; JanaÄ‡koviÄ‡, P.; GavriloviÄ‡, M.; StanojeviÄ‡, O.; VukojeviÄ‡, J. Frankincense and myrrh essential oils and burn incense fume against micro-inhabitants of sacral ambients.Shameem, I. Phytochemical & therapeutic potentials of Murr makki (.Oxidative stress and immunotoxic effects of lead and their amelioration with myrrh (Commiphora molmol) emulsion.Essential Oils: Magical Ingredients for Skin Care.Chakravarty, N.; Kellogg, C.; Alvarez, J.; Equils, O.; Morgan, M. UV Protection by Natural Products: C. myrrha Oil Versus Sunscreen.Hamidpour, R.; Hamidpour, S.; Hamidpour, M.; Shahlari, M. Frankincense (ä¹³é¦™ RÇ” XiÄ\\x81ng;.species): From the selection of traditional applications to the novel phytotherapy for the prevention and treatment of serious diseases.Chemistry and immunomodulatory activity of frankincense oil.Compositions containing Boswellia extracts.; Cooper, E. Frankincense and myrrh as remedies in children.[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0',\n",
       " 'label': tensor(1)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on device: cuda:0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='765' max='765' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [765/765 06:17, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.853800</td>\n",
       "      <td>0.807487</td>\n",
       "      <td>0.679570</td>\n",
       "      <td>0.370726</td>\n",
       "      <td>0.536870</td>\n",
       "      <td>0.679570</td>\n",
       "      <td>0.569931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.642000</td>\n",
       "      <td>0.873716</td>\n",
       "      <td>0.619355</td>\n",
       "      <td>0.440389</td>\n",
       "      <td>0.631241</td>\n",
       "      <td>0.619355</td>\n",
       "      <td>0.609869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.344900</td>\n",
       "      <td>1.074860</td>\n",
       "      <td>0.679570</td>\n",
       "      <td>0.508496</td>\n",
       "      <td>0.668876</td>\n",
       "      <td>0.679570</td>\n",
       "      <td>0.671306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.122300</td>\n",
       "      <td>1.385410</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.512295</td>\n",
       "      <td>0.656922</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.657986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.130600</td>\n",
       "      <td>1.805486</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.505783</td>\n",
       "      <td>0.666394</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.652937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.167500</td>\n",
       "      <td>1.661119</td>\n",
       "      <td>0.662366</td>\n",
       "      <td>0.503840</td>\n",
       "      <td>0.651414</td>\n",
       "      <td>0.662366</td>\n",
       "      <td>0.656291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.078900</td>\n",
       "      <td>1.998063</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.536419</td>\n",
       "      <td>0.673813</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.669992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.027800</td>\n",
       "      <td>2.200383</td>\n",
       "      <td>0.647312</td>\n",
       "      <td>0.507318</td>\n",
       "      <td>0.658202</td>\n",
       "      <td>0.647312</td>\n",
       "      <td>0.652312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>2.216806</td>\n",
       "      <td>0.698925</td>\n",
       "      <td>0.525177</td>\n",
       "      <td>0.679660</td>\n",
       "      <td>0.698925</td>\n",
       "      <td>0.685906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>2.299875</td>\n",
       "      <td>0.670968</td>\n",
       "      <td>0.508612</td>\n",
       "      <td>0.671389</td>\n",
       "      <td>0.670968</td>\n",
       "      <td>0.669273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.018500</td>\n",
       "      <td>2.307745</td>\n",
       "      <td>0.681720</td>\n",
       "      <td>0.528303</td>\n",
       "      <td>0.672202</td>\n",
       "      <td>0.681720</td>\n",
       "      <td>0.676365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>2.306710</td>\n",
       "      <td>0.688172</td>\n",
       "      <td>0.535399</td>\n",
       "      <td>0.678120</td>\n",
       "      <td>0.688172</td>\n",
       "      <td>0.681425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>2.379634</td>\n",
       "      <td>0.670968</td>\n",
       "      <td>0.523210</td>\n",
       "      <td>0.671642</td>\n",
       "      <td>0.670968</td>\n",
       "      <td>0.671284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>2.384731</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.530701</td>\n",
       "      <td>0.675709</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.675474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>2.390747</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.528024</td>\n",
       "      <td>0.674213</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.674737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to /home/elson/12.2.4_electra/checkpoint-51\n",
      "Configuration saved in /home/elson/12.2.4_electra/checkpoint-51/config.json\n",
      "Model weights saved in /home/elson/12.2.4_electra/checkpoint-51/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/12.2.4_electra/checkpoint-102\n",
      "Configuration saved in /home/elson/12.2.4_electra/checkpoint-102/config.json\n",
      "Model weights saved in /home/elson/12.2.4_electra/checkpoint-102/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/12.2.4_electra/checkpoint-153\n",
      "Configuration saved in /home/elson/12.2.4_electra/checkpoint-153/config.json\n",
      "Model weights saved in /home/elson/12.2.4_electra/checkpoint-153/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/12.2.4_electra/checkpoint-102] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/12.2.4_electra/checkpoint-204\n",
      "Configuration saved in /home/elson/12.2.4_electra/checkpoint-204/config.json\n",
      "Model weights saved in /home/elson/12.2.4_electra/checkpoint-204/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/12.2.4_electra/checkpoint-153] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/12.2.4_electra/checkpoint-255\n",
      "Configuration saved in /home/elson/12.2.4_electra/checkpoint-255/config.json\n",
      "Model weights saved in /home/elson/12.2.4_electra/checkpoint-255/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/12.2.4_electra/checkpoint-204] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/12.2.4_electra/checkpoint-306\n",
      "Configuration saved in /home/elson/12.2.4_electra/checkpoint-306/config.json\n",
      "Model weights saved in /home/elson/12.2.4_electra/checkpoint-306/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/12.2.4_electra/checkpoint-255] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/12.2.4_electra/checkpoint-357\n",
      "Configuration saved in /home/elson/12.2.4_electra/checkpoint-357/config.json\n",
      "Model weights saved in /home/elson/12.2.4_electra/checkpoint-357/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/12.2.4_electra/checkpoint-306] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/12.2.4_electra/checkpoint-408\n",
      "Configuration saved in /home/elson/12.2.4_electra/checkpoint-408/config.json\n",
      "Model weights saved in /home/elson/12.2.4_electra/checkpoint-408/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/12.2.4_electra/checkpoint-357] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/12.2.4_electra/checkpoint-459\n",
      "Configuration saved in /home/elson/12.2.4_electra/checkpoint-459/config.json\n",
      "Model weights saved in /home/elson/12.2.4_electra/checkpoint-459/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/12.2.4_electra/checkpoint-51] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/12.2.4_electra/checkpoint-408] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/12.2.4_electra/checkpoint-510\n",
      "Configuration saved in /home/elson/12.2.4_electra/checkpoint-510/config.json\n",
      "Model weights saved in /home/elson/12.2.4_electra/checkpoint-510/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/12.2.4_electra/checkpoint-561\n",
      "Configuration saved in /home/elson/12.2.4_electra/checkpoint-561/config.json\n",
      "Model weights saved in /home/elson/12.2.4_electra/checkpoint-561/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/12.2.4_electra/checkpoint-510] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/12.2.4_electra/checkpoint-612\n",
      "Configuration saved in /home/elson/12.2.4_electra/checkpoint-612/config.json\n",
      "Model weights saved in /home/elson/12.2.4_electra/checkpoint-612/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/12.2.4_electra/checkpoint-561] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/12.2.4_electra/checkpoint-663\n",
      "Configuration saved in /home/elson/12.2.4_electra/checkpoint-663/config.json\n",
      "Model weights saved in /home/elson/12.2.4_electra/checkpoint-663/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/12.2.4_electra/checkpoint-612] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/12.2.4_electra/checkpoint-714\n",
      "Configuration saved in /home/elson/12.2.4_electra/checkpoint-714/config.json\n",
      "Model weights saved in /home/elson/12.2.4_electra/checkpoint-714/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/12.2.4_electra/checkpoint-663] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/12.2.4_electra/checkpoint-765\n",
      "Configuration saved in /home/elson/12.2.4_electra/checkpoint-765/config.json\n",
      "Model weights saved in /home/elson/12.2.4_electra/checkpoint-765/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/12.2.4_electra/checkpoint-714] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/elson/12.2.4_electra/checkpoint-459 (score: 0.6989247311827957).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /home/elson/12.2.4_electra/best_model/config.json\n",
      "Model weights saved in /home/elson/12.2.4_electra/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/12.2.4_electra/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/12.2.4_electra/best_model/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/12.2.4_electra/best_model/tokenizer_config.json',\n",
       " '/home/elson/12.2.4_electra/best_model/special_tokens_map.json',\n",
       " '/home/elson/12.2.4_electra/best_model/vocab.txt',\n",
       " '/home/elson/12.2.4_electra/best_model/added_tokens.json',\n",
       " '/home/elson/12.2.4_electra/best_model/tokenizer.json')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/12.2.4_electra/',\n",
    "    num_train_epochs=15,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.06,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(\"cuda:0\"),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "print(f\"Model is on device: {next(model.parameters()).device}\")\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/12.2.4_electra/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/12.2.4_electra/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cdee1665",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/12.2.4_electra/best_model/config.json\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"/home/elson/12.2.4_electra/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"finetuning_task\": \"mnli\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"entailment\",\n",
      "    \"1\": \"neutral\",\n",
      "    \"2\": \"contradiction\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"contradiction\": 2,\n",
      "    \"entailment\": 0,\n",
      "    \"neutral\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file /home/elson/12.2.4_electra/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing ElectraForSequenceClassification.\n",
      "\n",
      "All the weights of ElectraForSequenceClassification were initialized from the model checkpoint at /home/elson/12.2.4_electra/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ElectraForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 32\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/12.2.4_electra/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[-5.137   ,  4.57    ,  1.175   ],\n",
      "       [-4.062   ,  6.79    , -2.182   ],\n",
      "       [-4.105   ,  6.887   , -2.293   ],\n",
      "       [-3.852   ,  4.613   , -0.2115  ],\n",
      "       [-3.393   ,  6.56    , -2.793   ],\n",
      "       [-3.936   ,  6.887   , -2.51    ],\n",
      "       [-1.407   ,  6.03    , -4.73    ],\n",
      "       [-4.4     ,  6.824   , -1.797   ],\n",
      "       [-3.836   ,  6.836   , -2.545   ],\n",
      "       [ 1.014   ,  0.6655  , -1.879   ],\n",
      "       [-4.387   ,  6.812   , -1.788   ],\n",
      "       [ 2.096   ,  3.55    , -6.656   ],\n",
      "       [-3.516   ,  6.617   , -2.588   ],\n",
      "       [-4.125   ,  6.79    , -2.111   ],\n",
      "       [-5.215   ,  5.688   ,  0.1827  ],\n",
      "       [-4.07    ,  6.766   , -2.057   ],\n",
      "       [-3.26    ,  6.637   , -3.002   ],\n",
      "       [-3.82    , -1.49    ,  5.645   ],\n",
      "       [ 0.3323  ,  4.918   , -5.812   ],\n",
      "       [-3.16    ,  6.77    , -3.326   ],\n",
      "       [-3.89    ,  6.887   , -2.523   ],\n",
      "       [-5.664   ,  2.785   ,  3.396   ],\n",
      "       [-3.924   ,  6.68    , -2.182   ],\n",
      "       [ 2.955   , -4.344   ,  1.14    ],\n",
      "       [-3.18    ,  6.395   , -2.605   ],\n",
      "       [ 4.87    , -3.256   , -2.37    ],\n",
      "       [-4.008   ,  6.934   , -2.414   ],\n",
      "       [-0.378   ,  0.1377  ,  0.4324  ],\n",
      "       [-5.117   ,  5.277   ,  0.5034  ],\n",
      "       [-2.4     ,  6.543   , -4.02    ],\n",
      "       [ 3.855   , -0.45    , -4.348   ],\n",
      "       [-3.658   ,  6.785   , -2.723   ],\n",
      "       [-3.887   ,  6.906   , -2.564   ],\n",
      "       [-2.12    ,  5.633   , -3.234   ],\n",
      "       [-5.29    ,  6.195   , -0.1592  ],\n",
      "       [-3.768   ,  6.85    , -2.656   ],\n",
      "       [-4.324   ,  6.883   , -1.973   ],\n",
      "       [-4.03    ,  6.523   , -2.04    ],\n",
      "       [ 4.383   , -0.012215, -5.574   ],\n",
      "       [-4.094   ,  6.477   , -1.851   ],\n",
      "       [-5.625   ,  4.324   ,  1.935   ],\n",
      "       [-3.879   ,  6.91    , -2.55    ],\n",
      "       [-2.32    ,  6.297   , -3.82    ],\n",
      "       [ 5.01    , -2.223   , -3.82    ],\n",
      "       [-5.65    ,  5.52    ,  0.774   ],\n",
      "       [-4.977   ,  6.582   , -0.8965  ],\n",
      "       [-4.906   ,  6.695   , -1.08    ],\n",
      "       [-3.65    ,  6.7     , -2.568   ],\n",
      "       [-3.543   ,  6.83    , -2.855   ],\n",
      "       [ 4.89    , -1.236   , -4.86    ],\n",
      "       [-3.959   ,  6.797   , -2.338   ],\n",
      "       [-2.154   ,  5.992   , -3.625   ],\n",
      "       [-0.6123  , -1.864   ,  2.604   ],\n",
      "       [-5.48    ,  5.836   ,  0.3015  ],\n",
      "       [ 5.14    , -2.523   , -3.543   ],\n",
      "       [-3.396   ,  6.836   , -3.11    ],\n",
      "       [-2.92    ,  4.805   , -1.493   ],\n",
      "       [-4.156   ,  6.88    , -2.16    ],\n",
      "       [-3.262   ,  6.75    , -3.086   ],\n",
      "       [-4.11    ,  6.883   , -2.242   ],\n",
      "       [-4.13    ,  6.867   , -2.174   ],\n",
      "       [ 4.94    , -1.267   , -4.883   ],\n",
      "       [-3.562   ,  5.77    , -1.621   ],\n",
      "       [-1.497   ,  5.58    , -4.203   ],\n",
      "       [-5.258   ,  6.414   , -0.438   ],\n",
      "       [-3.16    ,  6.707   , -3.191   ],\n",
      "       [-3.969   ,  6.875   , -2.455   ],\n",
      "       [-3.754   ,  6.875   , -2.686   ],\n",
      "       [-4.223   ,  6.715   , -1.844   ],\n",
      "       [-3.691   ,  6.15    , -1.808   ],\n",
      "       [-4.566   ,  6.676   , -1.507   ],\n",
      "       [-5.086   ,  4.324   ,  1.422   ],\n",
      "       [-4.78    ,  6.723   , -1.336   ],\n",
      "       [-4.023   ,  6.62    , -1.915   ],\n",
      "       [-3.668   , -1.959   ,  5.883   ],\n",
      "       [-3.344   ,  6.504   , -2.637   ],\n",
      "       [-3.857   ,  6.895   , -2.57    ],\n",
      "       [-3.447   ,  6.453   , -2.475   ],\n",
      "       [-3.936   ,  6.758   , -2.316   ],\n",
      "       [-3.77    ,  6.887   , -2.584   ],\n",
      "       [-4.066   ,  6.48    , -1.987   ],\n",
      "       [-4.273   ,  6.895   , -2.066   ],\n",
      "       [-5.65    ,  4.95    ,  1.365   ],\n",
      "       [-3.898   ,  6.926   , -2.543   ],\n",
      "       [-4.074   ,  6.855   , -2.295   ],\n",
      "       [ 2.084   ,  2.486   , -5.324   ],\n",
      "       [-3.588   ,  6.867   , -2.865   ],\n",
      "       [-5.29    ,  6.254   , -0.2317  ],\n",
      "       [-4.047   ,  6.86    , -2.266   ],\n",
      "       [-4.117   ,  5.43    , -0.6865  ],\n",
      "       [-3.889   ,  6.86    , -2.541   ],\n",
      "       [-3.77    ,  6.797   , -2.553   ],\n",
      "       [ 0.8022  ,  0.7407  , -1.882   ],\n",
      "       [-4.68    ,  6.684   , -1.352   ],\n",
      "       [-0.651   ,  3.75    , -3.256   ],\n",
      "       [-4.26    ,  6.664   , -1.877   ],\n",
      "       [-0.9204  ,  5.71    , -4.98    ],\n",
      "       [-3.268   ,  6.445   , -2.842   ],\n",
      "       [-3.771   ,  6.914   , -2.697   ],\n",
      "       [-3.559   , -2.082   ,  5.895   ],\n",
      "       [ 5.176   , -2.338   , -3.916   ],\n",
      "       [-4.01    , -0.8335  ,  5.18    ],\n",
      "       [-4.49    ,  6.875   , -1.749   ],\n",
      "       [-5.062   ,  6.535   , -0.7754  ],\n",
      "       [-4.2     ,  6.785   , -1.999   ],\n",
      "       [-4.016   ,  6.816   , -2.299   ],\n",
      "       [-4.94    ,  6.324   , -0.616   ],\n",
      "       [ 5.066   , -1.257   , -5.027   ],\n",
      "       [-4.617   ,  6.43    , -1.213   ],\n",
      "       [-4.207   ,  6.89    , -2.088   ],\n",
      "       [ 3.85    ,  0.6187  , -5.62    ],\n",
      "       [-4.27    ,  6.883   , -2.045   ],\n",
      "       [-4.05    ,  6.914   , -2.336   ],\n",
      "       [-3.924   ,  6.82    , -2.436   ],\n",
      "       [-4.395   ,  6.83    , -1.857   ],\n",
      "       [-4.12    ,  6.758   , -2.146   ],\n",
      "       [-3.393   ,  6.848   , -3.09    ],\n",
      "       [ 4.61    , -1.228   , -4.484   ],\n",
      "       [-3.664   ,  6.836   , -2.709   ],\n",
      "       [-3.334   ,  6.47    , -2.727   ],\n",
      "       [-4.2     ,  6.91    , -2.178   ],\n",
      "       [-4.59    ,  6.23    , -1.098   ],\n",
      "       [-4.062   ,  6.86    , -2.291   ],\n",
      "       [-4.074   ,  6.855   , -2.252   ],\n",
      "       [-3.58    ,  6.9     , -2.844   ],\n",
      "       [-3.016   ,  6.742   , -3.432   ],\n",
      "       [-0.63    ,  4.414   , -3.795   ],\n",
      "       [-4.17    ,  6.88    , -2.15    ],\n",
      "       [-4.02    ,  6.645   , -2.152   ],\n",
      "       [-3.932   ,  6.89    , -2.486   ],\n",
      "       [-2.592   ,  5.62    , -2.62    ],\n",
      "       [ 1.204   ,  2.06    , -3.72    ],\n",
      "       [-4.555   ,  6.656   , -1.479   ],\n",
      "       [-3.71    ,  6.75    , -2.502   ],\n",
      "       [-4.062   ,  6.492   , -1.885   ],\n",
      "       [-4.703   ,  6.66    , -1.227   ],\n",
      "       [-3.889   ,  6.824   , -2.402   ],\n",
      "       [ 5.117   , -2.332   , -3.824   ],\n",
      "       [ 5.344   , -2.516   , -3.848   ],\n",
      "       [-2.996   , -2.645   ,  5.86    ],\n",
      "       [-4.105   ,  6.88    , -2.262   ],\n",
      "       [-4.105   ,  6.85    , -2.197   ],\n",
      "       [-1.848   ,  5.664   , -3.703   ],\n",
      "       [-3.941   ,  6.875   , -2.447   ],\n",
      "       [ 2.031   , -2.154   , -0.0853  ],\n",
      "       [-5.223   ,  2.682   ,  3.066   ],\n",
      "       [-3.932   ,  5.152   , -0.4724  ],\n",
      "       [-3.396   ,  4.227   , -0.2917  ],\n",
      "       [-3.398   ,  6.832   , -3.035   ],\n",
      "       [ 5.16    , -2.904   , -3.088   ],\n",
      "       [-3.346   ,  6.734   , -3.016   ],\n",
      "       [-4.09    ,  6.832   , -2.26    ],\n",
      "       [-4.594   ,  6.81    , -1.574   ],\n",
      "       [-4.535   ,  6.754   , -1.622   ],\n",
      "       [-4.15    ,  6.883   , -2.21    ],\n",
      "       [-3.893   ,  6.92    , -2.469   ],\n",
      "       [-4.074   ,  6.918   , -2.31    ],\n",
      "       [-4.49    ,  6.863   , -1.749   ],\n",
      "       [ 4.88    , -2.406   , -3.494   ],\n",
      "       [-1.855   ,  4.555   , -2.39    ],\n",
      "       [ 1.702   , -4.297   ,  2.55    ],\n",
      "       [-2.22    ,  5.598   , -3.2     ],\n",
      "       [-3.498   ,  6.812   , -2.906   ],\n",
      "       [ 1.919   ,  3.08    , -5.906   ],\n",
      "       [-4.047   ,  6.29    , -1.641   ],\n",
      "       [-3.787   ,  6.664   , -2.336   ],\n",
      "       [-3.615   ,  6.62    , -2.6     ],\n",
      "       [-3.238   ,  6.76    , -3.152   ],\n",
      "       [-4.81    ,  4.11    ,  1.355   ],\n",
      "       [-3.9     ,  6.676   , -2.246   ],\n",
      "       [-1.927   ,  2.611   , -0.325   ],\n",
      "       [-2.574   ,  5.65    , -2.662   ],\n",
      "       [ 4.03    ,  0.3809  , -5.58    ],\n",
      "       [-4.055   ,  6.84    , -2.287   ],\n",
      "       [-3.89    ,  6.848   , -2.494   ],\n",
      "       [ 2.19    , -0.03156 , -2.791   ],\n",
      "       [-5.27    ,  5.668   ,  0.3928  ],\n",
      "       [-1.868   ,  5.535   , -3.361   ],\n",
      "       [-3.969   ,  6.914   , -2.416   ],\n",
      "       [-1.3125  ,  5.188   , -3.77    ],\n",
      "       [-0.713   ,  4.527   , -3.877   ],\n",
      "       [-3.889   ,  5.914   , -1.403   ],\n",
      "       [ 2.885   ,  2.148   , -6.062   ],\n",
      "       [-4.24    ,  4.293   ,  0.4521  ],\n",
      "       [-5.34    ,  5.812   ,  0.1501  ],\n",
      "       [-1.279   ,  5.98    , -4.887   ],\n",
      "       [-3.777   ,  6.53    , -2.098   ],\n",
      "       [-4.074   ,  6.887   , -2.281   ],\n",
      "       [-0.07056 ,  4.277   , -4.652   ],\n",
      "       [-4.21    ,  6.812   , -2.078   ],\n",
      "       [-4.703   ,  6.64    , -1.304   ],\n",
      "       [-3.38    ,  6.805   , -3.012   ],\n",
      "       [-1.805   ,  6.26    , -4.527   ],\n",
      "       [-4.773   ,  6.625   , -1.243   ],\n",
      "       [ 5.234   , -1.427   , -5.055   ],\n",
      "       [-3.182   ,  6.707   , -3.26    ],\n",
      "       [-4.336   ,  6.82    , -1.927   ],\n",
      "       [-4.13    ,  6.934   , -2.273   ],\n",
      "       [-4.453   ,  6.805   , -1.798   ],\n",
      "       [-5.37    ,  5.07    ,  0.9893  ],\n",
      "       [-3.459   ,  6.824   , -3.016   ],\n",
      "       [-3.83    ,  6.85    , -2.617   ],\n",
      "       [-4.863   ,  3.328   ,  1.947   ],\n",
      "       [-4.258   ,  6.723   , -1.993   ],\n",
      "       [-4.473   ,  6.81    , -1.709   ],\n",
      "       [-4.492   ,  1.472   ,  3.387   ],\n",
      "       [-3.996   ,  6.883   , -2.344   ],\n",
      "       [-5.508   ,  5.434   ,  0.816   ],\n",
      "       [-4.035   ,  6.887   , -2.314   ],\n",
      "       [-4.285   ,  3.42    ,  1.427   ],\n",
      "       [-4.977   ,  2.242   ,  3.24    ],\n",
      "       [-5.176   ,  4.19    ,  1.656   ],\n",
      "       [-3.662   ,  6.855   , -2.79    ],\n",
      "       [-3.97    ,  6.848   , -2.324   ],\n",
      "       [-4.176   ,  6.875   , -2.195   ],\n",
      "       [-3.838   ,  6.816   , -2.434   ],\n",
      "       [-4.406   ,  6.81    , -1.74    ],\n",
      "       [-0.725   ,  5.06    , -4.395   ],\n",
      "       [-3.578   ,  6.855   , -2.883   ],\n",
      "       [ 3.414   ,  0.565   , -4.977   ],\n",
      "       [-3.896   ,  6.9     , -2.518   ],\n",
      "       [-3.69    ,  6.89    , -2.74    ],\n",
      "       [-0.11273 ,  0.691   , -0.5483  ],\n",
      "       [-4.17    ,  6.855   , -2.152   ],\n",
      "       [-4.145   ,  6.844   , -2.121   ],\n",
      "       [-3.734   ,  6.85    , -2.705   ],\n",
      "       [-3.584   ,  6.83    , -2.844   ],\n",
      "       [-2.062   , -2.936   ,  5.133   ],\n",
      "       [-2.031   ,  5.15    , -2.846   ],\n",
      "       [ 2.39    , -4.59    ,  1.989   ],\n",
      "       [-4.37    ,  6.87    , -1.939   ],\n",
      "       [-3.2     ,  6.49    , -2.87    ],\n",
      "       [-3.934   ,  6.93    , -2.486   ],\n",
      "       [ 4.65    , -2.982   , -2.36    ]], dtype=float16), label_ids=array([1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 2, 2, 1, 2, 1, 1, 2, 2,\n",
      "       1, 2, 0, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 0, 2, 1, 1,\n",
      "       1, 2, 1, 1, 1, 0, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 0, 2, 1, 2, 0,\n",
      "       1, 1, 0, 0, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       0, 2, 1, 2, 0, 1, 1, 1, 1, 1, 1, 2, 0, 2, 1, 2, 1, 1, 1, 2, 1, 1,\n",
      "       2, 1, 2, 1, 2, 1, 1, 1, 0, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 2, 1, 2, 1, 1, 1, 2, 0, 2, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2,\n",
      "       1, 1, 1, 2, 1, 0, 0, 0, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1,\n",
      "       1, 0, 1, 1, 1, 1, 0, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 0, 2, 1, 1, 1,\n",
      "       1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 0, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 0]), metrics={'test_loss': 2.6478166580200195, 'test_accuracy': 0.6538461538461539, 'test_balanced_accuracy': 0.44773032909593774, 'test_precision': 0.6479509094893711, 'test_recall': 0.6538461538461539, 'test_f1': 0.605337729209699, 'test_runtime': 1.2247, 'test_samples_per_second': 191.075, 'test_steps_per_second': 6.532})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be81d0c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "probabilities = torch.softmax(torch.tensor(test_results.predictions).to(torch.float32), dim=-1)\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)\n",
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef4c67fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_save = []\n",
    "for idx in range(len(test_data)):\n",
    "    item = dataset['test'][idx]\n",
    "    actual_label = item['label']\n",
    "    predicted_label = predictions[idx]\n",
    "    claim = item['claim'] \n",
    "    premise = item['premise'] \n",
    "    category = item['category']\n",
    "    \n",
    "    # Append the information as a dictionary to the list\n",
    "    data_to_save.append({\n",
    "        'Claim': claim,\n",
    "        'Premise': premise,\n",
    "        'Actual Label': actual_label,\n",
    "        'Predicted Label': predicted_label,\n",
    "        'Category' : category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_to_save)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/home/elson/results/12.2.4_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a1a63a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correctly classified instances\n",
    "correctly_classified = df[df['Actual Label'] == df['Predicted Label']]\n",
    "\n",
    "# Calculate misclassified instances\n",
    "misclassified = df[df['Actual Label'] != df['Predicted Label']]\n",
    "\n",
    "# Count the number of correctly classified and misclassified by category\n",
    "correct_classification_counts = correctly_classified['Category'].value_counts()\n",
    "misclassification_counts = misclassified['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c4055e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           35\n",
       "Fitness                  13\n",
       "Bone health              12\n",
       "Cancer                   12\n",
       "Diabetes                 10\n",
       "Throat                    9\n",
       "Hair                      8\n",
       "Cardiovascular Health     8\n",
       "Neurological health       8\n",
       "Skin                      7\n",
       "Ear                       6\n",
       "Blood                     5\n",
       "Eye                       5\n",
       "Women' s Health           4\n",
       "COVID                     3\n",
       "Dental Health             3\n",
       "Mental Health             2\n",
       "Muscles                   2\n",
       "Vascular                  1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "117a1d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Skin                     17\n",
       "General Health           16\n",
       "Bone health               9\n",
       "Men's health              6\n",
       "Hair                      4\n",
       "Blood                     4\n",
       "Muscles                   4\n",
       "Cardiovascular Health     4\n",
       "Eye                       4\n",
       "COVID                     3\n",
       "Diabetes                  2\n",
       "Fitness                   2\n",
       "Women' s Health           2\n",
       "Vascular                  2\n",
       "Mental Health             1\n",
       "Neurological health       1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
