{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score,balanced_accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "260a29d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using custom data configuration default-6274d2e8b2aaf27b\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-6274d2e8b2aaf27b/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 507.42it/s]\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-6274d2e8b2aaf27b/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-11cf639ca5c8f9ee.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: ['neutral', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'neutral', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'contradiction', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'contradiction', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'contradiction', 'entailment', 'contradiction', 'contradiction', 'neutral', 'contradiction', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'neutral', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'contradiction', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'contradiction', 'contradiction', 'entailment', 'entailment', 'entailment', 'contradiction', 'contradiction', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'contradiction', 'entailment', 'contradiction', 'entailment', 'neutral', 'entailment', 'contradiction', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'contradiction', 'entailment', 'contradiction', 'contradiction', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'contradiction', 'contradiction', 'contradiction', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'contradiction', 'contradiction', 'contradiction', 'contradiction', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'contradiction', 'contradiction', 'entailment', 'contradiction', 'entailment', 'entailment', 'contradiction', 'contradiction', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'contradiction', 'entailment', 'neutral', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'neutral', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'contradiction', 'contradiction', 'contradiction', 'entailment', 'contradiction', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'contradiction', 'entailment', 'contradiction', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'contradiction', 'entailment', 'entailment', 'contradiction', 'contradiction', 'entailment', 'entailment', 'contradiction', 'contradiction', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'neutral', 'entailment', 'entailment', 'contradiction', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'contradiction', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'neutral', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'contradiction', 'contradiction', 'entailment', 'contradiction', 'entailment', 'contradiction', 'entailment', 'entailment', 'contradiction', 'contradiction', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'contradiction', 'entailment', 'contradiction', 'entailment', 'neutral', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'contradiction', 'contradiction', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'neutral', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'neutral', 'entailment', 'entailment', 'contradiction', 'entailment', 'contradiction', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'contradiction', 'entailment', 'contradiction', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'neutral', 'entailment', 'contradiction', 'contradiction', 'contradiction', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'contradiction', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'neutral', 'contradiction', 'entailment', 'entailment', 'contradiction', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'contradiction', 'contradiction', 'entailment', 'contradiction', 'entailment', 'neutral', 'entailment', 'entailment', 'neutral', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'contradiction', 'entailment', 'contradiction', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'contradiction', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'entailment', 'contradiction', 'entailment', 'entailment']\n",
      "Metrics: {'accuracy': 0.7080103359173127, 'f1': 0.6783103361821334, 'precision': 0.6621122317069292, 'recall': 0.7080103359173127, 'balanced_accuracy': 0.4866722644330214}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Set the environment variable for CUDA\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "# Load the dataset from the CSV file\n",
    "dataset = load_dataset(\n",
    "    'csv',\n",
    "    data_files='datasethumanattribution.csv',\n",
    "    delimiter=',',\n",
    "    column_names=[\n",
    "        \"folder\",\"filename\",\"claim\",\"label\",\"url\",\"premise\",\"category\",\"gemini_label\",\"gemini_explanation\",\"gpt4_label\",\"gpt4_rationale\",\"split\"\n",
    "    ],\n",
    "    skiprows=1\n",
    ")\n",
    "\n",
    "# Keep only the required columns\n",
    "columns_to_keep = [\"claim\", \"premise\", \"label\"]\n",
    "all_columns = dataset['train'].column_names\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)\n",
    "\n",
    "# Define label mappings\n",
    "label2id = {\n",
    "    \"contradiction\": 0,\n",
    "    \"entailment\": 1,\n",
    "    \"neutral\": 2\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping.get(example['label'], 'neutral')\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "# Load pre-trained tokenizer and model\n",
    "model_name = \"pritamdeka/PubMedBERT-MNLI-MedNLI\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "model.eval()\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Tokenize the entire dataset\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='pritamdeka/PubMedBERT-MNLI-MedNLI'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "        \n",
    "        # Extracting claim and premise texts\n",
    "        claim = str(item['claim']) if item['claim'] is not None else \"\"\n",
    "        premise = str(item['premise']) if item['premise'] is not None else \"\"\n",
    "        \n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "            premise, claim,\n",
    "            return_tensors=\"pt\",\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            add_special_tokens=True\n",
    "        )\n",
    "        \n",
    "        # Remove batch dimension and add to item\n",
    "        item['input_ids'] = inputs['input_ids'].squeeze(0)\n",
    "        item['attention_mask'] = inputs['attention_mask'].squeeze(0)\n",
    "        \n",
    "        if 'label' in item:\n",
    "            item['labels'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return item\n",
    "\n",
    "# Convert entire dataset to MediClaimDataset\n",
    "full_dataset = MediClaimDataset(dataset['train'], tokenizer_name=model_name)\n",
    "\n",
    "# Create DataLoader for the full dataset\n",
    "full_loader = torch.utils.data.DataLoader(full_dataset, batch_size=8, collate_fn=lambda x: x)\n",
    "\n",
    "# Perform inference\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in full_loader:\n",
    "        # Ensure no None values in batch\n",
    "        batch = [b for b in batch if b is not None]\n",
    "        input_ids = torch.stack([b['input_ids'] for b in batch]).to(device)\n",
    "        attention_mask = torch.stack([b['attention_mask'] for b in batch]).to(device)\n",
    "        labels = torch.stack([b['labels'] for b in batch]).to(device)\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        \n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Compute metrics\n",
    "accuracy = accuracy_score(all_labels, all_predictions)\n",
    "f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "precision = precision_score(all_labels, all_predictions, average='weighted')\n",
    "recall = recall_score(all_labels, all_predictions, average='weighted')\n",
    "balanced_accuracy = balanced_accuracy_score(all_labels, all_predictions)\n",
    "\n",
    "metrics = {\n",
    "    'accuracy': accuracy,\n",
    "    'f1': f1,\n",
    "    'precision': precision,\n",
    "    'recall': recall,\n",
    "    'balanced_accuracy': balanced_accuracy\n",
    "}\n",
    "\n",
    "# Map predicted labels back to their original labels\n",
    "predicted_labels = [id2label[label] for label in all_predictions]\n",
    "\n",
    "# Print the predictions and metrics\n",
    "print(\"Predicted labels:\", predicted_labels)\n",
    "print(\"Metrics:\", metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset from the CSV file\n",
    "dataset = load_dataset(\n",
    "    'csv',\n",
    "    data_files='datasethumanattribution.csv',\n",
    "    delimiter=',',\n",
    "    column_names=[\n",
    "        \"folder\",\"filename\",\"claim\",\"label\",\"url\",\"premise\",\"category\",\"gemini_label\",\"gemini_explanation\",\"gpt4_label\",\"gpt4_rationale\",\"split\"\n",
    "    ],\n",
    "    skiprows=1\n",
    ")\n",
    "\n",
    "\n",
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f1db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\"claim\", \"premise\", \"label\",\"category\"]\n",
    "all_columns = dataset[\"train\"].column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 0,\n",
    "    \"entailment\": 1,\n",
    "    \"neutral\": 2\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='pritamdeka/PubMedBERT-MNLI-MedNLI'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "        # Extracting claim and evidence texts\n",
    "\n",
    "        claim = str(item['claim'])\n",
    "        premise = str(item['premise'])\n",
    "        \n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "            premise, claim,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "        item['input_ids'] = inputs['input_ids'].squeeze()  # Remove batch dimension\n",
    "        item['attention_mask']= inputs['attention_mask'].squeeze() # Remove batch dimension\n",
    "        \n",
    "        if 'label' in item:\n",
    "            item['labels'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62421eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"pritamdeka/PubMedBERT-MNLI-MedNLI\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=3, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    bal_accuracy = balanced_accuracy_score(labels,preds)\n",
    "\n",
    "    return {\"accuracy\": acc, \"balanced_accuracy\":bal_accuracy, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c5e0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/1.5.1_pubmedbert/',\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.01,\n",
    "    weight_decay=0.1,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/1.5.1_pubmedbert/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/1.5.1_pubmedbert/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63deaea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_path = \"/home/elson/1.5.1_pubmedbert/best_model/\"\n",
    "#model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd75bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "probabilities = torch.softmax(torch.tensor(test_results.predictions).to(torch.float32), dim=-1)\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)\n",
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766c4460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_save = []\n",
    "for idx in range(len(test_data)):\n",
    "    item = dataset['test'][idx]\n",
    "    actual_label = item['label']\n",
    "    predicted_label = predictions[idx]\n",
    "    claim = item['claim'] \n",
    "    premise = item['premise'] \n",
    "    category = item['category']\n",
    "    \n",
    "    # Append the information as a dictionary to the list\n",
    "    data_to_save.append({\n",
    "        'Claim': claim,\n",
    "        'Premise': premise,\n",
    "        'Actual Label': actual_label,\n",
    "        'Predicted Label': predicted_label,\n",
    "        'Category' : category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_to_save)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/home/elson/results/1.5.1_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e1cc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correctly classified instances\n",
    "correctly_classified = df[df['Actual Label'] == df['Predicted Label']]\n",
    "\n",
    "# Calculate misclassified instances\n",
    "misclassified = df[df['Actual Label'] != df['Predicted Label']]\n",
    "\n",
    "# Count the number of correctly classified and misclassified by category\n",
    "correct_classification_counts = correctly_classified['Category'].value_counts()\n",
    "misclassification_counts = misclassified['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd884e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6477f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassification_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
