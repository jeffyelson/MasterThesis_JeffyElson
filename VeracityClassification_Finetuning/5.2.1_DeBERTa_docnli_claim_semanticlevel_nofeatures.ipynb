{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-056e0caec74e8696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/elson/.cache/huggingface/datasets/csv/default-056e0caec74e8696/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 3454.95it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 1021.26it/s]\n",
      "                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/elson/.cache/huggingface/datasets/csv/default-056e0caec74e8696/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 189.56it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('csv',data_files='dataset_semanticattribution_nerfeatures_split.csv',delimiter=',',column_names=[\"claim\",\"premise\",\"label\",\"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\",\"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\",\"url\", \"entities\",\"entity_map\",\"gold_exp\",\"gem_exp\",\"gem_label\",\"entity_map_ev\",\"entity_ev\",\"split\"],skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e2914c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'gold_exp', 'gem_exp', 'gem_label', 'entity_map_ev', 'entity_ev', 'split'],\n",
       "        num_rows: 2322\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57d56e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'test',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['split']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ce96b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 31.90ba/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 32.25ba/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 31.27ba/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'gold_exp', 'gem_exp', 'gem_label', 'entity_map_ev', 'entity_ev', 'split'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'gold_exp', 'gem_exp', 'gem_label', 'entity_map_ev', 'entity_ev', 'split'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'gold_exp', 'gem_exp', 'gem_label', 'entity_map_ev', 'entity_ev', 'split'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41f1db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\"claim\", \"premise\", \"label\",\"category\"]\n",
    "all_columns = dataset[\"train\"].column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1623/1623 [00:00<00:00, 12176.91ex/s]\n",
      "100%|██████████| 465/465 [00:00<00:00, 12656.32ex/s]\n",
      "100%|██████████| 234/234 [00:00<00:00, 12400.72ex/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 1, 'entailment': 0, 'neutral': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 1,\n",
    "    \"entailment\": 0,\n",
    "    \"neutral\": 1\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='MoritzLaurer/DeBERTa-v3-base-mnli-fever-docnli-ling-2c'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "        # Extracting claim and evidence texts\n",
    "\n",
    "        claim = item['claim'].lower()\n",
    "        premise = item['premise'].lower().replace('\\n', '')\n",
    "        item['claim']=claim\n",
    "        item['premise']=premise\n",
    "        \n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "            claim, premise,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "        item['input_ids'] = inputs['input_ids'].squeeze()  # Remove batch dimension\n",
    "        item['attention_mask']= inputs['attention_mask'].squeeze() # Remove batch dimension\n",
    "        \n",
    "        if 'label' in item:\n",
    "            item['labels'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62421eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DebertaV2ForSequenceClassification(\n",
       "  (deberta): DebertaV2Model(\n",
       "    (embeddings): DebertaV2Embeddings(\n",
       "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaV2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (1): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (2): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (3): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (4): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (5): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (6): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (7): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (8): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (9): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (10): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (11): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (pooler): ContextPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): StableDropout()\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): StableDropout()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"MoritzLaurer/DeBERTa-v3-base-mnli-fever-docnli-ling-2c\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=2, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    bal_accuracy = balanced_accuracy_score(labels,preds)\n",
    "\n",
    "    return {\"accuracy\": acc, \"balanced_accuracy\":bal_accuracy, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17c5e0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'claim': 'myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.',\n",
       " 'premise': '; unkoviä‡, n.; dimkiä‡, i.; janaä‡koviä‡, p.; gavriloviä‡, m.; stanojeviä‡, o.; vukojeviä‡, j. frankincense and myrrh essential oils and burn incense fume against micro-inhabitants of sacral ambients.shameem, i. phytochemical & therapeutic potentials of murr makki (.oxidative stress and immunotoxic effects of lead and their amelioration with myrrh (commiphora molmol) emulsion.essential oils: magical ingredients for skin care.chakravarty, n.; kellogg, c.; alvarez, j.; equils, o.; morgan, m. uv protection by natural products: c. myrrha oil versus sunscreen.hamidpour, r.; hamidpour, s.; hamidpour, m.; shahlari, m. frankincense (ä¹³é¦™ rç” xiä\\x81ng;.species): from the selection of traditional applications to the novel phytotherapy for the prevention and treatment of serious diseases.chemistry and immunomodulatory activity of frankincense oil.compositions containing boswellia extracts.; cooper, e. frankincense and myrrh as remedies in children.',\n",
       " 'label': 0,\n",
       " 'category': 'General Health',\n",
       " 'input_ids': tensor([     1,  98237,   1830,   1080,    269,   1359,    427,    267,  17847,\n",
       "            633,    264,    408,   1300,    262,   2658,    265,    262,   1158,\n",
       "            260,      2,   2600,   1655,  16876,    667,  15726,  61593,    261,\n",
       "           2030,    260,    346,  15302,   6848,  15726,  61593,    261,    584,\n",
       "            260,    346,  33770,    452,  15726,  61593,  16876,    667,  15726,\n",
       "          61593,    261,    845,    260,    346,  14033,   2179,  24360,  34984,\n",
       "          15726,  61593,    261,   1917,    260,    346,  51194,  73907,   8007,\n",
       "          15726,  61593,    261,   2673,    260,    346,   1942,   3359,  73907,\n",
       "           8007,  15726,  61593,    261,   4402,    260,  88609,    263,  98237,\n",
       "           1830,   6725,    263,   5134,  30055,  77487,    532,   4014,    271,\n",
       "            547,  52263,  16224,    265,  86207,  14178,    268,    260,  62713,\n",
       "           4379,    261,    584,    260,  41529,  23399,    429,   8068,   1068,\n",
       "            268,    265,  42543,    834,   1917, 110269,    287,    260, 116367,\n",
       "           2148,    263,  25348,  20413,   1563,    265,    917,    263,    308,\n",
       "            266,  84530,  62542,    275,  98237,    287,    549,   6177,  65073,\n",
       "          44845,  22317,    285,  36774,    260,  30689,   6725,    294,   6162,\n",
       "           2731,    270,   1158,    599,    260,  46362,  41546,  71547,    261,\n",
       "           2030,    260,    346,  10918,    436,  80984,    261,   2285,    260,\n",
       "            346,    266,  46177,  28220,    261,   4402,    260,    346,  56545,\n",
       "          15150,    261,   2673,    260,    346,  95311,    261,   1917,    260,\n",
       "          54761,   1856,    293,   1008,    633,    294,   2285,    260,  98237,\n",
       "            452,   1080,   4796,  18839,    260,   5720,   4765,  39151,    261,\n",
       "           3638,    260,    346,  11965,   4765,  39151,    261,   1550,    260,\n",
       "            346,  11965,   4765,  39151,    261,   1917,    260,    346,  93607,\n",
       "          60641,    261,   1917,    260,  88609,    287,  15726,   2209,   5858,\n",
       "          25499,   3004,   3638,  27197,    318,  58813,  15726,    198,    133,\n",
       "           5900,    346,    260,  43427,    285,    294,    292,    262,   1857,\n",
       "            265,   1471,   1567,    264,    262,   2626,  41529,  28479,    270,\n",
       "            262,   5937,    263,   1035,    265,   1721,   4253,    260,  35753,\n",
       "            263, 121470,   1506,    265,  88609,   1080,    260,  99352,    268,\n",
       "           4086,  75371,   4191,   2767,  15808,    260,    346,  62510,    261,\n",
       "            865,    260,  88609,    263,  98237,    283,  11882,    267,    572,\n",
       "            260,      2,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'labels': tensor(0)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1530\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1530' max='1530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1530/1530 12:37, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.592800</td>\n",
       "      <td>0.524290</td>\n",
       "      <td>0.756989</td>\n",
       "      <td>0.737305</td>\n",
       "      <td>0.763956</td>\n",
       "      <td>0.756989</td>\n",
       "      <td>0.759674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.304300</td>\n",
       "      <td>0.824813</td>\n",
       "      <td>0.670968</td>\n",
       "      <td>0.696518</td>\n",
       "      <td>0.732934</td>\n",
       "      <td>0.670968</td>\n",
       "      <td>0.680830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.218900</td>\n",
       "      <td>0.839688</td>\n",
       "      <td>0.698925</td>\n",
       "      <td>0.702363</td>\n",
       "      <td>0.732368</td>\n",
       "      <td>0.698925</td>\n",
       "      <td>0.707105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.155400</td>\n",
       "      <td>0.964623</td>\n",
       "      <td>0.718280</td>\n",
       "      <td>0.733440</td>\n",
       "      <td>0.760622</td>\n",
       "      <td>0.718280</td>\n",
       "      <td>0.726510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.193300</td>\n",
       "      <td>1.023300</td>\n",
       "      <td>0.761290</td>\n",
       "      <td>0.737179</td>\n",
       "      <td>0.765201</td>\n",
       "      <td>0.761290</td>\n",
       "      <td>0.762954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.043100</td>\n",
       "      <td>1.349572</td>\n",
       "      <td>0.746237</td>\n",
       "      <td>0.749277</td>\n",
       "      <td>0.772079</td>\n",
       "      <td>0.746237</td>\n",
       "      <td>0.752562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.042400</td>\n",
       "      <td>1.407811</td>\n",
       "      <td>0.735484</td>\n",
       "      <td>0.729607</td>\n",
       "      <td>0.755157</td>\n",
       "      <td>0.735484</td>\n",
       "      <td>0.741200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.789541</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.716346</td>\n",
       "      <td>0.744749</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.737404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.768138</td>\n",
       "      <td>0.759140</td>\n",
       "      <td>0.747235</td>\n",
       "      <td>0.771083</td>\n",
       "      <td>0.759140</td>\n",
       "      <td>0.763081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.029600</td>\n",
       "      <td>1.921666</td>\n",
       "      <td>0.744086</td>\n",
       "      <td>0.734351</td>\n",
       "      <td>0.759527</td>\n",
       "      <td>0.744086</td>\n",
       "      <td>0.748926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>2.030093</td>\n",
       "      <td>0.739785</td>\n",
       "      <td>0.721154</td>\n",
       "      <td>0.749302</td>\n",
       "      <td>0.739785</td>\n",
       "      <td>0.743305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.098816</td>\n",
       "      <td>0.739785</td>\n",
       "      <td>0.721154</td>\n",
       "      <td>0.749302</td>\n",
       "      <td>0.739785</td>\n",
       "      <td>0.743305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.136739</td>\n",
       "      <td>0.735484</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.746256</td>\n",
       "      <td>0.735484</td>\n",
       "      <td>0.739372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.157541</td>\n",
       "      <td>0.735484</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.746256</td>\n",
       "      <td>0.735484</td>\n",
       "      <td>0.739372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.164259</td>\n",
       "      <td>0.735484</td>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.746256</td>\n",
       "      <td>0.735484</td>\n",
       "      <td>0.739372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.1_deberta_docnli/checkpoint-102\n",
      "Configuration saved in /home/elson/5.2.1_deberta_docnli/checkpoint-102/config.json\n",
      "Model weights saved in /home/elson/5.2.1_deberta_docnli/checkpoint-102/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.1_deberta_docnli/checkpoint-204\n",
      "Configuration saved in /home/elson/5.2.1_deberta_docnli/checkpoint-204/config.json\n",
      "Model weights saved in /home/elson/5.2.1_deberta_docnli/checkpoint-204/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.1_deberta_docnli/checkpoint-306\n",
      "Configuration saved in /home/elson/5.2.1_deberta_docnli/checkpoint-306/config.json\n",
      "Model weights saved in /home/elson/5.2.1_deberta_docnli/checkpoint-306/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.2.1_deberta_docnli/checkpoint-204] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.1_deberta_docnli/checkpoint-408\n",
      "Configuration saved in /home/elson/5.2.1_deberta_docnli/checkpoint-408/config.json\n",
      "Model weights saved in /home/elson/5.2.1_deberta_docnli/checkpoint-408/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.2.1_deberta_docnli/checkpoint-306] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.1_deberta_docnli/checkpoint-510\n",
      "Configuration saved in /home/elson/5.2.1_deberta_docnli/checkpoint-510/config.json\n",
      "Model weights saved in /home/elson/5.2.1_deberta_docnli/checkpoint-510/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.2.1_deberta_docnli/checkpoint-102] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/5.2.1_deberta_docnli/checkpoint-408] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.1_deberta_docnli/checkpoint-612\n",
      "Configuration saved in /home/elson/5.2.1_deberta_docnli/checkpoint-612/config.json\n",
      "Model weights saved in /home/elson/5.2.1_deberta_docnli/checkpoint-612/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.1_deberta_docnli/checkpoint-714\n",
      "Configuration saved in /home/elson/5.2.1_deberta_docnli/checkpoint-714/config.json\n",
      "Model weights saved in /home/elson/5.2.1_deberta_docnli/checkpoint-714/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.2.1_deberta_docnli/checkpoint-612] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.1_deberta_docnli/checkpoint-816\n",
      "Configuration saved in /home/elson/5.2.1_deberta_docnli/checkpoint-816/config.json\n",
      "Model weights saved in /home/elson/5.2.1_deberta_docnli/checkpoint-816/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.2.1_deberta_docnli/checkpoint-714] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.1_deberta_docnli/checkpoint-918\n",
      "Configuration saved in /home/elson/5.2.1_deberta_docnli/checkpoint-918/config.json\n",
      "Model weights saved in /home/elson/5.2.1_deberta_docnli/checkpoint-918/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.2.1_deberta_docnli/checkpoint-816] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.1_deberta_docnli/checkpoint-1020\n",
      "Configuration saved in /home/elson/5.2.1_deberta_docnli/checkpoint-1020/config.json\n",
      "Model weights saved in /home/elson/5.2.1_deberta_docnli/checkpoint-1020/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.2.1_deberta_docnli/checkpoint-918] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.1_deberta_docnli/checkpoint-1122\n",
      "Configuration saved in /home/elson/5.2.1_deberta_docnli/checkpoint-1122/config.json\n",
      "Model weights saved in /home/elson/5.2.1_deberta_docnli/checkpoint-1122/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.2.1_deberta_docnli/checkpoint-1020] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.1_deberta_docnli/checkpoint-1224\n",
      "Configuration saved in /home/elson/5.2.1_deberta_docnli/checkpoint-1224/config.json\n",
      "Model weights saved in /home/elson/5.2.1_deberta_docnli/checkpoint-1224/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.2.1_deberta_docnli/checkpoint-1122] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.1_deberta_docnli/checkpoint-1326\n",
      "Configuration saved in /home/elson/5.2.1_deberta_docnli/checkpoint-1326/config.json\n",
      "Model weights saved in /home/elson/5.2.1_deberta_docnli/checkpoint-1326/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.2.1_deberta_docnli/checkpoint-1224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.1_deberta_docnli/checkpoint-1428\n",
      "Configuration saved in /home/elson/5.2.1_deberta_docnli/checkpoint-1428/config.json\n",
      "Model weights saved in /home/elson/5.2.1_deberta_docnli/checkpoint-1428/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.2.1_deberta_docnli/checkpoint-1326] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/5.2.1_deberta_docnli/checkpoint-1530\n",
      "Configuration saved in /home/elson/5.2.1_deberta_docnli/checkpoint-1530/config.json\n",
      "Model weights saved in /home/elson/5.2.1_deberta_docnli/checkpoint-1530/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.2.1_deberta_docnli/checkpoint-1428] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/elson/5.2.1_deberta_docnli/checkpoint-510 (score: 0.7612903225806451).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /home/elson/5.2.1_deberta_docnli/best_model/config.json\n",
      "Model weights saved in /home/elson/5.2.1_deberta_docnli/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/5.2.1_deberta_docnli/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/5.2.1_deberta_docnli/best_model/special_tokens_map.json\n",
      "added tokens file saved in /home/elson/5.2.1_deberta_docnli/best_model/added_tokens.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/5.2.1_deberta_docnli/best_model/tokenizer_config.json',\n",
       " '/home/elson/5.2.1_deberta_docnli/best_model/special_tokens_map.json',\n",
       " '/home/elson/5.2.1_deberta_docnli/best_model/spm.model',\n",
       " '/home/elson/5.2.1_deberta_docnli/best_model/added_tokens.json')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/5.2.1_deberta_docnli/',\n",
    "    num_train_epochs=15,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.06,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/5.2.1_deberta_docnli/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/5.2.1_deberta_docnli/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63deaea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/5.2.1_deberta_docnli/best_model/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"/home/elson/5.2.1_deberta_docnli/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"entailment\",\n",
      "    \"1\": \"not_entailment\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"entailment\": 0,\n",
      "    \"not_entailment\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file /home/elson/5.2.1_deberta_docnli/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at /home/elson/5.2.1_deberta_docnli/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 16\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/5.2.1_deberta_docnli/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[ 2.2168e+00, -2.1133e+00],\n",
      "       [-2.0410e+00,  2.1797e+00],\n",
      "       [ 3.2891e+00, -3.1328e+00],\n",
      "       [-2.2031e+00,  2.3652e+00],\n",
      "       [ 1.9592e-01, -1.4746e-01],\n",
      "       [ 3.3164e+00, -3.1660e+00],\n",
      "       [ 3.1348e+00, -3.0000e+00],\n",
      "       [ 3.6816e+00, -3.5078e+00],\n",
      "       [ 3.1367e+00, -2.9961e+00],\n",
      "       [ 3.3047e+00, -3.1582e+00],\n",
      "       [ 3.1895e+00, -3.0449e+00],\n",
      "       [ 3.7363e+00, -3.5547e+00],\n",
      "       [ 1.1602e+00, -1.0869e+00],\n",
      "       [ 3.3887e+00, -3.2344e+00],\n",
      "       [ 2.2812e+00, -2.1855e+00],\n",
      "       [-2.8594e+00,  3.0371e+00],\n",
      "       [ 1.6934e+00, -1.6104e+00],\n",
      "       [ 3.3867e+00, -3.2305e+00],\n",
      "       [ 3.6309e+00, -3.4590e+00],\n",
      "       [ 3.3398e+00, -3.1875e+00],\n",
      "       [-1.2070e+00,  1.3643e+00],\n",
      "       [ 2.1680e+00, -2.0723e+00],\n",
      "       [ 3.5664e+00, -3.4004e+00],\n",
      "       [-2.6289e+00,  2.7988e+00],\n",
      "       [-5.0964e-02,  8.7158e-02],\n",
      "       [-4.2188e+00,  4.4062e+00],\n",
      "       [ 3.5938e+00, -3.4180e+00],\n",
      "       [ 2.7285e+00, -2.6055e+00],\n",
      "       [ 3.0312e+00, -2.9043e+00],\n",
      "       [ 3.5781e+00, -3.4121e+00],\n",
      "       [ 2.7266e+00, -2.6035e+00],\n",
      "       [ 2.0781e+00, -1.9883e+00],\n",
      "       [ 3.5098e+00, -3.3457e+00],\n",
      "       [ 2.7148e+00, -2.6016e+00],\n",
      "       [-1.7178e+00,  1.8672e+00],\n",
      "       [-6.7383e-01,  7.7100e-01],\n",
      "       [-3.1875e+00,  3.3750e+00],\n",
      "       [ 3.3672e+00, -3.2148e+00],\n",
      "       [-3.0176e+00,  3.1934e+00],\n",
      "       [ 8.9551e-01, -8.3008e-01],\n",
      "       [ 9.0771e-01, -8.4424e-01],\n",
      "       [ 3.8691e+00, -3.6777e+00],\n",
      "       [-1.0059e+00,  1.1367e+00],\n",
      "       [-4.2891e+00,  4.4961e+00],\n",
      "       [-1.7432e+00,  1.8936e+00],\n",
      "       [ 3.6680e+00, -3.4922e+00],\n",
      "       [ 3.1074e+00, -2.9668e+00],\n",
      "       [ 2.8320e+00, -2.7012e+00],\n",
      "       [ 3.5820e+00, -3.4121e+00],\n",
      "       [-2.6699e+00,  2.8320e+00],\n",
      "       [-1.2588e+00,  1.3945e+00],\n",
      "       [ 1.4756e+00, -1.4004e+00],\n",
      "       [ 2.7578e+00, -2.6445e+00],\n",
      "       [ 3.3398e+00, -3.1875e+00],\n",
      "       [-1.9360e-01,  2.0972e-01],\n",
      "       [ 3.6191e+00, -3.4434e+00],\n",
      "       [-2.6016e+00,  2.7715e+00],\n",
      "       [ 3.1543e+00, -3.0156e+00],\n",
      "       [ 3.1953e+00, -3.0527e+00],\n",
      "       [ 1.6084e+00, -1.5264e+00],\n",
      "       [ 2.4922e+00, -2.3867e+00],\n",
      "       [-3.1094e+00,  3.2812e+00],\n",
      "       [ 2.6465e+00, -2.5273e+00],\n",
      "       [ 4.6112e-02, -4.0779e-03],\n",
      "       [ 1.9795e+00, -1.8857e+00],\n",
      "       [ 3.4980e+00, -3.3340e+00],\n",
      "       [ 3.7246e+00, -3.5430e+00],\n",
      "       [ 3.8320e+00, -3.6445e+00],\n",
      "       [ 2.9863e+00, -2.8496e+00],\n",
      "       [-5.8350e-01,  6.4600e-01],\n",
      "       [ 2.7148e+00, -2.5977e+00],\n",
      "       [ 2.3770e+00, -2.2754e+00],\n",
      "       [ 1.9893e+00, -1.8916e+00],\n",
      "       [ 2.8828e+00, -2.7500e+00],\n",
      "       [ 1.2080e+00, -1.1309e+00],\n",
      "       [-2.7930e-01,  3.1128e-01],\n",
      "       [ 3.7207e+00, -3.5391e+00],\n",
      "       [ 3.4258e+00, -3.2695e+00],\n",
      "       [ 2.1211e+00, -2.0293e+00],\n",
      "       [ 2.6074e+00, -2.4922e+00],\n",
      "       [ 3.1523e+00, -3.0078e+00],\n",
      "       [ 3.7480e+00, -3.5684e+00],\n",
      "       [ 3.3652e+00, -3.2070e+00],\n",
      "       [ 3.3477e+00, -3.1934e+00],\n",
      "       [ 3.0156e+00, -2.8809e+00],\n",
      "       [ 2.6309e+00, -2.5195e+00],\n",
      "       [ 3.8477e+00, -3.6543e+00],\n",
      "       [ 3.4199e+00, -3.2637e+00],\n",
      "       [ 1.5820e+00, -1.5000e+00],\n",
      "       [ 3.2695e+00, -3.1191e+00],\n",
      "       [ 3.4824e+00, -3.3184e+00],\n",
      "       [ 2.6973e+00, -2.5840e+00],\n",
      "       [-1.2461e+00,  1.3965e+00],\n",
      "       [ 2.4180e+00, -2.3184e+00],\n",
      "       [ 2.6055e+00, -2.4961e+00],\n",
      "       [-1.5049e+00,  1.6533e+00],\n",
      "       [ 1.8730e+00, -1.7822e+00],\n",
      "       [ 2.4414e+00, -2.3359e+00],\n",
      "       [ 3.7168e+00, -3.5391e+00],\n",
      "       [ 4.1016e+00, -3.8926e+00],\n",
      "       [-2.8242e+00,  3.0000e+00],\n",
      "       [ 3.8086e+00, -3.6230e+00],\n",
      "       [ 2.6836e+00, -2.5605e+00],\n",
      "       [ 1.9365e+00, -1.8477e+00],\n",
      "       [ 3.2969e+00, -3.1445e+00],\n",
      "       [ 2.9258e+00, -2.7988e+00],\n",
      "       [ 2.7773e+00, -2.6582e+00],\n",
      "       [-4.1406e+00,  4.3477e+00],\n",
      "       [ 2.9453e+00, -2.8184e+00],\n",
      "       [ 3.3867e+00, -3.2324e+00],\n",
      "       [ 3.5703e+00, -3.4004e+00],\n",
      "       [ 3.5117e+00, -3.3496e+00],\n",
      "       [ 1.7715e+00, -1.6924e+00],\n",
      "       [ 3.8848e+00, -3.6914e+00],\n",
      "       [ 3.1270e+00, -2.9902e+00],\n",
      "       [ 2.3789e+00, -2.2754e+00],\n",
      "       [ 3.5566e+00, -3.3906e+00],\n",
      "       [ 2.8809e+00, -2.7578e+00],\n",
      "       [ 3.5977e+00, -3.4277e+00],\n",
      "       [ 3.2949e+00, -3.1465e+00],\n",
      "       [ 3.5938e+00, -3.4219e+00],\n",
      "       [ 1.5420e+00, -1.4697e+00],\n",
      "       [ 2.9668e+00, -2.8379e+00],\n",
      "       [ 1.3066e+00, -1.2363e+00],\n",
      "       [ 3.8613e+00, -3.6680e+00],\n",
      "       [ 3.5332e+00, -3.3711e+00],\n",
      "       [ 3.4219e+00, -3.2637e+00],\n",
      "       [ 2.4727e+00, -2.3672e+00],\n",
      "       [ 2.7168e+00, -2.5977e+00],\n",
      "       [ 1.6855e+00, -1.6172e+00],\n",
      "       [ 1.3086e+00, -1.2471e+00],\n",
      "       [ 3.5706e-02,  5.7564e-03],\n",
      "       [ 2.9531e+00, -2.8223e+00],\n",
      "       [ 2.6387e+00, -2.5254e+00],\n",
      "       [ 2.6270e+00, -2.5098e+00],\n",
      "       [-4.2578e+00,  4.4609e+00],\n",
      "       [ 2.6797e+00, -2.5605e+00],\n",
      "       [-3.8730e+00,  4.0625e+00],\n",
      "       [-1.1250e+00,  1.2686e+00],\n",
      "       [-1.1279e+00,  1.2607e+00],\n",
      "       [ 3.8887e+00, -3.6934e+00],\n",
      "       [ 2.5410e+00, -2.4375e+00],\n",
      "       [ 1.8389e+00, -1.7617e+00],\n",
      "       [ 3.7734e+00, -3.5938e+00],\n",
      "       [-8.5400e-01,  9.3701e-01],\n",
      "       [-8.5400e-01,  9.4775e-01],\n",
      "       [-8.0664e-01,  8.9990e-01],\n",
      "       [ 8.1348e-01, -7.5098e-01],\n",
      "       [ 3.8438e+00, -3.6543e+00],\n",
      "       [-4.0547e+00,  4.2500e+00],\n",
      "       [ 3.2852e+00, -3.1348e+00],\n",
      "       [ 3.5195e+00, -3.3496e+00],\n",
      "       [ 3.5156e+00, -3.3496e+00],\n",
      "       [ 3.1973e+00, -3.0469e+00],\n",
      "       [ 1.9062e+00, -1.8223e+00],\n",
      "       [ 3.7617e+00, -3.5781e+00],\n",
      "       [ 3.4668e+00, -3.3066e+00],\n",
      "       [-3.0742e+00,  3.2578e+00],\n",
      "       [ 2.3613e+00, -2.2637e+00],\n",
      "       [-5.6104e-01,  5.8691e-01],\n",
      "       [-3.3496e+00,  3.5215e+00],\n",
      "       [-2.0195e+00,  2.1836e+00],\n",
      "       [ 3.4199e+00, -3.2617e+00],\n",
      "       [-2.1445e+00,  2.2969e+00],\n",
      "       [ 9.5557e-01, -8.8623e-01],\n",
      "       [ 1.2852e+00, -1.2119e+00],\n",
      "       [ 3.0684e+00, -2.9336e+00],\n",
      "       [ 2.4648e+00, -2.3555e+00],\n",
      "       [-4.8267e-01,  5.1416e-01],\n",
      "       [ 1.8447e+00, -1.7607e+00],\n",
      "       [-3.9395e+00,  4.1289e+00],\n",
      "       [ 3.2402e+00, -3.0957e+00],\n",
      "       [-3.8281e+00,  4.0312e+00],\n",
      "       [ 3.0430e+00, -2.9102e+00],\n",
      "       [ 3.5957e+00, -3.4258e+00],\n",
      "       [ 2.6641e+00, -2.5469e+00],\n",
      "       [ 1.7617e+00, -1.6846e+00],\n",
      "       [ 1.5703e+00, -1.4902e+00],\n",
      "       [ 3.4297e+00, -3.2715e+00],\n",
      "       [ 2.0195e+00, -1.9355e+00],\n",
      "       [-2.1797e+00,  2.3418e+00],\n",
      "       [ 2.6816e+00, -2.5664e+00],\n",
      "       [-2.8652e+00,  3.0312e+00],\n",
      "       [ 2.8125e+00, -2.6816e+00],\n",
      "       [-1.1113e+00,  1.2510e+00],\n",
      "       [ 2.5566e+00, -2.4473e+00],\n",
      "       [ 3.3730e+00, -3.2168e+00],\n",
      "       [ 2.8105e+00, -2.6855e+00],\n",
      "       [-1.2910e+00,  1.4248e+00],\n",
      "       [ 3.5703e+00, -3.4043e+00],\n",
      "       [ 1.3340e+00, -1.2676e+00],\n",
      "       [ 3.2598e+00, -3.1133e+00],\n",
      "       [ 3.6777e+00, -3.5020e+00],\n",
      "       [ 2.9961e+00, -2.8574e+00],\n",
      "       [-3.0605e+00,  3.2344e+00],\n",
      "       [ 3.3340e+00, -3.1836e+00],\n",
      "       [ 1.8955e+00, -1.8115e+00],\n",
      "       [ 3.0195e+00, -2.8809e+00],\n",
      "       [ 2.9961e+00, -2.8633e+00],\n",
      "       [-2.6099e-01,  2.7759e-01],\n",
      "       [ 3.6230e+00, -3.4531e+00],\n",
      "       [ 3.5742e+00, -3.4082e+00],\n",
      "       [ 2.8711e+00, -2.7422e+00],\n",
      "       [ 3.2988e+00, -3.1504e+00],\n",
      "       [-1.2568e+00,  1.3926e+00],\n",
      "       [-1.6602e+00,  1.8242e+00],\n",
      "       [ 3.4980e+00, -3.3320e+00],\n",
      "       [ 1.6904e+00, -1.6152e+00],\n",
      "       [ 3.2988e+00, -3.1445e+00],\n",
      "       [ 1.9785e+00, -1.8916e+00],\n",
      "       [ 3.5723e+00, -3.4004e+00],\n",
      "       [-6.8115e-01,  7.3047e-01],\n",
      "       [ 3.8535e+00, -3.6641e+00],\n",
      "       [ 2.3379e+00, -2.2383e+00],\n",
      "       [ 3.0020e+00, -2.8672e+00],\n",
      "       [ 1.9199e+00, -1.8428e+00],\n",
      "       [ 2.6074e+00, -2.4961e+00],\n",
      "       [ 1.6680e+00, -1.5850e+00],\n",
      "       [ 3.5391e+00, -3.3711e+00],\n",
      "       [ 2.9766e+00, -2.8477e+00],\n",
      "       [ 3.8574e+00, -3.6660e+00],\n",
      "       [ 3.8750e+00, -3.6816e+00],\n",
      "       [ 1.9932e+00, -1.9004e+00],\n",
      "       [ 3.7344e+00, -3.5527e+00],\n",
      "       [ 2.6914e+00, -2.5684e+00],\n",
      "       [ 3.4980e+00, -3.3359e+00],\n",
      "       [ 3.5586e+00, -3.3926e+00],\n",
      "       [-3.4766e+00,  3.6699e+00],\n",
      "       [ 1.8135e+00, -1.7344e+00],\n",
      "       [ 2.6074e+00, -2.4941e+00],\n",
      "       [ 3.9531e+00, -3.7539e+00],\n",
      "       [ 3.3047e+00, -3.1543e+00],\n",
      "       [ 3.4707e+00, -3.3145e+00],\n",
      "       [ 1.4639e+00, -1.3857e+00]], dtype=float16), label_ids=array([0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
      "       0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
      "       0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1,\n",
      "       0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "       1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "       0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
      "       0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "       0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
      "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
      "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1]), metrics={'test_loss': 1.4092614650726318, 'test_accuracy': 0.717948717948718, 'test_balanced_accuracy': 0.6485278863799568, 'test_precision': 0.7089813647190696, 'test_recall': 0.717948717948718, 'test_f1': 0.6977823915888086, 'test_runtime': 2.3089, 'test_samples_per_second': 101.349, 'test_steps_per_second': 6.497})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73395d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "probabilities = torch.softmax(torch.tensor(test_results.predictions).to(torch.float32), dim=-1)\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)\n",
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb603377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_save = []\n",
    "for idx in range(len(test_data)):\n",
    "    item = dataset['test'][idx]\n",
    "    actual_label = item['label']\n",
    "    predicted_label = predictions[idx]\n",
    "    claim = item['claim'] \n",
    "    premise = item['premise'] \n",
    "    category = item['category']\n",
    "    \n",
    "    # Append the information as a dictionary to the list\n",
    "    data_to_save.append({\n",
    "        'Claim': claim,\n",
    "        'Premise': premise,\n",
    "        'Actual Label': actual_label,\n",
    "        'Predicted Label': predicted_label,\n",
    "        'Category' : category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_to_save)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/home/elson/results/5.2.1_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c23339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correctly classified instances\n",
    "correctly_classified = df[df['Actual Label'] == df['Predicted Label']]\n",
    "\n",
    "# Calculate misclassified instances\n",
    "misclassified = df[df['Actual Label'] != df['Predicted Label']]\n",
    "\n",
    "# Count the number of correctly classified and misclassified by category\n",
    "correct_classification_counts = correctly_classified['Category'].value_counts()\n",
    "misclassification_counts = misclassified['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca0def77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           37\n",
       "Bone health              17\n",
       "Diabetes                 12\n",
       "Cancer                   12\n",
       "Fitness                  12\n",
       "Throat                    9\n",
       "Cardiovascular Health     9\n",
       "Hair                      8\n",
       "Neurological health       7\n",
       "Ear                       6\n",
       "COVID                     6\n",
       "Skin                      6\n",
       "Men's health              5\n",
       "Muscles                   5\n",
       "Blood                     5\n",
       "Women' s Health           4\n",
       "Eye                       4\n",
       "Vascular                  2\n",
       "Mental Health             2\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0fddd944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Skin                     18\n",
       "General Health           14\n",
       "Eye                       5\n",
       "Hair                      4\n",
       "Bone health               4\n",
       "Blood                     4\n",
       "Cardiovascular Health     3\n",
       "Fitness                   3\n",
       "Dental Health             3\n",
       "Women' s Health           2\n",
       "Neurological health       2\n",
       "Vascular                  1\n",
       "Muscles                   1\n",
       "Mental Health             1\n",
       "Men's health              1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38b899b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_counts = df['Category'].value_counts()\n",
    "\n",
    "# Calculate ratios\n",
    "correct_classification_ratios = correct_classification_counts / total_counts\n",
    "misclassification_ratios = misclassification_counts / total_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c3598b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blood                    0.555556\n",
      "Bone health              0.809524\n",
      "COVID                    1.000000\n",
      "Cancer                   1.000000\n",
      "Cardiovascular Health    0.750000\n",
      "Dental Health                 NaN\n",
      "Diabetes                 1.000000\n",
      "Ear                      1.000000\n",
      "Eye                      0.444444\n",
      "Fitness                  0.800000\n",
      "General Health           0.725490\n",
      "Hair                     0.666667\n",
      "Men's health             0.833333\n",
      "Mental Health            0.666667\n",
      "Muscles                  0.833333\n",
      "Neurological health      0.777778\n",
      "Skin                     0.250000\n",
      "Throat                   1.000000\n",
      "Vascular                 0.666667\n",
      "Women' s Health          0.666667\n",
      "Name: Category, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(correct_classification_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27602a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blood                    0.444444\n",
      "Bone health              0.190476\n",
      "COVID                         NaN\n",
      "Cancer                        NaN\n",
      "Cardiovascular Health    0.250000\n",
      "Dental Health            1.000000\n",
      "Diabetes                      NaN\n",
      "Ear                           NaN\n",
      "Eye                      0.555556\n",
      "Fitness                  0.200000\n",
      "General Health           0.274510\n",
      "Hair                     0.333333\n",
      "Men's health             0.166667\n",
      "Mental Health            0.333333\n",
      "Muscles                  0.166667\n",
      "Neurological health      0.222222\n",
      "Skin                     0.750000\n",
      "Throat                        NaN\n",
      "Vascular                 0.333333\n",
      "Women' s Health          0.333333\n",
      "Name: Category, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(misclassification_ratios)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
