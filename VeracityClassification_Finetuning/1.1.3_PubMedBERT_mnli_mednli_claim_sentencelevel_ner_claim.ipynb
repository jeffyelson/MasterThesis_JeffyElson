{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-cfbf7584a6bb7c13\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 222.50it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('csv',data_files='dataset_sentenceattribution_nerfeatures_split.csv',delimiter=',',column_names=[\"claim\",\"premise\",\"label\",\"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\",\"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\",\"url\", \"entities\",\"entity_map\",\"gem_exp\",\"gem_label\",\"gpt_label\",\"gpt_exp\",\"gold_exp\",\"entity_map_ev\",\"entity_ev\",\"synonym\",\"voice\",\"split\"],skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ca8e735",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-aa1fd4d2889f655e.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-9cd628f4430f2ace.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-df968f39da4ad12a.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01252e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\"claim\", \"premise\", \"label\", \"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\"]\n",
    "all_columns = dataset[\"train\"].column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-15d57d6ca022b60e.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-cb38033f3eb137f6.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-b3e656009b8974a0.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 0, 'entailment': 1, 'neutral': 2}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 0,\n",
    "    \"entailment\": 1,\n",
    "    \"neutral\": 2\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e15010ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='pritamdeka/PubMedBERT-MNLI-MedNLI'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "        # Extracting claim and evidence texts\n",
    "        claim = item['claim'] \n",
    "        evidences = item['premise']\n",
    "        item['premise']=evidences\n",
    "        item['claim']=claim\n",
    "        additional_features = [\n",
    "            \"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\"]\n",
    "    \n",
    "        for feature in additional_features:\n",
    "            if feature in item:\n",
    "                claim += \"[SEP]\" + str(item[feature])\n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "            evidences,claim,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "         # Construct the output item\n",
    "        output_item = {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),  # Remove batch dimension\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),  # Remove batch dimension\n",
    "            'claim': claim,  # Include augmented claim text\n",
    "            'evidences': evidences  # Include original evidence text\n",
    "        }\n",
    "        \n",
    "        if 'label' in item:\n",
    "            output_item['label'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return output_item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62421eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"pritamdeka/PubMedBERT-MNLI-MedNLI\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=512)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=3, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    return {\"accuracy\": acc, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f5cf584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([    2,  4950,    16,  6033, 12255,  2877,  3426,  4783,  2594,  1988,\n",
       "          1920, 14542,  4006,  4480,  1930, 14227,  5004,  4415,  6691,  3547,\n",
       "          2578,  5527,  1920,  9570,  1927, 16973,  2037,  4407, 14512,  1942,\n",
       "         20201,  2007,  3605,  4407,  2877,  3426,    18,     3, 14227,  5004,\n",
       "          4415,  6691,  1977,  8929,  2251,  1922,  4407,  5715,  4461,  1942,\n",
       "          4087,  3326,  1920,  7818,  1927,  1920,  4407,    18,     3,    20,\n",
       "             3,    20,     3,    20,     3,    20,     3,    20,     3,    20,\n",
       "             3,    20,     3,    20,     3,    20,     3,    20,     3,    20,\n",
       "             3,    20,     3,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'claim': 'Myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0',\n",
       " 'evidences': 'Additionally, laser doppler blood flow measurement showed that the frankincense and myrrh essential oil compound could promote the elimination of capillaries from skin epidermis to dermis by increasing skin blood flow.',\n",
       " 'label': tensor(2)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1530\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1530' max='1530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1530/1530 07:00, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.728800</td>\n",
       "      <td>0.986880</td>\n",
       "      <td>0.627957</td>\n",
       "      <td>0.461970</td>\n",
       "      <td>0.627957</td>\n",
       "      <td>0.520548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.523100</td>\n",
       "      <td>0.890090</td>\n",
       "      <td>0.653763</td>\n",
       "      <td>0.685626</td>\n",
       "      <td>0.653763</td>\n",
       "      <td>0.654803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.402800</td>\n",
       "      <td>1.095684</td>\n",
       "      <td>0.658065</td>\n",
       "      <td>0.654026</td>\n",
       "      <td>0.658065</td>\n",
       "      <td>0.655892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.209900</td>\n",
       "      <td>1.415983</td>\n",
       "      <td>0.660215</td>\n",
       "      <td>0.664445</td>\n",
       "      <td>0.660215</td>\n",
       "      <td>0.662068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.310400</td>\n",
       "      <td>1.403687</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.685047</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.663343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.147400</td>\n",
       "      <td>1.819850</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.652961</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.654224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.082600</td>\n",
       "      <td>1.902994</td>\n",
       "      <td>0.660215</td>\n",
       "      <td>0.663070</td>\n",
       "      <td>0.660215</td>\n",
       "      <td>0.661596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.078100</td>\n",
       "      <td>1.986247</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.648720</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.650121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>2.303854</td>\n",
       "      <td>0.670968</td>\n",
       "      <td>0.659368</td>\n",
       "      <td>0.670968</td>\n",
       "      <td>0.664102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>2.362253</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666859</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.665133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>2.382763</td>\n",
       "      <td>0.662366</td>\n",
       "      <td>0.660565</td>\n",
       "      <td>0.662366</td>\n",
       "      <td>0.660946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>2.424015</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.680582</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.672455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.028300</td>\n",
       "      <td>2.487509</td>\n",
       "      <td>0.664516</td>\n",
       "      <td>0.671037</td>\n",
       "      <td>0.664516</td>\n",
       "      <td>0.667525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>2.500775</td>\n",
       "      <td>0.673118</td>\n",
       "      <td>0.681105</td>\n",
       "      <td>0.673118</td>\n",
       "      <td>0.676560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>2.515286</td>\n",
       "      <td>0.673118</td>\n",
       "      <td>0.679174</td>\n",
       "      <td>0.673118</td>\n",
       "      <td>0.675577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to /home/elson/1.1.3_pubmedbert/checkpoint-102\n",
      "Configuration saved in /home/elson/1.1.3_pubmedbert/checkpoint-102/config.json\n",
      "Model weights saved in /home/elson/1.1.3_pubmedbert/checkpoint-102/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.1.3_pubmedbert/checkpoint-408] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/1.1.3_pubmedbert/checkpoint-1530] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/1.1.3_pubmedbert/checkpoint-204\n",
      "Configuration saved in /home/elson/1.1.3_pubmedbert/checkpoint-204/config.json\n",
      "Model weights saved in /home/elson/1.1.3_pubmedbert/checkpoint-204/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.1.3_pubmedbert/checkpoint-102] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/1.1.3_pubmedbert/checkpoint-306\n",
      "Configuration saved in /home/elson/1.1.3_pubmedbert/checkpoint-306/config.json\n",
      "Model weights saved in /home/elson/1.1.3_pubmedbert/checkpoint-306/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.1.3_pubmedbert/checkpoint-204] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/1.1.3_pubmedbert/checkpoint-408\n",
      "Configuration saved in /home/elson/1.1.3_pubmedbert/checkpoint-408/config.json\n",
      "Model weights saved in /home/elson/1.1.3_pubmedbert/checkpoint-408/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.1.3_pubmedbert/checkpoint-306] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/1.1.3_pubmedbert/checkpoint-510\n",
      "Configuration saved in /home/elson/1.1.3_pubmedbert/checkpoint-510/config.json\n",
      "Model weights saved in /home/elson/1.1.3_pubmedbert/checkpoint-510/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.1.3_pubmedbert/checkpoint-408] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/1.1.3_pubmedbert/checkpoint-612\n",
      "Configuration saved in /home/elson/1.1.3_pubmedbert/checkpoint-612/config.json\n",
      "Model weights saved in /home/elson/1.1.3_pubmedbert/checkpoint-612/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/1.1.3_pubmedbert/checkpoint-714\n",
      "Configuration saved in /home/elson/1.1.3_pubmedbert/checkpoint-714/config.json\n",
      "Model weights saved in /home/elson/1.1.3_pubmedbert/checkpoint-714/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.1.3_pubmedbert/checkpoint-612] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/1.1.3_pubmedbert/checkpoint-816\n",
      "Configuration saved in /home/elson/1.1.3_pubmedbert/checkpoint-816/config.json\n",
      "Model weights saved in /home/elson/1.1.3_pubmedbert/checkpoint-816/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.1.3_pubmedbert/checkpoint-714] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/1.1.3_pubmedbert/checkpoint-918\n",
      "Configuration saved in /home/elson/1.1.3_pubmedbert/checkpoint-918/config.json\n",
      "Model weights saved in /home/elson/1.1.3_pubmedbert/checkpoint-918/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.1.3_pubmedbert/checkpoint-510] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/1.1.3_pubmedbert/checkpoint-816] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/1.1.3_pubmedbert/checkpoint-1020\n",
      "Configuration saved in /home/elson/1.1.3_pubmedbert/checkpoint-1020/config.json\n",
      "Model weights saved in /home/elson/1.1.3_pubmedbert/checkpoint-1020/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.1.3_pubmedbert/checkpoint-918] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/1.1.3_pubmedbert/checkpoint-1122\n",
      "Configuration saved in /home/elson/1.1.3_pubmedbert/checkpoint-1122/config.json\n",
      "Model weights saved in /home/elson/1.1.3_pubmedbert/checkpoint-1122/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/1.1.3_pubmedbert/checkpoint-1224\n",
      "Configuration saved in /home/elson/1.1.3_pubmedbert/checkpoint-1224/config.json\n",
      "Model weights saved in /home/elson/1.1.3_pubmedbert/checkpoint-1224/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.1.3_pubmedbert/checkpoint-1020] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/1.1.3_pubmedbert/checkpoint-1122] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/1.1.3_pubmedbert/checkpoint-1326\n",
      "Configuration saved in /home/elson/1.1.3_pubmedbert/checkpoint-1326/config.json\n",
      "Model weights saved in /home/elson/1.1.3_pubmedbert/checkpoint-1326/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/1.1.3_pubmedbert/checkpoint-1428\n",
      "Configuration saved in /home/elson/1.1.3_pubmedbert/checkpoint-1428/config.json\n",
      "Model weights saved in /home/elson/1.1.3_pubmedbert/checkpoint-1428/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.1.3_pubmedbert/checkpoint-1224] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/1.1.3_pubmedbert/checkpoint-1326] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/1.1.3_pubmedbert/checkpoint-1530\n",
      "Configuration saved in /home/elson/1.1.3_pubmedbert/checkpoint-1530/config.json\n",
      "Model weights saved in /home/elson/1.1.3_pubmedbert/checkpoint-1530/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/elson/1.1.3_pubmedbert/checkpoint-1428 (score: 0.6765595030295246).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /home/elson/1.1.3_pubmedbert/best_model/config.json\n",
      "Model weights saved in /home/elson/1.1.3_pubmedbert/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/1.1.3_pubmedbert/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/1.1.3_pubmedbert/best_model/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/1.1.3_pubmedbert/best_model/tokenizer_config.json',\n",
       " '/home/elson/1.1.3_pubmedbert/best_model/special_tokens_map.json',\n",
       " '/home/elson/1.1.3_pubmedbert/best_model/vocab.txt',\n",
       " '/home/elson/1.1.3_pubmedbert/best_model/added_tokens.json',\n",
       " '/home/elson/1.1.3_pubmedbert/best_model/tokenizer.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/1.1.3_pubmedbert/',\n",
    "    num_train_epochs=15,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.06,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/1.1.3_pubmedbert/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/1.1.3_pubmedbert/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63deaea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/1.1.3_pubmedbert/best_model/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"/home/elson/1.1.3_pubmedbert/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"contradiction\",\n",
      "    \"1\": \"entailment\",\n",
      "    \"2\": \"neutral\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"contradiction\": 0,\n",
      "    \"entailment\": 1,\n",
      "    \"neutral\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file /home/elson/1.1.3_pubmedbert/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at /home/elson/1.1.3_pubmedbert/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 16\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/1.1.3_pubmedbert/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[-4.3    ,  3.96   , -0.8345 ],\n",
      "       [-3.75   ,  6.65   , -4.     ],\n",
      "       [-4.293  ,  6.402  , -3.443  ],\n",
      "       [-2.404  , -3.66   ,  5.992  ],\n",
      "       [-4.11   ,  6.547  , -3.672  ],\n",
      "       [-3.98   ,  6.54   , -3.777  ],\n",
      "       [-3.6    ,  6.637  , -3.994  ],\n",
      "       [-4.195  ,  6.562  , -3.596  ],\n",
      "       [-4.055  ,  6.59   , -3.697  ],\n",
      "       [ 3.812  , -3.37   ,  0.3186 ],\n",
      "       [-3.457  ,  6.598  , -4.09   ],\n",
      "       [-3.656  ,  6.64   , -4.043  ],\n",
      "       [-2.361  ,  4.22   , -2.861  ],\n",
      "       [-3.775  ,  6.637  , -3.924  ],\n",
      "       [-4.18   , -1.851  ,  5.832  ],\n",
      "       [-2.598  , -1.694  ,  4.02   ],\n",
      "       [-3.402  ,  6.594  , -4.14   ],\n",
      "       [-4.273  ,  6.39   , -3.373  ],\n",
      "       [-3.525  ,  6.617  , -4.113  ],\n",
      "       [-3.785  ,  6.637  , -3.975  ],\n",
      "       [-4.26   ,  5.82   , -3.088  ],\n",
      "       [-4.38   ,  6.37   , -3.312  ],\n",
      "       [-4.02   , -1.571  ,  5.62   ],\n",
      "       [-3.05   , -2.469  ,  5.105  ],\n",
      "       [ 6.188  , -2.754  , -2.373  ],\n",
      "       [ 6.27   , -3.057  , -2.074  ],\n",
      "       [-3.629  ,  6.582  , -4.086  ],\n",
      "       [-4.418  ,  6.41   , -3.22   ],\n",
      "       [-3.814  ,  5.625  , -2.967  ],\n",
      "       [-3.715  ,  6.63   , -3.979  ],\n",
      "       [-4.74   ,  2.508  ,  1.64   ],\n",
      "       [-3.781  ,  6.63   , -3.92   ],\n",
      "       [-3.57   ,  6.645  , -4.113  ],\n",
      "       [-3.646  , -2.781  ,  6.27   ],\n",
      "       [-4.676  ,  0.3032 ,  4.27   ],\n",
      "       [-3.664  ,  6.625  , -4.08   ],\n",
      "       [-4.02   ,  6.574  , -3.75   ],\n",
      "       [-3.826  ,  6.547  , -3.867  ],\n",
      "       [-1.761  , -3.322  ,  5.246  ],\n",
      "       [-3.975  ,  6.49   , -3.805  ],\n",
      "       [-4.24   , -0.801  ,  4.28   ],\n",
      "       [-4.4    ,  6.32   , -3.262  ],\n",
      "       [-4.652  ,  4.52   , -1.236  ],\n",
      "       [ 1.938  , -4.3    ,  3.018  ],\n",
      "       [-4.734  ,  3.867  , -0.1654 ],\n",
      "       [-4.53   ,  5.715  , -2.713  ],\n",
      "       [-3.387  , -2.953  ,  6.25   ],\n",
      "       [-3.625  ,  6.65   , -4.01   ],\n",
      "       [-3.725  ,  6.543  , -4.02   ],\n",
      "       [ 2.352  , -2.44   ,  0.7935 ],\n",
      "       [-4.12   ,  5.51   , -2.758  ],\n",
      "       [-3.7    , -2.717  ,  6.297  ],\n",
      "       [-3.703  , -1.974  ,  5.223  ],\n",
      "       [ 1.878  ,  0.9863 , -2.91   ],\n",
      "       [ 6.023  , -3.24   , -1.638  ],\n",
      "       [-3.635  ,  6.625  , -3.994  ],\n",
      "       [ 6.41   , -2.83   , -2.36   ],\n",
      "       [-4.305  ,  6.38   , -3.451  ],\n",
      "       [-3.568  ,  6.617  , -4.062  ],\n",
      "       [-3.73   ,  6.594  , -4.04   ],\n",
      "       [-3.77   ,  6.61   , -3.986  ],\n",
      "       [ 6.457  , -2.82   , -2.371  ],\n",
      "       [-2.633  , -3.484  ,  6.29   ],\n",
      "       [-4.242  ,  6.473  , -3.385  ],\n",
      "       [-2.29   , -3.041  ,  5.39   ],\n",
      "       [-3.615  ,  6.617  , -4.133  ],\n",
      "       [-4.02   ,  6.56   , -3.697  ],\n",
      "       [-3.918  ,  6.62   , -3.775  ],\n",
      "       [-3.121  , -2.904  ,  6.145  ],\n",
      "       [ 5.863  , -3.193  , -1.59   ],\n",
      "       [-4.08   , -2.236  ,  6.055  ],\n",
      "       [-3.102  , -1.828  ,  4.57   ],\n",
      "       [-3.863  ,  0.3467 ,  3.121  ],\n",
      "       [ 1.99   , -0.3394 , -1.729  ],\n",
      "       [-3.814  ,  6.63   , -3.936  ],\n",
      "       [-4.934  ,  5.242  , -1.566  ],\n",
      "       [-3.873  ,  6.516  , -3.861  ],\n",
      "       [-3.805  ,  6.625  , -3.941  ],\n",
      "       [-3.45   ,  6.625  , -4.156  ],\n",
      "       [-3.928  ,  6.54   , -3.81   ],\n",
      "       [-3.514  ,  6.62   , -4.043  ],\n",
      "       [-3.717  ,  6.605  , -3.97   ],\n",
      "       [-3.887  ,  6.64   , -3.803  ],\n",
      "       [-3.451  ,  6.594  , -4.113  ],\n",
      "       [-3.639  ,  6.652  , -4.008  ],\n",
      "       [-2.418  , -3.924  ,  6.324  ],\n",
      "       [-3.97   ,  6.562  , -3.795  ],\n",
      "       [-0.1278 ,  0.573  , -1.257  ],\n",
      "       [-4.523  , -0.4077 ,  4.32   ],\n",
      "       [-2.633  , -3.484  ,  6.29   ],\n",
      "       [-4.418  ,  6.207  , -3.166  ],\n",
      "       [-3.803  ,  6.586  , -3.92   ],\n",
      "       [-2.47   , -3.605  ,  5.96   ],\n",
      "       [-3.646  ,  6.617  , -3.955  ],\n",
      "       [-3.771  ,  6.63   , -3.926  ],\n",
      "       [-4.547  ,  5.426  , -2.383  ],\n",
      "       [-3.238  ,  3.188  , -1.349  ],\n",
      "       [-3.557  , -2.463  ,  5.812  ],\n",
      "       [-3.547  ,  6.574  , -4.145  ],\n",
      "       [-3.764  ,  6.652  , -3.99   ],\n",
      "       [ 4.37   , -2.215  , -1.264  ],\n",
      "       [-4.234  ,  3.285  , -0.559  ],\n",
      "       [-3.766  ,  6.617  , -3.97   ],\n",
      "       [-1.9    , -2.555  ,  4.42   ],\n",
      "       [-4.617  ,  6.18   , -2.78   ],\n",
      "       [-3.756  ,  6.582  , -3.904  ],\n",
      "       [-5.027  ,  3.676  ,  0.03064],\n",
      "       [-3.188  , -3.22   ,  6.52   ],\n",
      "       [-3.848  ,  6.6    , -3.89   ],\n",
      "       [-5.33   ,  3.875  ,  0.7485 ],\n",
      "       [ 0.2018 ,  0.7197 , -1.395  ],\n",
      "       [-3.648  ,  6.645  , -4.07   ],\n",
      "       [-3.36   ,  6.58   , -4.184  ],\n",
      "       [-3.777  ,  6.6    , -3.861  ],\n",
      "       [-3.932  ,  6.613  , -3.883  ],\n",
      "       [-4.145  ,  6.387  , -3.49   ],\n",
      "       [-3.719  ,  6.633  , -4.004  ],\n",
      "       [-3.79   ,  6.633  , -3.8    ],\n",
      "       [-3.963  ,  6.54   , -3.705  ],\n",
      "       [-3.867  ,  6.547  , -3.941  ],\n",
      "       [-2.623  , -2.418  ,  4.832  ],\n",
      "       [-5.008  ,  5.438  , -1.404  ],\n",
      "       [-3.826  , -0.8296 ,  4.01   ],\n",
      "       [-5.098  ,  1.634  ,  2.66   ],\n",
      "       [-4.785  ,  2.367  ,  1.64   ],\n",
      "       [-3.885  ,  6.613  , -3.861  ],\n",
      "       [-3.434  , -2.148  ,  5.28   ],\n",
      "       [-3.697  ,  6.64   , -3.994  ],\n",
      "       [-3.873  ,  6.4    , -3.832  ],\n",
      "       [-3.174  , -3.246  ,  6.562  ],\n",
      "       [-3.959  ,  6.566  , -3.676  ],\n",
      "       [-3.783  , -2.389  ,  6.01   ],\n",
      "       [-3.934  ,  6.465  , -3.729  ],\n",
      "       [-2.84   , -3.508  ,  6.383  ],\n",
      "       [-3.533  , -1.624  ,  4.68   ],\n",
      "       [-4.473  ,  5.355  , -2.365  ],\n",
      "       [-3.95   ,  6.52   , -3.77   ],\n",
      "       [-0.779  , -3.805  ,  4.76   ],\n",
      "       [ 1.773  , -3.602  ,  2.268  ],\n",
      "       [-3.809  ,  6.637  , -3.963  ],\n",
      "       [-3.791  ,  6.582  , -4.004  ],\n",
      "       [-3.44   , -3.021  ,  6.39   ],\n",
      "       [-4.684  , -1.106  ,  5.477  ],\n",
      "       [-3.805  ,  6.598  , -3.953  ],\n",
      "       [-3.715  ,  6.594  , -3.85   ],\n",
      "       [-1.409  , -1.909  ,  2.799  ],\n",
      "       [-4.082  ,  6.414  , -3.564  ],\n",
      "       [-3.197  , -2.553  ,  5.688  ],\n",
      "       [-4.305  ,  6.24   , -3.277  ],\n",
      "       [-4.44   ,  6.348  , -3.053  ],\n",
      "       [-5.164  ,  1.207  ,  3.635  ],\n",
      "       [-4.24   ,  6.133  , -3.385  ],\n",
      "       [-3.877  ,  6.633  , -3.912  ],\n",
      "       [-3.77   ,  6.637  , -3.951  ],\n",
      "       [-4.086  ,  6.535  , -3.715  ],\n",
      "       [-3.549  ,  6.62   , -4.145  ],\n",
      "       [-3.885  ,  6.613  , -3.879  ],\n",
      "       [-4.363  ,  5.516  , -2.611  ],\n",
      "       [-3.08   , -2.334  ,  5.133  ],\n",
      "       [ 5.91   , -3.475  , -1.15   ],\n",
      "       [ 5.09   , -2.896  , -1.111  ],\n",
      "       [ 6.01   , -3.979  , -0.5625 ],\n",
      "       [-3.79   ,  6.637  , -3.97   ],\n",
      "       [ 2.229  , -3.338  ,  1.485  ],\n",
      "       [-3.732  ,  6.65   , -4.008  ],\n",
      "       [-4.242  ,  1.605  ,  1.458  ],\n",
      "       [-4.086  , -2.08   ,  5.777  ],\n",
      "       [ 1.354  , -2.924  ,  2.082  ],\n",
      "       [ 6.258  , -3.148  , -1.759  ],\n",
      "       [ 3.934  , -1.128  , -2.426  ],\n",
      "       [ 6.2    , -2.982  , -2.074  ],\n",
      "       [-3.564  ,  6.656  , -4.098  ],\n",
      "       [-2.904  , -3.398  ,  6.477  ],\n",
      "       [-3.64   ,  6.625  , -3.998  ],\n",
      "       [-3.729  , -2.     ,  5.453  ],\n",
      "       [-3.096  , -3.385  ,  6.492  ],\n",
      "       [-3.76   ,  6.656  , -3.936  ],\n",
      "       [ 4.098  , -4.043  ,  1.003  ],\n",
      "       [-5.223  ,  1.475  ,  3.393  ],\n",
      "       [ 6.324  , -2.982  , -2.225  ],\n",
      "       [-3.455  , -2.441  ,  5.8    ],\n",
      "       [-3.906  ,  6.48   , -3.727  ],\n",
      "       [-3.137  , -2.61   ,  5.613  ],\n",
      "       [-4.07   ,  6.52   , -3.469  ],\n",
      "       [-3.312  , -2.682  ,  5.797  ],\n",
      "       [-3.594  ,  6.64   , -4.062  ],\n",
      "       [-4.14   ,  6.293  , -3.473  ],\n",
      "       [-3.928  ,  6.59   , -3.85   ],\n",
      "       [-3.996  , -1.608  ,  5.285  ],\n",
      "       [-3.602  ,  6.645  , -4.086  ],\n",
      "       [ 5.434  , -3.64   , -0.73   ],\n",
      "       [-4.52   , -0.0678 ,  4.492  ],\n",
      "       [-3.768  , -1.194  ,  4.668  ],\n",
      "       [-4.832  ,  4.867  , -1.57   ],\n",
      "       [-3.26   , -0.87   ,  3.502  ],\n",
      "       [-3.658  ,  6.652  , -4.02   ],\n",
      "       [-5.266  ,  4.77   , -0.882  ],\n",
      "       [-3.854  ,  6.637  , -3.938  ],\n",
      "       [-3.873  ,  6.637  , -3.922  ],\n",
      "       [-3.227  ,  4.117  , -2.354  ],\n",
      "       [-3.717  ,  6.65   , -3.912  ],\n",
      "       [-4.562  ,  6.137  , -3.072  ],\n",
      "       [-4.06   ,  6.56   , -3.668  ],\n",
      "       [-3.568  ,  6.605  , -4.01   ],\n",
      "       [-4.723  , -0.11505,  4.496  ],\n",
      "       [-2.963  , -2.965  ,  5.668  ],\n",
      "       [-3.775  ,  6.637  , -3.928  ],\n",
      "       [-3.979  ,  6.633  , -3.697  ],\n",
      "       [-3.797  ,  6.625  , -3.947  ],\n",
      "       [-3.469  , -3.043  ,  6.418  ],\n",
      "       [ 3.27   , -0.283  , -2.7    ],\n",
      "       [-1.549  , -1.827  ,  3.098  ],\n",
      "       [-3.627  ,  6.65   , -4.086  ],\n",
      "       [-4.734  ,  5.98   , -2.666  ],\n",
      "       [-3.588  ,  6.617  , -4.08   ],\n",
      "       [-2.434  , -2.91   ,  5.07   ],\n",
      "       [-1.958  , -2.994  ,  4.992  ],\n",
      "       [ 5.7    , -2.81   , -1.739  ],\n",
      "       [-3.654  ,  6.637  , -3.996  ],\n",
      "       [ 1.23   , -1.946  ,  0.9355 ],\n",
      "       [-3.607  ,  6.61   , -4.113  ],\n",
      "       [-3.623  ,  6.64   , -4.12   ],\n",
      "       [-3.709  ,  6.637  , -4.02   ],\n",
      "       [-3.67   ,  6.605  , -4.043  ],\n",
      "       [-4.203  ,  5.996  , -3.18   ],\n",
      "       [-3.938  ,  6.586  , -3.877  ],\n",
      "       [-3.627  ,  6.652  , -4.03   ],\n",
      "       [ 1.747  , -3.363  ,  1.808  ],\n",
      "       [-4.43   ,  6.105  , -3.121  ],\n",
      "       [-3.828  ,  6.617  , -3.766  ],\n",
      "       [-3.51   ,  6.582  , -4.15   ],\n",
      "       [-4.62   ,  6.207  , -2.918  ],\n",
      "       [-4.47   ,  5.977  , -2.85   ],\n",
      "       [ 6.004  , -2.299  , -2.76   ]], dtype=float16), label_ids=array([2, 2, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, 0, 1, 2, 1, 2, 2, 1, 1, 2, 2,\n",
      "       2, 2, 2, 0, 1, 0, 2, 1, 1, 1, 1, 1, 2, 2, 0, 1, 0, 2, 2, 2, 1, 2,\n",
      "       2, 2, 2, 2, 2, 0, 2, 1, 2, 2, 2, 1, 2, 2, 1, 1, 1, 0, 2, 1, 2, 1,\n",
      "       2, 1, 0, 2, 1, 2, 2, 2, 1, 0, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1,\n",
      "       2, 2, 1, 1, 2, 1, 2, 1, 2, 2, 1, 2, 0, 2, 1, 2, 1, 1, 2, 2, 1, 1,\n",
      "       2, 1, 1, 1, 2, 1, 1, 1, 0, 2, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 2,\n",
      "       1, 2, 1, 2, 1, 1, 2, 1, 0, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 1, 2, 2,\n",
      "       1, 1, 1, 2, 1, 1, 0, 0, 1, 0, 1, 2, 1, 2, 2, 1, 0, 1, 2, 1, 1, 2,\n",
      "       1, 2, 1, 1, 2, 0, 2, 1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 2, 2, 1, 0,\n",
      "       1, 1, 1, 1, 1, 1, 1, 2, 0, 1, 0, 1, 1, 0]), metrics={'test_loss': 2.9060564041137695, 'test_accuracy': 0.6410256410256411, 'test_precision': 0.6416153227213135, 'test_recall': 0.6410256410256411, 'test_f1': 0.6308118245570572, 'test_runtime': 1.2084, 'test_samples_per_second': 193.65, 'test_steps_per_second': 12.413})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e098b45f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "probabilities = torch.softmax(torch.tensor(test_results.predictions).to(torch.float32), dim=-1)\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)\n",
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9020641b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_save = []\n",
    "for idx in range(len(test_data)):\n",
    "    item = dataset['test'][idx]\n",
    "    actual_label = item['label']\n",
    "    predicted_label = predictions[idx]\n",
    "    claim = item['claim'] \n",
    "    premise = item['premise'] \n",
    "    category = item['category']\n",
    "    \n",
    "    # Append the information as a dictionary to the list\n",
    "    data_to_save.append({\n",
    "        'Claim': claim,\n",
    "        'Premise': premise,\n",
    "        'Actual Label': actual_label,\n",
    "        'Predicted Label': predicted_label,\n",
    "        'Category' : category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_to_save)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/home/elson/results/1.1.3_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "797ffc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correctly classified instances\n",
    "correctly_classified = df[df['Actual Label'] == df['Predicted Label']]\n",
    "\n",
    "# Calculate misclassified instances\n",
    "misclassified = df[df['Actual Label'] != df['Predicted Label']]\n",
    "\n",
    "# Count the number of correctly classified and misclassified by category\n",
    "correct_classification_counts = correctly_classified['Category'].value_counts()\n",
    "misclassification_counts = misclassified['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0d83b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           34\n",
       "Bone health              16\n",
       "Skin                     15\n",
       "Cancer                   12\n",
       "Fitness                   8\n",
       "Cardiovascular Health     8\n",
       "Diabetes                  8\n",
       "Throat                    7\n",
       "Neurological health       6\n",
       "Hair                      6\n",
       "Eye                       5\n",
       "Blood                     5\n",
       "Ear                       5\n",
       "COVID                     4\n",
       "Mental Health             3\n",
       "Women' s Health           3\n",
       "Muscles                   2\n",
       "Men's health              2\n",
       "Vascular                  1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "947d26ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           17\n",
       "Skin                      9\n",
       "Fitness                   7\n",
       "Hair                      6\n",
       "Bone health               5\n",
       "Cardiovascular Health     4\n",
       "Muscles                   4\n",
       "Men's health              4\n",
       "Eye                       4\n",
       "Blood                     4\n",
       "Diabetes                  4\n",
       "Women' s Health           3\n",
       "Neurological health       3\n",
       "Dental Health             3\n",
       "COVID                     2\n",
       "Vascular                  2\n",
       "Throat                    2\n",
       "Ear                       1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
