{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score,balanced_accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82806f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jul 30 19:26:31 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:61:00.0 Off |                    0 |\n",
      "| N/A   46C    P0    58W / 300W |  15162MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  Off  | 00000000:62:00.0 Off |                    0 |\n",
      "| N/A   46C    P0    58W / 300W |  15162MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  Off  | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   45C    P0    61W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  Off  | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   45C    P0    60W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     24885      C   ...son/factcheck/bin/python3    15159MiB |\n",
      "|    1   N/A  N/A     24305      C   ...son/factcheck/bin/python3    15159MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-31dfe7adddcf5ced\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 171.87it/s]\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-ad71be204b279b28.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-e7b6b615907c24ca.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-bee802838a3bfaea.arrow\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset from the CSV file\n",
    "dataset = load_dataset(\n",
    "    'csv',\n",
    "    data_files='dataset_semanticattribution_nerfeatures_split.csv',\n",
    "    delimiter=',',\n",
    "    column_names=[\n",
    "        \"claim\", \"premise\", \"label\", \"category\", \"count_bf\", \"count_ca\", \"count_dis\",\n",
    "        \"count_food\", \"count_lipid\", \"count_treat\", \"pres_bf\", \"pres_ca\", \"pres_dis\",\n",
    "        \"pres_food\", \"pres_lipid\", \"pres_treat\", \"counte_bf\", \"counte_ca\", \"counte_dis\",\n",
    "        \"counte_food\", \"counte_lipid\", \"counte_treat\", \"prese_bf\", \"prese_ca\", \"prese_dis\",\n",
    "        \"prese_food\", \"prese_lipid\", \"prese_treat\", \"url\", \"entities\", \"entity_map\",\n",
    "        \"gold_exp\", \"gemini_exp\", \"gemini_label\",\"entity_ev\",\"entity_map_ev\", \"split\"\n",
    "    ],\n",
    "    skiprows=1\n",
    ")\n",
    "\n",
    "# Assuming 'split' column contains strings 'train', 'validation', 'test'\n",
    "# Filter the loaded dataset into subsets\n",
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'gold_exp', 'gemini_exp', 'gemini_label', 'entity_ev', 'entity_map_ev', 'split'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f3e71be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41f1db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['claim', 'premise', 'label','category','count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat','counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat']\n",
    "all_columns = train_dataset.column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-2b0030fb2dfa4c5c.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-2af2b7abf1a08f75.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-0bbf36fdf8be1d2b.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 0, 'entailment': 1, 'neutral': 2}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 0,\n",
    "    \"entailment\": 1,\n",
    "    \"neutral\": 2\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b5bb17f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "465"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['val']['claim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='bioformers/bioformer-8L-mnli'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "\n",
    "        claim = item['claim']\n",
    "        premise = item['premise'].replace('\\n', '').replace('[','').replace(']','')\n",
    "        \n",
    "        additional_features = [\n",
    "            \"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\"]\n",
    "    \n",
    "        for feature in additional_features:\n",
    "            if feature in item:\n",
    "                claim += \"[SEP]\" + str(item[feature])\n",
    "        \n",
    "        additional_features_ev = [\n",
    "            'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat']\n",
    "    \n",
    "        for feature_ev in additional_features_ev:\n",
    "            if feature_ev in item:\n",
    "                premise += \"[SEP]\" + str(item[feature])\n",
    "        item['claim']=claim\n",
    "        item['premise']=premise        \n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "             premise, claim,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "        item['input_ids'] = inputs['input_ids'].squeeze()  # Remove batch dimension\n",
    "        item['attention_mask']= inputs['attention_mask'].squeeze() # Remove batch dimension\n",
    "        \n",
    "        output_item = {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),  # Remove batch dimension\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),  # Remove batch dimension\n",
    "            'claim': claim,  # Include augmented claim text\n",
    "            'evidences': premise  # Include original evidence text\n",
    "        }\n",
    "        \n",
    "        if 'label' in item:\n",
    "            output_item['label'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return output_item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62421eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bioformers/bioformer-8L-mnli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=3, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f72c5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model is on device: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    bal_accuracy = balanced_accuracy_score(labels,preds)\n",
    "\n",
    "    return {\"accuracy\": acc, \"balanced_accuracy\":bal_accuracy, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17c5e0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  101,   132,   100,   336,   117,   151,   119,   132,   100,   336,\n",
       "           117,   146,   119,   132,   100,   336,   100,   336,   117,   153,\n",
       "           119,   132,   100,   336,   117,   150,   119,   132,   100,   336,\n",
       "           117,   152,   119,   132,   100,   336,   117,   147,   119, 26248,\n",
       "          2848,  9507,  1111,  1435,  2573,  1109,  4258,  3720, 15658,  1435,\n",
       "          8619,  1544,  3670, 13976,  1111,  2782,  2110,   118, 21901,  1431,\n",
       "         24417, 11643,  1113,   119, 26904,  4910,  1121,   117,   146,   119,\n",
       "         23293,  3919,   111,  3131,  8132,  1431, 24011,  1109,  2067,  1137,\n",
       "         14997,   113,   119, 21770,  2543,  1435, 10270,  5097, 30192,  1115,\n",
       "          1990,  1431,  2387,  1435,  1785, 28458,  1461,  2573,  1109,  4258,\n",
       "           113, 24383,  6169,  9565,  6814,  8952,   114, 18260,   119, 31651,\n",
       "           152,  4661,   131, 28447,  1527, 25714,  3062,  5642,  1471, 19601,\n",
       "          9248,   119, 23525, 26279, 17196,  1109,  2534,   117,   151,   119,\n",
       "           132, 11860,  3141,  1518,  1138,   117,   140,   119,   132,  1999,\n",
       "         23576, 14015,   117,   147,   119,   132, 11349,  4661,   117,   152,\n",
       "           119,   132,  9738,  2287,   117,   150,   119,  5959, 23114,  1520,\n",
       "         19077, 24358,  1481,   131,   140,   119,  2573,  1109,  4258,  1118,\n",
       "           152,  1473, 27495,  1463, 21906, 12695, 22906,   119, 31992,  1462,\n",
       "         12488,  1452,   117,   155,   119,   132, 31992,  1462, 12488,  1452,\n",
       "           117,   156,   119,   132, 31992,  1462, 12488,  1452,   117,   150,\n",
       "           119,   132, 25473, 22952,  1699,   117,   150,   119, 26248,  2848,\n",
       "          9507,  1111,   113,   100,   100,   333,   100,   132,   119,  2439,\n",
       "           114,   131,  5299,  1425,  4115,  1431,  5329,  4647,  1446,  1425,\n",
       "          3036, 20924, 17338,  1471,  1425,  4573,  1435,  1786,  1431,  5876,\n",
       "          3054,   119, 12459,  4503,  1435, 16228,  1950,  1431,  2132,  4765,\n",
       "          2848,  9507,  1111,  6187,   119,  6784,  3108,  1113,  3264, 27579,\n",
       "         15864,  1619,  6688,   119,   132,  3985,  2565,   117,   142,   119,\n",
       "         26248,  2848,  9507,  1111,  1435,  2573,  1109,  4258,  1475, 14868,\n",
       "          1559,  1427,  2409,   119,   102,   121,   102,   121,   102,   121,\n",
       "           102,   121,   102,   121,   102,   121,   102,   121,   102,   121,\n",
       "           102,   121,   102,   121,   102,   121,   102,   121,   102, 31487,\n",
       "          4258,  3720,  6187,  1478,  8811,  1822,  1427,  3550,  5183,  4030,\n",
       "          1446,  3346,  2520,  1425,  6875,  1431,  1425,  3550,   119,   102,\n",
       "           121,   102,   121,   102,   121,   102,   121,   102,   121,   102,\n",
       "           121,   102,   121,   102,   121,   102,   121,   102,   121,   102,\n",
       "           121,   102,   121,   102,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'claim': 'Myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0',\n",
       " 'evidences': '; UnkoviÄ‡, N.; DimkiÄ‡, I.; JanaÄ‡koviÄ‡, P.; GavriloviÄ‡, M.; StanojeviÄ‡, O.; VukojeviÄ‡, J. Frankincense and myrrh essential oils and burn incense fume against micro-inhabitants of sacral ambients.Shameem, I. Phytochemical & therapeutic potentials of Murr makki (.Oxidative stress and immunotoxic effects of lead and their amelioration with myrrh (Commiphora molmol) emulsion.Essential Oils: Magical Ingredients for Skin Care.Chakravarty, N.; Kellogg, C.; Alvarez, J.; Equils, O.; Morgan, M. UV Protection by Natural Products: C. myrrha Oil Versus Sunscreen.Hamidpour, R.; Hamidpour, S.; Hamidpour, M.; Shahlari, M. Frankincense (ä¹³é¦™ RÇ” XiÄ\\x81ng;.species): From the selection of traditional applications to the novel phytotherapy for the prevention and treatment of serious diseases.Chemistry and immunomodulatory activity of frankincense oil.Compositions containing Boswellia extracts.; Cooper, E. Frankincense and myrrh as remedies in children.[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0',\n",
       " 'label': tensor(1)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on device: cuda:0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='765' max='765' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [765/765 03:02, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.865800</td>\n",
       "      <td>0.856123</td>\n",
       "      <td>0.630108</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.484369</td>\n",
       "      <td>0.630108</td>\n",
       "      <td>0.546281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.757200</td>\n",
       "      <td>0.833359</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>0.425073</td>\n",
       "      <td>0.633120</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>0.615713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.545900</td>\n",
       "      <td>0.973159</td>\n",
       "      <td>0.632258</td>\n",
       "      <td>0.436059</td>\n",
       "      <td>0.616507</td>\n",
       "      <td>0.632258</td>\n",
       "      <td>0.621854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.217800</td>\n",
       "      <td>1.230310</td>\n",
       "      <td>0.647312</td>\n",
       "      <td>0.447429</td>\n",
       "      <td>0.624322</td>\n",
       "      <td>0.647312</td>\n",
       "      <td>0.634329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.157400</td>\n",
       "      <td>1.527516</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>0.436247</td>\n",
       "      <td>0.613925</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>0.617893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.120800</td>\n",
       "      <td>1.714247</td>\n",
       "      <td>0.587097</td>\n",
       "      <td>0.433576</td>\n",
       "      <td>0.614786</td>\n",
       "      <td>0.587097</td>\n",
       "      <td>0.599169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.048700</td>\n",
       "      <td>1.798415</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.483983</td>\n",
       "      <td>0.641754</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.639893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.047600</td>\n",
       "      <td>2.028518</td>\n",
       "      <td>0.587097</td>\n",
       "      <td>0.433576</td>\n",
       "      <td>0.620833</td>\n",
       "      <td>0.587097</td>\n",
       "      <td>0.601155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.060600</td>\n",
       "      <td>2.196743</td>\n",
       "      <td>0.563441</td>\n",
       "      <td>0.430820</td>\n",
       "      <td>0.618115</td>\n",
       "      <td>0.563441</td>\n",
       "      <td>0.581378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.045100</td>\n",
       "      <td>2.061433</td>\n",
       "      <td>0.619355</td>\n",
       "      <td>0.453742</td>\n",
       "      <td>0.628079</td>\n",
       "      <td>0.619355</td>\n",
       "      <td>0.623281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.048200</td>\n",
       "      <td>2.104021</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>0.465227</td>\n",
       "      <td>0.637331</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>0.631265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>2.234294</td>\n",
       "      <td>0.610753</td>\n",
       "      <td>0.448005</td>\n",
       "      <td>0.630915</td>\n",
       "      <td>0.610753</td>\n",
       "      <td>0.619521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>2.250161</td>\n",
       "      <td>0.610753</td>\n",
       "      <td>0.443616</td>\n",
       "      <td>0.624256</td>\n",
       "      <td>0.610753</td>\n",
       "      <td>0.615394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>2.234419</td>\n",
       "      <td>0.627957</td>\n",
       "      <td>0.445595</td>\n",
       "      <td>0.627363</td>\n",
       "      <td>0.627957</td>\n",
       "      <td>0.627308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>2.249635</td>\n",
       "      <td>0.630108</td>\n",
       "      <td>0.449341</td>\n",
       "      <td>0.628708</td>\n",
       "      <td>0.630108</td>\n",
       "      <td>0.628898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.2.5_bioformer/checkpoint-51\n",
      "Configuration saved in /home/elson/11.2.5_bioformer/checkpoint-51/config.json\n",
      "Model weights saved in /home/elson/11.2.5_bioformer/checkpoint-51/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.2.5_bioformer/checkpoint-102\n",
      "Configuration saved in /home/elson/11.2.5_bioformer/checkpoint-102/config.json\n",
      "Model weights saved in /home/elson/11.2.5_bioformer/checkpoint-102/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.2.5_bioformer/checkpoint-153\n",
      "Configuration saved in /home/elson/11.2.5_bioformer/checkpoint-153/config.json\n",
      "Model weights saved in /home/elson/11.2.5_bioformer/checkpoint-153/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.2.5_bioformer/checkpoint-51] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/11.2.5_bioformer/checkpoint-102] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.2.5_bioformer/checkpoint-204\n",
      "Configuration saved in /home/elson/11.2.5_bioformer/checkpoint-204/config.json\n",
      "Model weights saved in /home/elson/11.2.5_bioformer/checkpoint-204/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.2.5_bioformer/checkpoint-153] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.2.5_bioformer/checkpoint-255\n",
      "Configuration saved in /home/elson/11.2.5_bioformer/checkpoint-255/config.json\n",
      "Model weights saved in /home/elson/11.2.5_bioformer/checkpoint-255/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.2.5_bioformer/checkpoint-306\n",
      "Configuration saved in /home/elson/11.2.5_bioformer/checkpoint-306/config.json\n",
      "Model weights saved in /home/elson/11.2.5_bioformer/checkpoint-306/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.2.5_bioformer/checkpoint-255] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.2.5_bioformer/checkpoint-357\n",
      "Configuration saved in /home/elson/11.2.5_bioformer/checkpoint-357/config.json\n",
      "Model weights saved in /home/elson/11.2.5_bioformer/checkpoint-357/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.2.5_bioformer/checkpoint-306] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.2.5_bioformer/checkpoint-408\n",
      "Configuration saved in /home/elson/11.2.5_bioformer/checkpoint-408/config.json\n",
      "Model weights saved in /home/elson/11.2.5_bioformer/checkpoint-408/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.2.5_bioformer/checkpoint-357] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.2.5_bioformer/checkpoint-459\n",
      "Configuration saved in /home/elson/11.2.5_bioformer/checkpoint-459/config.json\n",
      "Model weights saved in /home/elson/11.2.5_bioformer/checkpoint-459/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.2.5_bioformer/checkpoint-408] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.2.5_bioformer/checkpoint-510\n",
      "Configuration saved in /home/elson/11.2.5_bioformer/checkpoint-510/config.json\n",
      "Model weights saved in /home/elson/11.2.5_bioformer/checkpoint-510/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.2.5_bioformer/checkpoint-459] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.2.5_bioformer/checkpoint-561\n",
      "Configuration saved in /home/elson/11.2.5_bioformer/checkpoint-561/config.json\n",
      "Model weights saved in /home/elson/11.2.5_bioformer/checkpoint-561/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.2.5_bioformer/checkpoint-510] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.2.5_bioformer/checkpoint-612\n",
      "Configuration saved in /home/elson/11.2.5_bioformer/checkpoint-612/config.json\n",
      "Model weights saved in /home/elson/11.2.5_bioformer/checkpoint-612/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.2.5_bioformer/checkpoint-561] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.2.5_bioformer/checkpoint-663\n",
      "Configuration saved in /home/elson/11.2.5_bioformer/checkpoint-663/config.json\n",
      "Model weights saved in /home/elson/11.2.5_bioformer/checkpoint-663/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.2.5_bioformer/checkpoint-612] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.2.5_bioformer/checkpoint-714\n",
      "Configuration saved in /home/elson/11.2.5_bioformer/checkpoint-714/config.json\n",
      "Model weights saved in /home/elson/11.2.5_bioformer/checkpoint-714/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.2.5_bioformer/checkpoint-663] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.2.5_bioformer/checkpoint-765\n",
      "Configuration saved in /home/elson/11.2.5_bioformer/checkpoint-765/config.json\n",
      "Model weights saved in /home/elson/11.2.5_bioformer/checkpoint-765/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.2.5_bioformer/checkpoint-714] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/elson/11.2.5_bioformer/checkpoint-204 (score: 0.6473118279569893).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /home/elson/11.2.5_bioformer/best_model/config.json\n",
      "Model weights saved in /home/elson/11.2.5_bioformer/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/11.2.5_bioformer/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/11.2.5_bioformer/best_model/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/11.2.5_bioformer/best_model/tokenizer_config.json',\n",
       " '/home/elson/11.2.5_bioformer/best_model/special_tokens_map.json',\n",
       " '/home/elson/11.2.5_bioformer/best_model/vocab.txt',\n",
       " '/home/elson/11.2.5_bioformer/best_model/added_tokens.json',\n",
       " '/home/elson/11.2.5_bioformer/best_model/tokenizer.json')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/11.2.5_bioformer/',\n",
    "    num_train_epochs=15,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.06,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(\"cuda:0\"),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "print(f\"Model is on device: {next(model.parameters()).device}\")\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/11.2.5_bioformer/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/11.2.5_bioformer/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cdee1665",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/11.2.5_bioformer/best_model/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"/home/elson/11.2.5_bioformer/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"finetuning_task\": \"mnli\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 512,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"entailment\",\n",
      "    \"1\": \"neutral\",\n",
      "    \"2\": \"contradiction\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2048,\n",
      "  \"label2id\": {\n",
      "    \"contradiction\": 2,\n",
      "    \"entailment\": 0,\n",
      "    \"neutral\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 8,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32768\n",
      "}\n",
      "\n",
      "loading weights file /home/elson/11.2.5_bioformer/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at /home/elson/11.2.5_bioformer/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 32\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/11.2.5_bioformer/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[-1.4590e+00,  6.7285e-01,  6.6992e-01],\n",
      "       [-2.6660e+00,  3.0449e+00, -3.8867e-01],\n",
      "       [-2.8457e+00,  4.1445e+00, -1.0850e+00],\n",
      "       [ 2.8750e+00, -3.7378e-01, -2.8379e+00],\n",
      "       [-1.4082e+00,  3.0469e+00, -1.4834e+00],\n",
      "       [-3.1211e+00,  3.9648e+00, -4.5435e-01],\n",
      "       [-1.0166e+00,  3.5332e+00, -2.1816e+00],\n",
      "       [-3.0957e+00,  3.8477e+00, -4.6704e-01],\n",
      "       [-2.7910e+00,  4.1523e+00, -1.1895e+00],\n",
      "       [-7.1094e-01,  6.2695e-01,  4.7803e-01],\n",
      "       [-2.6289e+00,  3.4023e+00, -5.6055e-01],\n",
      "       [ 3.0664e-01,  2.4883e+00, -2.7637e+00],\n",
      "       [-1.4443e+00,  3.5352e+00, -2.1660e+00],\n",
      "       [-3.1992e+00,  3.5664e+00,  1.0262e-02],\n",
      "       [-3.6660e+00,  1.8428e+00,  1.7861e+00],\n",
      "       [-8.3398e-01,  1.6104e+00, -1.1982e+00],\n",
      "       [-3.0566e+00,  3.2461e+00,  1.4656e-02],\n",
      "       [-2.5703e+00,  1.6680e+00,  5.3613e-01],\n",
      "       [-1.3135e+00,  3.1758e+00, -1.6758e+00],\n",
      "       [-2.0547e+00,  4.0977e+00, -1.9111e+00],\n",
      "       [-3.4531e+00,  3.2109e+00,  2.7783e-01],\n",
      "       [-3.3945e+00,  2.9238e+00,  5.2393e-01],\n",
      "       [-2.6230e+00,  3.8789e+00, -1.1748e+00],\n",
      "       [ 1.4414e+00, -1.1646e-01, -1.3730e+00],\n",
      "       [ 8.5645e-01,  6.3574e-01, -1.7334e+00],\n",
      "       [ 8.3496e-01, -1.5361e+00,  8.7646e-01],\n",
      "       [-1.7744e+00,  4.2031e+00, -2.2383e+00],\n",
      "       [-2.4023e+00,  2.9902e+00, -5.3809e-01],\n",
      "       [-2.9531e+00,  1.4639e+00,  1.7041e+00],\n",
      "       [-1.2988e+00,  3.6602e+00, -2.2969e+00],\n",
      "       [-1.7803e+00,  1.9014e+00, -3.4882e-02],\n",
      "       [-2.7207e+00,  4.1133e+00, -9.7070e-01],\n",
      "       [-3.0703e+00,  2.9277e+00,  1.3684e-01],\n",
      "       [-2.2656e-01,  2.0859e+00, -1.5957e+00],\n",
      "       [-3.2773e+00,  2.4277e+00,  9.1406e-01],\n",
      "       [-3.0840e+00,  3.5176e+00, -3.7280e-01],\n",
      "       [-2.2910e+00,  4.2500e+00, -1.8369e+00],\n",
      "       [-2.6523e+00,  4.1328e+00, -1.3008e+00],\n",
      "       [ 3.0039e+00, -1.1836e+00, -1.9229e+00],\n",
      "       [-3.4219e+00,  1.4463e+00,  1.9297e+00],\n",
      "       [-1.2539e+00,  2.0527e+00, -9.2822e-01],\n",
      "       [-2.9766e+00,  2.7656e+00,  3.3203e-02],\n",
      "       [-6.2109e-01,  6.6748e-01, -5.4102e-01],\n",
      "       [-1.4277e+00,  2.7539e+00, -1.4785e+00],\n",
      "       [-2.9785e+00,  3.2363e+00, -1.4453e-01],\n",
      "       [-2.7812e+00,  3.8613e+00, -1.0420e+00],\n",
      "       [-3.3652e+00,  3.5254e+00,  1.5405e-01],\n",
      "       [-2.3906e+00,  2.8203e+00, -3.9551e-01],\n",
      "       [-2.6426e+00,  4.2188e+00, -1.2979e+00],\n",
      "       [ 2.9102e+00, -1.6074e+00, -1.4443e+00],\n",
      "       [-2.6230e+00,  1.7217e+00,  6.0986e-01],\n",
      "       [-6.7676e-01,  2.3730e+00, -1.5303e+00],\n",
      "       [ 1.4121e+00, -6.2317e-02, -1.3203e+00],\n",
      "       [-3.5273e+00,  2.8145e+00,  1.0088e+00],\n",
      "       [ 5.0000e-01, -7.5488e-01,  2.9907e-01],\n",
      "       [-1.5615e+00,  3.9980e+00, -2.3691e+00],\n",
      "       [-6.1816e-01,  1.9707e+00, -1.5420e+00],\n",
      "       [-2.7852e+00,  3.5078e+00, -6.9775e-01],\n",
      "       [-2.3164e+00,  4.1602e+00, -1.5254e+00],\n",
      "       [-2.9590e+00,  3.6367e+00, -6.8652e-01],\n",
      "       [-2.8633e+00,  3.8672e+00, -6.7627e-01],\n",
      "       [ 2.7480e+00, -1.2891e+00, -1.8174e+00],\n",
      "       [-2.8359e+00,  1.5342e+00,  1.4717e+00],\n",
      "       [ 6.3037e-01,  1.7871e+00, -2.1328e+00],\n",
      "       [-3.5410e+00,  3.3750e+00,  3.8208e-01],\n",
      "       [-2.4766e+00,  4.0391e+00, -1.4424e+00],\n",
      "       [-3.0020e+00,  3.6621e+00, -2.8418e-01],\n",
      "       [-2.1367e+00,  3.5059e+00, -1.2988e+00],\n",
      "       [-2.8770e+00,  3.4863e+00, -3.3496e-01],\n",
      "       [-7.2784e-03,  3.4271e-02, -1.4893e-01],\n",
      "       [-3.0547e+00,  2.6953e+00,  5.5908e-01],\n",
      "       [-3.1426e+00,  3.8711e+00, -3.9893e-01],\n",
      "       [-3.3008e+00,  2.5762e+00,  1.0967e+00],\n",
      "       [-2.9824e+00,  3.6016e+00, -3.0811e-01],\n",
      "       [-2.0918e+00,  1.9812e-01,  1.4551e+00],\n",
      "       [-2.8066e+00,  3.9727e+00, -9.5947e-01],\n",
      "       [-2.0977e+00,  3.7012e+00, -1.6367e+00],\n",
      "       [-1.9297e+00,  3.7656e+00, -1.7461e+00],\n",
      "       [-2.4824e+00,  3.2949e+00, -5.7617e-01],\n",
      "       [-2.1055e+00,  3.1797e+00, -1.0615e+00],\n",
      "       [-3.1641e+00,  3.1953e+00,  2.1179e-01],\n",
      "       [-2.3965e+00,  4.0430e+00, -1.4795e+00],\n",
      "       [-2.7773e+00,  3.8770e+00, -1.0381e+00],\n",
      "       [-2.3691e+00,  4.1484e+00, -1.5762e+00],\n",
      "       [-3.0527e+00,  3.9922e+00, -4.5264e-01],\n",
      "       [-1.8545e+00,  2.9160e+00, -7.1436e-01],\n",
      "       [-1.9424e+00,  3.7500e+00, -1.8828e+00],\n",
      "       [-3.3398e+00,  3.4922e+00, -2.1805e-02],\n",
      "       [-2.7168e+00,  1.9609e+00,  6.6113e-01],\n",
      "       [-1.9375e+00, -8.3203e-01,  2.6270e+00],\n",
      "       [-2.8418e+00,  4.0312e+00, -9.6338e-01],\n",
      "       [-2.5801e+00,  4.0664e+00, -1.1338e+00],\n",
      "       [ 7.2900e-01,  9.5654e-01, -1.7041e+00],\n",
      "       [-3.2090e+00,  2.6191e+00,  4.0991e-01],\n",
      "       [ 1.4482e+00,  1.1348e+00, -2.6641e+00],\n",
      "       [-1.1338e+00, -2.5854e-01,  8.3203e-01],\n",
      "       [-1.5195e+00,  3.0176e+00, -1.5918e+00],\n",
      "       [ 5.2734e-02,  2.1465e+00, -2.3340e+00],\n",
      "       [-2.9453e+00,  3.8711e+00, -6.2891e-01],\n",
      "       [-2.2617e+00,  2.6484e+00, -5.9814e-01],\n",
      "       [ 3.0352e+00, -1.7617e+00, -1.4707e+00],\n",
      "       [-3.1836e+00,  3.1074e+00,  1.1670e-01],\n",
      "       [-3.0762e+00,  3.8809e+00, -3.7744e-01],\n",
      "       [-3.5137e+00,  2.6758e+00,  1.0088e+00],\n",
      "       [-2.3906e+00,  3.8555e+00, -1.2520e+00],\n",
      "       [-2.7598e+00,  3.9961e+00, -9.6289e-01],\n",
      "       [-3.3320e+00,  3.2715e+00,  1.8152e-01],\n",
      "       [-1.3340e+00,  3.1934e+00, -1.8105e+00],\n",
      "       [-2.8457e+00,  3.7461e+00, -4.3311e-01],\n",
      "       [-2.6035e+00,  3.6699e+00, -1.0117e+00],\n",
      "       [-2.8086e+00,  2.1523e+00,  9.9707e-01],\n",
      "       [-3.1719e+00,  3.6836e+00, -1.5320e-01],\n",
      "       [-2.2754e+00,  2.8398e+00, -5.0342e-01],\n",
      "       [-2.8867e+00,  4.2109e+00, -1.1611e+00],\n",
      "       [-2.7676e+00,  3.7461e+00, -9.3457e-01],\n",
      "       [-2.5215e+00,  3.8730e+00, -1.3594e+00],\n",
      "       [-9.2041e-01,  3.5586e+00, -2.5918e+00],\n",
      "       [ 7.4365e-01, -1.2734e+00,  6.0889e-01],\n",
      "       [-2.5273e+00,  3.6328e+00, -9.2822e-01],\n",
      "       [-2.4238e+00,  4.1367e+00, -1.5410e+00],\n",
      "       [-3.2715e+00,  3.5488e+00, -5.5054e-02],\n",
      "       [-2.8945e+00,  3.0488e+00, -1.9943e-02],\n",
      "       [-2.8125e+00,  3.2363e+00, -5.9668e-01],\n",
      "       [-1.6602e+00,  3.7109e+00, -1.9590e+00],\n",
      "       [-2.0430e+00,  3.6055e+00, -1.5752e+00],\n",
      "       [-1.4941e+00,  3.9395e+00, -2.3887e+00],\n",
      "       [-2.0840e+00,  4.0703e+00, -1.8857e+00],\n",
      "       [-3.0879e+00,  3.7676e+00, -7.4316e-01],\n",
      "       [-3.1016e+00,  3.7344e+00, -4.4214e-01],\n",
      "       [-2.8750e+00,  3.5723e+00, -4.2773e-01],\n",
      "       [ 2.7637e+00, -1.1631e+00, -1.5762e+00],\n",
      "       [ 1.1377e+00, -4.9683e-01, -7.6221e-01],\n",
      "       [-3.0723e+00,  3.8906e+00, -7.0508e-01],\n",
      "       [-1.6309e+00,  2.7012e+00, -1.1729e+00],\n",
      "       [-2.3105e+00,  4.0352e+00, -1.5537e+00],\n",
      "       [-2.5605e+00,  4.2109e+00, -1.4834e+00],\n",
      "       [-2.8594e+00,  3.4922e+00, -5.4883e-01],\n",
      "       [-1.6870e-01,  2.3418e+00, -2.4805e+00],\n",
      "       [-6.0303e-01,  2.4854e-01,  5.4541e-01],\n",
      "       [-3.3418e+00,  6.7090e-01,  3.0508e+00],\n",
      "       [-2.3770e+00,  4.0117e+00, -1.6777e+00],\n",
      "       [-3.1113e+00,  3.1426e+00,  2.2839e-01],\n",
      "       [-1.8184e+00,  2.9375e+00, -7.2363e-01],\n",
      "       [-2.2832e+00,  4.2617e+00, -1.8262e+00],\n",
      "       [-1.0266e-01, -7.2705e-01,  8.8965e-01],\n",
      "       [-2.5410e+00,  1.7598e+00,  5.7031e-01],\n",
      "       [ 4.7559e-01, -5.3436e-02, -3.4204e-01],\n",
      "       [-5.6738e-01,  5.7129e-01, -3.1836e-01],\n",
      "       [-2.2852e+00,  3.3203e+00, -1.2080e+00],\n",
      "       [-1.5049e+00,  2.6289e+00, -1.0566e+00],\n",
      "       [-2.2852e+00,  3.8984e+00, -1.3369e+00],\n",
      "       [-3.0547e+00,  3.9336e+00, -6.8066e-01],\n",
      "       [-2.8418e+00,  3.7539e+00, -8.5107e-01],\n",
      "       [-2.6582e+00,  3.0977e+00, -2.7490e-01],\n",
      "       [-3.0254e+00,  4.1055e+00, -6.5186e-01],\n",
      "       [-2.2324e+00,  3.0957e+00, -3.2593e-01],\n",
      "       [-2.0566e+00,  4.1367e+00, -1.9717e+00],\n",
      "       [-2.2988e+00,  4.0000e+00, -1.6494e+00],\n",
      "       [ 1.5840e+00, -1.9492e+00,  4.3286e-01],\n",
      "       [ 3.9819e-01,  1.5137e-01, -3.6133e-01],\n",
      "       [ 3.5718e-01, -1.4092e+00,  1.2197e+00],\n",
      "       [ 2.2012e+00, -1.0029e+00, -1.2207e+00],\n",
      "       [-2.7461e+00,  3.7148e+00, -7.9736e-01],\n",
      "       [ 6.5869e-01, -1.1221e+00,  2.3499e-01],\n",
      "       [-1.4131e+00,  6.2370e-04,  1.3721e+00],\n",
      "       [-1.9863e+00,  3.2754e+00, -1.4121e+00],\n",
      "       [-2.7891e+00,  3.8730e+00, -1.0684e+00],\n",
      "       [-2.4414e+00,  2.6934e+00, -2.9272e-01],\n",
      "       [-1.8884e-01, -1.6387e+00,  1.8926e+00],\n",
      "       [ 7.7588e-01,  4.8657e-01, -1.1318e+00],\n",
      "       [ 1.1152e+00, -1.6230e+00,  7.4805e-01],\n",
      "       [ 7.9492e-01, -1.4697e+00,  7.6611e-01],\n",
      "       [-1.4746e+00,  3.9219e+00, -2.2246e+00],\n",
      "       [-1.7871e+00,  4.0898e+00, -2.1680e+00],\n",
      "       [-3.0664e+00,  4.0586e+00, -5.8008e-01],\n",
      "       [-2.6191e+00,  1.7607e+00,  1.0928e+00],\n",
      "       [-2.6465e+00,  8.6670e-01,  1.9189e+00],\n",
      "       [ 1.0938e+00,  5.8057e-01, -1.7939e+00],\n",
      "       [-2.5703e+00,  4.0391e+00, -1.2520e+00],\n",
      "       [ 1.3965e+00, -1.6296e-01, -1.1982e+00],\n",
      "       [ 3.2983e-01,  2.1816e+00, -2.6738e+00],\n",
      "       [-1.7197e+00, -3.2520e-03,  1.4766e+00],\n",
      "       [ 2.1074e+00, -1.4297e+00, -6.9824e-01],\n",
      "       [-2.7871e+00,  2.2051e+00,  6.4062e-01],\n",
      "       [-2.6816e+00,  4.0625e+00, -1.0322e+00],\n",
      "       [-1.5645e+00,  3.7422e+00, -2.0938e+00],\n",
      "       [-1.7783e+00,  4.1133e+00, -2.3164e+00],\n",
      "       [-3.1016e+00,  4.0508e+00, -5.9766e-01],\n",
      "       [ 6.5234e-01,  1.1777e+00, -1.7334e+00],\n",
      "       [-3.1250e+00,  1.6191e+00,  1.3838e+00],\n",
      "       [-2.1562e+00,  3.7793e+00, -1.4219e+00],\n",
      "       [-1.0889e+00,  3.4980e+00, -2.5176e+00],\n",
      "       [ 1.4141e+00,  1.9551e+00, -3.7266e+00],\n",
      "       [-2.5508e+00,  6.0498e-01,  1.7744e+00],\n",
      "       [ 3.2363e+00, -1.0127e+00, -2.5273e+00],\n",
      "       [-2.4922e+00,  3.6562e+00, -6.7969e-01],\n",
      "       [-3.1387e+00,  3.3438e+00, -1.4160e-01],\n",
      "       [-2.8965e+00,  4.1055e+00, -8.7549e-01],\n",
      "       [-2.4824e+00,  4.1680e+00, -1.3965e+00],\n",
      "       [-3.1367e+00,  3.6953e+00, -2.4292e-01],\n",
      "       [-2.3418e+00,  4.1289e+00, -1.5537e+00],\n",
      "       [-2.8730e+00,  4.1445e+00, -1.0186e+00],\n",
      "       [-2.2598e+00,  1.8887e+00,  1.4148e-01],\n",
      "       [-2.5918e+00,  3.9824e+00, -1.0908e+00],\n",
      "       [-2.2930e+00,  3.3613e+00, -1.0312e+00],\n",
      "       [ 6.5979e-02,  2.2734e+00, -2.5625e+00],\n",
      "       [-2.8203e+00,  4.0586e+00, -1.1504e+00],\n",
      "       [-1.4707e+00, -5.4346e-01,  1.7451e+00],\n",
      "       [-2.5957e+00,  4.1367e+00, -1.4727e+00],\n",
      "       [-3.5913e-01,  2.0469e+00, -1.8828e+00],\n",
      "       [-3.2695e+00,  1.0635e+00,  2.6621e+00],\n",
      "       [-3.1152e+00,  3.9062e+00, -5.3613e-01],\n",
      "       [-2.5508e+00,  4.1094e+00, -1.3447e+00],\n",
      "       [-2.9375e+00,  3.6348e+00, -6.6016e-01],\n",
      "       [-3.0801e+00,  3.8164e+00, -2.9224e-01],\n",
      "       [-2.8262e+00,  3.8457e+00, -7.9590e-01],\n",
      "       [-2.6562e+00,  3.0781e+00, -4.2407e-01],\n",
      "       [-9.0186e-01,  1.3584e+00, -5.8301e-01],\n",
      "       [-2.6426e+00,  3.8125e+00, -8.1152e-01],\n",
      "       [ 1.5723e+00, -1.2109e-01, -1.3271e+00],\n",
      "       [-1.0566e+00,  3.7949e+00, -2.7441e+00],\n",
      "       [-3.0742e+00,  2.3613e+00,  8.6328e-01],\n",
      "       [-3.1465e+00,  2.9160e+00,  2.9443e-01],\n",
      "       [-2.6328e+00,  4.2109e+00, -1.3916e+00],\n",
      "       [-2.0977e+00,  3.7129e+00, -1.4443e+00],\n",
      "       [-3.2285e+00,  3.7422e+00, -1.6992e-01],\n",
      "       [-2.7402e+00,  3.8750e+00, -8.0176e-01],\n",
      "       [ 8.1934e-01,  3.4009e-01, -1.3584e+00],\n",
      "       [-1.7070e+00,  1.8271e+00, -4.2651e-01],\n",
      "       [ 1.1455e+00, -1.8047e+00,  7.7100e-01],\n",
      "       [-2.8438e+00,  4.1133e+00, -1.2119e+00],\n",
      "       [-6.8701e-01,  4.6118e-01, -6.2439e-02],\n",
      "       [-2.1016e+00,  4.0586e+00, -1.8164e+00],\n",
      "       [ 7.7783e-01, -1.3193e+00,  6.8652e-01]], dtype=float16), label_ids=array([1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 2, 2, 1, 2, 1, 1, 2, 2,\n",
      "       1, 2, 0, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 0, 2, 1, 1,\n",
      "       1, 2, 1, 1, 1, 0, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 0, 2, 1, 2, 0,\n",
      "       1, 1, 0, 0, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       0, 2, 1, 2, 0, 1, 1, 1, 1, 1, 1, 2, 0, 2, 1, 2, 1, 1, 1, 2, 1, 1,\n",
      "       2, 1, 2, 1, 2, 1, 1, 1, 0, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 2, 1, 2, 1, 1, 1, 2, 0, 2, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2,\n",
      "       1, 1, 1, 2, 1, 0, 0, 0, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1,\n",
      "       1, 0, 1, 1, 1, 1, 0, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 0, 2, 1, 1, 1,\n",
      "       1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 0, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 0]), metrics={'test_loss': 1.2950856685638428, 'test_accuracy': 0.6324786324786325, 'test_balanced_accuracy': 0.4672652023264796, 'test_precision': 0.5696463528128108, 'test_recall': 0.6324786324786325, 'test_f1': 0.5829779625741236, 'test_runtime': 0.6936, 'test_samples_per_second': 337.39, 'test_steps_per_second': 11.535})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be81d0c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "probabilities = torch.softmax(torch.tensor(test_results.predictions).to(torch.float32), dim=-1)\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)\n",
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef4c67fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_save = []\n",
    "for idx in range(len(test_data)):\n",
    "    item = dataset['test'][idx]\n",
    "    actual_label = item['label']\n",
    "    predicted_label = predictions[idx]\n",
    "    claim = item['claim'] \n",
    "    premise = item['premise'] \n",
    "    category = item['category']\n",
    "    \n",
    "    # Append the information as a dictionary to the list\n",
    "    data_to_save.append({\n",
    "        'Claim': claim,\n",
    "        'Premise': premise,\n",
    "        'Actual Label': actual_label,\n",
    "        'Predicted Label': predicted_label,\n",
    "        'Category' : category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_to_save)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/home/elson/results/11.2.5_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a1a63a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correctly classified instances\n",
    "correctly_classified = df[df['Actual Label'] == df['Predicted Label']]\n",
    "\n",
    "# Calculate misclassified instances\n",
    "misclassified = df[df['Actual Label'] != df['Predicted Label']]\n",
    "\n",
    "# Count the number of correctly classified and misclassified by category\n",
    "correct_classification_counts = correctly_classified['Category'].value_counts()\n",
    "misclassification_counts = misclassified['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c4055e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           33\n",
       "Bone health              12\n",
       "Fitness                  12\n",
       "Diabetes                 12\n",
       "Cancer                   11\n",
       "Skin                     10\n",
       "Cardiovascular Health     9\n",
       "Throat                    9\n",
       "Eye                       7\n",
       "Hair                      6\n",
       "Ear                       6\n",
       "Women' s Health           4\n",
       "Blood                     4\n",
       "Neurological health       4\n",
       "COVID                     3\n",
       "Muscles                   2\n",
       "Men's health              2\n",
       "Mental Health             2\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "117a1d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           18\n",
       "Skin                     14\n",
       "Bone health               9\n",
       "Hair                      6\n",
       "Neurological health       5\n",
       "Blood                     5\n",
       "Men's health              4\n",
       "Muscles                   4\n",
       "Vascular                  3\n",
       "Dental Health             3\n",
       "Fitness                   3\n",
       "Cardiovascular Health     3\n",
       "COVID                     3\n",
       "Eye                       2\n",
       "Women' s Health           2\n",
       "Mental Health             1\n",
       "Cancer                    1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
