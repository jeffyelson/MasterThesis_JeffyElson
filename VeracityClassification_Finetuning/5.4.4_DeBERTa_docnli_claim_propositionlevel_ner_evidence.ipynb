{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-022bc67e9c58e92d\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 205.55it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('csv',data_files='dataset_propositionattribution_nerfeatures.csv',delimiter=',',column_names=[\"claim\",\"premise\",\"label\",\"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\",\"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\",\"url\", \"entities\",\"entity_map\",\"entity_map_ev\",\"entities_ev\",\"gem_exp\",\"gem_label\",\"gpt_label\",\"gpt_exp\",\"gold_exp\",\"synonym\",\"voice\",\"split\"],skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e2914c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'entity_map_ev', 'entities_ev', 'gem_exp', 'gem_label', 'gpt_label', 'gpt_exp', 'gold_exp', 'synonym', 'voice', 'split'],\n",
       "        num_rows: 2322\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57d56e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'test',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'test',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'validation',\n",
       " 'train',\n",
       " 'test',\n",
       " 'train',\n",
       " ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']['split']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ce96b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-2b8e361375c0e153.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-0cc9bb699c2761fb.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-608a44ac65076739.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'entity_map_ev', 'entities_ev', 'gem_exp', 'gem_label', 'gpt_label', 'gpt_exp', 'gold_exp', 'synonym', 'voice', 'split'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'entity_map_ev', 'entities_ev', 'gem_exp', 'gem_label', 'gpt_label', 'gpt_exp', 'gold_exp', 'synonym', 'voice', 'split'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'entity_map_ev', 'entities_ev', 'gem_exp', 'gem_label', 'gpt_label', 'gpt_exp', 'gold_exp', 'synonym', 'voice', 'split'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41f1db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['claim', 'premise', 'label','category','counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat']\n",
    "all_columns = dataset[\"train\"].column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1623/1623 [00:00<00:00, 6964.58ex/s]\n",
      "100%|██████████| 465/465 [00:00<00:00, 6913.96ex/s]\n",
      "100%|██████████| 234/234 [00:00<00:00, 6746.31ex/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 1, 'entailment': 0, 'neutral': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 1,\n",
    "    \"entailment\": 0,\n",
    "    \"neutral\": 1\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='MoritzLaurer/DeBERTa-v3-base-mnli-fever-docnli-ling-2c'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "        # Extracting claim and evidence texts\n",
    "\n",
    "\n",
    "        claim = item['claim']\n",
    "        premise = item['premise'].replace('\\n', '').replace('[','').replace(']','')\n",
    "        \n",
    "        \n",
    "        additional_features_ev = [\n",
    "            'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat']\n",
    "    \n",
    "        for feature_ev in additional_features_ev:\n",
    "            if feature_ev in item:\n",
    "                premise += \"[SEP]\" + str(item[feature_ev])\n",
    "        item['claim']=claim\n",
    "        item['premise']=premise        \n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "             premise, claim,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "        item['input_ids'] = inputs['input_ids'].squeeze()  # Remove batch dimension\n",
    "        item['attention_mask']= inputs['attention_mask'].squeeze() # Remove batch dimension\n",
    "        \n",
    "        output_item = {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),  # Remove batch dimension\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),  # Remove batch dimension\n",
    "            'claim': claim,  # Include augmented claim text\n",
    "            'evidences': premise  # Include original evidence text\n",
    "        }\n",
    "        \n",
    "        if 'label' in item:\n",
    "            output_item['label'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return output_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62421eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DebertaV2ForSequenceClassification(\n",
       "  (deberta): DebertaV2Model(\n",
       "    (embeddings): DebertaV2Embeddings(\n",
       "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaV2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (1): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (2): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (3): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (4): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (5): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (6): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (7): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (8): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (9): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (10): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (11): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (pooler): ContextPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): StableDropout()\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): StableDropout()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"MoritzLaurer/DeBERTa-v3-base-mnli-fever-docnli-ling-2c\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=2, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    bal_accuracy = balanced_accuracy_score(labels,preds)\n",
    "\n",
    "    return {\"accuracy\": acc, \"balanced_accuracy\":bal_accuracy, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "17c5e0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([    1,   279,  1830,  6725,   265, 88609,   263, 98237,   993,   262,\n",
       "         49462,   265,   262, 22003, 96579,   267,   262, 61462,   263,   575,\n",
       "           262, 26217,   263,  9854,  1730,   264,   993,   262, 39632,   265,\n",
       "           262,  1158,   263,  4843,   262,  7275,  1290,   260,     2,   767,\n",
       "             2,   767,     2,   767,     2,   767,     2,   767,     2,   767,\n",
       "             2,   767,     2,   767,     2,   767,     2,   767,     2,   767,\n",
       "             2,   767,     2,   573, 52341,  1830,  1080,   269,  1359,   427,\n",
       "           267, 17847,   633,   264,   408,  1300,   262,  2658,   265,   262,\n",
       "          1158,   260,     2,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'claim': 'Myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.',\n",
       " 'evidences': 'The essential oils of frankincense and myrrh increase the fluidity of the lipid bilayer in the cuticle and change the orderly and dense structure to increase the permeability of the skin and decrease the barrier effect.[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0',\n",
       " 'label': tensor(0)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1020\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1020' max='1020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1020/1020 15:15, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.811100</td>\n",
       "      <td>0.859063</td>\n",
       "      <td>0.688172</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.720211</td>\n",
       "      <td>0.688172</td>\n",
       "      <td>0.694711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.472400</td>\n",
       "      <td>0.658250</td>\n",
       "      <td>0.696774</td>\n",
       "      <td>0.698182</td>\n",
       "      <td>0.720045</td>\n",
       "      <td>0.696774</td>\n",
       "      <td>0.702548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.399200</td>\n",
       "      <td>0.660154</td>\n",
       "      <td>0.696774</td>\n",
       "      <td>0.699545</td>\n",
       "      <td>0.721415</td>\n",
       "      <td>0.696774</td>\n",
       "      <td>0.702675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.242800</td>\n",
       "      <td>0.740577</td>\n",
       "      <td>0.707527</td>\n",
       "      <td>0.701061</td>\n",
       "      <td>0.722323</td>\n",
       "      <td>0.707527</td>\n",
       "      <td>0.712017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.311300</td>\n",
       "      <td>0.840822</td>\n",
       "      <td>0.711828</td>\n",
       "      <td>0.733030</td>\n",
       "      <td>0.756223</td>\n",
       "      <td>0.711828</td>\n",
       "      <td>0.718013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.230900</td>\n",
       "      <td>0.759007</td>\n",
       "      <td>0.737634</td>\n",
       "      <td>0.723030</td>\n",
       "      <td>0.743387</td>\n",
       "      <td>0.737634</td>\n",
       "      <td>0.739839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.187300</td>\n",
       "      <td>0.886393</td>\n",
       "      <td>0.711828</td>\n",
       "      <td>0.728939</td>\n",
       "      <td>0.750917</td>\n",
       "      <td>0.711828</td>\n",
       "      <td>0.718028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.120700</td>\n",
       "      <td>1.202480</td>\n",
       "      <td>0.690323</td>\n",
       "      <td>0.689091</td>\n",
       "      <td>0.711723</td>\n",
       "      <td>0.690323</td>\n",
       "      <td>0.696002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>1.553659</td>\n",
       "      <td>0.688172</td>\n",
       "      <td>0.705152</td>\n",
       "      <td>0.729887</td>\n",
       "      <td>0.688172</td>\n",
       "      <td>0.694886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.083500</td>\n",
       "      <td>1.454398</td>\n",
       "      <td>0.711828</td>\n",
       "      <td>0.697576</td>\n",
       "      <td>0.719943</td>\n",
       "      <td>0.711828</td>\n",
       "      <td>0.714824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.058500</td>\n",
       "      <td>1.517728</td>\n",
       "      <td>0.701075</td>\n",
       "      <td>0.697424</td>\n",
       "      <td>0.719047</td>\n",
       "      <td>0.701075</td>\n",
       "      <td>0.706149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.107300</td>\n",
       "      <td>1.660373</td>\n",
       "      <td>0.668817</td>\n",
       "      <td>0.694242</td>\n",
       "      <td>0.723942</td>\n",
       "      <td>0.668817</td>\n",
       "      <td>0.675561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.110800</td>\n",
       "      <td>1.508418</td>\n",
       "      <td>0.707527</td>\n",
       "      <td>0.711970</td>\n",
       "      <td>0.732665</td>\n",
       "      <td>0.707527</td>\n",
       "      <td>0.713275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.040400</td>\n",
       "      <td>1.222452</td>\n",
       "      <td>0.698925</td>\n",
       "      <td>0.676667</td>\n",
       "      <td>0.702395</td>\n",
       "      <td>0.698925</td>\n",
       "      <td>0.700453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.021700</td>\n",
       "      <td>1.823810</td>\n",
       "      <td>0.707527</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.718901</td>\n",
       "      <td>0.707527</td>\n",
       "      <td>0.711348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>1.679832</td>\n",
       "      <td>0.688172</td>\n",
       "      <td>0.666970</td>\n",
       "      <td>0.693172</td>\n",
       "      <td>0.688172</td>\n",
       "      <td>0.690290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.032800</td>\n",
       "      <td>2.077074</td>\n",
       "      <td>0.705376</td>\n",
       "      <td>0.703485</td>\n",
       "      <td>0.724519</td>\n",
       "      <td>0.705376</td>\n",
       "      <td>0.710547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>2.106226</td>\n",
       "      <td>0.703226</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>0.725692</td>\n",
       "      <td>0.703226</td>\n",
       "      <td>0.708810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>2.236946</td>\n",
       "      <td>0.701075</td>\n",
       "      <td>0.702879</td>\n",
       "      <td>0.724261</td>\n",
       "      <td>0.701075</td>\n",
       "      <td>0.706767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>2.269496</td>\n",
       "      <td>0.701075</td>\n",
       "      <td>0.702879</td>\n",
       "      <td>0.724261</td>\n",
       "      <td>0.701075</td>\n",
       "      <td>0.706767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.4_deberta_docnli/checkpoint-51\n",
      "Configuration saved in /home/elson/5.4.4_deberta_docnli/checkpoint-51/config.json\n",
      "Model weights saved in /home/elson/5.4.4_deberta_docnli/checkpoint-51/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.4_deberta_docnli/checkpoint-102\n",
      "Configuration saved in /home/elson/5.4.4_deberta_docnli/checkpoint-102/config.json\n",
      "Model weights saved in /home/elson/5.4.4_deberta_docnli/checkpoint-102/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.4.4_deberta_docnli/checkpoint-51] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.4_deberta_docnli/checkpoint-153\n",
      "Configuration saved in /home/elson/5.4.4_deberta_docnli/checkpoint-153/config.json\n",
      "Model weights saved in /home/elson/5.4.4_deberta_docnli/checkpoint-153/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.4_deberta_docnli/checkpoint-204\n",
      "Configuration saved in /home/elson/5.4.4_deberta_docnli/checkpoint-204/config.json\n",
      "Model weights saved in /home/elson/5.4.4_deberta_docnli/checkpoint-204/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.4.4_deberta_docnli/checkpoint-102] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/5.4.4_deberta_docnli/checkpoint-153] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.4_deberta_docnli/checkpoint-255\n",
      "Configuration saved in /home/elson/5.4.4_deberta_docnli/checkpoint-255/config.json\n",
      "Model weights saved in /home/elson/5.4.4_deberta_docnli/checkpoint-255/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.4.4_deberta_docnli/checkpoint-204] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.4_deberta_docnli/checkpoint-306\n",
      "Configuration saved in /home/elson/5.4.4_deberta_docnli/checkpoint-306/config.json\n",
      "Model weights saved in /home/elson/5.4.4_deberta_docnli/checkpoint-306/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.4.4_deberta_docnli/checkpoint-255] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.4_deberta_docnli/checkpoint-357\n",
      "Configuration saved in /home/elson/5.4.4_deberta_docnli/checkpoint-357/config.json\n",
      "Model weights saved in /home/elson/5.4.4_deberta_docnli/checkpoint-357/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.4_deberta_docnli/checkpoint-408\n",
      "Configuration saved in /home/elson/5.4.4_deberta_docnli/checkpoint-408/config.json\n",
      "Model weights saved in /home/elson/5.4.4_deberta_docnli/checkpoint-408/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.4.4_deberta_docnli/checkpoint-357] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.4_deberta_docnli/checkpoint-459\n",
      "Configuration saved in /home/elson/5.4.4_deberta_docnli/checkpoint-459/config.json\n",
      "Model weights saved in /home/elson/5.4.4_deberta_docnli/checkpoint-459/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.4.4_deberta_docnli/checkpoint-408] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.4_deberta_docnli/checkpoint-510\n",
      "Configuration saved in /home/elson/5.4.4_deberta_docnli/checkpoint-510/config.json\n",
      "Model weights saved in /home/elson/5.4.4_deberta_docnli/checkpoint-510/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.4.4_deberta_docnli/checkpoint-459] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.4_deberta_docnli/checkpoint-561\n",
      "Configuration saved in /home/elson/5.4.4_deberta_docnli/checkpoint-561/config.json\n",
      "Model weights saved in /home/elson/5.4.4_deberta_docnli/checkpoint-561/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.4.4_deberta_docnli/checkpoint-510] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.4_deberta_docnli/checkpoint-612\n",
      "Configuration saved in /home/elson/5.4.4_deberta_docnli/checkpoint-612/config.json\n",
      "Model weights saved in /home/elson/5.4.4_deberta_docnli/checkpoint-612/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.4.4_deberta_docnli/checkpoint-561] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.4_deberta_docnli/checkpoint-663\n",
      "Configuration saved in /home/elson/5.4.4_deberta_docnli/checkpoint-663/config.json\n",
      "Model weights saved in /home/elson/5.4.4_deberta_docnli/checkpoint-663/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.4.4_deberta_docnli/checkpoint-612] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.4_deberta_docnli/checkpoint-714\n",
      "Configuration saved in /home/elson/5.4.4_deberta_docnli/checkpoint-714/config.json\n",
      "Model weights saved in /home/elson/5.4.4_deberta_docnli/checkpoint-714/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.4.4_deberta_docnli/checkpoint-663] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.4_deberta_docnli/checkpoint-765\n",
      "Configuration saved in /home/elson/5.4.4_deberta_docnli/checkpoint-765/config.json\n",
      "Model weights saved in /home/elson/5.4.4_deberta_docnli/checkpoint-765/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.4.4_deberta_docnli/checkpoint-714] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.4_deberta_docnli/checkpoint-816\n",
      "Configuration saved in /home/elson/5.4.4_deberta_docnli/checkpoint-816/config.json\n",
      "Model weights saved in /home/elson/5.4.4_deberta_docnli/checkpoint-816/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.4.4_deberta_docnli/checkpoint-765] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.4_deberta_docnli/checkpoint-867\n",
      "Configuration saved in /home/elson/5.4.4_deberta_docnli/checkpoint-867/config.json\n",
      "Model weights saved in /home/elson/5.4.4_deberta_docnli/checkpoint-867/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.4.4_deberta_docnli/checkpoint-816] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.4_deberta_docnli/checkpoint-918\n",
      "Configuration saved in /home/elson/5.4.4_deberta_docnli/checkpoint-918/config.json\n",
      "Model weights saved in /home/elson/5.4.4_deberta_docnli/checkpoint-918/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.4.4_deberta_docnli/checkpoint-867] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.4_deberta_docnli/checkpoint-969\n",
      "Configuration saved in /home/elson/5.4.4_deberta_docnli/checkpoint-969/config.json\n",
      "Model weights saved in /home/elson/5.4.4_deberta_docnli/checkpoint-969/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.4.4_deberta_docnli/checkpoint-918] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/5.4.4_deberta_docnli/checkpoint-1020\n",
      "Configuration saved in /home/elson/5.4.4_deberta_docnli/checkpoint-1020/config.json\n",
      "Model weights saved in /home/elson/5.4.4_deberta_docnli/checkpoint-1020/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/5.4.4_deberta_docnli/checkpoint-969] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/elson/5.4.4_deberta_docnli/checkpoint-306 (score: 0.7376344086021506).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /home/elson/5.4.4_deberta_docnli/best_model/config.json\n",
      "Model weights saved in /home/elson/5.4.4_deberta_docnli/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/5.4.4_deberta_docnli/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/5.4.4_deberta_docnli/best_model/special_tokens_map.json\n",
      "added tokens file saved in /home/elson/5.4.4_deberta_docnli/best_model/added_tokens.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/5.4.4_deberta_docnli/best_model/tokenizer_config.json',\n",
       " '/home/elson/5.4.4_deberta_docnli/best_model/special_tokens_map.json',\n",
       " '/home/elson/5.4.4_deberta_docnli/best_model/spm.model',\n",
       " '/home/elson/5.4.4_deberta_docnli/best_model/added_tokens.json')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/5.4.4_deberta_docnli/',\n",
    "    num_train_epochs=20,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.6,\n",
    "    weight_decay=0.1,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/5.4.4_deberta_docnli/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/5.4.4_deberta_docnli/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63deaea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/5.4.4_deberta_docnli/best_model/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"/home/elson/5.4.4_deberta_docnli/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"entailment\",\n",
      "    \"1\": \"not_entailment\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"entailment\": 0,\n",
      "    \"not_entailment\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file /home/elson/5.4.4_deberta_docnli/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at /home/elson/5.4.4_deberta_docnli/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 32\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/5.4.4_deberta_docnli/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[ 1.819  , -1.765  ],\n",
      "       [ 1.359  , -1.324  ],\n",
      "       [ 2.42   , -2.34   ],\n",
      "       [-1.961  ,  2.213  ],\n",
      "       [ 1.548  , -1.516  ],\n",
      "       [ 2.594  , -2.512  ],\n",
      "       [ 0.606  , -0.578  ],\n",
      "       [ 1.724  , -1.682  ],\n",
      "       [ 1.08   , -1.047  ],\n",
      "       [ 1.432  , -1.396  ],\n",
      "       [-0.272  ,  0.287  ],\n",
      "       [ 2.574  , -2.49   ],\n",
      "       [ 0.02481, -0.00948],\n",
      "       [ 2.78   , -2.684  ],\n",
      "       [ 1.827  , -1.775  ],\n",
      "       [-0.752  ,  0.8394 ],\n",
      "       [-0.3315 ,  0.3296 ],\n",
      "       [ 2.715  , -2.623  ],\n",
      "       [ 2.424  , -2.346  ],\n",
      "       [ 2.086  , -2.025  ],\n",
      "       [-1.152  ,  1.363  ],\n",
      "       [ 0.8066 , -0.789  ],\n",
      "       [ 1.973  , -1.917  ],\n",
      "       [-1.9795 ,  2.24   ],\n",
      "       [ 2.064  , -2.     ],\n",
      "       [-2.988  ,  3.246  ],\n",
      "       [ 2.764  , -2.67   ],\n",
      "       [ 0.501  , -0.4866 ],\n",
      "       [ 2.023  , -1.966  ],\n",
      "       [-1.48   ,  1.717  ],\n",
      "       [-1.6    ,  1.851  ],\n",
      "       [ 1.631  , -1.595  ],\n",
      "       [-1.391  ,  1.628  ],\n",
      "       [-0.1841 ,  0.2075 ],\n",
      "       [-1.047  ,  1.22   ],\n",
      "       [-1.535  ,  1.791  ],\n",
      "       [-0.8286 ,  0.932  ],\n",
      "       [ 1.223  , -1.206  ],\n",
      "       [-1.477  ,  1.71   ],\n",
      "       [-0.31   ,  0.3364 ],\n",
      "       [ 1.701  , -1.658  ],\n",
      "       [ 1.478  , -1.444  ],\n",
      "       [ 1.146  , -1.119  ],\n",
      "       [-1.711  ,  1.954  ],\n",
      "       [-1.115  ,  1.302  ],\n",
      "       [ 2.545  , -2.463  ],\n",
      "       [-1.712  ,  1.977  ],\n",
      "       [ 3.074  , -2.96   ],\n",
      "       [ 3.283  , -3.156  ],\n",
      "       [-0.4922 ,  0.529  ],\n",
      "       [-1.087  ,  1.299  ],\n",
      "       [-1.012  ,  1.151  ],\n",
      "       [-1.351  ,  1.579  ],\n",
      "       [-0.999  ,  1.143  ],\n",
      "       [-1.925  ,  2.188  ],\n",
      "       [ 2.426  , -2.352  ],\n",
      "       [-1.523  ,  1.772  ],\n",
      "       [ 1.375  , -1.345  ],\n",
      "       [ 2.309  , -2.242  ],\n",
      "       [ 1.286  , -1.254  ],\n",
      "       [ 1.847  , -1.797  ],\n",
      "       [-0.1356 ,  0.1521 ],\n",
      "       [ 1.372  , -1.338  ],\n",
      "       [ 1.378  , -1.351  ],\n",
      "       [-0.71   ,  0.783  ],\n",
      "       [ 1.921  , -1.871  ],\n",
      "       [ 2.457  , -2.38   ],\n",
      "       [ 1.444  , -1.408  ],\n",
      "       [ 1.326  , -1.291  ],\n",
      "       [ 1.908  , -1.852  ],\n",
      "       [ 2.371  , -2.3    ],\n",
      "       [-1.19   ,  1.377  ],\n",
      "       [ 1.538  , -1.508  ],\n",
      "       [ 1.758  , -1.714  ],\n",
      "       [ 1.442  , -1.402  ],\n",
      "       [ 2.156  , -2.094  ],\n",
      "       [ 2.152  , -2.09   ],\n",
      "       [ 1.798  , -1.752  ],\n",
      "       [ 2.5    , -2.418  ],\n",
      "       [ 1.621  , -1.575  ],\n",
      "       [ 1.198  , -1.166  ],\n",
      "       [ 1.204  , -1.182  ],\n",
      "       [ 1.23   , -1.198  ],\n",
      "       [ 2.72   , -2.629  ],\n",
      "       [ 2.635  , -2.55   ],\n",
      "       [-1.867  ,  2.137  ],\n",
      "       [ 2.13   , -2.068  ],\n",
      "       [-1.577  ,  1.834  ],\n",
      "       [ 2.25   , -2.184  ],\n",
      "       [ 1.261  , -1.2295 ],\n",
      "       [ 2.512  , -2.428  ],\n",
      "       [ 2.408  , -2.33   ],\n",
      "       [-1.185  ,  1.385  ],\n",
      "       [ 2.945  , -2.838  ],\n",
      "       [ 1.189  , -1.163  ],\n",
      "       [ 0.771  , -0.753  ],\n",
      "       [-1.507  ,  1.747  ],\n",
      "       [ 1.13   , -1.106  ],\n",
      "       [ 2.309  , -2.238  ],\n",
      "       [ 0.3    , -0.2812 ],\n",
      "       [ 1.621  , -1.58   ],\n",
      "       [ 2.527  , -2.445  ],\n",
      "       [ 2.582  , -2.494  ],\n",
      "       [ 2.05   , -1.997  ],\n",
      "       [ 2.305  , -2.238  ],\n",
      "       [ 2.643  , -2.555  ],\n",
      "       [-0.7456 ,  0.839  ],\n",
      "       [ 0.524  , -0.51   ],\n",
      "       [ 1.915  , -1.86   ],\n",
      "       [-1.197  ,  1.405  ],\n",
      "       [-0.6543 ,  0.7197 ],\n",
      "       [ 2.293  , -2.225  ],\n",
      "       [ 2.453  , -2.371  ],\n",
      "       [ 2.328  , -2.256  ],\n",
      "       [ 1.414  , -1.383  ],\n",
      "       [ 1.933  , -1.884  ],\n",
      "       [ 2.646  , -2.56   ],\n",
      "       [ 2.562  , -2.479  ],\n",
      "       [ 1.439  , -1.405  ],\n",
      "       [ 1.7705 , -1.724  ],\n",
      "       [ 1.194  , -1.162  ],\n",
      "       [ 2.11   , -2.049  ],\n",
      "       [ 0.776  , -0.762  ],\n",
      "       [-1.34   ,  1.562  ],\n",
      "       [-1.18   ,  1.34   ],\n",
      "       [ 1.528  , -1.493  ],\n",
      "       [ 0.2354 , -0.2141 ],\n",
      "       [ 1.738  , -1.693  ],\n",
      "       [ 2.42   , -2.348  ],\n",
      "       [ 1.065  , -1.052  ],\n",
      "       [-0.3188 ,  0.34   ],\n",
      "       [-1.364  ,  1.589  ],\n",
      "       [ 0.9414 , -0.9297 ],\n",
      "       [-1.5625 ,  1.811  ],\n",
      "       [ 1.016  , -0.9873 ],\n",
      "       [-1.271  ,  1.479  ],\n",
      "       [ 1.468  , -1.424  ],\n",
      "       [-1.356  ,  1.587  ],\n",
      "       [-1.866  ,  2.135  ],\n",
      "       [ 2.365  , -2.29   ],\n",
      "       [ 2.8    , -2.705  ],\n",
      "       [-0.1382 ,  0.1484 ],\n",
      "       [ 0.09546, -0.0778 ],\n",
      "       [ 3.059  , -2.945  ],\n",
      "       [ 0.398  , -0.3777 ],\n",
      "       [ 0.7295 , -0.706  ],\n",
      "       [ 0.9575 , -0.9375 ],\n",
      "       [-1.747  ,  2.002  ],\n",
      "       [ 2.127  , -2.059  ],\n",
      "       [-1.003  ,  1.162  ],\n",
      "       [ 0.82   , -0.794  ],\n",
      "       [ 2.564  , -2.477  ],\n",
      "       [ 2.156  , -2.105  ],\n",
      "       [ 1.85   , -1.798  ],\n",
      "       [ 1.476  , -1.439  ],\n",
      "       [ 3.172  , -3.047  ],\n",
      "       [ 2.033  , -1.973  ],\n",
      "       [-1.247  ,  1.469  ],\n",
      "       [ 1.554  , -1.511  ],\n",
      "       [-1.865  ,  2.127  ],\n",
      "       [-3.29   ,  3.576  ],\n",
      "       [-2.72   ,  2.984  ],\n",
      "       [ 1.294  , -1.2705 ],\n",
      "       [ 1.085  , -1.059  ],\n",
      "       [ 0.7646 , -0.7476 ],\n",
      "       [-0.7593 ,  0.8735 ],\n",
      "       [ 2.475  , -2.4    ],\n",
      "       [-2.043  ,  2.312  ],\n",
      "       [-1.121  ,  1.302  ],\n",
      "       [ 1.219  , -1.183  ],\n",
      "       [-2.734  ,  3.002  ],\n",
      "       [-1.589  ,  1.839  ],\n",
      "       [ 1.414  , -1.381  ],\n",
      "       [ 2.95   , -2.848  ],\n",
      "       [ 2.615  , -2.531  ],\n",
      "       [-2.139  ,  2.4    ],\n",
      "       [ 2.35   , -2.275  ],\n",
      "       [ 1.556  , -1.509  ],\n",
      "       [ 1.4    , -1.371  ],\n",
      "       [-0.7007 ,  0.7734 ],\n",
      "       [-1.148  ,  1.359  ],\n",
      "       [ 0.7144 , -0.698  ],\n",
      "       [ 0.672  , -0.6475 ],\n",
      "       [-1.096  ,  1.255  ],\n",
      "       [-1.135  ,  1.325  ],\n",
      "       [ 2.564  , -2.479  ],\n",
      "       [ 2.475  , -2.396  ],\n",
      "       [ 1.989  , -1.933  ],\n",
      "       [ 1.477  , -1.445  ],\n",
      "       [-1.166  ,  1.368  ],\n",
      "       [-0.681  ,  0.748  ],\n",
      "       [-0.6074 ,  0.66   ],\n",
      "       [ 1.853  , -1.804  ],\n",
      "       [ 0.00458,  0.01947],\n",
      "       [-0.3035 ,  0.2866 ],\n",
      "       [ 2.34   , -2.268  ],\n",
      "       [ 1.637  , -1.601  ],\n",
      "       [ 2.193  , -2.127  ],\n",
      "       [ 1.883  , -1.828  ],\n",
      "       [-0.349  ,  0.3625 ],\n",
      "       [ 2.188  , -2.123  ],\n",
      "       [ 1.511  , -1.474  ],\n",
      "       [ 1.098  , -1.06   ],\n",
      "       [ 1.976  , -1.921  ],\n",
      "       [-0.8423 ,  0.9565 ],\n",
      "       [-1.637  ,  1.893  ],\n",
      "       [ 1.638  , -1.594  ],\n",
      "       [ 0.8677 , -0.846  ],\n",
      "       [ 2.742  , -2.648  ],\n",
      "       [ 1.71   , -1.669  ],\n",
      "       [-0.2421 ,  0.2556 ],\n",
      "       [-0.1141 ,  0.12195],\n",
      "       [ 1.859  , -1.814  ],\n",
      "       [ 1.312  , -1.276  ],\n",
      "       [ 2.295  , -2.229  ],\n",
      "       [-1.271  ,  1.482  ],\n",
      "       [-1.031  ,  1.197  ],\n",
      "       [-0.8115 ,  0.8926 ],\n",
      "       [ 1.953  , -1.9    ],\n",
      "       [ 0.91   , -0.885  ],\n",
      "       [ 2.36   , -2.291  ],\n",
      "       [-1.069  ,  1.249  ],\n",
      "       [-0.9673 ,  1.125  ],\n",
      "       [ 2.625  , -2.54   ],\n",
      "       [ 1.545  , -1.51   ],\n",
      "       [ 1.775  , -1.729  ],\n",
      "       [ 2.111  , -2.055  ],\n",
      "       [-1.569  ,  1.823  ],\n",
      "       [ 1.305  , -1.275  ],\n",
      "       [ 1.907  , -1.849  ],\n",
      "       [ 2.895  , -2.793  ],\n",
      "       [ 2.285  , -2.217  ],\n",
      "       [ 1.39   , -1.362  ],\n",
      "       [-1.051  ,  1.199  ]], dtype=float16), label_ids=array([0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
      "       0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0,\n",
      "       1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
      "       0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
      "       0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "       1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
      "       0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
      "       1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n",
      "       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
      "       0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1]), metrics={'test_loss': 1.0319315195083618, 'test_accuracy': 0.6495726495726496, 'test_balanced_accuracy': 0.623641304347826, 'test_precision': 0.6426692965154504, 'test_recall': 0.6495726495726496, 'test_f1': 0.6421744648345633, 'test_runtime': 1.9698, 'test_samples_per_second': 118.792, 'test_steps_per_second': 4.061})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73395d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "probabilities = torch.softmax(torch.tensor(test_results.predictions).to(torch.float32), dim=-1)\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)\n",
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb603377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_save = []\n",
    "for idx in range(len(test_data)):\n",
    "    item = dataset['test'][idx]\n",
    "    actual_label = item['label']\n",
    "    predicted_label = predictions[idx]\n",
    "    claim = item['claim'] \n",
    "    premise = item['premise'] \n",
    "    category = item['category']\n",
    "    \n",
    "    # Append the information as a dictionary to the list\n",
    "    data_to_save.append({\n",
    "        'Claim': claim,\n",
    "        'Premise': premise,\n",
    "        'Actual Label': actual_label,\n",
    "        'Predicted Label': predicted_label,\n",
    "        'Category' : category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_to_save)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/home/elson/results/5.4.4_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c23339b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correctly classified instances\n",
    "correctly_classified = df[df['Actual Label'] == df['Predicted Label']]\n",
    "\n",
    "# Calculate misclassified instances\n",
    "misclassified = df[df['Actual Label'] != df['Predicted Label']]\n",
    "\n",
    "# Count the number of correctly classified and misclassified by category\n",
    "correct_classification_counts = correctly_classified['Category'].value_counts()\n",
    "misclassification_counts = misclassified['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca0def77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           45\n",
       "Bone health              13\n",
       "Fitness                  11\n",
       "Cancer                    8\n",
       "Skin                      8\n",
       "Eye                       8\n",
       "Cardiovascular Health     8\n",
       "Neurological health       7\n",
       "Hair                      6\n",
       "Ear                       6\n",
       "Diabetes                  6\n",
       "COVID                     5\n",
       "Women' s Health           5\n",
       "Muscles                   4\n",
       "Blood                     4\n",
       "Mental Health             3\n",
       "Throat                    3\n",
       "Vascular                  1\n",
       "Men's health              1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0fddd944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Skin                     16\n",
       "Bone health               8\n",
       "Hair                      6\n",
       "General Health            6\n",
       "Throat                    6\n",
       "Diabetes                  6\n",
       "Men's health              5\n",
       "Blood                     5\n",
       "Fitness                   4\n",
       "Cardiovascular Health     4\n",
       "Cancer                    4\n",
       "Dental Health             3\n",
       "Muscles                   2\n",
       "Vascular                  2\n",
       "Neurological health       2\n",
       "Eye                       1\n",
       "Women' s Health           1\n",
       "COVID                     1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38b899b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_counts = df['Category'].value_counts()\n",
    "\n",
    "# Calculate ratios\n",
    "correct_classification_ratios = correct_classification_counts / total_counts\n",
    "misclassification_ratios = misclassification_counts / total_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c3598b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blood                    0.444444\n",
      "Bone health              0.619048\n",
      "COVID                    0.833333\n",
      "Cancer                   0.666667\n",
      "Cardiovascular Health    0.666667\n",
      "Dental Health                 NaN\n",
      "Diabetes                 0.500000\n",
      "Ear                      1.000000\n",
      "Eye                      0.888889\n",
      "Fitness                  0.733333\n",
      "General Health           0.882353\n",
      "Hair                     0.500000\n",
      "Men's health             0.166667\n",
      "Mental Health            1.000000\n",
      "Muscles                  0.666667\n",
      "Neurological health      0.777778\n",
      "Skin                     0.333333\n",
      "Throat                   0.333333\n",
      "Vascular                 0.333333\n",
      "Women' s Health          0.833333\n",
      "Name: Category, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(correct_classification_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27602a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blood                    0.555556\n",
      "Bone health              0.380952\n",
      "COVID                    0.166667\n",
      "Cancer                   0.333333\n",
      "Cardiovascular Health    0.333333\n",
      "Dental Health            1.000000\n",
      "Diabetes                 0.500000\n",
      "Ear                           NaN\n",
      "Eye                      0.111111\n",
      "Fitness                  0.266667\n",
      "General Health           0.117647\n",
      "Hair                     0.500000\n",
      "Men's health             0.833333\n",
      "Mental Health                 NaN\n",
      "Muscles                  0.333333\n",
      "Neurological health      0.222222\n",
      "Skin                     0.666667\n",
      "Throat                   0.666667\n",
      "Vascular                 0.666667\n",
      "Women' s Health          0.166667\n",
      "Name: Category, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(misclassification_ratios)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
