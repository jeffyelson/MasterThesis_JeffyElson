{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification,AutoConfig\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score,precision_recall_fscore_support\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-927ab0163adb9fdb\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-927ab0163adb9fdb/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 241.77it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('csv',data_files='dataset_propositionattribution_nerfeatures.csv',delimiter=',',column_names=[\"claim\",\"premise\",\"label\",\"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\",\"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\",\"url\", \"entities\",\"entity_map\",\"gem_exp\",\"gem_label\",\"gpt_label\",\"gpt_exp\",\"gold_exp\",\"entity_map_ev\",\"entity_ev\",\"split\"],skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "133f9357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-927ab0163adb9fdb/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-d013d5114fa105ab.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-927ab0163adb9fdb/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-16f9acbdd82fea07.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-927ab0163adb9fdb/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-47c7de469e4087a2.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01252e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\"claim\", \"premise\", \"label\", \"category\",\"count_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\"]\n",
    "all_columns = dataset[\"train\"].column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-927ab0163adb9fdb/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-bda5d1d3d7d60220.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-927ab0163adb9fdb/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-a2607a237944b55e.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-927ab0163adb9fdb/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-cdb1806ca2a08beb.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 2, 'entailment': 0, 'neutral': 1}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 2,\n",
    "    \"entailment\": 0,\n",
    "    \"neutral\": 1\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e15010ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['test']['counte_dis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='sjrhuschlee/flan-t5-base-mnli'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "        # Extracting claim and evidence texts\n",
    "        claim = item['claim'].lower() \n",
    "        evidences = item['premise']\n",
    "        item['premise']=evidences\n",
    "        item['claim']=claim\n",
    "        additional_features_evidence = [\n",
    "            \"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\"]\n",
    "    \n",
    "        for feature in additional_features_evidence:\n",
    "            if feature in item:\n",
    "                evidences += \"[SEP]\" + str(item[feature])\n",
    "        additional_features = [\n",
    "            \"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\"]\n",
    "    \n",
    "        for feature_ev in additional_features:\n",
    "            if feature_ev in item:\n",
    "                claim += \"[SEP]\" + str(item[feature_ev])\n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "            evidences,claim,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "         # Construct the output item\n",
    "        output_item = {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),  # Remove batch dimension\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),  # Remove batch dimension\n",
    "            'claim': claim,  # Include augmented claim text\n",
    "            'evidences': evidences  # Include original evidence text\n",
    "        }\n",
    "        \n",
    "        if 'label' in item:\n",
    "            output_item['label'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return output_item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62421eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "T5ForSequenceClassification(\n",
       "  (transformer): T5Model(\n",
       "    (shared): Embedding(32128, 768)\n",
       "    (encoder): T5Stack(\n",
       "      (embed_tokens): Embedding(32128, 768)\n",
       "      (block): ModuleList(\n",
       "        (0): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 12)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (6): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (7): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (8): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (9): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (10): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (11): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): T5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (decoder): T5Stack(\n",
       "      (embed_tokens): Embedding(32128, 768)\n",
       "      (block): ModuleList(\n",
       "        (0): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (relative_attention_bias): Embedding(32, 12)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (6): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (7): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (8): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (9): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (10): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (11): T5Block(\n",
       "          (layer): ModuleList(\n",
       "            (0): T5LayerSelfAttention(\n",
       "              (SelfAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (1): T5LayerCrossAttention(\n",
       "              (EncDecAttention): T5Attention(\n",
       "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
       "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (2): T5LayerFF(\n",
       "              (DenseReluDense): T5DenseGatedGeluDense(\n",
       "                (wi_0): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wi_1): Linear(in_features=768, out_features=2048, bias=False)\n",
       "                (wo): Linear(in_features=2048, out_features=768, bias=False)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "                (gelu_act): NewGELUActivation()\n",
       "              )\n",
       "              (layer_norm): T5LayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (final_layer_norm): T5LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (classification_head): T5ClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"sjrhuschlee/flan-t5-base-mnli\"\n",
    "config = AutoConfig.from_pretrained(\n",
    "    model_name, num_labels=len(label2id), id2label=id2label, label2id=label2id\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=512)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,ignore_mismatched_sizes=True,config=config, trust_remote_code=True)\n",
    "device = \"cuda:0\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    if isinstance(\n",
    "        logits, tuple\n",
    "    ):  # if the model also returns hidden_states or attentions\n",
    "        logits = logits[0]\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, predictions, average=\"weighted\"\n",
    "    )\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "\n",
    "\n",
    "    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category', 'count_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f5cf584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([   37,  2942,    13, 25567,  1874,     7,    33,  4313,   778,   116,\n",
       "            79,    54,    36,  4260,    28,  9109,   757,  9508,     5,  6306,\n",
       "           134,  8569,   908,   632,  6306,   134,  8569,   908,   536,  6306,\n",
       "           134,  8569,   908,   632,  6306,   134,  8569,   908,   632,  6306,\n",
       "           134,  8569,   908,   632,  6306,   134,  8569,   908,   632,  6306,\n",
       "           134,  8569,   908,   632,  6306,   134,  8569,   908,   536,  6306,\n",
       "           134,  8569,   908,   632,  6306,   134,  8569,   908,   632,  6306,\n",
       "           134,  8569,   908,   632,     1, 25567,  1874,    54,    36,  4260,\n",
       "            28,  3730,     6, 11423,  3918,     6, 11932,  3918,     6,    11,\n",
       "         26324,     5,  6306,   134,  8569,   908,   632,     1,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'claim': 'prostate cancer can be treated with surgery, radiation therapy, hormone therapy, and chemotherapy.[SEP]0',\n",
       " 'evidences': 'The majority of prostate cancers are identified early when they can be treated with curative intent.[SEP]0[SEP]1[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]1[SEP]0[SEP]0[SEP]0',\n",
       " 'label': tensor(0)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3045\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3045' max='3045' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3045/3045 41:45, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.590600</td>\n",
       "      <td>0.938701</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.677696</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.663515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.205400</td>\n",
       "      <td>1.634067</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.713614</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.670035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>2.149245</td>\n",
       "      <td>0.690323</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.690323</td>\n",
       "      <td>0.705851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.132400</td>\n",
       "      <td>2.980803</td>\n",
       "      <td>0.640860</td>\n",
       "      <td>0.705068</td>\n",
       "      <td>0.640860</td>\n",
       "      <td>0.665873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>3.078597</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.713566</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.690208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>3.099267</td>\n",
       "      <td>0.683871</td>\n",
       "      <td>0.727409</td>\n",
       "      <td>0.683871</td>\n",
       "      <td>0.701622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.206260</td>\n",
       "      <td>0.711828</td>\n",
       "      <td>0.721824</td>\n",
       "      <td>0.711828</td>\n",
       "      <td>0.715934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.122200</td>\n",
       "      <td>3.559554</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.715519</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.692828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.481183</td>\n",
       "      <td>0.703226</td>\n",
       "      <td>0.718698</td>\n",
       "      <td>0.703226</td>\n",
       "      <td>0.709668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.539972</td>\n",
       "      <td>0.701075</td>\n",
       "      <td>0.717392</td>\n",
       "      <td>0.701075</td>\n",
       "      <td>0.707809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.738056</td>\n",
       "      <td>0.679570</td>\n",
       "      <td>0.706084</td>\n",
       "      <td>0.679570</td>\n",
       "      <td>0.689165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.768079</td>\n",
       "      <td>0.681720</td>\n",
       "      <td>0.707254</td>\n",
       "      <td>0.681720</td>\n",
       "      <td>0.691025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.806121</td>\n",
       "      <td>0.690323</td>\n",
       "      <td>0.711153</td>\n",
       "      <td>0.690323</td>\n",
       "      <td>0.698299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.780111</td>\n",
       "      <td>0.692473</td>\n",
       "      <td>0.713501</td>\n",
       "      <td>0.692473</td>\n",
       "      <td>0.700544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.783626</td>\n",
       "      <td>0.692473</td>\n",
       "      <td>0.713501</td>\n",
       "      <td>0.692473</td>\n",
       "      <td>0.700544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/10.4.5_flant5/checkpoint-203\n",
      "Configuration saved in /home/elson/10.4.5_flant5/checkpoint-203/config.json\n",
      "Model weights saved in /home/elson/10.4.5_flant5/checkpoint-203/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/10.4.5_flant5/checkpoint-406\n",
      "Configuration saved in /home/elson/10.4.5_flant5/checkpoint-406/config.json\n",
      "Model weights saved in /home/elson/10.4.5_flant5/checkpoint-406/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/10.4.5_flant5/checkpoint-609\n",
      "Configuration saved in /home/elson/10.4.5_flant5/checkpoint-609/config.json\n",
      "Model weights saved in /home/elson/10.4.5_flant5/checkpoint-609/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/10.4.5_flant5/checkpoint-406] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/10.4.5_flant5/checkpoint-812\n",
      "Configuration saved in /home/elson/10.4.5_flant5/checkpoint-812/config.json\n",
      "Model weights saved in /home/elson/10.4.5_flant5/checkpoint-812/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/10.4.5_flant5/checkpoint-609] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/10.4.5_flant5/checkpoint-1015\n",
      "Configuration saved in /home/elson/10.4.5_flant5/checkpoint-1015/config.json\n",
      "Model weights saved in /home/elson/10.4.5_flant5/checkpoint-1015/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/10.4.5_flant5/checkpoint-812] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/10.4.5_flant5/checkpoint-1218\n",
      "Configuration saved in /home/elson/10.4.5_flant5/checkpoint-1218/config.json\n",
      "Model weights saved in /home/elson/10.4.5_flant5/checkpoint-1218/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/10.4.5_flant5/checkpoint-1015] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/10.4.5_flant5/checkpoint-1421\n",
      "Configuration saved in /home/elson/10.4.5_flant5/checkpoint-1421/config.json\n",
      "Model weights saved in /home/elson/10.4.5_flant5/checkpoint-1421/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/10.4.5_flant5/checkpoint-1218] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/10.4.5_flant5/checkpoint-1624\n",
      "Configuration saved in /home/elson/10.4.5_flant5/checkpoint-1624/config.json\n",
      "Model weights saved in /home/elson/10.4.5_flant5/checkpoint-1624/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/10.4.5_flant5/checkpoint-1421] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/10.4.5_flant5/checkpoint-1827\n",
      "Configuration saved in /home/elson/10.4.5_flant5/checkpoint-1827/config.json\n",
      "Model weights saved in /home/elson/10.4.5_flant5/checkpoint-1827/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/10.4.5_flant5/checkpoint-1624] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/10.4.5_flant5/checkpoint-2030\n",
      "Configuration saved in /home/elson/10.4.5_flant5/checkpoint-2030/config.json\n",
      "Model weights saved in /home/elson/10.4.5_flant5/checkpoint-2030/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/10.4.5_flant5/checkpoint-1827] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/10.4.5_flant5/checkpoint-2233\n",
      "Configuration saved in /home/elson/10.4.5_flant5/checkpoint-2233/config.json\n",
      "Model weights saved in /home/elson/10.4.5_flant5/checkpoint-2233/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/10.4.5_flant5/checkpoint-2030] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/10.4.5_flant5/checkpoint-2436\n",
      "Configuration saved in /home/elson/10.4.5_flant5/checkpoint-2436/config.json\n",
      "Model weights saved in /home/elson/10.4.5_flant5/checkpoint-2436/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/10.4.5_flant5/checkpoint-2233] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/10.4.5_flant5/checkpoint-2639\n",
      "Configuration saved in /home/elson/10.4.5_flant5/checkpoint-2639/config.json\n",
      "Model weights saved in /home/elson/10.4.5_flant5/checkpoint-2639/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/10.4.5_flant5/checkpoint-2436] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/10.4.5_flant5/checkpoint-2842\n",
      "Configuration saved in /home/elson/10.4.5_flant5/checkpoint-2842/config.json\n",
      "Model weights saved in /home/elson/10.4.5_flant5/checkpoint-2842/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/10.4.5_flant5/checkpoint-2639] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/10.4.5_flant5/checkpoint-3045\n",
      "Configuration saved in /home/elson/10.4.5_flant5/checkpoint-3045/config.json\n",
      "Model weights saved in /home/elson/10.4.5_flant5/checkpoint-3045/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/10.4.5_flant5/checkpoint-2842] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/elson/10.4.5_flant5/checkpoint-203 (score: 0.9387012720108032).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='89' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [59/59 01:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /home/elson/10.4.5_flant5/best_model/config.json\n",
      "Model weights saved in /home/elson/10.4.5_flant5/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/10.4.5_flant5/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/10.4.5_flant5/best_model/special_tokens_map.json\n",
      "Copy vocab file to /home/elson/10.4.5_flant5/best_model/spiece.model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/10.4.5_flant5/best_model/tokenizer_config.json',\n",
       " '/home/elson/10.4.5_flant5/best_model/special_tokens_map.json',\n",
       " '/home/elson/10.4.5_flant5/best_model/spiece.model',\n",
       " '/home/elson/10.4.5_flant5/best_model/added_tokens.json',\n",
       " '/home/elson/10.4.5_flant5/best_model/tokenizer.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/10.4.5_flant5/',\n",
    "    num_train_epochs=15,\n",
    "    learning_rate=3e-4,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=False,\n",
    "    logging_steps=10,\n",
    "    warmup_ratio=0.06,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/10.4.5_flant5/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/10.4.5_flant5/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63deaea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/10.4.5_flant5/best_model/config.json\n",
      "Model config T5Config {\n",
      "  \"_name_or_path\": \"/home/elson/10.4.5_flant5/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"T5ForSequenceClassification\"\n",
      "  ],\n",
      "  \"auto_map\": {\n",
      "    \"AutoModelForSequenceClassification\": \"modeling_t5seq.T5ForSequenceClassification\"\n",
      "  },\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_ff\": 2048,\n",
      "  \"d_kv\": 64,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_start_token_id\": 0,\n",
      "  \"dense_act_fn\": \"gelu_new\",\n",
      "  \"dropout_rate\": 0.1,\n",
      "  \"eos_token_id\": 1,\n",
      "  \"feed_forward_proj\": \"gated-gelu\",\n",
      "  \"finetuning_task\": \"mnli\",\n",
      "  \"id2label\": {\n",
      "    \"0\": \"entailment\",\n",
      "    \"1\": \"neutral\",\n",
      "    \"2\": \"contradiction\"\n",
      "  },\n",
      "  \"initializer_factor\": 1.0,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"is_gated_act\": true,\n",
      "  \"label2id\": {\n",
      "    \"contradiction\": 2,\n",
      "    \"entailment\": 0,\n",
      "    \"neutral\": 1\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"model_type\": \"t5\",\n",
      "  \"n_positions\": 512,\n",
      "  \"num_decoder_layers\": 12,\n",
      "  \"num_heads\": 12,\n",
      "  \"num_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"relative_attention_max_distance\": 128,\n",
      "  \"relative_attention_num_buckets\": 32,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 200,\n",
      "      \"min_length\": 30,\n",
      "      \"no_repeat_ngram_size\": 3,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"summarize: \"\n",
      "    },\n",
      "    \"translation_en_to_de\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to German: \"\n",
      "    },\n",
      "    \"translation_en_to_fr\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to French: \"\n",
      "    },\n",
      "    \"translation_en_to_ro\": {\n",
      "      \"early_stopping\": true,\n",
      "      \"max_length\": 300,\n",
      "      \"num_beams\": 4,\n",
      "      \"prefix\": \"translate English to Romanian: \"\n",
      "    }\n",
      "  },\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32128\n",
      "}\n",
      "\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "loading weights file /home/elson/10.4.5_flant5/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing T5ForSequenceClassification.\n",
      "\n",
      "All the weights of T5ForSequenceClassification were initialized from the model checkpoint at /home/elson/10.4.5_flant5/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use T5ForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 8\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/10.4.5_flant5/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path,trust_remote_code=True).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=(array([[ 0.92853487,  0.60627717, -1.5252962 ],\n",
      "       [ 2.4099474 , -0.46452674, -1.6304376 ],\n",
      "       [ 2.4967644 , -1.1688173 , -1.0594951 ],\n",
      "       [-0.33133006, -2.0176976 ,  2.177302  ],\n",
      "       [-1.0078266 ,  0.46016705,  0.2995761 ],\n",
      "       [ 3.6369305 , -1.0006007 , -2.0752623 ],\n",
      "       [ 2.6296396 , -1.0244296 , -1.2308052 ],\n",
      "       [ 3.1514933 , -0.8417974 , -1.9502017 ],\n",
      "       [ 2.056772  , -0.74919695, -1.1484596 ],\n",
      "       [ 1.3065368 ,  0.02776234, -1.2562824 ],\n",
      "       [ 2.7881517 , -1.5272243 , -0.8115805 ],\n",
      "       [ 3.0115287 , -0.5119863 , -2.0613608 ],\n",
      "       [ 0.57374775,  0.5801558 , -1.2680557 ],\n",
      "       [ 3.2514246 , -0.93809426, -1.9078338 ],\n",
      "       [ 2.8620796 , -0.54232514, -1.9170536 ],\n",
      "       [ 0.07173715, -0.1423008 , -0.01356403],\n",
      "       [ 2.059647  , -0.10891748, -1.6994964 ],\n",
      "       [ 2.9025998 , -0.9410832 , -1.5459411 ],\n",
      "       [ 3.2513475 , -0.65947646, -2.0923414 ],\n",
      "       [ 2.6297402 , -0.0305263 , -2.2036602 ],\n",
      "       [-1.2758249 ,  0.3401151 ,  0.60951525],\n",
      "       [ 1.8198618 , -0.21774668, -1.4887679 ],\n",
      "       [ 2.4524004 , -1.0955642 , -1.1615874 ],\n",
      "       [-0.7625035 , -1.6913471 ,  2.071369  ],\n",
      "       [ 1.242703  , -1.6211437 ,  0.5059692 ],\n",
      "       [-1.1673652 , -0.91467977,  1.8367594 ],\n",
      "       [ 3.3309927 , -0.829169  , -1.965912  ],\n",
      "       [ 1.4830859 ,  0.11474685, -1.4537084 ],\n",
      "       [ 2.8514132 , -0.3456098 , -2.1073835 ],\n",
      "       [ 2.114592  , -1.1292478 , -0.83207357],\n",
      "       [ 0.25962335,  1.1803339 , -1.4274731 ],\n",
      "       [ 3.08175   , -0.63343096, -1.9738847 ],\n",
      "       [ 1.5023357 , -0.726809  , -0.6088725 ],\n",
      "       [ 0.36187804,  0.6409197 , -1.0062621 ],\n",
      "       [-0.5757775 , -0.07189378,  0.4383552 ],\n",
      "       [ 1.7520702 , -0.02279904, -1.4598852 ],\n",
      "       [ 0.31268626, -0.40045574,  0.05441712],\n",
      "       [ 3.1364107 , -0.8015813 , -1.9269452 ],\n",
      "       [-0.7006689 , -1.2473813 ,  1.5619963 ],\n",
      "       [ 1.8209184 ,  0.17348786, -1.6854912 ],\n",
      "       [-1.2207814 ,  0.10445372,  0.7819718 ],\n",
      "       [ 2.0039272 ,  0.33895484, -2.0832405 ],\n",
      "       [ 0.1362526 ,  0.6081848 , -0.89575344],\n",
      "       [-0.9920733 , -0.5926735 ,  1.2310038 ],\n",
      "       [-0.5341362 , -0.39105847,  0.7468781 ],\n",
      "       [ 2.4858313 , -0.76777136, -1.3378093 ],\n",
      "       [ 0.9372612 , -0.45230922, -0.5108551 ],\n",
      "       [ 3.185575  , -1.1109148 , -1.6519891 ],\n",
      "       [ 3.427329  , -1.2706294 , -1.68431   ],\n",
      "       [ 0.7438678 , -1.1361499 ,  0.4568808 ],\n",
      "       [-1.2676392 , -0.38536817,  1.2609425 ],\n",
      "       [ 0.27188796,  0.735639  , -1.030203  ],\n",
      "       [ 0.49198318, -0.0434027 , -0.55254054],\n",
      "       [ 2.3057375 , -0.621155  , -1.2584058 ],\n",
      "       [-0.22692832,  0.12145608, -0.00481068],\n",
      "       [ 1.7504418 , -0.96669567, -0.6607019 ],\n",
      "       [-1.5495584 ,  1.2119243 , -0.0612465 ],\n",
      "       [ 2.8072746 , -0.56106734, -1.8507775 ],\n",
      "       [ 1.1771456 , -0.19228636, -0.8860123 ],\n",
      "       [ 2.9046812 , -0.9297397 , -1.5943638 ],\n",
      "       [ 2.4294255 , -0.80255485, -1.4303924 ],\n",
      "       [ 0.45004097, -0.98435026,  0.4498939 ],\n",
      "       [ 1.6124321 , -0.06525664, -1.2877388 ],\n",
      "       [-0.32678688,  0.24165764, -0.03234711],\n",
      "       [ 0.10197094,  0.59074104, -0.78562987],\n",
      "       [ 2.8052695 , -0.7016393 , -1.8078566 ],\n",
      "       [ 3.3114161 , -1.0754813 , -1.8357569 ],\n",
      "       [ 3.195869  , -0.78624165, -1.9729666 ],\n",
      "       [ 2.6260674 , -1.5167506 , -0.72877973],\n",
      "       [ 1.3218119 , -1.426854  ,  0.26592952],\n",
      "       [ 3.0512252 , -1.2503983 , -1.4165497 ],\n",
      "       [ 0.02289249,  0.07214048, -0.22086744],\n",
      "       [ 0.8560962 ,  0.26101288, -1.0392718 ],\n",
      "       [ 0.8045673 ,  0.5783052 , -1.3973482 ],\n",
      "       [ 1.3544518 , -0.22259964, -0.9938484 ],\n",
      "       [ 2.371872  , -1.2203312 , -0.8730255 ],\n",
      "       [ 2.334845  , -0.6446733 , -1.3842015 ],\n",
      "       [ 2.9696324 , -0.90820926, -1.7091928 ],\n",
      "       [ 3.2777915 , -1.5457685 , -1.3104397 ],\n",
      "       [ 0.9772418 ,  0.11482457, -0.9608773 ],\n",
      "       [ 3.3257253 , -1.1393586 , -1.7607759 ],\n",
      "       [ 2.873403  , -0.55190456, -1.9108795 ],\n",
      "       [-0.10240466,  0.6042613 , -0.6266834 ],\n",
      "       [ 1.4506193 , -1.4110171 ,  0.16976894],\n",
      "       [ 3.327517  , -1.1195483 , -1.7951034 ],\n",
      "       [ 0.08611987,  0.78701925, -0.8729343 ],\n",
      "       [ 2.2199664 , -0.89956355, -1.126368  ],\n",
      "       [ 0.7891578 , -0.41235116, -0.42073748],\n",
      "       [ 2.046143  , -0.2751173 , -1.6068232 ],\n",
      "       [ 1.7067734 ,  0.02401094, -1.4348456 ],\n",
      "       [ 2.8137548 , -1.3113296 , -1.1699414 ],\n",
      "       [ 3.1785207 , -1.4915829 , -1.3980331 ],\n",
      "       [ 0.0354056 , -1.4728233 ,  1.2387698 ],\n",
      "       [ 3.1891456 , -1.1165894 , -1.665942  ],\n",
      "       [ 0.96282387,  0.3682276 , -1.2047297 ],\n",
      "       [-0.68664163,  1.320095  , -0.7975785 ],\n",
      "       [ 0.70493084, -1.687065  ,  0.8325686 ],\n",
      "       [ 0.9310005 ,  0.04646508, -0.89789647],\n",
      "       [ 2.9870799 , -1.3542963 , -1.308551  ],\n",
      "       [ 2.1618574 , -0.3366291 , -1.5411747 ],\n",
      "       [-0.37695754, -1.7411648 ,  1.9039806 ],\n",
      "       [ 2.670515  , -0.51825106, -1.7818768 ],\n",
      "       [ 3.6354592 , -1.449064  , -1.6459398 ],\n",
      "       [ 0.53904897,  0.33913574, -0.8883749 ],\n",
      "       [ 2.7581484 , -0.6086663 , -1.7817678 ],\n",
      "       [ 3.0859702 , -1.0487343 , -1.7576566 ],\n",
      "       [ 1.96634   , -1.3750223 , -0.48732042],\n",
      "       [-0.600109  , -0.4483038 ,  0.77885246],\n",
      "       [ 2.3940558 , -0.7126142 , -1.4866692 ],\n",
      "       [ 1.3274589 , -0.75822866, -0.48095945],\n",
      "       [ 1.4601178 , -0.18912938, -1.0107105 ],\n",
      "       [ 3.336593  , -1.0526657 , -1.8753476 ],\n",
      "       [ 2.585     , -0.62631655, -1.667042  ],\n",
      "       [ 2.440444  , -0.87161285, -1.2485044 ],\n",
      "       [ 3.3621616 , -0.8930216 , -1.9693092 ],\n",
      "       [ 3.1958823 , -0.97176254, -1.8564874 ],\n",
      "       [ 3.334369  , -1.1788479 , -1.711502  ],\n",
      "       [ 2.6397438 , -0.58623004, -1.8204448 ],\n",
      "       [ 2.714833  , -1.1719136 , -1.1118985 ],\n",
      "       [ 2.858865  , -0.7920321 , -1.6854607 ],\n",
      "       [-0.1205911 ,  0.14282882, -0.16658798],\n",
      "       [ 3.1771932 , -1.3731769 , -1.3879546 ],\n",
      "       [ 2.4136047 , -0.16522607, -1.9383878 ],\n",
      "       [-0.90421015,  1.2473156 , -0.5642587 ],\n",
      "       [ 1.1160157 ,  0.16424763, -1.1829792 ],\n",
      "       [ 3.145554  , -0.81093335, -1.9137784 ],\n",
      "       [ 0.49447635, -0.14912847, -0.32884505],\n",
      "       [ 3.1324587 , -1.0508039 , -1.7081631 ],\n",
      "       [ 2.7395926 , -1.0720441 , -1.349904  ],\n",
      "       [ 2.4766002 , -0.26198915, -1.8484857 ],\n",
      "       [ 0.66315305, -0.07194816, -0.5597388 ],\n",
      "       [-0.6348879 , -1.2027416 ,  1.4846768 ],\n",
      "       [ 3.1768396 , -0.7919092 , -1.9658694 ],\n",
      "       [-1.107119  ,  0.512918  ,  0.1882869 ],\n",
      "       [ 2.3081462 , -0.6499357 , -1.346522  ],\n",
      "       [-1.2438841 , -0.0754324 ,  1.0800886 ],\n",
      "       [ 1.5866247 , -0.5629906 , -0.817152  ],\n",
      "       [-0.41886693, -0.34542918,  0.5896223 ],\n",
      "       [-0.14139557,  0.3852799 , -0.35301825],\n",
      "       [ 3.5460527 , -1.349192  , -1.6884656 ],\n",
      "       [ 2.6234992 , -0.65934825, -1.5711591 ],\n",
      "       [ 1.671053  , -1.1369641 , -0.5128727 ],\n",
      "       [ 0.14593731,  0.8792119 , -1.0911058 ],\n",
      "       [ 3.3826659 , -0.84361565, -2.0309515 ],\n",
      "       [ 2.215169  , -0.8639421 , -1.1642131 ],\n",
      "       [ 2.1584504 , -0.39426067, -1.5304646 ],\n",
      "       [-0.6411044 , -0.13588788,  0.57419324],\n",
      "       [-0.4603031 , -1.2005659 ,  1.4048432 ],\n",
      "       [ 2.2811403 , -0.72002995, -1.2735714 ],\n",
      "       [-0.8087042 ,  0.13166523,  0.41110522],\n",
      "       [ 0.8794373 , -0.14452916, -0.66449213],\n",
      "       [ 2.7639248 , -1.241878  , -1.1853977 ],\n",
      "       [ 2.830934  , -0.31411114, -2.138112  ],\n",
      "       [ 1.9602724 , -0.185674  , -1.5089937 ],\n",
      "       [ 3.226959  , -1.314451  , -1.4668905 ],\n",
      "       [ 3.2920744 , -1.3863357 , -1.5310267 ],\n",
      "       [ 2.125629  , -1.3827498 , -0.41900596],\n",
      "       [ 2.2833133 , -0.5737922 , -1.4788432 ],\n",
      "       [ 1.1847382 ,  0.04080074, -1.1436244 ],\n",
      "       [-1.3632472 , -1.3386049 ,  2.1395817 ],\n",
      "       [-1.0591265 , -0.77449936,  1.5326706 ],\n",
      "       [-1.008372  , -1.9373312 ,  2.6357558 ],\n",
      "       [ 0.6506574 ,  0.48240682, -1.1258335 ],\n",
      "       [-0.5540079 , -0.43240035,  0.7518139 ],\n",
      "       [-0.7210458 ,  1.1331593 , -0.59121066],\n",
      "       [-1.119532  ,  0.2136055 ,  0.60449815],\n",
      "       [ 2.974394  , -1.3218457 , -1.3079499 ],\n",
      "       [-0.13188429, -0.27038416,  0.2693969 ],\n",
      "       [ 0.14577033, -1.091606  ,  0.7828192 ],\n",
      "       [ 1.4644952 , -0.7120835 , -0.57817364],\n",
      "       [-1.033343  , -0.8457426 ,  1.6130306 ],\n",
      "       [ 1.9159981 , -0.90165603, -0.78798264],\n",
      "       [-0.3750213 , -0.14441532,  0.22989489],\n",
      "       [ 2.9386322 , -0.8515827 , -1.7246277 ],\n",
      "       [ 3.7141178 , -1.4740348 , -1.6882656 ],\n",
      "       [ 1.0055012 ,  0.70364344, -1.4452319 ],\n",
      "       [ 3.0734086 , -1.3345195 , -1.3973509 ],\n",
      "       [ 0.75188196, -1.1431938 ,  0.34834808],\n",
      "       [ 3.0233426 , -0.91621065, -1.7555088 ],\n",
      "       [ 0.38837707, -0.1849966 , -0.29480416],\n",
      "       [ 0.3009894 , -0.7730722 ,  0.36423564],\n",
      "       [-0.37709677, -0.7868115 ,  0.8604244 ],\n",
      "       [-0.66060096, -1.1599905 ,  1.4437491 ],\n",
      "       [ 0.633689  ,  1.3814634 , -1.9506949 ],\n",
      "       [-1.4272804 , -0.88416207,  1.8940035 ],\n",
      "       [ 3.2229905 , -0.5303428 , -2.147947  ],\n",
      "       [ 0.9473228 ,  0.29287693, -1.2580308 ],\n",
      "       [ 3.5265756 , -1.1348944 , -1.889783  ],\n",
      "       [-1.4813459 ,  0.22760814,  0.9708251 ],\n",
      "       [ 2.172523  , -0.39781   , -1.5909557 ],\n",
      "       [-0.26456475,  0.55442214, -0.43921313],\n",
      "       [ 2.578246  , -0.9523509 , -1.390638  ],\n",
      "       [ 2.9791086 , -1.1461836 , -1.4019334 ],\n",
      "       [ 0.78219944, -0.33397758, -0.41458556],\n",
      "       [-1.1942899 , -1.1153752 ,  1.9479238 ],\n",
      "       [ 3.2019966 , -0.66355205, -2.0470614 ],\n",
      "       [ 2.2290196 , -0.4567118 , -1.6072879 ],\n",
      "       [ 3.5287087 , -1.2224398 , -1.8322836 ],\n",
      "       [ 2.2321253 , -1.3739363 , -0.5914783 ],\n",
      "       [ 0.91224116, -0.29966903, -0.532416  ],\n",
      "       [ 3.0860634 , -1.1347618 , -1.4636317 ],\n",
      "       [ 3.4376206 , -0.8147255 , -2.1330204 ],\n",
      "       [-0.15322019,  1.037841  , -1.0499587 ],\n",
      "       [ 2.9675884 , -0.8541486 , -1.7804129 ],\n",
      "       [-0.27906924, -0.57788044,  0.6526992 ],\n",
      "       [-0.2911358 ,  0.84230363, -0.67148334],\n",
      "       [ 2.7651172 , -0.63587004, -1.7836877 ],\n",
      "       [ 2.7597086 , -0.6350317 , -1.7862213 ],\n",
      "       [ 3.233471  , -1.1334739 , -1.7008076 ],\n",
      "       [ 1.3930316 ,  0.16729954, -1.4055548 ],\n",
      "       [ 1.0385386 , -0.9604444 , -0.02513538],\n",
      "       [ 0.87688446, -0.30888182, -0.5107493 ],\n",
      "       [ 2.2059822 , -0.33029473, -1.585871  ],\n",
      "       [ 2.2680178 , -0.48928103, -1.5562967 ],\n",
      "       [ 3.198398  , -1.1467081 , -1.7461993 ],\n",
      "       [-1.2615806 , -0.17896688,  1.0030179 ],\n",
      "       [-0.9251295 , -0.86157316,  1.3382865 ],\n",
      "       [ 2.171906  , -1.077211  , -0.8642388 ],\n",
      "       [ 3.2139428 , -0.5948752 , -2.1604948 ],\n",
      "       [ 1.6293727 , -0.7613135 , -0.6461609 ],\n",
      "       [ 2.8301425 , -0.45294136, -1.9357636 ],\n",
      "       [ 2.5462084 , -0.53287965, -1.684153  ],\n",
      "       [ 0.31153536, -1.6825689 ,  1.1816825 ],\n",
      "       [ 3.0404482 , -1.4368088 , -1.2305366 ],\n",
      "       [ 3.0469825 , -1.0326555 , -1.6635678 ],\n",
      "       [ 3.2651958 , -0.58551073, -2.1898377 ],\n",
      "       [ 3.5372324 , -1.216952  , -1.8701634 ],\n",
      "       [-0.4301262 ,  0.754426  , -0.46864584],\n",
      "       [ 0.15492228, -0.87193984,  0.56688666],\n",
      "       [ 0.7327346 ,  0.11681113, -0.86815566],\n",
      "       [ 3.0060585 , -0.72601247, -1.8397796 ],\n",
      "       [ 3.177221  , -1.1018701 , -1.7349318 ],\n",
      "       [ 2.9367719 , -1.0591062 , -1.5004047 ],\n",
      "       [ 0.6719864 , -1.3640248 ,  0.55700403]], dtype=float32), array([[[ 1.76915992e-02, -8.82915035e-03, -5.68565838e-02, ...,\n",
      "          6.96254000e-02,  1.55493477e-02,  7.21367821e-02],\n",
      "        [ 1.43282861e-01,  1.48404136e-01, -1.12079484e-02, ...,\n",
      "          5.06911427e-02, -8.82085189e-02, -5.43529689e-02],\n",
      "        [ 4.24600951e-03,  4.91782464e-03,  6.91779470e-03, ...,\n",
      "          5.33834472e-03, -3.90575267e-03, -1.27083259e-02],\n",
      "        ...,\n",
      "        [ 2.21623465e-01,  7.14671463e-02, -1.78283036e-01, ...,\n",
      "          3.84089500e-01,  8.75108317e-03,  1.63377360e-01],\n",
      "        [ 2.21623465e-01,  7.14671463e-02, -1.78283036e-01, ...,\n",
      "          3.84089500e-01,  8.75108317e-03,  1.63377360e-01],\n",
      "        [ 2.21623465e-01,  7.14671463e-02, -1.78283036e-01, ...,\n",
      "          3.84089500e-01,  8.75108317e-03,  1.63377360e-01]],\n",
      "\n",
      "       [[-2.89651036e-01,  9.43215415e-02, -5.92887402e-02, ...,\n",
      "          1.45084068e-01, -7.74910003e-02, -4.78347912e-02],\n",
      "        [-8.15204903e-02, -1.80778921e-01, -2.85558812e-02, ...,\n",
      "          5.90275601e-02, -8.77086520e-02,  1.00128680e-01],\n",
      "        [-2.26423025e-01, -1.16346508e-01,  1.02328680e-01, ...,\n",
      "          2.01738894e-01, -4.81183194e-02, -8.27806350e-03],\n",
      "        ...,\n",
      "        [ 5.07571027e-02,  2.79482901e-02, -5.95461242e-02, ...,\n",
      "          3.59929681e-01, -3.06202173e-02,  4.18796699e-04],\n",
      "        [ 5.07571027e-02,  2.79482901e-02, -5.95461242e-02, ...,\n",
      "          3.59929681e-01, -3.06202173e-02,  4.18796699e-04],\n",
      "        [ 5.07571027e-02,  2.79482901e-02, -5.95461242e-02, ...,\n",
      "          3.59929681e-01, -3.06202173e-02,  4.18796699e-04]],\n",
      "\n",
      "       [[-2.11071044e-01, -3.01009137e-02, -1.59944683e-01, ...,\n",
      "          8.90239328e-02,  4.46175151e-02, -9.30803865e-02],\n",
      "        [-7.32339248e-02, -3.52544636e-02, -1.22486025e-01, ...,\n",
      "          1.90858260e-01,  1.00617796e-01,  6.29760027e-02],\n",
      "        [-2.28314206e-01, -1.06392741e-01, -8.30691978e-02, ...,\n",
      "          5.91723956e-02, -5.16116172e-02, -3.41120139e-02],\n",
      "        ...,\n",
      "        [ 1.80955860e-04, -2.05628946e-03, -9.53732431e-02, ...,\n",
      "          3.62112343e-01,  3.28163542e-02,  5.73849678e-03],\n",
      "        [ 1.80955860e-04, -2.05628946e-03, -9.53732431e-02, ...,\n",
      "          3.62112343e-01,  3.28163542e-02,  5.73849678e-03],\n",
      "        [ 1.80955860e-04, -2.05628946e-03, -9.53732431e-02, ...,\n",
      "          3.62112343e-01,  3.28163542e-02,  5.73849678e-03]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 8.60618427e-02, -6.13862835e-02, -8.84577483e-02, ...,\n",
      "          1.45998774e-02,  3.00166775e-02, -2.90803947e-02],\n",
      "        [ 1.27535135e-01, -1.91101491e-01,  7.39721879e-02, ...,\n",
      "         -6.57736976e-03,  9.86507609e-02,  1.82644367e-01],\n",
      "        [ 1.71993569e-01, -3.17749798e-01,  7.08214119e-02, ...,\n",
      "         -6.80036321e-02, -1.16270415e-01,  1.80749953e-01],\n",
      "        ...,\n",
      "        [ 6.39876127e-02, -4.37541157e-02, -4.52902541e-02, ...,\n",
      "          3.05685431e-01, -8.09605494e-02,  9.65985954e-02],\n",
      "        [ 6.39876127e-02, -4.37541157e-02, -4.52902541e-02, ...,\n",
      "          3.05685431e-01, -8.09605494e-02,  9.65985954e-02],\n",
      "        [ 6.39876127e-02, -4.37541157e-02, -4.52902541e-02, ...,\n",
      "          3.05685431e-01, -8.09605494e-02,  9.65985954e-02]],\n",
      "\n",
      "       [[-1.60532519e-01, -1.33481920e-01,  1.91797346e-01, ...,\n",
      "          5.46898358e-02, -1.33781135e-01, -1.85819805e-01],\n",
      "        [-1.48385823e-01, -6.82624131e-02,  2.13909918e-03, ...,\n",
      "         -6.98453039e-02, -2.85556108e-01, -1.27053693e-01],\n",
      "        [ 5.21140955e-02, -6.86283931e-02,  4.69230954e-03, ...,\n",
      "         -2.75380388e-02, -8.75254497e-02, -1.58878535e-01],\n",
      "        ...,\n",
      "        [ 5.67119718e-02, -1.46118309e-02,  3.46168280e-02, ...,\n",
      "          2.61460662e-01, -8.25781003e-02, -1.93338748e-02],\n",
      "        [ 5.67119718e-02, -1.46118309e-02,  3.46168280e-02, ...,\n",
      "          2.61460662e-01, -8.25781003e-02, -1.93338748e-02],\n",
      "        [ 5.67119718e-02, -1.46118309e-02,  3.46168280e-02, ...,\n",
      "          2.61460662e-01, -8.25781003e-02, -1.93338748e-02]],\n",
      "\n",
      "       [[-7.23087117e-02, -5.45685329e-02, -1.69238880e-01, ...,\n",
      "         -4.15644720e-02, -2.42912788e-02, -2.35757917e-01],\n",
      "        [ 5.72385564e-02, -1.21182643e-01, -2.25644067e-01, ...,\n",
      "          1.18774630e-01, -1.81202546e-01, -7.93574974e-02],\n",
      "        [ 1.30421728e-01,  2.42619161e-02, -2.34831423e-01, ...,\n",
      "          1.01969816e-01, -2.84080952e-01, -6.30141273e-02],\n",
      "        ...,\n",
      "        [ 1.43388892e-02,  1.30758807e-01, -1.03982143e-01, ...,\n",
      "          1.92196697e-01, -8.90718773e-02,  6.86991215e-02],\n",
      "        [ 1.43388892e-02,  1.30758807e-01, -1.03982143e-01, ...,\n",
      "          1.92196697e-01, -8.90718773e-02,  6.86991215e-02],\n",
      "        [ 1.43388892e-02,  1.30758807e-01, -1.03982143e-01, ...,\n",
      "          1.92196697e-01, -8.90718773e-02,  6.86991215e-02]]],\n",
      "      dtype=float32)), label_ids=array([0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 2,\n",
      "       0, 1, 2, 2, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 2, 1, 0, 0,\n",
      "       0, 2, 0, 0, 2, 2, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 2, 1, 0, 1, 2,\n",
      "       0, 0, 2, 2, 0, 0, 1, 1, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "       2, 1, 0, 0, 2, 0, 0, 0, 2, 0, 0, 1, 2, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "       1, 0, 1, 0, 1, 0, 0, 0, 2, 2, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2,\n",
      "       0, 1, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 2, 2, 0, 0, 0, 0, 1, 1,\n",
      "       0, 0, 0, 1, 0, 2, 2, 2, 0, 0, 0, 1, 0, 0, 2, 0, 2, 0, 1, 0, 0, 0,\n",
      "       0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 1, 0, 0, 0, 0, 1, 1, 2, 0, 0,\n",
      "       0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 2]), metrics={'test_loss': 0.9740774035453796, 'test_accuracy': 0.6239316239316239, 'test_precision': 0.5933712638446366, 'test_recall': 0.6239316239316239, 'test_f1': 0.6039382039030559, 'test_runtime': 7.6938, 'test_samples_per_second': 30.414, 'test_steps_per_second': 3.899})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "808dd68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48fb2163",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions_array = np.array(test_results.predictions[0])\n",
    "\n",
    "predictions_tensor = torch.tensor(predictions_array).to(torch.float32)\n",
    "probabilities = torch.softmax(predictions_tensor, dim=-1)\n",
    "\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed6cfde2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")  # Adjust xticklabels and yticklabels as needed\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "346c6d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_save = []\n",
    "for idx in range(len(test_data)):\n",
    "    item = dataset['test'][idx]\n",
    "    actual_label = item['label']\n",
    "    predicted_label = predictions[idx]\n",
    "    claim = item['claim'] \n",
    "    premise = item['premise'] \n",
    "    category = item['category']\n",
    "    \n",
    "    # Append the information as a dictionary to the list\n",
    "    data_to_save.append({\n",
    "        'Claim': claim,\n",
    "        'Premise': premise,\n",
    "        'Actual Label': actual_label,\n",
    "        'Predicted Label': predicted_label,\n",
    "        'Category' : category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_to_save)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/home/elson/results/10.4.4_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4543aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correctly classified instances\n",
    "correctly_classified = df[df['Actual Label'] == df['Predicted Label']]\n",
    "\n",
    "# Calculate misclassified instances\n",
    "misclassified = df[df['Actual Label'] != df['Predicted Label']]\n",
    "\n",
    "# Count the number of correctly classified and misclassified by category\n",
    "correct_classification_counts = correctly_classified['Category'].value_counts()\n",
    "misclassification_counts = misclassified['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad099d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           34\n",
       "Bone health              16\n",
       "Fitness                  12\n",
       "Cancer                   12\n",
       "Throat                    9\n",
       "Cardiovascular Health     9\n",
       "Skin                      9\n",
       "Hair                      7\n",
       "Neurological health       6\n",
       "Ear                       6\n",
       "Diabetes                  5\n",
       "Women' s Health           5\n",
       "Blood                     4\n",
       "COVID                     4\n",
       "Mental Health             3\n",
       "Eye                       3\n",
       "Men's health              1\n",
       "Muscles                   1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d45817c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           17\n",
       "Skin                     15\n",
       "Diabetes                  7\n",
       "Eye                       6\n",
       "Muscles                   5\n",
       "Men's health              5\n",
       "Hair                      5\n",
       "Blood                     5\n",
       "Bone health               5\n",
       "Fitness                   3\n",
       "Vascular                  3\n",
       "Dental Health             3\n",
       "Neurological health       3\n",
       "Cardiovascular Health     3\n",
       "COVID                     2\n",
       "Women' s Health           1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
