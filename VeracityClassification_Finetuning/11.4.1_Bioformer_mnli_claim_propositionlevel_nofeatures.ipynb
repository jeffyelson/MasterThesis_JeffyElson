{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-022bc67e9c58e92d\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 200.21it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('csv',data_files='dataset_propositionattribution_nerfeatures.csv',delimiter=',',column_names=[\"claim\",\"premise\",\"label\",\"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\",\"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\",\"url\", \"entities\",\"entity_map\",\"entity_map_ev\",\"entities_ev\",\"gem_exp\",\"gem_label\",\"gpt_label\",\"gpt_exp\",\"gold_exp\",\"synonym\",\"voice\",\"split\"],skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "133f9357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-2b8e361375c0e153.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-0cc9bb699c2761fb.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-608a44ac65076739.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01252e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\"claim\", \"premise\", \"label\",\"category\"]\n",
    "all_columns = dataset[\"train\"].column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-ec19dfd27de43963.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-10d23eaef378d5d1.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-e72c65ea7c63cdc8.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 2, 'entailment': 0, 'neutral': 1}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 2,\n",
    "    \"entailment\": 0,\n",
    "    \"neutral\": 1\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e15010ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='bioformers/bioformer-8L-mnli'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "        # Extracting claim and evidence texts\n",
    "\n",
    "        claim = item['claim']\n",
    "        evidences = item['premise']\n",
    "        item['premise']=evidences\n",
    "        item['claim']=claim\n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "            evidences, claim,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "        item['input_ids'] = inputs['input_ids'].squeeze()  # Remove batch dimension\n",
    "        item['attention_mask']= inputs['attention_mask'].squeeze() # Remove batch dimension\n",
    "        \n",
    "        if 'label' in item:\n",
    "            item['labels'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62421eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(32768, 512, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 512)\n",
       "      (token_type_embeddings): Embedding(2, 512)\n",
       "      (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=512, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"bioformers/bioformer-8L-mnli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=512)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=3, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    return {\"accuracy\": acc, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f5cf584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'claim': 'Myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.',\n",
       " 'premise': 'The essential oils of frankincense and myrrh increase the fluidity of the lipid bilayer in the cuticle and change the orderly and dense structure to increase the permeability of the skin and decrease the barrier effect.',\n",
       " 'label': 0,\n",
       " 'category': 'General Health',\n",
       " 'input_ids': tensor([  101,  1480,  3720, 15658,  1431,  2132,  4765,  2848,  9507,  1111,\n",
       "          1435,  2573,  1109,  4258,  2161,  1425, 26267,  1431,  1425,  3460,\n",
       "         14360,  1427,  1425, 26669,  1435,  2731,  1425,  2784,  1456,  1435,\n",
       "         10036,  2700,  1446,  2161,  1425,  7805,  1431,  1425,  3550,  1435,\n",
       "          3026,  1425,  6245,  1997,   119,   102, 31487,  4258,  3720,  6187,\n",
       "          1478,  8811,  1822,  1427,  3550,  5183,  4030,  1446,  3346,  2520,\n",
       "          1425,  6875,  1431,  1425,  3550,   119,   102,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'labels': tensor(0)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1530\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1530' max='1530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1530/1530 03:22, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.831100</td>\n",
       "      <td>0.801122</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.607100</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.615050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.609400</td>\n",
       "      <td>0.946945</td>\n",
       "      <td>0.595699</td>\n",
       "      <td>0.659861</td>\n",
       "      <td>0.595699</td>\n",
       "      <td>0.617690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.354700</td>\n",
       "      <td>1.124198</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.651831</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.645558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.151400</td>\n",
       "      <td>1.390462</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.677494</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.656332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.182400</td>\n",
       "      <td>1.399811</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.637720</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.642504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.110200</td>\n",
       "      <td>1.767818</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.622283</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.629775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.046700</td>\n",
       "      <td>1.926944</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.651304</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.649907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.033800</td>\n",
       "      <td>2.075726</td>\n",
       "      <td>0.632258</td>\n",
       "      <td>0.649941</td>\n",
       "      <td>0.632258</td>\n",
       "      <td>0.640031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.048800</td>\n",
       "      <td>2.134717</td>\n",
       "      <td>0.653763</td>\n",
       "      <td>0.637841</td>\n",
       "      <td>0.653763</td>\n",
       "      <td>0.641650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.090400</td>\n",
       "      <td>2.280915</td>\n",
       "      <td>0.647312</td>\n",
       "      <td>0.648571</td>\n",
       "      <td>0.647312</td>\n",
       "      <td>0.647298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>2.367424</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.642625</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.645230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>2.382480</td>\n",
       "      <td>0.647312</td>\n",
       "      <td>0.642436</td>\n",
       "      <td>0.647312</td>\n",
       "      <td>0.644113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>2.412229</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.643272</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.643029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>2.430244</td>\n",
       "      <td>0.647312</td>\n",
       "      <td>0.649903</td>\n",
       "      <td>0.647312</td>\n",
       "      <td>0.648210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>2.421915</td>\n",
       "      <td>0.640860</td>\n",
       "      <td>0.640945</td>\n",
       "      <td>0.640860</td>\n",
       "      <td>0.640254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.1_bioformer/checkpoint-102\n",
      "Configuration saved in /home/elson/11.4.1_bioformer/checkpoint-102/config.json\n",
      "Model weights saved in /home/elson/11.4.1_bioformer/checkpoint-102/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.1_bioformer/checkpoint-459] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/11.4.1_bioformer/checkpoint-765] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.1_bioformer/checkpoint-204\n",
      "Configuration saved in /home/elson/11.4.1_bioformer/checkpoint-204/config.json\n",
      "Model weights saved in /home/elson/11.4.1_bioformer/checkpoint-204/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.1_bioformer/checkpoint-306\n",
      "Configuration saved in /home/elson/11.4.1_bioformer/checkpoint-306/config.json\n",
      "Model weights saved in /home/elson/11.4.1_bioformer/checkpoint-306/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.1_bioformer/checkpoint-102] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/11.4.1_bioformer/checkpoint-204] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.1_bioformer/checkpoint-408\n",
      "Configuration saved in /home/elson/11.4.1_bioformer/checkpoint-408/config.json\n",
      "Model weights saved in /home/elson/11.4.1_bioformer/checkpoint-408/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.1_bioformer/checkpoint-510\n",
      "Configuration saved in /home/elson/11.4.1_bioformer/checkpoint-510/config.json\n",
      "Model weights saved in /home/elson/11.4.1_bioformer/checkpoint-510/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.1_bioformer/checkpoint-306] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/11.4.1_bioformer/checkpoint-408] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.1_bioformer/checkpoint-612\n",
      "Configuration saved in /home/elson/11.4.1_bioformer/checkpoint-612/config.json\n",
      "Model weights saved in /home/elson/11.4.1_bioformer/checkpoint-612/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.1_bioformer/checkpoint-714\n",
      "Configuration saved in /home/elson/11.4.1_bioformer/checkpoint-714/config.json\n",
      "Model weights saved in /home/elson/11.4.1_bioformer/checkpoint-714/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.1_bioformer/checkpoint-612] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.1_bioformer/checkpoint-816\n",
      "Configuration saved in /home/elson/11.4.1_bioformer/checkpoint-816/config.json\n",
      "Model weights saved in /home/elson/11.4.1_bioformer/checkpoint-816/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.1_bioformer/checkpoint-714] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.1_bioformer/checkpoint-918\n",
      "Configuration saved in /home/elson/11.4.1_bioformer/checkpoint-918/config.json\n",
      "Model weights saved in /home/elson/11.4.1_bioformer/checkpoint-918/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.1_bioformer/checkpoint-816] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.1_bioformer/checkpoint-1020\n",
      "Configuration saved in /home/elson/11.4.1_bioformer/checkpoint-1020/config.json\n",
      "Model weights saved in /home/elson/11.4.1_bioformer/checkpoint-1020/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.1_bioformer/checkpoint-918] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.1_bioformer/checkpoint-1122\n",
      "Configuration saved in /home/elson/11.4.1_bioformer/checkpoint-1122/config.json\n",
      "Model weights saved in /home/elson/11.4.1_bioformer/checkpoint-1122/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.1_bioformer/checkpoint-1020] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.1_bioformer/checkpoint-1224\n",
      "Configuration saved in /home/elson/11.4.1_bioformer/checkpoint-1224/config.json\n",
      "Model weights saved in /home/elson/11.4.1_bioformer/checkpoint-1224/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.1_bioformer/checkpoint-1122] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.1_bioformer/checkpoint-1326\n",
      "Configuration saved in /home/elson/11.4.1_bioformer/checkpoint-1326/config.json\n",
      "Model weights saved in /home/elson/11.4.1_bioformer/checkpoint-1326/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.1_bioformer/checkpoint-1224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.1_bioformer/checkpoint-1428\n",
      "Configuration saved in /home/elson/11.4.1_bioformer/checkpoint-1428/config.json\n",
      "Model weights saved in /home/elson/11.4.1_bioformer/checkpoint-1428/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.1_bioformer/checkpoint-1326] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.1_bioformer/checkpoint-1530\n",
      "Configuration saved in /home/elson/11.4.1_bioformer/checkpoint-1530/config.json\n",
      "Model weights saved in /home/elson/11.4.1_bioformer/checkpoint-1530/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.1_bioformer/checkpoint-1428] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/elson/11.4.1_bioformer/checkpoint-510 (score: 0.6666666666666666).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /home/elson/11.4.1_bioformer/best_model/config.json\n",
      "Model weights saved in /home/elson/11.4.1_bioformer/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/11.4.1_bioformer/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/11.4.1_bioformer/best_model/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/11.4.1_bioformer/best_model/tokenizer_config.json',\n",
       " '/home/elson/11.4.1_bioformer/best_model/special_tokens_map.json',\n",
       " '/home/elson/11.4.1_bioformer/best_model/vocab.txt',\n",
       " '/home/elson/11.4.1_bioformer/best_model/added_tokens.json',\n",
       " '/home/elson/11.4.1_bioformer/best_model/tokenizer.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/11.4.1_bioformer/',\n",
    "    num_train_epochs=15,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.1,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/11.4.1_bioformer/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/11.4.1_bioformer/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63deaea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/11.4.1_bioformer/best_model/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"/home/elson/11.4.1_bioformer/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"finetuning_task\": \"mnli\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 512,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"entailment\",\n",
      "    \"1\": \"neutral\",\n",
      "    \"2\": \"contradiction\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2048,\n",
      "  \"label2id\": {\n",
      "    \"contradiction\": 2,\n",
      "    \"entailment\": 0,\n",
      "    \"neutral\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 8,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32768\n",
      "}\n",
      "\n",
      "loading weights file /home/elson/11.4.1_bioformer/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at /home/elson/11.4.1_bioformer/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 16\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/11.4.1_bioformer/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[ 2.6504e+00, -1.5400e+00, -1.1729e+00],\n",
      "       [ 1.8291e+00,  1.8027e+00, -3.5938e+00],\n",
      "       [ 4.3750e+00, -2.2520e+00, -2.2031e+00],\n",
      "       [-2.2324e+00, -1.1650e+00,  3.5859e+00],\n",
      "       [ 4.2344e+00, -1.9580e+00, -2.1621e+00],\n",
      "       [ 4.7344e+00, -1.8105e+00, -2.7734e+00],\n",
      "       [ 4.5000e+00, -2.4688e+00, -2.0430e+00],\n",
      "       [ 4.5664e+00, -1.5537e+00, -2.9609e+00],\n",
      "       [ 3.2012e+00, -9.4287e-01, -2.5312e+00],\n",
      "       [-5.5566e-01,  7.7295e-01,  1.5356e-01],\n",
      "       [ 4.2812e+00, -3.0645e+00, -1.3633e+00],\n",
      "       [ 4.6641e+00, -2.4297e+00, -2.1582e+00],\n",
      "       [ 4.5938e+00, -1.6973e+00, -2.8730e+00],\n",
      "       [ 4.6367e+00, -1.6514e+00, -3.0098e+00],\n",
      "       [ 4.7070e+00, -1.5439e+00, -3.1152e+00],\n",
      "       [-5.2686e-01,  1.4307e+00, -9.7754e-01],\n",
      "       [ 4.7461e+00, -2.3379e+00, -2.3750e+00],\n",
      "       [ 4.7031e+00, -2.0645e+00, -2.6230e+00],\n",
      "       [ 4.4102e+00, -2.2383e+00, -2.2539e+00],\n",
      "       [ 4.5195e+00, -2.0234e+00, -2.5039e+00],\n",
      "       [ 2.2812e+00, -2.1895e+00, -5.5811e-01],\n",
      "       [-4.3970e-01,  1.1562e+00, -9.2920e-01],\n",
      "       [ 3.9785e+00, -2.1094e+00, -1.9502e+00],\n",
      "       [-1.9365e+00, -1.5293e+00,  3.5156e+00],\n",
      "       [ 3.1519e-01, -1.8838e+00,  1.6953e+00],\n",
      "       [-1.2393e+00, -9.7803e-01,  2.3105e+00],\n",
      "       [ 4.7578e+00, -2.1777e+00, -2.5215e+00],\n",
      "       [-1.3896e+00,  3.9941e+00, -2.0332e+00],\n",
      "       [ 4.5547e+00, -1.7676e+00, -2.8359e+00],\n",
      "       [ 3.3711e+00, -2.1094e+00, -1.4102e+00],\n",
      "       [ 2.4043e+00, -1.5059e+00, -9.4531e-01],\n",
      "       [ 4.4922e+00, -1.2080e+00, -3.1934e+00],\n",
      "       [ 3.7246e+00, -1.3213e+00, -2.6465e+00],\n",
      "       [-1.2334e+00,  2.6989e-03,  1.6064e+00],\n",
      "       [ 3.5625e+00, -1.1299e+00, -2.7559e+00],\n",
      "       [ 4.7695e+00, -1.9102e+00, -2.8320e+00],\n",
      "       [ 4.5312e+00, -2.4395e+00, -2.1211e+00],\n",
      "       [ 4.3789e+00, -9.1406e-01, -3.4355e+00],\n",
      "       [-7.9150e-01, -2.3379e+00,  3.2598e+00],\n",
      "       [ 4.7383e+00, -1.9307e+00, -2.8047e+00],\n",
      "       [ 3.1494e-01,  2.3230e-01, -2.8442e-01],\n",
      "       [ 1.3906e+00,  2.0664e+00, -3.4766e+00],\n",
      "       [ 1.6045e+00, -1.7148e+00, -2.2827e-01],\n",
      "       [ 9.6777e-01, -3.2402e+00,  1.9629e+00],\n",
      "       [ 4.0312e+00, -1.3916e+00, -2.8379e+00],\n",
      "       [ 4.7305e+00, -1.8779e+00, -2.7949e+00],\n",
      "       [ 4.4023e+00, -1.7549e+00, -2.6855e+00],\n",
      "       [ 4.4688e+00, -1.4219e+00, -3.0684e+00],\n",
      "       [ 4.3984e+00, -2.7832e+00, -1.6865e+00],\n",
      "       [-2.0837e-01, -1.4238e+00,  1.8945e+00],\n",
      "       [ 2.6992e+00, -2.5605e+00, -5.6250e-01],\n",
      "       [-2.0488e+00,  2.4199e+00,  3.6652e-02],\n",
      "       [ 3.9258e+00, -1.1553e+00, -2.8359e+00],\n",
      "       [ 3.6328e-01,  1.9023e+00, -2.1387e+00],\n",
      "       [-1.6836e+00, -8.7549e-01,  2.5703e+00],\n",
      "       [ 9.0332e-01, -9.6533e-01, -2.1924e-01],\n",
      "       [-2.3965e+00,  2.9180e+00, -1.6785e-01],\n",
      "       [ 1.0723e+00,  2.4062e+00, -3.4805e+00],\n",
      "       [ 3.0566e+00, -1.3467e+00, -2.0098e+00],\n",
      "       [ 4.2422e+00, -2.3809e+00, -2.1250e+00],\n",
      "       [ 4.5508e+00, -1.9717e+00, -2.4727e+00],\n",
      "       [-2.2620e-01, -1.3857e+00,  1.7949e+00],\n",
      "       [ 4.0352e+00, -5.3906e-01, -3.4414e+00],\n",
      "       [ 3.9023e+00, -1.2656e+00, -2.5156e+00],\n",
      "       [ 4.4727e+00, -1.0908e+00, -3.3867e+00],\n",
      "       [ 4.4219e+00, -2.6191e+00, -1.8154e+00],\n",
      "       [ 4.7617e+00, -2.0430e+00, -2.6641e+00],\n",
      "       [ 4.3516e+00, -1.7197e+00, -2.8164e+00],\n",
      "       [ 4.3125e+00, -3.1191e+00, -1.3203e+00],\n",
      "       [ 9.0027e-02, -1.3271e+00,  1.3037e+00],\n",
      "       [ 4.5703e+00, -1.5010e+00, -3.0605e+00],\n",
      "       [ 3.3594e+00, -1.4619e+00, -2.0879e+00],\n",
      "       [ 4.7305e+00, -2.4023e+00, -2.3320e+00],\n",
      "       [ 4.4648e+00, -9.5312e-01, -3.3398e+00],\n",
      "       [ 3.0977e+00, -2.0254e+00, -1.2695e+00],\n",
      "       [ 3.6602e+00, -2.8516e+00, -1.0811e+00],\n",
      "       [ 4.4297e+00, -2.6152e+00, -1.8760e+00],\n",
      "       [ 4.4062e+00, -1.9229e+00, -2.4551e+00],\n",
      "       [ 4.5508e+00, -2.2871e+00, -2.3613e+00],\n",
      "       [ 3.2344e+00, -2.9785e+00, -4.6143e-01],\n",
      "       [ 4.5820e+00, -1.9014e+00, -2.6855e+00],\n",
      "       [ 4.6875e+00, -1.6748e+00, -3.0547e+00],\n",
      "       [ 4.4258e+00, -2.4082e+00, -2.1523e+00],\n",
      "       [ 3.9902e+00, -2.5312e+00, -1.7031e+00],\n",
      "       [ 4.7422e+00, -2.0664e+00, -2.6309e+00],\n",
      "       [ 3.0859e+00, -1.7822e+00, -1.2363e+00],\n",
      "       [ 4.3164e+00, -2.8496e+00, -1.4912e+00],\n",
      "       [ 4.1875e+00, -1.7822e+00, -2.4824e+00],\n",
      "       [ 1.3340e+00,  1.9883e+00, -3.3711e+00],\n",
      "       [ 1.6924e+00,  1.3301e+00, -2.8027e+00],\n",
      "       [ 4.5000e+00, -2.3535e+00, -2.2422e+00],\n",
      "       [ 4.2070e+00, -5.9473e-01, -3.5293e+00],\n",
      "       [-2.0879e+00, -3.3545e-01,  2.5449e+00],\n",
      "       [ 4.5703e+00, -2.0215e+00, -2.6172e+00],\n",
      "       [-1.4395e+00, -3.3569e-01,  1.7178e+00],\n",
      "       [ 1.1387e+00, -9.5264e-01, -2.9492e-01],\n",
      "       [ 8.5059e-01, -2.8633e+00,  1.7754e+00],\n",
      "       [ 2.0508e+00, -8.1104e-01, -1.4932e+00],\n",
      "       [ 4.4961e+00, -1.3389e+00, -3.1504e+00],\n",
      "       [ 4.6484e+00, -1.8926e+00, -2.6914e+00],\n",
      "       [ 2.2637e+00, -3.1914e+00,  8.9893e-01],\n",
      "       [ 4.7344e+00, -2.1211e+00, -2.5059e+00],\n",
      "       [ 4.7461e+00, -2.1758e+00, -2.5195e+00],\n",
      "       [ 4.4414e+00, -9.6338e-01, -3.4609e+00],\n",
      "       [ 4.1992e+00, -8.6670e-01, -3.3301e+00],\n",
      "       [ 4.4531e+00, -1.2588e+00, -3.1973e+00],\n",
      "       [ 3.6406e+00, -2.2969e+00, -1.4395e+00],\n",
      "       [-6.4697e-02, -1.0811e+00,  1.2441e+00],\n",
      "       [ 3.7051e+00, -1.9763e-01, -3.6426e+00],\n",
      "       [ 4.2812e+00, -8.2617e-01, -3.3809e+00],\n",
      "       [ 2.6387e+00,  8.7256e-01, -3.4863e+00],\n",
      "       [ 4.5234e+00, -1.7090e+00, -2.8340e+00],\n",
      "       [ 4.3281e+00, -2.4746e+00, -2.0000e+00],\n",
      "       [ 4.4922e+00, -2.5176e+00, -2.0137e+00],\n",
      "       [ 3.6172e+00, -1.2607e+00, -2.4922e+00],\n",
      "       [ 4.5234e+00, -1.3877e+00, -3.0957e+00],\n",
      "       [ 4.7070e+00, -2.0488e+00, -2.6895e+00],\n",
      "       [ 4.3384e-01, -3.0742e+00,  2.8047e+00],\n",
      "       [ 4.3555e+00, -2.3770e+00, -2.0527e+00],\n",
      "       [ 4.6250e+00, -1.8008e+00, -2.7949e+00],\n",
      "       [ 1.5986e+00,  2.2871e+00, -3.6484e+00],\n",
      "       [ 4.3867e+00, -1.0469e+00, -3.2676e+00],\n",
      "       [ 3.4219e+00,  5.8887e-01, -3.8945e+00],\n",
      "       [-1.1786e-01,  3.1035e+00, -2.8555e+00],\n",
      "       [-1.5955e-01,  3.4043e+00, -2.8340e+00],\n",
      "       [ 4.7227e+00, -1.8457e+00, -2.9219e+00],\n",
      "       [ 4.0039e+00, -1.1621e+00, -2.9746e+00],\n",
      "       [ 4.3555e+00, -2.1543e+00, -2.4277e+00],\n",
      "       [ 4.4727e+00, -2.2344e+00, -2.2578e+00],\n",
      "       [ 4.6641e+00, -2.2969e+00, -2.4727e+00],\n",
      "       [ 2.2715e+00, -2.3418e+00,  1.0437e-01],\n",
      "       [-1.4785e+00,  6.9275e-02,  1.3359e+00],\n",
      "       [ 4.6016e+00, -1.4434e+00, -3.1016e+00],\n",
      "       [ 6.3379e-01, -3.0527e+00,  2.0371e+00],\n",
      "       [ 4.1953e+00, -6.8945e-01, -3.3730e+00],\n",
      "       [ 4.5625e+00, -2.2988e+00, -2.3477e+00],\n",
      "       [ 3.9883e+00, -2.8281e+00, -1.3271e+00],\n",
      "       [ 2.2070e+00, -7.9443e-01, -1.6543e+00],\n",
      "       [-1.6582e+00,  1.2568e+00,  7.5635e-01],\n",
      "       [ 4.7617e+00, -2.2207e+00, -2.4766e+00],\n",
      "       [ 4.6914e+00, -1.8594e+00, -2.7734e+00],\n",
      "       [-2.2910e+00, -2.1985e-01,  2.5645e+00],\n",
      "       [-1.2432e+00,  9.2725e-01,  5.8154e-01],\n",
      "       [ 4.7617e+00, -2.0020e+00, -2.6797e+00],\n",
      "       [ 3.6797e+00, -2.5996e+00, -1.1836e+00],\n",
      "       [ 3.9785e+00, -2.4434e+00, -1.7783e+00],\n",
      "       [-2.4355e+00, -9.0039e-01,  3.3633e+00],\n",
      "       [ 1.4380e-01, -1.1113e+00,  1.0830e+00],\n",
      "       [ 4.6016e+00, -1.7900e+00, -2.8164e+00],\n",
      "       [ 3.3516e+00,  4.2480e-01, -3.7168e+00],\n",
      "       [ 4.0234e+00, -8.6572e-01, -3.2090e+00],\n",
      "       [ 4.5039e+00, -2.3320e+00, -2.2852e+00],\n",
      "       [ 1.8418e+00, -1.0488e+00, -9.1650e-01],\n",
      "       [ 4.4570e+00, -2.6680e+00, -1.8633e+00],\n",
      "       [ 4.6992e+00, -2.2129e+00, -2.4434e+00],\n",
      "       [ 4.5625e+00, -2.5762e+00, -1.9912e+00],\n",
      "       [ 4.3633e+00, -2.6211e+00, -1.8760e+00],\n",
      "       [ 4.5469e+00, -2.1621e+00, -2.4238e+00],\n",
      "       [-2.7578e+00,  7.6294e-02,  2.9512e+00],\n",
      "       [-1.7373e+00, -2.0625e+00,  3.8555e+00],\n",
      "       [-1.4385e+00, -2.1855e+00,  3.8242e+00],\n",
      "       [-1.4004e+00, -1.4385e+00,  3.0312e+00],\n",
      "       [ 1.9379e-02, -1.4180e+00,  1.1836e+00],\n",
      "       [-1.8623e+00, -1.5039e+00,  3.1289e+00],\n",
      "       [ 1.6250e+00, -1.2598e+00, -6.4746e-01],\n",
      "       [ 3.7461e+00, -2.4844e+00, -1.6143e+00],\n",
      "       [ 4.5391e+00, -1.8594e+00, -2.7363e+00],\n",
      "       [ 9.1309e-01, -1.4463e+00,  4.8561e-03],\n",
      "       [ 8.3069e-02, -4.1162e-01,  4.2017e-01],\n",
      "       [-3.9307e-01, -1.2314e+00,  1.9492e+00],\n",
      "       [-2.2734e+00, -7.2461e-01,  3.1152e+00],\n",
      "       [-6.8701e-01, -8.4717e-01,  1.9150e+00],\n",
      "       [ 2.0723e+00, -1.3604e+00, -7.2119e-01],\n",
      "       [ 3.8340e+00, -4.8975e-01, -3.4043e+00],\n",
      "       [ 4.7344e+00, -2.1973e+00, -2.4180e+00],\n",
      "       [ 1.5078e+00, -1.1650e+00, -1.7468e-01],\n",
      "       [ 4.5938e+00, -1.8779e+00, -2.7012e+00],\n",
      "       [ 1.6816e+00, -2.2988e+00,  8.0127e-01],\n",
      "       [ 4.2383e+00, -2.3086e+00, -1.8887e+00],\n",
      "       [-1.5251e-02,  1.3389e+00, -8.3789e-01],\n",
      "       [ 8.8770e-01,  6.8945e-01, -1.7773e+00],\n",
      "       [ 3.3398e+00, -2.0508e+00, -1.4033e+00],\n",
      "       [-5.5859e-01, -7.2803e-01,  1.5596e+00],\n",
      "       [ 3.6445e+00, -1.1455e+00, -2.3516e+00],\n",
      "       [-1.9873e+00,  3.3887e-01,  1.4902e+00],\n",
      "       [ 4.5977e+00, -2.5020e+00, -2.1270e+00],\n",
      "       [ 4.6250e+00, -1.7412e+00, -2.8281e+00],\n",
      "       [ 4.6914e+00, -1.9365e+00, -2.6465e+00],\n",
      "       [ 3.8730e+00, -6.1523e-01, -3.1289e+00],\n",
      "       [ 4.4609e+00, -1.7520e+00, -2.7324e+00],\n",
      "       [ 3.9185e-01,  2.6836e+00, -3.0586e+00],\n",
      "       [ 2.2910e+00, -1.2119e+00, -1.0117e+00],\n",
      "       [ 4.1484e+00, -2.6094e+00, -1.5371e+00],\n",
      "       [ 2.6406e+00,  7.5586e-01, -3.6133e+00],\n",
      "       [-3.1465e+00,  1.8018e-01,  3.1465e+00],\n",
      "       [ 4.6562e+00, -1.8672e+00, -2.7578e+00],\n",
      "       [ 3.0781e+00, -3.8135e-01, -2.9844e+00],\n",
      "       [ 4.7656e+00, -2.0996e+00, -2.5645e+00],\n",
      "       [ 3.9707e+00, -2.5000e+00, -1.7646e+00],\n",
      "       [ 2.0723e+00,  4.7778e-01, -2.8008e+00],\n",
      "       [ 4.7070e+00, -2.4805e+00, -2.1406e+00],\n",
      "       [ 4.7266e+00, -1.6953e+00, -2.9102e+00],\n",
      "       [ 2.3281e+00, -1.2031e+00, -1.0918e+00],\n",
      "       [ 2.5469e+00,  9.9512e-01, -3.6270e+00],\n",
      "       [ 3.8164e+00, -1.2393e+00, -2.7617e+00],\n",
      "       [-1.3535e+00, -5.5957e-01,  2.1855e+00],\n",
      "       [ 4.4844e+00, -2.3242e+00, -2.2930e+00],\n",
      "       [ 4.1602e+00, -1.2529e+00, -3.1289e+00],\n",
      "       [ 4.6680e+00, -2.0020e+00, -2.6934e+00],\n",
      "       [ 3.0137e+00, -1.2529e+00, -2.1699e+00],\n",
      "       [ 2.9414e+00,  9.5801e-01, -3.8203e+00],\n",
      "       [ 3.0547e+00, -7.7051e-01, -2.5527e+00],\n",
      "       [ 2.0547e+00, -1.9141e+00, -5.0732e-01],\n",
      "       [ 4.1680e+00, -1.0312e+00, -3.2129e+00],\n",
      "       [ 4.7422e+00, -2.0859e+00, -2.6016e+00],\n",
      "       [-1.6904e+00, -2.4688e+00,  4.1016e+00],\n",
      "       [ 8.3350e-01, -2.8945e+00,  1.6631e+00],\n",
      "       [ 3.0527e+00, -2.4004e+00, -7.9395e-01],\n",
      "       [ 4.6211e+00, -1.5742e+00, -2.9941e+00],\n",
      "       [ 1.0596e+00,  7.2852e-01, -1.6426e+00],\n",
      "       [ 4.6719e+00, -1.6250e+00, -2.9668e+00],\n",
      "       [ 3.8145e+00, -1.6638e-01, -3.7090e+00],\n",
      "       [ 6.6357e-01, -2.3008e+00,  1.3721e+00],\n",
      "       [ 4.6445e+00, -1.6758e+00, -2.9355e+00],\n",
      "       [ 4.4453e+00, -2.3457e+00, -2.0137e+00],\n",
      "       [ 4.7539e+00, -1.7227e+00, -2.9082e+00],\n",
      "       [ 4.6562e+00, -1.8779e+00, -2.7539e+00],\n",
      "       [-1.8926e+00, -4.1235e-01,  2.5254e+00],\n",
      "       [ 1.6748e+00, -1.5674e+00, -3.5583e-02],\n",
      "       [-1.1377e+00, -1.0332e+00,  2.5703e+00],\n",
      "       [ 4.7109e+00, -1.9424e+00, -2.6895e+00],\n",
      "       [ 4.5547e+00, -1.9189e+00, -2.5820e+00],\n",
      "       [ 4.2656e+00, -2.6250e+00, -1.5127e+00],\n",
      "       [ 1.9814e+00, -2.3027e+00,  4.7095e-01]], dtype=float16), label_ids=array([0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
      "       0, 1, 2, 2, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 2, 0, 2, 1, 0, 0,\n",
      "       1, 2, 0, 0, 0, 2, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 2, 1, 0, 1, 0,\n",
      "       0, 1, 2, 2, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
      "       0, 1, 0, 0, 1, 0, 1, 1, 2, 0, 0, 1, 2, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "       1, 2, 0, 0, 1, 0, 0, 0, 1, 2, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
      "       0, 1, 0, 1, 0, 0, 1, 0, 2, 0, 0, 0, 1, 1, 2, 1, 0, 0, 0, 0, 1, 1,\n",
      "       2, 0, 0, 1, 0, 2, 2, 2, 1, 0, 0, 1, 0, 1, 2, 0, 2, 0, 1, 0, 0, 0,\n",
      "       0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 2, 2, 0, 1, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 2, 0, 0,\n",
      "       0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 2, 0, 0, 1]), metrics={'test_loss': 1.7642346620559692, 'test_accuracy': 0.6111111111111112, 'test_precision': 0.5963193752077102, 'test_recall': 0.6111111111111112, 'test_f1': 0.559266238023614, 'test_runtime': 0.5752, 'test_samples_per_second': 406.787, 'test_steps_per_second': 26.076})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "808dd68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48fb2163",
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = torch.softmax(torch.tensor(test_results.predictions).to(torch.float32), dim=-1)\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed6cfde2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")  # Adjust xticklabels and yticklabels as needed\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "346c6d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_save = []\n",
    "for idx in range(len(test_data)):\n",
    "    item = test_data.__getitem__(idx)\n",
    "    actual_label = item['label']\n",
    "    predicted_label = predictions[idx]\n",
    "    claim = item['claim'] \n",
    "    premise = item['premise'] \n",
    "    category = item['category']\n",
    "    \n",
    "    # Append the information as a dictionary to the list\n",
    "    data_to_save.append({\n",
    "        'Claim': claim,\n",
    "        'Premise': premise,\n",
    "        'Actual Label': actual_label,\n",
    "        'Predicted Label': predicted_label,\n",
    "        'Category' : category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_to_save)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/home/elson/results/11.4.1_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4543aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correctly classified instances\n",
    "correctly_classified = df[df['Actual Label'] == df['Predicted Label']]\n",
    "\n",
    "# Calculate misclassified instances\n",
    "misclassified = df[df['Actual Label'] != df['Predicted Label']]\n",
    "\n",
    "# Count the number of correctly classified and misclassified by category\n",
    "correct_classification_counts = correctly_classified['Category'].value_counts()\n",
    "misclassification_counts = misclassified['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad099d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           37\n",
       "Fitness                  12\n",
       "Bone health              11\n",
       "Skin                     10\n",
       "Throat                    9\n",
       "Cancer                    9\n",
       "Cardiovascular Health     8\n",
       "Diabetes                  8\n",
       "Ear                       6\n",
       "Neurological health       6\n",
       "Blood                     5\n",
       "Hair                      5\n",
       "Women' s Health           4\n",
       "Men's health              3\n",
       "Eye                       3\n",
       "Mental Health             3\n",
       "COVID                     3\n",
       "Muscles                   1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d45817c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           14\n",
       "Skin                     14\n",
       "Bone health              10\n",
       "Hair                      7\n",
       "Eye                       6\n",
       "Muscles                   5\n",
       "Blood                     4\n",
       "Diabetes                  4\n",
       "Cardiovascular Health     4\n",
       "COVID                     3\n",
       "Men's health              3\n",
       "Vascular                  3\n",
       "Dental Health             3\n",
       "Neurological health       3\n",
       "Fitness                   3\n",
       "Cancer                    3\n",
       "Women' s Health           2\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
