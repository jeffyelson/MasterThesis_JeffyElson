{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score,balanced_accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-b1cea7a0edcc1ad9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/elson/.cache/huggingface/datasets/csv/default-b1cea7a0edcc1ad9/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|██████████| 1/1 [00:00<00:00, 2968.37it/s]\n",
      "Extracting data files: 100%|██████████| 1/1 [00:00<00:00, 451.19it/s]\n",
      "                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/elson/.cache/huggingface/datasets/csv/default-b1cea7a0edcc1ad9/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 167.50it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 20.41ba/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 20.08ba/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 27.72ba/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset from the CSV file\n",
    "dataset = load_dataset(\n",
    "    'csv',\n",
    "    data_files='dataset_semanticattribution_nerfeatures_split.csv',\n",
    "    delimiter=',',\n",
    "    column_names=[\n",
    "        \"claim\", \"premise\", \"label\", \"category\", \"count_bf\", \"count_ca\", \"count_dis\",\n",
    "        \"count_food\", \"count_lipid\", \"count_treat\", \"pres_bf\", \"pres_ca\", \"pres_dis\",\n",
    "        \"pres_food\", \"pres_lipid\", \"pres_treat\", \"counte_bf\", \"counte_ca\", \"counte_dis\",\n",
    "        \"counte_food\", \"counte_lipid\", \"counte_treat\", \"prese_bf\", \"prese_ca\", \"prese_dis\",\n",
    "        \"prese_food\", \"prese_lipid\", \"prese_treat\", \"url\", \"entities\", \"entity_map\",\n",
    "        \"gold_exp\", \"gemini_exp\", \"gemini_label\",\"entity_map_ev\",\"entity_ev\",\"split\"\n",
    "    ],\n",
    "    skiprows=1\n",
    ")\n",
    "\n",
    "\n",
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'gold_exp', 'gemini_exp', 'gemini_label', 'entity_map_ev', 'entity_ev', 'split'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'gold_exp', 'gemini_exp', 'gemini_label', 'entity_map_ev', 'entity_ev', 'split'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'gold_exp', 'gemini_exp', 'gemini_label', 'entity_map_ev', 'entity_ev', 'split'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41f1db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\"claim\", \"premise\", \"label\",\"category\"]\n",
    "all_columns = dataset[\"train\"].column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1623/1623 [00:00<00:00, 10416.76ex/s]\n",
      "100%|██████████| 465/465 [00:00<00:00, 9707.20ex/s]\n",
      "100%|██████████| 234/234 [00:00<00:00, 11596.33ex/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 0, 'entailment': 1, 'neutral': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 0,\n",
    "    \"entailment\": 1,\n",
    "    \"neutral\": 2\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='pritamdeka/PubMedBERT-MNLI-MedNLI'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "        # Extracting claim and evidence texts\n",
    "\n",
    "        claim = item['claim']\n",
    "        premise = item['premise'].replace('\\n', '').replace('[','').replace(']','')\n",
    "        item['claim']=claim\n",
    "        item['premise']=premise\n",
    "        \n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "            premise, claim,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "        item['input_ids'] = inputs['input_ids'].squeeze()  # Remove batch dimension\n",
    "        item['attention_mask']= inputs['attention_mask'].squeeze() # Remove batch dimension\n",
    "        \n",
    "        if 'label' in item:\n",
    "            item['labels'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62421eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"pritamdeka/PubMedBERT-MNLI-MedNLI\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=3, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    bal_accuracy = balanced_accuracy_score(labels,preds)\n",
    "\n",
    "    return {\"accuracy\": acc, \"balanced_accuracy\":bal_accuracy, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17c5e0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'claim': 'Myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.',\n",
       " 'premise': '; UnkoviÄ‡, N.; DimkiÄ‡, I.; JanaÄ‡koviÄ‡, P.; GavriloviÄ‡, M.; StanojeviÄ‡, O.; VukojeviÄ‡, J. Frankincense and myrrh essential oils and burn incense fume against micro-inhabitants of sacral ambients.Shameem, I. Phytochemical & therapeutic potentials of Murr makki (.Oxidative stress and immunotoxic effects of lead and their amelioration with myrrh (Commiphora molmol) emulsion.Essential Oils: Magical Ingredients for Skin Care.Chakravarty, N.; Kellogg, C.; Alvarez, J.; Equils, O.; Morgan, M. UV Protection by Natural Products: C. myrrha Oil Versus Sunscreen.Hamidpour, R.; Hamidpour, S.; Hamidpour, M.; Shahlari, M. Frankincense (ä¹³é¦™ RÇ” XiÄ\\x81ng;.species): From the selection of traditional applications to the novel phytotherapy for the prevention and treatment of serious diseases.Chemistry and immunomodulatory activity of frankincense oil.Compositions containing Boswellia extracts.; Cooper, E. Frankincense and myrrh as remedies in children.',\n",
       " 'label': 1,\n",
       " 'category': 'General Health',\n",
       " 'input_ids': tensor([    2,    31,  2067, 29949,  2126,   240,    16,    56,    18,    31,\n",
       "          3363,  7369,  1019,   240,    16,    51,    18,    31,  7626,  5025,\n",
       "           240,  6235,  2165,  1019,   240,    16,    58,    18,    31,  4357,\n",
       "         23663,  1970, 25210,  1019,   240,    16,    55,    18,    31, 17725,\n",
       "          1037, 12518,  2165,  1019,   240,    16,    57,    18,    31, 28193,\n",
       "          8323, 12518,  2165,  1019,   240,    16,    52,    18, 14542,  4006,\n",
       "          4480,  1930, 14227,  5004,  4415, 16984,  1930, 10659,  2043,  4480,\n",
       "         13203,  1021,  3316,  2703,    17, 22248,  1927, 27041, 11638,  1036,\n",
       "            18,  8236,  5182,  1035,    16,    51,    18, 22719,    10,  4272,\n",
       "          9322,  1927, 26503,  4340,  7369,    12,    18,  5163,  3071,  1930,\n",
       "          6595,  4575, 18068,  1030,  2564,  1927,  2949,  1930,  2310, 11963,\n",
       "          1943,  1956, 14227,  5004,    12,  2689,  6285,  8846,  2629, 12492,\n",
       "          1024,    13, 19490,    18,  4415, 16984,    30,  9624,  2046, 18056,\n",
       "          1958,  4407,  2859,    18, 13297, 21783, 15777,  7446,  1012,    16,\n",
       "            56,    18,    31, 16080, 22284,  1029,    16,    45,    18,    31,\n",
       "         28374, 29834,    16,    52,    18,    31,  3009,  5002,    16,    57,\n",
       "            18,    31, 28098,    16,    55,    18,  5819,  6202,  2007,  4613,\n",
       "          4461,    30,    45,    18, 14227,  5004,  1019,  6691,  4072,  8147,\n",
       "         12709, 16527,    18,  8616,  1960,  7056,  1949,    16,    60,    18,\n",
       "            31,  8616,  1960,  7056,  1949,    16,    61,    18,    31,  8616,\n",
       "          1960,  7056,  1949,    16,    55,    18,    31, 26043,  5148,  3027,\n",
       "            16,    55,    18, 14542,  4006,  4480,    12,    43,  1574,  1216,\n",
       "          1021,  1793,  1062,  7399,   237, 27645,  2029,    31,    18,  3038,\n",
       "            13,    30,  2037,  1920,  4367,  1927,  6378,  5990,  1942,  1920,\n",
       "          4008, 25512, 20512,  1958,  1920,  5455,  1930,  2311,  1927,  7433,\n",
       "          3902,    18, 10021,  1930, 18659,  2455,  1927, 14542,  4006,  4480,\n",
       "          6691,    18, 15926,  3165, 16159, 11324,  2126,  6391,    18,    31,\n",
       "          9108,    16,    47,    18, 14542,  4006,  4480,  1930, 14227,  5004,\n",
       "          1966, 17186,  2062,  1922,  3069,    18,     3, 14227,  5004,  4415,\n",
       "          6691,  1977,  8929,  2251,  1922,  4407,  5715,  4461,  1942,  4087,\n",
       "          3326,  1920,  7818,  1927,  1920,  4407,    18,     3,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'labels': tensor(1)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 765\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='765' max='765' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [765/765 06:21, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.753900</td>\n",
       "      <td>0.871016</td>\n",
       "      <td>0.604301</td>\n",
       "      <td>0.537560</td>\n",
       "      <td>0.680174</td>\n",
       "      <td>0.604301</td>\n",
       "      <td>0.629845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.483200</td>\n",
       "      <td>0.965383</td>\n",
       "      <td>0.593548</td>\n",
       "      <td>0.466975</td>\n",
       "      <td>0.644567</td>\n",
       "      <td>0.593548</td>\n",
       "      <td>0.614737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.329100</td>\n",
       "      <td>1.059515</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.487657</td>\n",
       "      <td>0.651237</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.646894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.129400</td>\n",
       "      <td>1.540779</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.519702</td>\n",
       "      <td>0.675307</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.636180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.129800</td>\n",
       "      <td>2.046958</td>\n",
       "      <td>0.576344</td>\n",
       "      <td>0.483517</td>\n",
       "      <td>0.645974</td>\n",
       "      <td>0.576344</td>\n",
       "      <td>0.602988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.130600</td>\n",
       "      <td>1.952627</td>\n",
       "      <td>0.595699</td>\n",
       "      <td>0.525006</td>\n",
       "      <td>0.670819</td>\n",
       "      <td>0.595699</td>\n",
       "      <td>0.622083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.058700</td>\n",
       "      <td>1.893109</td>\n",
       "      <td>0.679570</td>\n",
       "      <td>0.584198</td>\n",
       "      <td>0.698991</td>\n",
       "      <td>0.679570</td>\n",
       "      <td>0.687592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.020100</td>\n",
       "      <td>2.371002</td>\n",
       "      <td>0.660215</td>\n",
       "      <td>0.569477</td>\n",
       "      <td>0.686938</td>\n",
       "      <td>0.660215</td>\n",
       "      <td>0.671083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.042600</td>\n",
       "      <td>2.319974</td>\n",
       "      <td>0.670968</td>\n",
       "      <td>0.546555</td>\n",
       "      <td>0.678932</td>\n",
       "      <td>0.670968</td>\n",
       "      <td>0.669930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.056800</td>\n",
       "      <td>2.547691</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.549009</td>\n",
       "      <td>0.690374</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.661878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>2.632284</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.557331</td>\n",
       "      <td>0.689172</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.657167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>2.475562</td>\n",
       "      <td>0.681720</td>\n",
       "      <td>0.576986</td>\n",
       "      <td>0.698384</td>\n",
       "      <td>0.681720</td>\n",
       "      <td>0.687657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>2.623396</td>\n",
       "      <td>0.658065</td>\n",
       "      <td>0.565981</td>\n",
       "      <td>0.693082</td>\n",
       "      <td>0.658065</td>\n",
       "      <td>0.672271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>2.561165</td>\n",
       "      <td>0.664516</td>\n",
       "      <td>0.550914</td>\n",
       "      <td>0.681028</td>\n",
       "      <td>0.664516</td>\n",
       "      <td>0.671130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>2.608141</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.548104</td>\n",
       "      <td>0.682549</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.666849</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.1_pubmedbert/checkpoint-51\n",
      "Configuration saved in /home/elson/1.2.1_pubmedbert/checkpoint-51/config.json\n",
      "Model weights saved in /home/elson/1.2.1_pubmedbert/checkpoint-51/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.1_pubmedbert/checkpoint-102\n",
      "Configuration saved in /home/elson/1.2.1_pubmedbert/checkpoint-102/config.json\n",
      "Model weights saved in /home/elson/1.2.1_pubmedbert/checkpoint-102/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.1_pubmedbert/checkpoint-153\n",
      "Configuration saved in /home/elson/1.2.1_pubmedbert/checkpoint-153/config.json\n",
      "Model weights saved in /home/elson/1.2.1_pubmedbert/checkpoint-153/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.2.1_pubmedbert/checkpoint-51] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/1.2.1_pubmedbert/checkpoint-102] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.1_pubmedbert/checkpoint-204\n",
      "Configuration saved in /home/elson/1.2.1_pubmedbert/checkpoint-204/config.json\n",
      "Model weights saved in /home/elson/1.2.1_pubmedbert/checkpoint-204/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.1_pubmedbert/checkpoint-255\n",
      "Configuration saved in /home/elson/1.2.1_pubmedbert/checkpoint-255/config.json\n",
      "Model weights saved in /home/elson/1.2.1_pubmedbert/checkpoint-255/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.2.1_pubmedbert/checkpoint-204] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.1_pubmedbert/checkpoint-306\n",
      "Configuration saved in /home/elson/1.2.1_pubmedbert/checkpoint-306/config.json\n",
      "Model weights saved in /home/elson/1.2.1_pubmedbert/checkpoint-306/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.2.1_pubmedbert/checkpoint-255] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.1_pubmedbert/checkpoint-357\n",
      "Configuration saved in /home/elson/1.2.1_pubmedbert/checkpoint-357/config.json\n",
      "Model weights saved in /home/elson/1.2.1_pubmedbert/checkpoint-357/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.2.1_pubmedbert/checkpoint-153] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/1.2.1_pubmedbert/checkpoint-306] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.1_pubmedbert/checkpoint-408\n",
      "Configuration saved in /home/elson/1.2.1_pubmedbert/checkpoint-408/config.json\n",
      "Model weights saved in /home/elson/1.2.1_pubmedbert/checkpoint-408/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.1_pubmedbert/checkpoint-459\n",
      "Configuration saved in /home/elson/1.2.1_pubmedbert/checkpoint-459/config.json\n",
      "Model weights saved in /home/elson/1.2.1_pubmedbert/checkpoint-459/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.2.1_pubmedbert/checkpoint-408] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.1_pubmedbert/checkpoint-510\n",
      "Configuration saved in /home/elson/1.2.1_pubmedbert/checkpoint-510/config.json\n",
      "Model weights saved in /home/elson/1.2.1_pubmedbert/checkpoint-510/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.2.1_pubmedbert/checkpoint-459] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.1_pubmedbert/checkpoint-561\n",
      "Configuration saved in /home/elson/1.2.1_pubmedbert/checkpoint-561/config.json\n",
      "Model weights saved in /home/elson/1.2.1_pubmedbert/checkpoint-561/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.2.1_pubmedbert/checkpoint-510] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.1_pubmedbert/checkpoint-612\n",
      "Configuration saved in /home/elson/1.2.1_pubmedbert/checkpoint-612/config.json\n",
      "Model weights saved in /home/elson/1.2.1_pubmedbert/checkpoint-612/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.2.1_pubmedbert/checkpoint-357] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/1.2.1_pubmedbert/checkpoint-561] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.1_pubmedbert/checkpoint-663\n",
      "Configuration saved in /home/elson/1.2.1_pubmedbert/checkpoint-663/config.json\n",
      "Model weights saved in /home/elson/1.2.1_pubmedbert/checkpoint-663/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.1_pubmedbert/checkpoint-714\n",
      "Configuration saved in /home/elson/1.2.1_pubmedbert/checkpoint-714/config.json\n",
      "Model weights saved in /home/elson/1.2.1_pubmedbert/checkpoint-714/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.2.1_pubmedbert/checkpoint-663] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.1_pubmedbert/checkpoint-765\n",
      "Configuration saved in /home/elson/1.2.1_pubmedbert/checkpoint-765/config.json\n",
      "Model weights saved in /home/elson/1.2.1_pubmedbert/checkpoint-765/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.2.1_pubmedbert/checkpoint-714] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/elson/1.2.1_pubmedbert/checkpoint-612 (score: 0.6817204301075269).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /home/elson/1.2.1_pubmedbert/best_model/config.json\n",
      "Model weights saved in /home/elson/1.2.1_pubmedbert/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/1.2.1_pubmedbert/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/1.2.1_pubmedbert/best_model/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/1.2.1_pubmedbert/best_model/tokenizer_config.json',\n",
       " '/home/elson/1.2.1_pubmedbert/best_model/special_tokens_map.json',\n",
       " '/home/elson/1.2.1_pubmedbert/best_model/vocab.txt',\n",
       " '/home/elson/1.2.1_pubmedbert/best_model/added_tokens.json',\n",
       " '/home/elson/1.2.1_pubmedbert/best_model/tokenizer.json')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/1.2.1_pubmedbert/',\n",
    "    num_train_epochs=15,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.06,\n",
    "    weight_decay=0.1,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/1.2.1_pubmedbert/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/1.2.1_pubmedbert/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63deaea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/1.2.1_pubmedbert/best_model/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"/home/elson/1.2.1_pubmedbert/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"contradiction\",\n",
      "    \"1\": \"entailment\",\n",
      "    \"2\": \"neutral\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"contradiction\": 0,\n",
      "    \"entailment\": 1,\n",
      "    \"neutral\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file /home/elson/1.2.1_pubmedbert/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at /home/elson/1.2.1_pubmedbert/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 32\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/1.2.1_pubmedbert/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[ 2.7852e+00,  7.2656e-01, -3.6562e+00],\n",
      "       [-4.1055e+00,  6.5312e+00, -3.7188e+00],\n",
      "       [-4.0391e+00,  6.6250e+00, -3.8789e+00],\n",
      "       [ 5.9805e+00, -1.0557e+00, -3.9434e+00],\n",
      "       [-1.5986e+00,  5.7578e+00, -5.0273e+00],\n",
      "       [-3.7363e+00,  6.5234e+00, -3.9941e+00],\n",
      "       [-3.9766e+00,  6.6992e+00, -3.8242e+00],\n",
      "       [-4.4766e+00,  6.2617e+00, -2.9785e+00],\n",
      "       [-4.4336e+00,  6.4883e+00, -3.3711e+00],\n",
      "       [-3.7578e+00,  6.4336e+00, -3.8789e+00],\n",
      "       [-3.2461e+00,  6.3281e+00, -4.3008e+00],\n",
      "       [-3.5820e+00,  6.6445e+00, -4.1094e+00],\n",
      "       [-3.7285e+00,  6.5156e+00, -3.9922e+00],\n",
      "       [-3.5059e+00,  6.4727e+00, -4.1445e+00],\n",
      "       [-5.4609e+00,  3.3848e+00,  1.1592e+00],\n",
      "       [ 6.6797e+00, -2.6367e+00, -3.0195e+00],\n",
      "       [-4.0195e+00,  6.6641e+00, -3.9336e+00],\n",
      "       [-3.9297e+00,  6.6445e+00, -3.9805e+00],\n",
      "       [-3.3613e+00,  6.6484e+00, -4.2422e+00],\n",
      "       [-3.9102e+00,  6.6836e+00, -3.9922e+00],\n",
      "       [-3.8574e+00,  6.5156e+00, -4.0000e+00],\n",
      "       [-5.1641e+00,  3.8398e+00, -1.0095e-01],\n",
      "       [-4.3438e+00,  4.6914e+00, -1.4785e+00],\n",
      "       [ 1.8818e+00, -4.3945e+00,  3.1973e+00],\n",
      "       [-2.0059e+00,  5.5625e+00, -4.6914e+00],\n",
      "       [-2.3398e+00, -2.7266e+00,  4.9922e+00],\n",
      "       [-3.2012e+00,  6.6172e+00, -4.3945e+00],\n",
      "       [-3.8281e+00,  6.6484e+00, -4.0078e+00],\n",
      "       [-3.7812e+00,  6.3516e+00, -3.7949e+00],\n",
      "       [-3.2090e+00,  6.6211e+00, -4.4492e+00],\n",
      "       [-3.2832e+00,  2.5410e+00,  1.4771e-01],\n",
      "       [-3.7188e+00,  6.6758e+00, -4.1055e+00],\n",
      "       [-3.4023e+00,  6.5977e+00, -4.3359e+00],\n",
      "       [-3.2031e+00,  3.7383e+00, -1.0488e+00],\n",
      "       [-4.5547e+00,  6.1836e+00, -2.8203e+00],\n",
      "       [-4.0195e+00,  6.6641e+00, -3.9355e+00],\n",
      "       [-4.0352e+00,  6.2227e+00, -3.4844e+00],\n",
      "       [-3.0547e+00,  6.4648e+00, -4.3320e+00],\n",
      "       [ 6.6172e+00, -1.8896e+00, -3.5879e+00],\n",
      "       [-3.6699e+00,  6.6719e+00, -4.2148e+00],\n",
      "       [-4.3848e-01, -1.7734e+00,  1.8623e+00],\n",
      "       [-3.8828e+00,  6.6836e+00, -3.9570e+00],\n",
      "       [-3.6270e+00,  6.5312e+00, -4.0195e+00],\n",
      "       [ 6.0312e+00, -2.8027e+00, -2.0430e+00],\n",
      "       [-1.9990e+00, -1.7451e+00,  3.4844e+00],\n",
      "       [-3.6602e+00,  6.6445e+00, -4.1133e+00],\n",
      "       [-1.0986e+00,  5.6641e+00, -5.4102e+00],\n",
      "       [-3.3418e+00,  6.5391e+00, -4.4336e+00],\n",
      "       [-3.3008e+00,  6.5742e+00, -4.4570e+00],\n",
      "       [ 6.5078e+00, -2.9297e+00, -2.1445e+00],\n",
      "       [-2.3145e+00,  3.7617e+00, -2.5938e+00],\n",
      "       [-4.7578e+00,  4.2891e+00, -1.4868e-01],\n",
      "       [ 2.7075e-01, -9.1675e-02,  1.5576e-01],\n",
      "       [-3.6582e+00,  6.6836e+00, -4.1484e+00],\n",
      "       [-1.4785e+00,  1.7061e+00, -5.6592e-01],\n",
      "       [-3.3203e+00,  6.6641e+00, -4.3750e+00],\n",
      "       [-2.1016e+00, -1.8877e+00,  4.2109e+00],\n",
      "       [-3.4902e+00, -2.7637e+00,  5.7539e+00],\n",
      "       [-3.0605e+00,  5.3984e+00, -3.5762e+00],\n",
      "       [-3.4531e+00,  6.6367e+00, -4.2852e+00],\n",
      "       [-3.2891e+00,  6.6016e+00, -4.4258e+00],\n",
      "       [ 6.6016e+00, -2.5840e+00, -2.7012e+00],\n",
      "       [-5.3867e+00,  3.1113e+00,  1.6025e+00],\n",
      "       [-1.5967e+00,  5.8711e+00, -5.2852e+00],\n",
      "       [-4.6328e+00,  4.4141e+00, -8.1934e-01],\n",
      "       [-3.0938e+00,  6.4375e+00, -4.4453e+00],\n",
      "       [-3.3340e+00,  6.5859e+00, -4.3477e+00],\n",
      "       [-3.1191e+00,  6.6250e+00, -4.4219e+00],\n",
      "       [-3.6543e+00,  6.6875e+00, -4.1367e+00],\n",
      "       [ 5.9023e+00, -1.5918e+00, -3.3379e+00],\n",
      "       [-3.3926e+00,  6.0156e+00, -3.7637e+00],\n",
      "       [-4.2031e+00,  6.5859e+00, -3.6777e+00],\n",
      "       [-4.8320e+00,  5.8516e+00, -2.5234e+00],\n",
      "       [-6.7285e-01,  3.9199e+00, -3.8633e+00],\n",
      "       [-5.4531e+00,  2.0430e+00,  2.4707e+00],\n",
      "       [-3.6641e+00,  6.5859e+00, -4.1289e+00],\n",
      "       [-4.0078e+00,  6.5234e+00, -3.6504e+00],\n",
      "       [-3.1797e+00,  6.4766e+00, -4.3750e+00],\n",
      "       [-3.3301e+00,  6.6328e+00, -4.3281e+00],\n",
      "       [-3.0957e+00,  6.0312e+00, -3.9844e+00],\n",
      "       [-3.4707e+00,  6.4531e+00, -4.1367e+00],\n",
      "       [-3.6191e+00,  6.6719e+00, -4.1719e+00],\n",
      "       [-3.9668e+00,  6.6211e+00, -3.9062e+00],\n",
      "       [-2.8867e+00,  6.5391e+00, -4.6211e+00],\n",
      "       [-3.8613e+00,  6.4805e+00, -3.7656e+00],\n",
      "       [-3.9062e+00,  5.2734e+00, -2.6797e+00],\n",
      "       [-3.4883e+00,  6.3867e+00, -3.8984e+00],\n",
      "       [-1.3438e+00,  5.7148e+00, -5.3984e+00],\n",
      "       [-2.4329e-01, -6.0791e-01, -2.7466e-03],\n",
      "       [-4.5352e+00,  6.3828e+00, -3.2695e+00],\n",
      "       [-3.8457e+00,  6.5625e+00, -4.0703e+00],\n",
      "       [-3.6855e+00,  6.6367e+00, -4.1406e+00],\n",
      "       [ 5.4102e+00, -4.0674e-01, -4.4180e+00],\n",
      "       [-3.6934e+00,  6.6562e+00, -4.1914e+00],\n",
      "       [-1.1738e+00,  5.4258e+00, -4.8789e+00],\n",
      "       [-3.9141e+00,  6.3398e+00, -3.7227e+00],\n",
      "       [-3.7949e+00,  5.6797e+00, -3.1973e+00],\n",
      "       [-3.2988e+00,  6.3555e+00, -4.2383e+00],\n",
      "       [-3.4609e+00,  6.6641e+00, -4.2305e+00],\n",
      "       [-3.5664e+00,  6.6484e+00, -4.2188e+00],\n",
      "       [ 6.5547e+00, -1.9053e+00, -3.5703e+00],\n",
      "       [-3.9199e+00,  6.6836e+00, -3.9082e+00],\n",
      "       [-3.3789e+00,  6.6016e+00, -4.2852e+00],\n",
      "       [-4.5195e+00,  2.2480e+00,  1.4746e+00],\n",
      "       [-3.8809e+00,  5.7852e+00, -3.1191e+00],\n",
      "       [-3.5742e+00,  6.6641e+00, -4.1719e+00],\n",
      "       [-2.6953e+00,  6.1094e+00, -4.6602e+00],\n",
      "       [-4.3320e+00,  5.9492e+00, -2.8066e+00],\n",
      "       [-2.9570e+00,  6.3945e+00, -4.5156e+00],\n",
      "       [-3.5137e+00,  6.6055e+00, -4.0195e+00],\n",
      "       [-3.5176e+00,  6.6680e+00, -4.2852e+00],\n",
      "       [-4.0586e+00,  6.3594e+00, -3.5117e+00],\n",
      "       [-3.9434e+00,  6.6680e+00, -3.9121e+00],\n",
      "       [-3.5293e+00,  6.5547e+00, -4.1406e+00],\n",
      "       [-3.6562e+00,  6.6445e+00, -4.1719e+00],\n",
      "       [-3.6914e+00,  6.5352e+00, -4.0234e+00],\n",
      "       [-3.6895e+00,  6.6641e+00, -4.1484e+00],\n",
      "       [-5.6328e+00,  3.3301e+00,  1.2764e+00],\n",
      "       [-3.1504e+00,  6.6055e+00, -4.5078e+00],\n",
      "       [-3.0000e+00,  6.4023e+00, -4.6055e+00],\n",
      "       [-4.7383e+00,  6.2148e+00, -2.7324e+00],\n",
      "       [-2.4922e+00,  5.0039e+00, -3.3066e+00],\n",
      "       [-5.0234e+00,  5.5742e+00, -1.9385e+00],\n",
      "       [-3.7559e+00,  6.4961e+00, -3.9766e+00],\n",
      "       [-3.5352e+00,  6.6719e+00, -4.2422e+00],\n",
      "       [-3.2559e+00,  6.6484e+00, -4.4023e+00],\n",
      "       [-2.8301e+00,  5.2695e+00, -3.3926e+00],\n",
      "       [-3.7539e+00,  6.6367e+00, -4.1641e+00],\n",
      "       [-5.0586e+00,  4.7305e+00, -1.0947e+00],\n",
      "       [-3.6094e+00,  6.6445e+00, -4.1523e+00],\n",
      "       [-4.3516e+00,  3.1113e+00,  4.5105e-02],\n",
      "       [ 5.6055e+00, -2.0332e+00, -2.3320e+00],\n",
      "       [-2.6973e+00,  6.2930e+00, -4.4023e+00],\n",
      "       [ 2.1035e+00,  1.3955e+00, -3.8066e+00],\n",
      "       [-3.7852e+00,  6.6133e+00, -3.9707e+00],\n",
      "       [-5.4258e+00,  4.9570e+00, -9.1406e-01],\n",
      "       [-3.5215e+00,  5.8945e+00, -3.5020e+00],\n",
      "       [ 6.6562e+00, -3.0449e+00, -2.4004e+00],\n",
      "       [ 5.7148e+00, -2.1621e+00, -2.7188e+00],\n",
      "       [-2.9473e+00, -3.4668e+00,  6.3047e+00],\n",
      "       [-3.8535e+00,  6.5859e+00, -3.9258e+00],\n",
      "       [-3.1738e+00, -4.9683e-01,  3.7695e+00],\n",
      "       [-4.6211e+00,  4.3789e+00, -7.3047e-01],\n",
      "       [-3.5879e+00,  6.6562e+00, -4.1562e+00],\n",
      "       [ 5.4922e+00, -4.8560e-01, -4.1016e+00],\n",
      "       [-5.2148e+00,  4.7227e+00, -8.2080e-01],\n",
      "       [ 2.3828e+00, -3.1758e+00,  1.5625e+00],\n",
      "       [ 5.5898e+00, -3.6035e-01, -4.4922e+00],\n",
      "       [-7.9248e-01,  4.9727e+00, -5.1523e+00],\n",
      "       [-3.9336e+00,  2.4727e+00,  6.1328e-01],\n",
      "       [-3.6738e+00,  6.5039e+00, -4.0078e+00],\n",
      "       [-2.7637e+00,  6.1055e+00, -4.5508e+00],\n",
      "       [-3.6660e+00,  6.6680e+00, -4.0938e+00],\n",
      "       [-3.7539e+00,  6.6094e+00, -4.0703e+00],\n",
      "       [-3.5078e+00,  6.5352e+00, -4.2656e+00],\n",
      "       [-3.7266e+00,  6.6797e+00, -4.0742e+00],\n",
      "       [-3.2344e+00,  6.5234e+00, -4.5039e+00],\n",
      "       [-3.8887e+00,  3.8359e+00, -1.2832e+00],\n",
      "       [-4.5664e+00,  6.2734e+00, -3.0762e+00],\n",
      "       [ 6.3125e+00, -3.1094e+00, -1.9912e+00],\n",
      "       [ 2.7402e+00, -3.5996e+00,  2.1348e+00],\n",
      "       [ 6.5742e+00, -1.9961e+00, -3.4883e+00],\n",
      "       [-4.3125e+00,  6.5781e+00, -3.5566e+00],\n",
      "       [ 3.5664e+00,  8.4961e-01, -4.2656e+00],\n",
      "       [-4.4414e+00,  5.8789e+00, -2.7754e+00],\n",
      "       [-4.3365e-02,  2.2598e+00, -2.8906e+00],\n",
      "       [-4.1055e+00,  6.0234e+00, -3.4121e+00],\n",
      "       [ 4.9297e+00, -1.6504e+00, -2.7754e+00],\n",
      "       [ 1.7031e+00,  1.1940e-02, -1.6641e+00],\n",
      "       [-4.2578e+00,  6.5234e+00, -3.5312e+00],\n",
      "       [ 1.2363e+00, -3.9473e+00,  3.8633e+00],\n",
      "       [-2.5742e+00,  5.6797e+00, -3.9141e+00],\n",
      "       [-3.9609e+00,  4.3516e+00, -1.5459e+00],\n",
      "       [-4.0859e+00,  6.6758e+00, -3.8359e+00],\n",
      "       [-3.2109e+00,  6.5312e+00, -4.4766e+00],\n",
      "       [-2.8398e+00, -2.2402e+00,  4.6719e+00],\n",
      "       [-3.3867e+00,  6.5977e+00, -4.2539e+00],\n",
      "       [ 5.8203e+00, -2.0762e+00, -2.7930e+00],\n",
      "       [-1.4707e+00,  6.0859e+00, -5.2461e+00],\n",
      "       [-1.6846e-02,  5.1133e+00, -5.7305e+00],\n",
      "       [ 5.6250e+00, -2.1152e+00, -2.5449e+00],\n",
      "       [-4.2852e+00,  6.0898e+00, -3.1484e+00],\n",
      "       [ 6.7031e+00, -2.2969e+00, -3.1895e+00],\n",
      "       [-3.3984e+00, -9.3652e-01,  3.6699e+00],\n",
      "       [-2.2773e+00, -6.5332e-01,  2.0527e+00],\n",
      "       [-3.4004e+00,  6.6875e+00, -4.2969e+00],\n",
      "       [-3.2676e+00,  6.3125e+00, -4.0625e+00],\n",
      "       [-3.7422e+00,  6.5117e+00, -3.9902e+00],\n",
      "       [-2.4062e+00,  6.2539e+00, -4.8945e+00],\n",
      "       [-3.8730e+00,  6.6836e+00, -3.9668e+00],\n",
      "       [-3.2129e+00,  6.2539e+00, -4.2773e+00],\n",
      "       [-3.7246e+00,  6.1328e+00, -3.7480e+00],\n",
      "       [-3.3262e+00,  6.5781e+00, -4.2891e+00],\n",
      "       [-3.3906e+00, -2.6016e+00,  5.7109e+00],\n",
      "       [ 6.6172e+00, -1.9297e+00, -3.5645e+00],\n",
      "       [-3.4336e+00,  6.6328e+00, -4.2812e+00],\n",
      "       [-3.8926e+00,  6.0352e+00, -3.6035e+00],\n",
      "       [-4.2695e+00,  6.5352e+00, -3.6172e+00],\n",
      "       [-2.3770e+00,  5.8359e+00, -4.6055e+00],\n",
      "       [-4.4961e+00,  6.2344e+00, -3.2129e+00],\n",
      "       [-3.6738e+00,  6.6758e+00, -4.1406e+00],\n",
      "       [-3.8164e+00,  6.5664e+00, -3.9336e+00],\n",
      "       [-7.5928e-01,  6.6309e-01, -2.6367e-01],\n",
      "       [-4.1562e+00,  6.6367e+00, -3.7031e+00],\n",
      "       [-3.9062e+00,  6.6367e+00, -3.8652e+00],\n",
      "       [-2.1172e+00,  2.6543e+00, -1.3652e+00],\n",
      "       [-3.4707e+00,  6.6367e+00, -4.2422e+00],\n",
      "       [-3.0859e-01, -1.4033e+00,  2.0332e+00],\n",
      "       [-3.5273e+00,  6.6250e+00, -4.2656e+00],\n",
      "       [-3.6660e+00,  6.4883e+00, -3.9941e+00],\n",
      "       [-4.0938e+00,  6.6680e+00, -3.8164e+00],\n",
      "       [-5.4375e+00,  3.3008e+00,  1.4658e+00],\n",
      "       [-3.2812e+00,  6.6406e+00, -4.4297e+00],\n",
      "       [-3.5078e+00, -1.0205e-01,  3.0820e+00],\n",
      "       [-3.8066e+00,  6.3750e+00, -3.6230e+00],\n",
      "       [ 4.1445e+00, -4.4180e+00,  1.5938e+00],\n",
      "       [ 4.2852e+00, -2.8027e+00, -6.2842e-01],\n",
      "       [-3.9297e+00,  6.5820e+00, -3.8750e+00],\n",
      "       [-3.3633e+00,  6.6523e+00, -4.3164e+00],\n",
      "       [-3.9297e+00,  6.5273e+00, -3.7773e+00],\n",
      "       [-3.2402e+00,  6.6172e+00, -4.3945e+00],\n",
      "       [-3.4824e+00,  6.6094e+00, -4.1758e+00],\n",
      "       [-3.6426e+00,  6.5547e+00, -4.0625e+00],\n",
      "       [-3.1328e+00,  6.6016e+00, -4.4766e+00],\n",
      "       [-2.6914e+00,  6.4453e+00, -4.6719e+00],\n",
      "       [-3.9082e+00,  6.5117e+00, -3.7832e+00],\n",
      "       [-2.9473e+00,  6.5586e+00, -4.4570e+00],\n",
      "       [-1.1006e+00, -3.9590e+00,  5.4609e+00],\n",
      "       [ 9.7070e-01, -4.7388e-01, -4.6875e-01],\n",
      "       [ 7.4170e-01, -3.4746e+00,  3.4199e+00],\n",
      "       [-3.4297e+00,  6.6250e+00, -4.3125e+00],\n",
      "       [-5.1250e+00,  4.5938e+00, -6.6211e-01],\n",
      "       [-2.5098e+00,  6.4102e+00, -4.7734e+00],\n",
      "       [ 6.6211e+00, -2.4180e+00, -3.0449e+00]], dtype=float16), label_ids=array([1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 2, 2, 1, 2, 1, 1, 2, 2,\n",
      "       1, 2, 0, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 0, 2, 1, 1,\n",
      "       1, 2, 1, 1, 1, 0, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 0, 2, 1, 2, 0,\n",
      "       1, 1, 0, 0, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       0, 2, 1, 2, 0, 1, 1, 1, 1, 1, 1, 2, 0, 2, 1, 2, 1, 1, 1, 2, 1, 1,\n",
      "       2, 1, 2, 1, 2, 1, 1, 1, 0, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 2, 1, 2, 1, 1, 1, 2, 0, 2, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2,\n",
      "       1, 1, 1, 2, 1, 0, 0, 0, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1,\n",
      "       1, 0, 1, 1, 1, 1, 0, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 0, 2, 1, 1, 1,\n",
      "       1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 0, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 0]), metrics={'test_loss': 2.4305813312530518, 'test_accuracy': 0.6794871794871795, 'test_balanced_accuracy': 0.5405907544143062, 'test_precision': 0.6355187953683424, 'test_recall': 0.6794871794871795, 'test_f1': 0.6374411432106507, 'test_runtime': 1.238, 'test_samples_per_second': 189.021, 'test_steps_per_second': 6.462})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1cd75bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "probabilities = torch.softmax(torch.tensor(test_results.predictions).to(torch.float32), dim=-1)\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)\n",
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "766c4460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_save = []\n",
    "for idx in range(len(test_data)):\n",
    "    item = dataset['test'][idx]\n",
    "    actual_label = item['label']\n",
    "    predicted_label = predictions[idx]\n",
    "    claim = item['claim'] \n",
    "    premise = item['premise'] \n",
    "    category = item['category']\n",
    "    \n",
    "    # Append the information as a dictionary to the list\n",
    "    data_to_save.append({\n",
    "        'Claim': claim,\n",
    "        'Premise': premise,\n",
    "        'Actual Label': actual_label,\n",
    "        'Predicted Label': predicted_label,\n",
    "        'Category' : category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_to_save)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/home/elson/results/1.2.1_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3e1cc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correctly classified instances\n",
    "correctly_classified = df[df['Actual Label'] == df['Predicted Label']]\n",
    "\n",
    "# Calculate misclassified instances\n",
    "misclassified = df[df['Actual Label'] != df['Predicted Label']]\n",
    "\n",
    "# Count the number of correctly classified and misclassified by category\n",
    "correct_classification_counts = correctly_classified['Category'].value_counts()\n",
    "misclassification_counts = misclassified['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "afd884e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           36\n",
       "Bone health              15\n",
       "Fitness                  14\n",
       "Cancer                   12\n",
       "Diabetes                 11\n",
       "Throat                    9\n",
       "Skin                      9\n",
       "Cardiovascular Health     9\n",
       "Neurological health       9\n",
       "Eye                       7\n",
       "Ear                       6\n",
       "Hair                      6\n",
       "Blood                     4\n",
       "Women' s Health           4\n",
       "Men's health              3\n",
       "COVID                     3\n",
       "Mental Health             2\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6477f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Skin                     15\n",
       "General Health           15\n",
       "Muscles                   6\n",
       "Hair                      6\n",
       "Bone health               6\n",
       "Blood                     5\n",
       "Cardiovascular Health     3\n",
       "Vascular                  3\n",
       "COVID                     3\n",
       "Men's health              3\n",
       "Dental Health             3\n",
       "Women' s Health           2\n",
       "Eye                       2\n",
       "Mental Health             1\n",
       "Diabetes                  1\n",
       "Fitness                   1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
