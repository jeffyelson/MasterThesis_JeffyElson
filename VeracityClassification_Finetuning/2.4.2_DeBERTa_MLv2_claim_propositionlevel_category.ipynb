{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-927ab0163adb9fdb\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-927ab0163adb9fdb/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 233.81it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('csv',data_files='dataset_propositionattribution_nerfeatures.csv',delimiter=',',column_names=[\"claim\",\"premise\",\"label\",\"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\",\"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\",\"url\", \"entities\",\"entity_map\",\"gem_exp\",\"gem_label\",\"gpt_label\",\"gpt_exp\",\"gold_exp\",\"entity_map_ev\",\"entity_ev\",\"split\"],skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "133f9357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-927ab0163adb9fdb/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-d013d5114fa105ab.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-927ab0163adb9fdb/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-16f9acbdd82fea07.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-927ab0163adb9fdb/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-47c7de469e4087a2.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01252e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\"claim\", \"premise\", \"label\",\"category\"]\n",
    "all_columns = dataset[\"train\"].column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-927ab0163adb9fdb/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-a0ade6057eafd020.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-927ab0163adb9fdb/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-c809019fdbb6b1ab.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-927ab0163adb9fdb/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-1b131fbcc3716578.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 0, 'entailment': 1, 'neutral': 2}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 0,\n",
    "    \"entailment\": 1,\n",
    "    \"neutral\": 2\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "        # Extracting claim and evidence texts\n",
    "\n",
    "        claim = item['claim'] + \"[SEP]\"+ item['category']\n",
    "        evidences = item['premise']\n",
    "        item['premise']=evidences\n",
    "        item['claim']=claim\n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "            evidences, claim,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "        item['input_ids'] = inputs['input_ids'].squeeze()  # Remove batch dimension\n",
    "        item['attention_mask']= inputs['attention_mask'].squeeze() # Remove batch dimension\n",
    "        \n",
    "        if 'label' in item:\n",
    "            item['labels'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62421eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DebertaV2ForSequenceClassification(\n",
       "  (deberta): DebertaV2Model(\n",
       "    (embeddings): DebertaV2Embeddings(\n",
       "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaV2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (1): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (2): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (3): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (4): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (5): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (6): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (7): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (8): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (9): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (10): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (11): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (pooler): ContextPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): StableDropout()\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (dropout): StableDropout()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=512)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=3, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    return {\"accuracy\": acc, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f5cf584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'claim': 'Myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.[SEP]General Health',\n",
       " 'premise': 'The essential oils of frankincense and myrrh increase the fluidity of the lipid bilayer in the cuticle and change the orderly and dense structure to increase the permeability of the skin and decrease the barrier effect.',\n",
       " 'label': 1,\n",
       " 'category': 'General Health',\n",
       " 'input_ids': tensor([    1,   279,  1830,  6725,   265, 88609,   263, 98237,   993,   262,\n",
       "         49462,   265,   262, 22003, 96579,   267,   262, 61462,   263,   575,\n",
       "           262, 26217,   263,  9854,  1730,   264,   993,   262, 39632,   265,\n",
       "           262,  1158,   263,  4843,   262,  7275,  1290,   260,     2,   573,\n",
       "         52341,  1830,  1080,   269,  1359,   427,   267, 17847,   633,   264,\n",
       "           408,  1300,   262,  2658,   265,   262,  1158,   260,     2,  1849,\n",
       "          1516,     2,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'labels': tensor(1)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2040\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2040' max='2040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2040/2040 52:13, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.791800</td>\n",
       "      <td>0.681700</td>\n",
       "      <td>0.707527</td>\n",
       "      <td>0.651809</td>\n",
       "      <td>0.707527</td>\n",
       "      <td>0.642358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.509900</td>\n",
       "      <td>0.978397</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.705016</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.661374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.257700</td>\n",
       "      <td>1.257769</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.685933</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.659249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.090800</td>\n",
       "      <td>1.755797</td>\n",
       "      <td>0.662366</td>\n",
       "      <td>0.680589</td>\n",
       "      <td>0.662366</td>\n",
       "      <td>0.669187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.038300</td>\n",
       "      <td>2.204754</td>\n",
       "      <td>0.692473</td>\n",
       "      <td>0.692169</td>\n",
       "      <td>0.692473</td>\n",
       "      <td>0.691999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>2.444238</td>\n",
       "      <td>0.688172</td>\n",
       "      <td>0.691022</td>\n",
       "      <td>0.688172</td>\n",
       "      <td>0.688596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.088300</td>\n",
       "      <td>2.704623</td>\n",
       "      <td>0.668817</td>\n",
       "      <td>0.699946</td>\n",
       "      <td>0.668817</td>\n",
       "      <td>0.682219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.792536</td>\n",
       "      <td>0.679570</td>\n",
       "      <td>0.712181</td>\n",
       "      <td>0.679570</td>\n",
       "      <td>0.692401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.812345</td>\n",
       "      <td>0.692473</td>\n",
       "      <td>0.719364</td>\n",
       "      <td>0.692473</td>\n",
       "      <td>0.703468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>2.891791</td>\n",
       "      <td>0.688172</td>\n",
       "      <td>0.717321</td>\n",
       "      <td>0.688172</td>\n",
       "      <td>0.699337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.958548</td>\n",
       "      <td>0.688172</td>\n",
       "      <td>0.709985</td>\n",
       "      <td>0.688172</td>\n",
       "      <td>0.697256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.104945</td>\n",
       "      <td>0.668817</td>\n",
       "      <td>0.703451</td>\n",
       "      <td>0.668817</td>\n",
       "      <td>0.682376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.070905</td>\n",
       "      <td>0.681720</td>\n",
       "      <td>0.704440</td>\n",
       "      <td>0.681720</td>\n",
       "      <td>0.690384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.085174</td>\n",
       "      <td>0.686022</td>\n",
       "      <td>0.705904</td>\n",
       "      <td>0.686022</td>\n",
       "      <td>0.693782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.013089</td>\n",
       "      <td>0.696774</td>\n",
       "      <td>0.708457</td>\n",
       "      <td>0.696774</td>\n",
       "      <td>0.701051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.034427</td>\n",
       "      <td>0.696774</td>\n",
       "      <td>0.711425</td>\n",
       "      <td>0.696774</td>\n",
       "      <td>0.702192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.054987</td>\n",
       "      <td>0.696774</td>\n",
       "      <td>0.711425</td>\n",
       "      <td>0.696774</td>\n",
       "      <td>0.702192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.068758</td>\n",
       "      <td>0.696774</td>\n",
       "      <td>0.712467</td>\n",
       "      <td>0.696774</td>\n",
       "      <td>0.702557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.079171</td>\n",
       "      <td>0.696774</td>\n",
       "      <td>0.712467</td>\n",
       "      <td>0.696774</td>\n",
       "      <td>0.702557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.126797</td>\n",
       "      <td>0.694624</td>\n",
       "      <td>0.713117</td>\n",
       "      <td>0.694624</td>\n",
       "      <td>0.701401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.4.2_deberta/checkpoint-102\n",
      "Configuration saved in /home/elson/2.4.2_deberta/checkpoint-102/config.json\n",
      "Model weights saved in /home/elson/2.4.2_deberta/checkpoint-102/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.4.2_deberta/checkpoint-204\n",
      "Configuration saved in /home/elson/2.4.2_deberta/checkpoint-204/config.json\n",
      "Model weights saved in /home/elson/2.4.2_deberta/checkpoint-204/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.4.2_deberta/checkpoint-306\n",
      "Configuration saved in /home/elson/2.4.2_deberta/checkpoint-306/config.json\n",
      "Model weights saved in /home/elson/2.4.2_deberta/checkpoint-306/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.4.2_deberta/checkpoint-204] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.4.2_deberta/checkpoint-408\n",
      "Configuration saved in /home/elson/2.4.2_deberta/checkpoint-408/config.json\n",
      "Model weights saved in /home/elson/2.4.2_deberta/checkpoint-408/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.4.2_deberta/checkpoint-306] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.4.2_deberta/checkpoint-510\n",
      "Configuration saved in /home/elson/2.4.2_deberta/checkpoint-510/config.json\n",
      "Model weights saved in /home/elson/2.4.2_deberta/checkpoint-510/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.4.2_deberta/checkpoint-408] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.4.2_deberta/checkpoint-612\n",
      "Configuration saved in /home/elson/2.4.2_deberta/checkpoint-612/config.json\n",
      "Model weights saved in /home/elson/2.4.2_deberta/checkpoint-612/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.4.2_deberta/checkpoint-510] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.4.2_deberta/checkpoint-714\n",
      "Configuration saved in /home/elson/2.4.2_deberta/checkpoint-714/config.json\n",
      "Model weights saved in /home/elson/2.4.2_deberta/checkpoint-714/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.4.2_deberta/checkpoint-612] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.4.2_deberta/checkpoint-816\n",
      "Configuration saved in /home/elson/2.4.2_deberta/checkpoint-816/config.json\n",
      "Model weights saved in /home/elson/2.4.2_deberta/checkpoint-816/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.4.2_deberta/checkpoint-714] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.4.2_deberta/checkpoint-918\n",
      "Configuration saved in /home/elson/2.4.2_deberta/checkpoint-918/config.json\n",
      "Model weights saved in /home/elson/2.4.2_deberta/checkpoint-918/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.4.2_deberta/checkpoint-816] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.4.2_deberta/checkpoint-1020\n",
      "Configuration saved in /home/elson/2.4.2_deberta/checkpoint-1020/config.json\n",
      "Model weights saved in /home/elson/2.4.2_deberta/checkpoint-1020/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.4.2_deberta/checkpoint-918] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.4.2_deberta/checkpoint-1122\n",
      "Configuration saved in /home/elson/2.4.2_deberta/checkpoint-1122/config.json\n",
      "Model weights saved in /home/elson/2.4.2_deberta/checkpoint-1122/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.4.2_deberta/checkpoint-1020] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.4.2_deberta/checkpoint-1224\n",
      "Configuration saved in /home/elson/2.4.2_deberta/checkpoint-1224/config.json\n",
      "Model weights saved in /home/elson/2.4.2_deberta/checkpoint-1224/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.4.2_deberta/checkpoint-1122] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.4.2_deberta/checkpoint-1326\n",
      "Configuration saved in /home/elson/2.4.2_deberta/checkpoint-1326/config.json\n",
      "Model weights saved in /home/elson/2.4.2_deberta/checkpoint-1326/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.4.2_deberta/checkpoint-1224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.4.2_deberta/checkpoint-1428\n",
      "Configuration saved in /home/elson/2.4.2_deberta/checkpoint-1428/config.json\n",
      "Model weights saved in /home/elson/2.4.2_deberta/checkpoint-1428/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.4.2_deberta/checkpoint-1326] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.4.2_deberta/checkpoint-1530\n",
      "Configuration saved in /home/elson/2.4.2_deberta/checkpoint-1530/config.json\n",
      "Model weights saved in /home/elson/2.4.2_deberta/checkpoint-1530/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.4.2_deberta/checkpoint-1428] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.4.2_deberta/checkpoint-1632\n",
      "Configuration saved in /home/elson/2.4.2_deberta/checkpoint-1632/config.json\n",
      "Model weights saved in /home/elson/2.4.2_deberta/checkpoint-1632/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.4.2_deberta/checkpoint-1530] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.4.2_deberta/checkpoint-1734\n",
      "Configuration saved in /home/elson/2.4.2_deberta/checkpoint-1734/config.json\n",
      "Model weights saved in /home/elson/2.4.2_deberta/checkpoint-1734/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.4.2_deberta/checkpoint-1632] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.4.2_deberta/checkpoint-1836\n",
      "Configuration saved in /home/elson/2.4.2_deberta/checkpoint-1836/config.json\n",
      "Model weights saved in /home/elson/2.4.2_deberta/checkpoint-1836/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.4.2_deberta/checkpoint-1734] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.4.2_deberta/checkpoint-1938\n",
      "Configuration saved in /home/elson/2.4.2_deberta/checkpoint-1938/config.json\n",
      "Model weights saved in /home/elson/2.4.2_deberta/checkpoint-1938/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.4.2_deberta/checkpoint-1836] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.4.2_deberta/checkpoint-2040\n",
      "Configuration saved in /home/elson/2.4.2_deberta/checkpoint-2040/config.json\n",
      "Model weights saved in /home/elson/2.4.2_deberta/checkpoint-2040/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.4.2_deberta/checkpoint-1938] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/elson/2.4.2_deberta/checkpoint-102 (score: 0.7075268817204301).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /home/elson/2.4.2_deberta/best_model/config.json\n",
      "Model weights saved in /home/elson/2.4.2_deberta/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/2.4.2_deberta/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/2.4.2_deberta/best_model/special_tokens_map.json\n",
      "added tokens file saved in /home/elson/2.4.2_deberta/best_model/added_tokens.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/2.4.2_deberta/best_model/tokenizer_config.json',\n",
       " '/home/elson/2.4.2_deberta/best_model/special_tokens_map.json',\n",
       " '/home/elson/2.4.2_deberta/best_model/spm.model',\n",
       " '/home/elson/2.4.2_deberta/best_model/added_tokens.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/2.4.2_deberta/',\n",
    "    num_train_epochs=20,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.06,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/2.4.2_deberta/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/2.4.2_deberta/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63deaea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/2.4.2_deberta/best_model/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"/home/elson/2.4.2_deberta/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"entailment\",\n",
      "    \"1\": \"neutral\",\n",
      "    \"2\": \"contradiction\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"contradiction\": 2,\n",
      "    \"entailment\": 0,\n",
      "    \"neutral\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file /home/elson/2.4.2_deberta/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at /home/elson/2.4.2_deberta/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 16\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/2.4.2_deberta/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[-1.8225e-01,  1.5371e+00, -1.7002e+00],\n",
      "       [-2.8784e-01,  1.5820e+00, -1.7002e+00],\n",
      "       [-5.6592e-01,  2.6172e+00, -2.4688e+00],\n",
      "       [ 1.7426e-02,  1.2598e+00, -1.6514e+00],\n",
      "       [-8.3191e-02,  1.1602e+00, -1.4297e+00],\n",
      "       [-4.8828e-01,  2.0352e+00, -1.9365e+00],\n",
      "       [-1.8994e-01,  1.5918e+00, -1.8008e+00],\n",
      "       [-5.3564e-01,  1.7607e+00, -1.6348e+00],\n",
      "       [-9.7705e-01,  2.5039e+00, -1.9316e+00],\n",
      "       [-2.7008e-03,  1.2900e+00, -1.6963e+00],\n",
      "       [-3.0078e-01,  1.3398e+00, -1.3525e+00],\n",
      "       [-1.7346e-01,  1.5430e+00, -1.7773e+00],\n",
      "       [-3.6401e-01,  1.3730e+00, -1.3906e+00],\n",
      "       [-5.9229e-01,  2.0195e+00, -1.8340e+00],\n",
      "       [-2.0728e-01,  1.6016e+00, -1.8164e+00],\n",
      "       [-4.6997e-01,  1.7393e+00, -1.6885e+00],\n",
      "       [-5.8398e-01,  1.5566e+00, -1.3994e+00],\n",
      "       [-5.4834e-01,  1.9277e+00, -1.8340e+00],\n",
      "       [-6.2622e-02,  1.5303e+00, -1.8916e+00],\n",
      "       [-3.9136e-01,  2.1484e+00, -2.1719e+00],\n",
      "       [ 1.3574e-01,  5.8838e-01, -9.8633e-01],\n",
      "       [ 2.8824e-02,  1.1719e+00, -1.5654e+00],\n",
      "       [-2.9370e-01,  1.6934e+00, -1.8213e+00],\n",
      "       [-2.9541e-02,  8.0322e-01, -1.0801e+00],\n",
      "       [ 1.9678e-01,  1.0615e+00, -1.6123e+00],\n",
      "       [ 2.9346e-01, -3.2422e-01, -1.6833e-01],\n",
      "       [-2.1863e-01,  1.7402e+00, -1.9580e+00],\n",
      "       [-1.0132e-01,  1.3545e+00, -1.6748e+00],\n",
      "       [-6.4453e-01,  1.9033e+00, -1.6533e+00],\n",
      "       [-7.1143e-01,  1.9062e+00, -1.6152e+00],\n",
      "       [ 4.3604e-01,  3.5254e-01, -1.0459e+00],\n",
      "       [-2.3181e-01,  1.6709e+00, -1.8486e+00],\n",
      "       [-3.4033e-01,  1.2646e+00, -1.2910e+00],\n",
      "       [ 2.4695e-01,  1.0781e+00, -1.6162e+00],\n",
      "       [-1.5906e-01,  1.1553e+00, -1.3438e+00],\n",
      "       [-5.1807e-01,  1.3408e+00, -1.2041e+00],\n",
      "       [-1.7908e-01,  1.3662e+00, -1.5713e+00],\n",
      "       [-4.7974e-01,  2.0645e+00, -1.9883e+00],\n",
      "       [ 8.1201e-01,  4.8975e-01, -1.5996e+00],\n",
      "       [-5.4492e-01,  1.3740e+00, -1.2119e+00],\n",
      "       [-3.0688e-01,  1.7295e+00, -1.8525e+00],\n",
      "       [-6.9775e-01,  2.1191e+00, -1.8789e+00],\n",
      "       [ 9.4910e-02,  1.3145e+00, -1.7988e+00],\n",
      "       [-3.3813e-01,  1.6709e+00, -1.7725e+00],\n",
      "       [-1.1530e-01,  8.5059e-01, -1.0811e+00],\n",
      "       [-6.9922e-01,  2.4648e+00, -2.2188e+00],\n",
      "       [-6.9141e-01,  1.8896e+00, -1.5664e+00],\n",
      "       [-5.0195e-01,  2.1328e+00, -2.0977e+00],\n",
      "       [-5.3711e-01,  1.9971e+00, -1.8506e+00],\n",
      "       [ 4.6460e-01,  8.7256e-01, -1.6553e+00],\n",
      "       [ 5.5695e-02,  7.9785e-01, -1.1406e+00],\n",
      "       [ 9.8572e-02,  1.1064e+00, -1.4893e+00],\n",
      "       [-1.8158e-02,  1.2188e+00, -1.5908e+00],\n",
      "       [-2.3486e-01,  1.5508e+00, -1.6709e+00],\n",
      "       [ 1.1902e-01,  8.8721e-01, -1.3564e+00],\n",
      "       [-5.6201e-01,  2.2266e+00, -2.1074e+00],\n",
      "       [ 3.6792e-01,  6.1719e-01, -1.3193e+00],\n",
      "       [-8.2520e-01,  2.3848e+00, -2.0156e+00],\n",
      "       [-2.5098e-01,  1.8643e+00, -2.0137e+00],\n",
      "       [-4.1357e-01,  1.6748e+00, -1.6514e+00],\n",
      "       [-1.2030e-01,  1.2070e+00, -1.4062e+00],\n",
      "       [ 4.8267e-01,  8.4473e-01, -1.6201e+00],\n",
      "       [-5.9570e-01,  1.6094e+00, -1.4551e+00],\n",
      "       [-9.9243e-02,  1.3076e+00, -1.5752e+00],\n",
      "       [-5.5176e-01,  1.4023e+00, -1.2451e+00],\n",
      "       [-4.2358e-01,  1.7793e+00, -1.7324e+00],\n",
      "       [-5.3516e-01,  2.0820e+00, -1.9766e+00],\n",
      "       [-4.2090e-01,  2.1172e+00, -2.1113e+00],\n",
      "       [-4.1699e-01,  1.7559e+00, -1.7090e+00],\n",
      "       [ 3.0151e-01,  9.3848e-01, -1.5771e+00],\n",
      "       [-3.0591e-01,  1.7061e+00, -1.7773e+00],\n",
      "       [-6.6992e-01,  1.8633e+00, -1.5791e+00],\n",
      "       [-5.8350e-01,  1.5342e+00, -1.3789e+00],\n",
      "       [-5.0928e-01,  1.7617e+00, -1.6768e+00],\n",
      "       [ 6.9275e-02,  9.2383e-01, -1.3477e+00],\n",
      "       [ 2.6611e-01,  1.2109e+00, -1.8711e+00],\n",
      "       [ 1.5198e-01,  1.3018e+00, -1.7637e+00],\n",
      "       [ 1.2500e-01,  7.3486e-01, -1.1367e+00],\n",
      "       [-8.7305e-01,  2.8066e+00, -2.3828e+00],\n",
      "       [ 2.6831e-01,  8.3350e-01, -1.4365e+00],\n",
      "       [-6.6309e-01,  2.2441e+00, -1.9473e+00],\n",
      "       [-4.6802e-01,  1.8096e+00, -1.7461e+00],\n",
      "       [-4.0674e-01,  1.7568e+00, -1.7520e+00],\n",
      "       [-3.4814e-01,  1.5957e+00, -1.6279e+00],\n",
      "       [-5.9814e-01,  2.2734e+00, -2.0938e+00],\n",
      "       [ 3.0786e-01,  3.5229e-01, -9.2285e-01],\n",
      "       [-7.9285e-02,  1.5957e+00, -1.8398e+00],\n",
      "       [-7.6514e-01,  2.1406e+00, -1.7607e+00],\n",
      "       [ 1.0252e-04,  1.2119e+00, -1.5830e+00],\n",
      "       [-6.5674e-01,  1.7119e+00, -1.4893e+00],\n",
      "       [-4.9121e-01,  2.4844e+00, -2.4219e+00],\n",
      "       [-6.7871e-01,  2.1758e+00, -1.9092e+00],\n",
      "       [ 2.6154e-02,  1.3545e+00, -1.7549e+00],\n",
      "       [-5.1172e-01,  2.1523e+00, -2.1133e+00],\n",
      "       [-8.8257e-02,  1.0430e+00, -1.2559e+00],\n",
      "       [ 2.3059e-01,  1.1719e+00, -1.7715e+00],\n",
      "       [ 4.0674e-01,  2.8687e-01, -9.4092e-01],\n",
      "       [ 2.0103e-03,  8.8232e-01, -1.1895e+00],\n",
      "       [-7.3730e-01,  2.7207e+00, -2.4355e+00],\n",
      "       [-3.4302e-01,  1.6240e+00, -1.7021e+00],\n",
      "       [ 4.2358e-01,  1.1172e+00, -1.8926e+00],\n",
      "       [-5.6396e-01,  1.8613e+00, -1.7393e+00],\n",
      "       [-6.3428e-01,  2.1230e+00, -1.8682e+00],\n",
      "       [-6.1523e-01,  1.5234e+00, -1.3135e+00],\n",
      "       [-4.0308e-01,  2.1523e+00, -2.1816e+00],\n",
      "       [-6.1865e-01,  1.9795e+00, -1.7979e+00],\n",
      "       [-6.0156e-01,  1.8662e+00, -1.6641e+00],\n",
      "       [ 3.1860e-01,  7.2266e-01, -1.3779e+00],\n",
      "       [-4.6875e-01,  1.7373e+00, -1.6963e+00],\n",
      "       [-6.7676e-01,  2.3496e+00, -2.0898e+00],\n",
      "       [-2.8442e-01,  1.8096e+00, -1.9170e+00],\n",
      "       [-6.8555e-01,  2.1016e+00, -1.7910e+00],\n",
      "       [-7.1875e-01,  2.2930e+00, -1.9727e+00],\n",
      "       [ 3.9612e-02,  1.5596e+00, -1.9258e+00],\n",
      "       [-7.9932e-01,  2.1133e+00, -1.7402e+00],\n",
      "       [-3.7646e-01,  1.6465e+00, -1.6367e+00],\n",
      "       [-5.4785e-01,  2.1133e+00, -1.9971e+00],\n",
      "       [ 4.7803e-01,  6.6064e-01, -1.4199e+00],\n",
      "       [-3.3423e-01,  1.6025e+00, -1.6055e+00],\n",
      "       [-3.2568e-01,  1.5811e+00, -1.6494e+00],\n",
      "       [-5.8252e-01,  1.5654e+00, -1.4160e+00],\n",
      "       [-7.3633e-01,  2.4941e+00, -2.1875e+00],\n",
      "       [-7.2607e-01,  2.0879e+00, -1.8174e+00],\n",
      "       [-7.7820e-02,  6.9238e-01, -8.6621e-01],\n",
      "       [-6.2256e-01,  1.9219e+00, -1.7412e+00],\n",
      "       [-6.0889e-01,  2.0020e+00, -1.7842e+00],\n",
      "       [-4.3359e-01,  1.3164e+00, -1.2979e+00],\n",
      "       [-4.1357e-01,  1.8281e+00, -1.8076e+00],\n",
      "       [-3.0298e-01,  1.5547e+00, -1.6299e+00],\n",
      "       [-3.2446e-01,  1.6211e+00, -1.6787e+00],\n",
      "       [ 2.7441e-01,  8.4082e-01, -1.4814e+00],\n",
      "       [-2.0740e-01,  8.7744e-01, -9.5508e-01],\n",
      "       [-4.3799e-01,  1.9268e+00, -1.8779e+00],\n",
      "       [-3.3203e-01,  1.7646e+00, -1.8018e+00],\n",
      "       [-5.2441e-01,  1.5996e+00, -1.5137e+00],\n",
      "       [-6.1859e-02,  9.2285e-01, -1.1904e+00],\n",
      "       [ 2.7441e-01,  9.3066e-01, -1.5557e+00],\n",
      "       [-4.3555e-01,  1.9043e+00, -1.9531e+00],\n",
      "       [ 1.7725e-01,  8.8281e-01, -1.3984e+00],\n",
      "       [-5.4980e-01,  2.0039e+00, -1.8320e+00],\n",
      "       [-7.5391e-01,  2.4941e+00, -2.1895e+00],\n",
      "       [-2.9224e-01,  1.6162e+00, -1.7119e+00],\n",
      "       [ 1.2341e-01,  1.2109e+00, -1.6143e+00],\n",
      "       [-2.0422e-01,  1.6172e+00, -1.8242e+00],\n",
      "       [-1.5625e-01,  1.2793e+00, -1.5205e+00],\n",
      "       [-4.7485e-01,  1.5537e+00, -1.4551e+00],\n",
      "       [-2.2302e-01,  1.5049e+00, -1.6836e+00],\n",
      "       [-7.5317e-02,  4.7021e-01, -6.2500e-01],\n",
      "       [-5.8008e-01,  1.7236e+00, -1.5576e+00],\n",
      "       [-4.2969e-01,  1.7197e+00, -1.7090e+00],\n",
      "       [-5.3760e-01,  1.5537e+00, -1.4482e+00],\n",
      "       [-5.4248e-01,  2.5293e+00, -2.4160e+00],\n",
      "       [-8.1494e-01,  1.9980e+00, -1.6074e+00],\n",
      "       [-4.6582e-01,  1.9131e+00, -1.8525e+00],\n",
      "       [-4.8633e-01,  1.7520e+00, -1.6357e+00],\n",
      "       [-8.1836e-01,  2.6094e+00, -2.2422e+00],\n",
      "       [-3.6670e-01,  1.8379e+00, -1.8555e+00],\n",
      "       [-1.7566e-01,  1.2031e+00, -1.3906e+00],\n",
      "       [ 2.8662e-01,  2.0020e-01, -7.2510e-01],\n",
      "       [-1.7981e-01,  1.0010e+00, -1.1377e+00],\n",
      "       [ 3.3521e-01, -6.0254e-01,  7.3120e-02],\n",
      "       [ 1.9763e-01,  8.0713e-01, -1.2988e+00],\n",
      "       [ 2.6245e-02,  7.8076e-01, -1.0869e+00],\n",
      "       [ 6.7578e-01,  2.9614e-01, -1.1807e+00],\n",
      "       [ 2.5415e-01,  1.0801e+00, -1.7139e+00],\n",
      "       [ 2.4979e-02,  1.0557e+00, -1.4268e+00],\n",
      "       [-2.9443e-01,  1.5869e+00, -1.6748e+00],\n",
      "       [-3.5815e-01,  1.3193e+00, -1.3477e+00],\n",
      "       [-2.4323e-02,  5.0928e-01, -7.3486e-01],\n",
      "       [ 1.2170e-01,  9.8877e-01, -1.4590e+00],\n",
      "       [ 2.3792e-01, -3.5425e-01, -6.9275e-02],\n",
      "       [-8.9111e-02,  1.4404e+00, -1.7559e+00],\n",
      "       [ 2.5952e-01,  9.4629e-01, -1.5820e+00],\n",
      "       [-2.3962e-01,  1.9580e+00, -2.1504e+00],\n",
      "       [-7.6074e-01,  2.4355e+00, -2.1035e+00],\n",
      "       [ 1.6614e-01,  6.2012e-01, -1.0518e+00],\n",
      "       [-8.4326e-01,  2.6855e+00, -2.2363e+00],\n",
      "       [ 2.6978e-01,  6.1182e-01, -1.1680e+00],\n",
      "       [-4.5239e-01,  1.6299e+00, -1.5840e+00],\n",
      "       [ 2.6929e-01,  1.0205e+00, -1.6592e+00],\n",
      "       [-4.1772e-01,  1.7559e+00, -1.7578e+00],\n",
      "       [ 7.9199e-01,  2.6514e-01, -1.3223e+00],\n",
      "       [ 7.2217e-01,  4.1919e-01, -1.4551e+00],\n",
      "       [-3.0045e-02,  1.3740e+00, -1.6807e+00],\n",
      "       [-5.0781e-02,  3.2043e-02, -1.8274e-01],\n",
      "       [-2.0312e-01,  1.6777e+00, -1.9248e+00],\n",
      "       [-4.9194e-01,  1.8779e+00, -1.8369e+00],\n",
      "       [-5.8105e-01,  2.0430e+00, -1.8477e+00],\n",
      "       [-6.8726e-02,  1.0898e+00, -1.3535e+00],\n",
      "       [-3.7964e-01,  1.5322e+00, -1.5547e+00],\n",
      "       [-1.3599e-01,  8.2129e-01, -9.7510e-01],\n",
      "       [-2.6978e-01,  1.7168e+00, -1.8643e+00],\n",
      "       [ 5.2872e-03,  1.4473e+00, -1.8613e+00],\n",
      "       [-3.5620e-01,  1.4707e+00, -1.4824e+00],\n",
      "       [ 8.1738e-01,  4.9487e-01, -1.6182e+00],\n",
      "       [-3.6719e-01,  2.0527e+00, -2.1172e+00],\n",
      "       [-2.1802e-01,  1.5469e+00, -1.7139e+00],\n",
      "       [-5.9229e-01,  2.1055e+00, -1.8975e+00],\n",
      "       [-3.2275e-01,  1.6943e+00, -1.7520e+00],\n",
      "       [-5.5518e-01,  1.8125e+00, -1.6650e+00],\n",
      "       [-2.6749e-02,  1.4824e+00, -1.8525e+00],\n",
      "       [-3.9160e-01,  1.9404e+00, -1.9326e+00],\n",
      "       [ 3.5950e-02,  1.1660e+00, -1.5078e+00],\n",
      "       [-4.4849e-01,  2.1699e+00, -2.1367e+00],\n",
      "       [-2.3413e-01,  1.3018e+00, -1.4209e+00],\n",
      "       [-2.4097e-01,  1.3291e+00, -1.4795e+00],\n",
      "       [-5.0879e-01,  2.0098e+00, -1.9043e+00],\n",
      "       [-4.4409e-01,  1.4346e+00, -1.3535e+00],\n",
      "       [-1.1123e+00,  2.9160e+00, -2.2266e+00],\n",
      "       [-3.0127e-01,  1.4141e+00, -1.4297e+00],\n",
      "       [-2.1924e-01,  1.5088e+00, -1.6445e+00],\n",
      "       [-5.8105e-01,  1.8193e+00, -1.6426e+00],\n",
      "       [ 1.4331e-01,  1.0225e+00, -1.5283e+00],\n",
      "       [-8.9062e-01,  2.3965e+00, -1.9219e+00],\n",
      "       [-6.2500e-01,  2.0684e+00, -1.8604e+00],\n",
      "       [ 5.2246e-02,  1.0703e+00, -1.4385e+00],\n",
      "       [-3.0243e-02,  1.1631e+00, -1.4658e+00],\n",
      "       [ 1.2262e-01,  9.1211e-01, -1.4170e+00],\n",
      "       [-3.5645e-01,  1.7705e+00, -1.8311e+00],\n",
      "       [ 1.2124e-04,  1.2998e+00, -1.7051e+00],\n",
      "       [ 1.6736e-01,  1.0879e+00, -1.6084e+00],\n",
      "       [-4.3970e-01,  1.4180e+00, -1.3555e+00],\n",
      "       [ 3.1470e-01,  8.5596e-01, -1.5107e+00],\n",
      "       [-8.3447e-01,  2.5742e+00, -2.1875e+00],\n",
      "       [-4.7095e-01,  1.6992e+00, -1.6289e+00],\n",
      "       [-5.6641e-01,  2.1641e+00, -1.9951e+00],\n",
      "       [-5.1514e-01,  2.2852e+00, -2.2070e+00],\n",
      "       [-2.7002e-01,  1.3887e+00, -1.5156e+00],\n",
      "       [ 5.8105e-01,  5.2930e-01, -1.4111e+00],\n",
      "       [ 3.3203e-01,  4.6143e-02, -5.9229e-01],\n",
      "       [-7.6709e-01,  2.5137e+00, -2.2070e+00],\n",
      "       [-1.3574e-01,  1.3037e+00, -1.5332e+00],\n",
      "       [-5.2539e-01,  1.7939e+00, -1.6465e+00],\n",
      "       [ 2.0471e-01,  7.1924e-01, -1.2803e+00]], dtype=float16), label_ids=array([1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 0,\n",
      "       1, 2, 0, 0, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 0, 2, 1, 1,\n",
      "       1, 0, 1, 1, 0, 0, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 0, 2, 1, 2, 0,\n",
      "       1, 1, 0, 0, 1, 1, 2, 2, 1, 0, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1,\n",
      "       0, 2, 1, 1, 0, 1, 1, 1, 0, 1, 1, 2, 0, 2, 1, 2, 1, 1, 1, 2, 1, 1,\n",
      "       2, 1, 2, 1, 2, 1, 1, 1, 0, 0, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 2, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2,\n",
      "       1, 1, 1, 2, 1, 0, 0, 0, 1, 1, 1, 2, 1, 1, 0, 1, 0, 1, 2, 1, 1, 1,\n",
      "       1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 1, 2, 1, 1, 1, 1, 2, 2, 0, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 0, 1, 1, 0]), metrics={'test_loss': 1.024988055229187, 'test_accuracy': 0.6452991452991453, 'test_precision': 0.5143288084464556, 'test_recall': 0.6452991452991453, 'test_f1': 0.5433032376428603, 'test_runtime': 6.3111, 'test_samples_per_second': 37.078, 'test_steps_per_second': 2.377})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d4e861c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "probabilities = torch.softmax(torch.tensor(test_results.predictions).to(torch.float32), dim=-1)\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)\n",
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1747566",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_save = []\n",
    "for idx in range(len(test_data)):\n",
    "    item = dataset['test'][idx]\n",
    "    actual_label = item['label']\n",
    "    predicted_label = predictions[idx]\n",
    "    claim = item['claim'] \n",
    "    premise = item['premise'] \n",
    "    category = item['category']\n",
    "    \n",
    "    # Append the information as a dictionary to the list\n",
    "    data_to_save.append({\n",
    "        'Claim': claim,\n",
    "        'Premise': premise,\n",
    "        'Actual Label': actual_label,\n",
    "        'Predicted Label': predicted_label,\n",
    "        'Category' : category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_to_save)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/home/elson/results/2.4.2_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f40c56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correctly classified instances\n",
    "correctly_classified = df[df['Actual Label'] == df['Predicted Label']]\n",
    "\n",
    "# Calculate misclassified instances\n",
    "misclassified = df[df['Actual Label'] != df['Predicted Label']]\n",
    "\n",
    "# Count the number of correctly classified and misclassified by category\n",
    "correct_classification_counts = correctly_classified['Category'].value_counts()\n",
    "misclassification_counts = misclassified['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61d30750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           36\n",
       "Fitness                  15\n",
       "Bone health              12\n",
       "Cancer                   12\n",
       "Skin                      9\n",
       "Neurological health       9\n",
       "Throat                    9\n",
       "Diabetes                  8\n",
       "Cardiovascular Health     6\n",
       "Hair                      6\n",
       "Ear                       6\n",
       "Eye                       6\n",
       "COVID                     4\n",
       "Women' s Health           4\n",
       "Blood                     3\n",
       "Muscles                   3\n",
       "Mental Health             3\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "670ffadf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Skin                     15\n",
       "General Health           15\n",
       "Bone health               9\n",
       "Blood                     6\n",
       "Hair                      6\n",
       "Men's health              6\n",
       "Cardiovascular Health     6\n",
       "Diabetes                  4\n",
       "Dental Health             3\n",
       "Vascular                  3\n",
       "Muscles                   3\n",
       "Eye                       3\n",
       "COVID                     2\n",
       "Women' s Health           2\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
