{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-022bc67e9c58e92d\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 203.83it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('csv',data_files='dataset_propositionattribution_nerfeatures.csv',delimiter=',',column_names=[\"claim\",\"premise\",\"label\",\"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\",\"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\",\"url\", \"entities\",\"entity_map\",\"entity_map_ev\",\"entities_ev\",\"gem_exp\",\"gem_label\",\"gpt_label\",\"gpt_exp\",\"gold_exp\",\"synonym\",\"voice\",\"split\"],skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "835b6a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-2b8e361375c0e153.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-0cc9bb699c2761fb.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-608a44ac65076739.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01252e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\"claim\", \"premise\", \"label\",\"category\"]\n",
    "all_columns = dataset[\"train\"].column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-ec19dfd27de43963.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-10d23eaef378d5d1.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-e72c65ea7c63cdc8.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 2, 'entailment': 0, 'neutral': 1}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 2,\n",
    "    \"entailment\": 0,\n",
    "    \"neutral\": 1\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e15010ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "        # Extracting claim and evidence texts\n",
    "\n",
    "        claim = item['claim']\n",
    "        evidences = item['premise']\n",
    "        item['premise']=evidences\n",
    "        item['claim']=claim\n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "            evidences,claim,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "        item['input_ids'] = inputs['input_ids'].squeeze()  # Remove batch dimension\n",
    "        item['attention_mask']= inputs['attention_mask'].squeeze() # Remove batch dimension\n",
    "        \n",
    "        if 'label' in item:\n",
    "            item['labels'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62421eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DebertaV2ForSequenceClassification(\n",
       "  (deberta): DebertaV2Model(\n",
       "    (embeddings): DebertaV2Embeddings(\n",
       "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaV2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (1): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (2): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (3): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (4): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (5): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (6): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (7): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (8): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (9): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (10): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (11): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (pooler): ContextPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): StableDropout()\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (dropout): StableDropout()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=512)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=3, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    return {\"accuracy\": acc, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f5cf584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'claim': 'Myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.',\n",
       " 'premise': 'The essential oils of frankincense and myrrh increase the fluidity of the lipid bilayer in the cuticle and change the orderly and dense structure to increase the permeability of the skin and decrease the barrier effect.',\n",
       " 'label': 0,\n",
       " 'category': 'General Health',\n",
       " 'input_ids': tensor([    1,   279,  1830,  6725,   265, 88609,   263, 98237,   993,   262,\n",
       "         49462,   265,   262, 22003, 96579,   267,   262, 61462,   263,   575,\n",
       "           262, 26217,   263,  9854,  1730,   264,   993,   262, 39632,   265,\n",
       "           262,  1158,   263,  4843,   262,  7275,  1290,   260,     2,   573,\n",
       "         52341,  1830,  1080,   269,  1359,   427,   267, 17847,   633,   264,\n",
       "           408,  1300,   262,  2658,   265,   262,  1158,   260,     2,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'labels': tensor(0)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1530\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1530' max='1530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1530/1530 12:28, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.705500</td>\n",
       "      <td>0.791041</td>\n",
       "      <td>0.692473</td>\n",
       "      <td>0.695634</td>\n",
       "      <td>0.692473</td>\n",
       "      <td>0.688913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.448700</td>\n",
       "      <td>1.064096</td>\n",
       "      <td>0.632258</td>\n",
       "      <td>0.703775</td>\n",
       "      <td>0.632258</td>\n",
       "      <td>0.652736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.295700</td>\n",
       "      <td>1.058868</td>\n",
       "      <td>0.636559</td>\n",
       "      <td>0.690558</td>\n",
       "      <td>0.636559</td>\n",
       "      <td>0.654862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.226500</td>\n",
       "      <td>1.309381</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.706309</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.668783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.198400</td>\n",
       "      <td>1.537970</td>\n",
       "      <td>0.662366</td>\n",
       "      <td>0.695842</td>\n",
       "      <td>0.662366</td>\n",
       "      <td>0.674711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.039600</td>\n",
       "      <td>1.642777</td>\n",
       "      <td>0.664516</td>\n",
       "      <td>0.672026</td>\n",
       "      <td>0.664516</td>\n",
       "      <td>0.667548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.075600</td>\n",
       "      <td>2.021899</td>\n",
       "      <td>0.636559</td>\n",
       "      <td>0.698964</td>\n",
       "      <td>0.636559</td>\n",
       "      <td>0.655100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.072300</td>\n",
       "      <td>2.176615</td>\n",
       "      <td>0.664516</td>\n",
       "      <td>0.683346</td>\n",
       "      <td>0.664516</td>\n",
       "      <td>0.670636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.050100</td>\n",
       "      <td>2.291495</td>\n",
       "      <td>0.664516</td>\n",
       "      <td>0.689111</td>\n",
       "      <td>0.664516</td>\n",
       "      <td>0.671782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.111800</td>\n",
       "      <td>2.488793</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.685675</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.667201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.023200</td>\n",
       "      <td>2.556879</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.692266</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.665494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>2.530430</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.681549</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.663613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>2.630208</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.682517</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.665908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>2.696933</td>\n",
       "      <td>0.653763</td>\n",
       "      <td>0.681131</td>\n",
       "      <td>0.653763</td>\n",
       "      <td>0.664278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.014100</td>\n",
       "      <td>2.717521</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.681461</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.662874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.4.1_deberta/checkpoint-102\n",
      "Configuration saved in /home/elson/2.4.1_deberta/checkpoint-102/config.json\n",
      "Model weights saved in /home/elson/2.4.1_deberta/checkpoint-102/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.4.1_deberta/checkpoint-1530] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.4.1_deberta/checkpoint-204\n",
      "Configuration saved in /home/elson/2.4.1_deberta/checkpoint-204/config.json\n",
      "Model weights saved in /home/elson/2.4.1_deberta/checkpoint-204/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.4.1_deberta/checkpoint-306\n",
      "Configuration saved in /home/elson/2.4.1_deberta/checkpoint-306/config.json\n",
      "Model weights saved in /home/elson/2.4.1_deberta/checkpoint-306/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.4.1_deberta/checkpoint-204] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.4.1_deberta/checkpoint-408\n",
      "Configuration saved in /home/elson/2.4.1_deberta/checkpoint-408/config.json\n",
      "Model weights saved in /home/elson/2.4.1_deberta/checkpoint-408/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.4.1_deberta/checkpoint-306] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.4.1_deberta/checkpoint-510\n",
      "Configuration saved in /home/elson/2.4.1_deberta/checkpoint-510/config.json\n",
      "Model weights saved in /home/elson/2.4.1_deberta/checkpoint-510/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.4.1_deberta/checkpoint-408] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.4.1_deberta/checkpoint-612\n",
      "Configuration saved in /home/elson/2.4.1_deberta/checkpoint-612/config.json\n",
      "Model weights saved in /home/elson/2.4.1_deberta/checkpoint-612/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.4.1_deberta/checkpoint-510] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.4.1_deberta/checkpoint-714\n",
      "Configuration saved in /home/elson/2.4.1_deberta/checkpoint-714/config.json\n",
      "Model weights saved in /home/elson/2.4.1_deberta/checkpoint-714/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.4.1_deberta/checkpoint-612] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.4.1_deberta/checkpoint-816\n",
      "Configuration saved in /home/elson/2.4.1_deberta/checkpoint-816/config.json\n",
      "Model weights saved in /home/elson/2.4.1_deberta/checkpoint-816/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.4.1_deberta/checkpoint-714] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.4.1_deberta/checkpoint-918\n",
      "Configuration saved in /home/elson/2.4.1_deberta/checkpoint-918/config.json\n",
      "Model weights saved in /home/elson/2.4.1_deberta/checkpoint-918/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.4.1_deberta/checkpoint-816] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.4.1_deberta/checkpoint-1020\n",
      "Configuration saved in /home/elson/2.4.1_deberta/checkpoint-1020/config.json\n",
      "Model weights saved in /home/elson/2.4.1_deberta/checkpoint-1020/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.4.1_deberta/checkpoint-918] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.4.1_deberta/checkpoint-1122\n",
      "Configuration saved in /home/elson/2.4.1_deberta/checkpoint-1122/config.json\n",
      "Model weights saved in /home/elson/2.4.1_deberta/checkpoint-1122/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.4.1_deberta/checkpoint-1020] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.4.1_deberta/checkpoint-1224\n",
      "Configuration saved in /home/elson/2.4.1_deberta/checkpoint-1224/config.json\n",
      "Model weights saved in /home/elson/2.4.1_deberta/checkpoint-1224/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.4.1_deberta/checkpoint-1122] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.4.1_deberta/checkpoint-1326\n",
      "Configuration saved in /home/elson/2.4.1_deberta/checkpoint-1326/config.json\n",
      "Model weights saved in /home/elson/2.4.1_deberta/checkpoint-1326/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.4.1_deberta/checkpoint-1224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.4.1_deberta/checkpoint-1428\n",
      "Configuration saved in /home/elson/2.4.1_deberta/checkpoint-1428/config.json\n",
      "Model weights saved in /home/elson/2.4.1_deberta/checkpoint-1428/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.4.1_deberta/checkpoint-1326] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.4.1_deberta/checkpoint-1530\n",
      "Configuration saved in /home/elson/2.4.1_deberta/checkpoint-1530/config.json\n",
      "Model weights saved in /home/elson/2.4.1_deberta/checkpoint-1530/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.4.1_deberta/checkpoint-1428] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/elson/2.4.1_deberta/checkpoint-102 (score: 0.6924731182795699).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /home/elson/2.4.1_deberta/best_model/config.json\n",
      "Model weights saved in /home/elson/2.4.1_deberta/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/2.4.1_deberta/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/2.4.1_deberta/best_model/special_tokens_map.json\n",
      "added tokens file saved in /home/elson/2.4.1_deberta/best_model/added_tokens.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/2.4.1_deberta/best_model/tokenizer_config.json',\n",
       " '/home/elson/2.4.1_deberta/best_model/special_tokens_map.json',\n",
       " '/home/elson/2.4.1_deberta/best_model/spm.model',\n",
       " '/home/elson/2.4.1_deberta/best_model/added_tokens.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/2.4.1_deberta/',\n",
    "    num_train_epochs=15,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.06,\n",
    "    weight_decay=0.1,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/2.4.1_deberta/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/2.4.1_deberta/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63deaea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/2.4.1_deberta/best_model/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"/home/elson/2.4.1_deberta/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"entailment\",\n",
      "    \"1\": \"neutral\",\n",
      "    \"2\": \"contradiction\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"contradiction\": 2,\n",
      "    \"entailment\": 0,\n",
      "    \"neutral\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file /home/elson/2.4.1_deberta/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at /home/elson/2.4.1_deberta/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 16\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/2.4.1_deberta/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[ 1.771   , -0.2622  , -1.5205  ],\n",
      "       [ 2.504   , -1.008   , -1.438   ],\n",
      "       [ 2.93    , -1.309   , -1.55    ],\n",
      "       [-1.011   , -0.9746  ,  1.939   ],\n",
      "       [ 1.118   , -0.1543  , -1.011   ],\n",
      "       [ 2.957   , -0.926   , -1.904   ],\n",
      "       [ 1.772   , -1.236   , -0.643   ],\n",
      "       [ 1.578   , -0.5894  , -0.9937  ],\n",
      "       [ 1.468   ,  0.0322  , -1.54    ],\n",
      "       [ 1.144   , -0.547   , -0.693   ],\n",
      "       [ 0.374   , -0.915   ,  0.3586  ],\n",
      "       [ 3.14    , -1.535   , -1.491   ],\n",
      "       [ 1.471   , -0.3567  , -1.123   ],\n",
      "       [ 2.252   , -1.003   , -1.185   ],\n",
      "       [ 2.182   , -0.756   , -1.402   ],\n",
      "       [ 0.2036  , -0.1527  , -0.1437  ],\n",
      "       [ 1.204   ,  0.0388  , -1.358   ],\n",
      "       [ 2.416   , -0.774   , -1.574   ],\n",
      "       [ 2.49    , -1.094   , -1.359   ],\n",
      "       [ 1.161   , -0.4614  , -0.796   ],\n",
      "       [-0.2625  ,  0.3203  , -0.05237 ],\n",
      "       [ 1.608   , -0.6387  , -1.023   ],\n",
      "       [ 2.209   , -0.83    , -1.324   ],\n",
      "       [-1.476   , -0.7153  ,  2.209   ],\n",
      "       [-0.4294  , -1.009   ,  1.32    ],\n",
      "       [-1.23    , -1.363   ,  2.467   ],\n",
      "       [ 2.705   , -0.954   , -1.631   ],\n",
      "       [ 2.064   , -0.563   , -1.486   ],\n",
      "       [ 2.58    , -0.679   , -1.783   ],\n",
      "       [ 0.6626  , -0.3347  , -0.4685  ],\n",
      "       [-0.02164 , -0.04272 ,  0.0381  ],\n",
      "       [ 2.018   , -0.551   , -1.446   ],\n",
      "       [ 2.58    , -1.026   , -1.475   ],\n",
      "       [ 0.8193  ,  0.0815  , -0.935   ],\n",
      "       [-0.09735 , -0.06683 ,  0.153   ],\n",
      "       [-0.1868  ,  0.389   , -0.256   ],\n",
      "       [ 1.004   , -0.4424  , -0.6587  ],\n",
      "       [ 2.047   , -0.2325  , -1.775   ],\n",
      "       [-0.9253  , -0.902   ,  1.776   ],\n",
      "       [ 0.3042  ,  0.1641  , -0.61    ],\n",
      "       [-0.0822  ,  0.014694,  0.02632 ],\n",
      "       [ 1.709   ,  0.05066 , -1.78    ],\n",
      "       [ 1.317   , -0.4233  , -0.959   ],\n",
      "       [-1.025   , -0.1609  ,  1.187   ],\n",
      "       [-0.2491  ,  0.6685  , -0.3926  ],\n",
      "       [ 2.383   , -0.7324  , -1.569   ],\n",
      "       [ 0.4644  ,  0.367   , -0.877   ],\n",
      "       [ 3.23    , -1.129   , -1.936   ],\n",
      "       [ 3.133   , -1.075   , -1.889   ],\n",
      "       [-0.2927  , -0.4858  ,  0.6934  ],\n",
      "       [-0.3123  ,  0.1926  ,  0.1322  ],\n",
      "       [ 0.7617  ,  0.258   , -1.045   ],\n",
      "       [ 0.803   , -0.1454  , -0.726   ],\n",
      "       [ 1.682   , -0.263   , -1.437   ],\n",
      "       [-0.6016  ,  1.11    , -0.5737  ],\n",
      "       [ 1.803   , -0.5537  , -1.233   ],\n",
      "       [-0.503   ,  0.656   , -0.1222  ],\n",
      "       [ 2.111   , -0.1971  , -1.8545  ],\n",
      "       [ 1.352   , -0.5977  , -0.813   ],\n",
      "       [ 2.727   , -1.02    , -1.609   ],\n",
      "       [ 1.951   , -0.3872  , -1.543   ],\n",
      "       [-0.2957  , -0.283   ,  0.5273  ],\n",
      "       [ 0.9     ,  0.0808  , -1.098   ],\n",
      "       [ 0.9775  ,  0.4453  , -1.534   ],\n",
      "       [-0.5815  ,  0.816   , -0.245   ],\n",
      "       [ 2.207   , -0.6113  , -1.533   ],\n",
      "       [ 1.677   , -0.4644  , -1.206   ],\n",
      "       [ 1.655   , -0.01519 , -1.662   ],\n",
      "       [ 0.1937  , -0.516   ,  0.1956  ],\n",
      "       [-0.508   , -0.9834  ,  1.388   ],\n",
      "       [ 2.055   , -0.4397  , -1.547   ],\n",
      "       [ 0.4128  ,  0.2847  , -0.7896  ],\n",
      "       [-0.05728 ,  0.948   , -1.07    ],\n",
      "       [ 2.92    , -1.014   , -1.7705  ],\n",
      "       [ 0.97    , -0.504   , -0.547   ],\n",
      "       [ 2.443   , -0.9087  , -1.452   ],\n",
      "       [ 1.195   , -0.623   , -0.6626  ],\n",
      "       [ 2.23    , -0.5625  , -1.574   ],\n",
      "       [ 3.057   , -1.296   , -1.618   ],\n",
      "       [ 0.6436  , -0.2449  , -0.4795  ],\n",
      "       [ 1.082   ,  0.0887  , -1.222   ],\n",
      "       [ 1.832   , -0.4763  , -1.35    ],\n",
      "       [ 1.83    , -0.6978  , -1.114   ],\n",
      "       [ 2.17    , -0.9937  , -1.165   ],\n",
      "       [ 1.803   , -0.596   , -1.214   ],\n",
      "       [-0.4363  , -0.316   ,  0.6846  ],\n",
      "       [ 1.025   , -0.7124  , -0.4368  ],\n",
      "       [ 0.6865  ,  0.3054  , -1.042   ],\n",
      "       [ 2.188   , -0.6323  , -1.51    ],\n",
      "       [ 0.7065  ,  0.22    , -1.062   ],\n",
      "       [ 3.088   , -1.337   , -1.659   ],\n",
      "       [ 1.934   , -0.5586  , -1.4     ],\n",
      "       [-0.775   , -1.044   ,  1.739   ],\n",
      "       [ 3.09    , -1.119   , -1.828   ],\n",
      "       [ 1.328   , -0.1288  , -1.305   ],\n",
      "       [ 1.386   , -0.6016  , -0.845   ],\n",
      "       [-0.2507  , -1.289   ,  1.364   ],\n",
      "       [ 1.167   ,  0.0664  , -1.328   ],\n",
      "       [ 2.92    , -1.232   , -1.574   ],\n",
      "       [ 1.844   , -0.4321  , -1.424   ],\n",
      "       [-0.2261  , -0.874   ,  0.9673  ],\n",
      "       [ 2.912   , -1.      , -1.766   ],\n",
      "       [ 2.559   , -0.8657  , -1.6     ],\n",
      "       [-0.02592 ,  0.6533  , -0.764   ],\n",
      "       [ 2.059   , -0.4329  , -1.627   ],\n",
      "       [ 1.818   , -0.316   , -1.496   ],\n",
      "       [ 1.012   , -0.4258  , -0.6987  ],\n",
      "       [-0.06946 ,  0.3137  , -0.2812  ],\n",
      "       [ 1.621   , -0.2576  , -1.356   ],\n",
      "       [ 1.147   , -0.01588 , -1.216   ],\n",
      "       [ 2.023   , -0.464   , -1.593   ],\n",
      "       [ 2.256   , -1.011   , -1.188   ],\n",
      "       [ 3.318   , -1.284   , -1.887   ],\n",
      "       [ 1.518   , -0.746   , -0.8384  ],\n",
      "       [ 1.986   , -0.3262  , -1.629   ],\n",
      "       [ 2.004   , -0.3975  , -1.567   ],\n",
      "       [ 1.952   , -0.751   , -1.196   ],\n",
      "       [ 1.693   , -0.612   , -1.127   ],\n",
      "       [ 1.464   , -0.2737  , -1.254   ],\n",
      "       [ 2.213   , -0.5054  , -1.645   ],\n",
      "       [ 0.7627  , -0.1664  , -0.716   ],\n",
      "       [ 1.936   , -0.636   , -1.27    ],\n",
      "       [ 1.296   ,  0.3218  , -1.709   ],\n",
      "       [ 0.323   ,  0.6255  , -1.012   ],\n",
      "       [ 0.707   ,  0.2435  , -1.05    ],\n",
      "       [ 1.413   , -0.2136  , -1.29    ],\n",
      "       [-0.338   ,  0.683   , -0.395   ],\n",
      "       [ 2.912   , -1.032   , -1.769   ],\n",
      "       [ 1.653   , -0.3955  , -1.261   ],\n",
      "       [ 0.3772  ,  0.7734  , -1.313   ],\n",
      "       [ 0.493   , -0.04773 , -0.538   ],\n",
      "       [-0.5107  , -0.4958  ,  0.934   ],\n",
      "       [ 1.831   , -0.1412  , -1.692   ],\n",
      "       [-0.4756  ,  0.02916 ,  0.501   ],\n",
      "       [ 1.533   , -0.2732  , -1.328   ],\n",
      "       [-0.11017 ,  0.02779 ,  0.0502  ],\n",
      "       [ 0.894   , -0.556   , -0.4336  ],\n",
      "       [-0.5103  , -0.004253,  0.4714  ],\n",
      "       [-0.656   ,  1.209   , -0.6074  ],\n",
      "       [ 2.525   , -0.85    , -1.58    ],\n",
      "       [ 2.492   , -0.736   , -1.66    ],\n",
      "       [ 0.5317  ,  0.2725  , -0.8633  ],\n",
      "       [ 0.878   ,  0.2025  , -1.124   ],\n",
      "       [ 2.568   , -0.773   , -1.661   ],\n",
      "       [ 0.1677  , -0.0107  , -0.2043  ],\n",
      "       [ 1.843   , -0.923   , -0.953   ],\n",
      "       [ 0.04184 ,  0.337   , -0.3713  ],\n",
      "       [-0.7744  , -0.3682  ,  1.106   ],\n",
      "       [ 2.451   , -0.965   , -1.408   ],\n",
      "       [ 0.7954  , -0.1289  , -0.7856  ],\n",
      "       [ 0.173   ,  0.3708  , -0.6665  ],\n",
      "       [ 3.092   , -1.347   , -1.651   ],\n",
      "       [ 2.355   , -0.4712  , -1.791   ],\n",
      "       [ 2.252   , -0.891   , -1.299   ],\n",
      "       [ 1.295   , -0.2323  , -1.134   ],\n",
      "       [ 3.281   , -1.352   , -1.752   ],\n",
      "       [ 2.607   , -1.068   , -1.472   ],\n",
      "       [ 0.0661  ,  0.0704  , -0.2292  ],\n",
      "       [ 0.09204 , -0.2086  ,  0.0459  ],\n",
      "       [-0.8643  ,  0.2465  ,  0.7305  ],\n",
      "       [-1.201   , -1.4     ,  2.506   ],\n",
      "       [-1.158   , -1.526   ,  2.645   ],\n",
      "       [ 0.12476 ,  0.553   , -0.732   ],\n",
      "       [ 0.4148  , -0.4224  , -0.0965  ],\n",
      "       [ 0.9585  , -0.295   , -0.7456  ],\n",
      "       [-0.2166  ,  0.2588  , -0.0542  ],\n",
      "       [ 1.792   , -0.4714  , -1.309   ],\n",
      "       [-1.096   ,  0.0434  ,  1.143   ],\n",
      "       [-0.2507  , -0.163   ,  0.3435  ],\n",
      "       [ 0.756   , -0.6206  , -0.2842  ],\n",
      "       [-1.341   , -0.6704  ,  1.989   ],\n",
      "       [ 0.9272  , -0.253   , -0.736   ],\n",
      "       [-0.2288  ,  0.3848  , -0.1583  ],\n",
      "       [ 2.863   , -0.878   , -1.85    ],\n",
      "       [ 2.672   , -0.7764  , -1.798   ],\n",
      "       [-0.1532  ,  0.2106  , -0.0474  ],\n",
      "       [ 2.512   , -0.9756  , -1.458   ],\n",
      "       [-0.4043  , -0.74    ,  1.048   ],\n",
      "       [ 1.476   , -0.1847  , -1.329   ],\n",
      "       [ 0.145   ,  0.3682  , -0.55    ],\n",
      "       [ 0.154   , -0.05374 , -0.1802  ],\n",
      "       [-0.1197  ,  0.0896  , -0.01233 ],\n",
      "       [-0.878   , -0.88    ,  1.706   ],\n",
      "       [ 1.127   ,  0.3984  , -1.673   ],\n",
      "       [-0.7812  ,  0.1251  ,  0.6826  ],\n",
      "       [ 2.477   , -0.7803  , -1.619   ],\n",
      "       [ 2.787   , -0.9854  , -1.665   ],\n",
      "       [ 2.135   , -0.431   , -1.66    ],\n",
      "       [ 1.172   , -0.1213  , -1.094   ],\n",
      "       [ 2.504   , -0.9395  , -1.5     ],\n",
      "       [ 0.1633  ,  0.304   , -0.509   ],\n",
      "       [ 1.745   , -0.3171  , -1.463   ],\n",
      "       [ 2.303   , -1.234   , -1.072   ],\n",
      "       [ 2.027   , -0.702   , -1.289   ],\n",
      "       [-0.6025  , -0.7256  ,  1.226   ],\n",
      "       [ 2.768   , -1.024   , -1.638   ],\n",
      "       [ 1.121   ,  0.4797  , -1.743   ],\n",
      "       [ 2.355   , -0.7305  , -1.571   ],\n",
      "       [ 2.38    , -0.983   , -1.364   ],\n",
      "       [ 0.713   , -0.2866  , -0.5376  ],\n",
      "       [ 2.223   , -1.0625  , -1.165   ],\n",
      "       [ 2.555   , -0.7144  , -1.743   ],\n",
      "       [ 0.9937  ,  0.2378  , -1.331   ],\n",
      "       [ 1.971   , -0.7275  , -1.283   ],\n",
      "       [-0.318   ,  0.0492  ,  0.2886  ],\n",
      "       [-0.892   ,  0.0706  ,  0.872   ],\n",
      "       [ 2.736   , -0.966   , -1.687   ],\n",
      "       [ 0.5166  , -0.575   , -0.0701  ],\n",
      "       [ 2.604   , -0.7354  , -1.758   ],\n",
      "       [ 1.116   , -0.00461 , -1.22    ],\n",
      "       [ 2.008   , -0.666   , -1.334   ],\n",
      "       [ 0.7744  , -0.4194  , -0.4707  ],\n",
      "       [ 1.91    , -0.55    , -1.357   ],\n",
      "       [ 1.48    ,  0.0825  , -1.593   ],\n",
      "       [ 0.7334  , -0.2455  , -0.591   ],\n",
      "       [-0.9375  , -0.05368 ,  1.043   ],\n",
      "       [-0.803   , -0.03018 ,  0.869   ],\n",
      "       [ 0.2289  , -0.0409  , -0.2354  ],\n",
      "       [ 2.324   , -0.713   , -1.529   ],\n",
      "       [ 0.02167 ,  0.2747  , -0.3352  ],\n",
      "       [ 2.03    , -0.486   , -1.507   ],\n",
      "       [ 2.9     , -1.096   , -1.69    ],\n",
      "       [ 1.549   , -0.821   , -0.774   ],\n",
      "       [ 2.04    , -1.189   , -0.8926  ],\n",
      "       [ 1.606   , -0.3203  , -1.301   ],\n",
      "       [ 2.336   , -0.361   , -1.91    ],\n",
      "       [ 2.037   , -0.471   , -1.529   ],\n",
      "       [-0.924   ,  0.10895 ,  0.881   ],\n",
      "       [ 0.833   , -0.0744  , -0.8447  ],\n",
      "       [-0.00895 , -0.05988 ,  0.0345  ],\n",
      "       [ 2.662   , -0.785   , -1.765   ],\n",
      "       [ 2.45    , -0.556   , -1.765   ],\n",
      "       [ 1.499   , -0.1744  , -1.341   ],\n",
      "       [ 0.2751  , -0.00804 , -0.291   ]], dtype=float16), label_ids=array([0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
      "       0, 1, 2, 2, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 2, 0, 2, 1, 0, 0,\n",
      "       1, 2, 0, 0, 0, 2, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 2, 1, 0, 1, 0,\n",
      "       0, 1, 2, 2, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
      "       0, 1, 0, 0, 1, 0, 1, 1, 2, 0, 0, 1, 2, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "       1, 2, 0, 0, 1, 0, 0, 0, 1, 2, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
      "       0, 1, 0, 1, 0, 0, 1, 0, 2, 0, 0, 0, 1, 1, 2, 1, 0, 0, 0, 0, 1, 1,\n",
      "       2, 0, 0, 1, 0, 2, 2, 2, 1, 0, 0, 1, 0, 1, 2, 0, 2, 0, 1, 0, 0, 0,\n",
      "       0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 2, 2, 0, 1, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 2, 0, 0,\n",
      "       0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 2, 0, 0, 1]), metrics={'test_loss': 0.8764830827713013, 'test_accuracy': 0.6709401709401709, 'test_precision': 0.6679877043034937, 'test_recall': 0.6709401709401709, 'test_f1': 0.6340586332418915, 'test_runtime': 2.1579, 'test_samples_per_second': 108.437, 'test_steps_per_second': 6.951})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9dcec8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "probabilities = torch.softmax(torch.tensor(test_results.predictions).to(torch.float32), dim=-1)\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)\n",
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef6c9463",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_save = []\n",
    "for idx in range(len(test_data)):\n",
    "    item = dataset['test'][idx]\n",
    "    actual_label = item['label']\n",
    "    predicted_label = predictions[idx]\n",
    "    claim = item['claim'] \n",
    "    premise = item['premise'] \n",
    "    category = item['category']\n",
    "    \n",
    "    # Append the information as a dictionary to the list\n",
    "    data_to_save.append({\n",
    "        'Claim': claim,\n",
    "        'Premise': premise,\n",
    "        'Actual Label': actual_label,\n",
    "        'Predicted Label': predicted_label,\n",
    "        'Category' : category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_to_save)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/home/elson/results/2.4.1_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12aae683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correctly classified instances\n",
    "correctly_classified = df[df['Actual Label'] == df['Predicted Label']]\n",
    "\n",
    "# Calculate misclassified instances\n",
    "misclassified = df[df['Actual Label'] != df['Predicted Label']]\n",
    "\n",
    "# Count the number of correctly classified and misclassified by category\n",
    "correct_classification_counts = correctly_classified['Category'].value_counts()\n",
    "misclassification_counts = misclassified['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f87d428a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           43\n",
       "Fitness                  13\n",
       "Bone health              13\n",
       "Skin                     10\n",
       "Cancer                    9\n",
       "Diabetes                  9\n",
       "Throat                    9\n",
       "Cardiovascular Health     7\n",
       "Neurological health       6\n",
       "Ear                       6\n",
       "Men's health              6\n",
       "COVID                     5\n",
       "Blood                     4\n",
       "Women' s Health           4\n",
       "Eye                       4\n",
       "Muscles                   3\n",
       "Mental Health             3\n",
       "Hair                      3\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e4feef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Skin                     14\n",
       "Hair                      9\n",
       "General Health            8\n",
       "Bone health               8\n",
       "Cardiovascular Health     5\n",
       "Eye                       5\n",
       "Blood                     5\n",
       "Vascular                  3\n",
       "Neurological health       3\n",
       "Muscles                   3\n",
       "Dental Health             3\n",
       "Diabetes                  3\n",
       "Cancer                    3\n",
       "Fitness                   2\n",
       "Women' s Health           2\n",
       "COVID                     1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
