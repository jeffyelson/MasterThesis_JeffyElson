{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score,balanced_accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82806f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jul 29 19:09:40 2024       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:61:00.0 Off |                    0 |\r\n",
      "| N/A   45C    P0    57W / 300W |      0MiB / 32768MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla V100-SXM2...  Off  | 00000000:62:00.0 Off |                    0 |\r\n",
      "| N/A   45C    P0    58W / 300W |      0MiB / 32768MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   2  Tesla V100-SXM2...  Off  | 00000000:89:00.0 Off |                    0 |\r\n",
      "| N/A   44C    P0    61W / 300W |      0MiB / 32768MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   3  Tesla V100-SXM2...  Off  | 00000000:8A:00.0 Off |                    0 |\r\n",
      "| N/A   44C    P0    60W / 300W |      0MiB / 32768MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-31dfe7adddcf5ced\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 216.87it/s]\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-ad71be204b279b28.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-e7b6b615907c24ca.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-bee802838a3bfaea.arrow\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset from the CSV file\n",
    "dataset = load_dataset(\n",
    "    'csv',\n",
    "    data_files='dataset_semanticattribution_nerfeatures_split.csv',\n",
    "    delimiter=',',\n",
    "    column_names=[\n",
    "        \"claim\", \"premise\", \"label\", \"category\", \"count_bf\", \"count_ca\", \"count_dis\",\n",
    "        \"count_food\", \"count_lipid\", \"count_treat\", \"pres_bf\", \"pres_ca\", \"pres_dis\",\n",
    "        \"pres_food\", \"pres_lipid\", \"pres_treat\", \"counte_bf\", \"counte_ca\", \"counte_dis\",\n",
    "        \"counte_food\", \"counte_lipid\", \"counte_treat\", \"prese_bf\", \"prese_ca\", \"prese_dis\",\n",
    "        \"prese_food\", \"prese_lipid\", \"prese_treat\", \"url\", \"entities\", \"entity_map\",\n",
    "        \"gold_exp\", \"gemini_exp\", \"gemini_label\",\"entity_ev\",\"entity_map_ev\", \"split\"\n",
    "    ],\n",
    "    skiprows=1\n",
    ")\n",
    "\n",
    "# Assuming 'split' column contains strings 'train', 'validation', 'test'\n",
    "# Filter the loaded dataset into subsets\n",
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'gold_exp', 'gemini_exp', 'gemini_label', 'entity_ev', 'entity_map_ev', 'split'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f3e71be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41f1db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['claim', 'premise', 'label','category','counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat']\n",
    "all_columns = train_dataset.column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-192f7cd55308f437.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-628e09c96e321cd1.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-1df942f735662e2b.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 0, 'entailment': 1, 'neutral': 2}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 0,\n",
    "    \"entailment\": 1,\n",
    "    \"neutral\": 2\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b5bb17f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "465"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['val']['claim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='pritamdeka/PubMedBERT-MNLI-MedNLI'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "        # Extracting claim and evidence texts\n",
    "\n",
    "        claim = item['claim']\n",
    "        premise = item['premise'].replace('\\n', '').replace('[','').replace(']','')\n",
    "        additional_features = [\n",
    "            'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat']\n",
    "    \n",
    "        for feature in additional_features:\n",
    "            if feature in item:\n",
    "                premise += \"[SEP]\" + str(item[feature])\n",
    "        item['claim']=claim\n",
    "        item['premise']=premise        \n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "             premise, claim,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "        item['input_ids'] = inputs['input_ids'].squeeze()  # Remove batch dimension\n",
    "        item['attention_mask']= inputs['attention_mask'].squeeze() # Remove batch dimension\n",
    "        \n",
    "        output_item = {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),  # Remove batch dimension\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),  # Remove batch dimension\n",
    "            'claim': claim,  # Include augmented claim text\n",
    "            'evidences': premise  # Include original evidence text\n",
    "        }\n",
    "        \n",
    "        if 'label' in item:\n",
    "            output_item['label'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return output_item\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62421eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"pritamdeka/PubMedBERT-MNLI-MedNLI\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=3, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f72c5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model is on device: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    bal_accuracy = balanced_accuracy_score(labels,preds)\n",
    "\n",
    "    return {\"accuracy\": acc, \"balanced_accuracy\":bal_accuracy, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17c5e0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([    2,    31,  2067, 29949,  2126,   240,    16,    56,    18,    31,\n",
       "          3363,  7369,  1019,   240,    16,    51,    18,    31,  7626,  5025,\n",
       "           240,  6235,  2165,  1019,   240,    16,    58,    18,    31,  4357,\n",
       "         23663,  1970, 25210,  1019,   240,    16,    55,    18,    31, 17725,\n",
       "          1037, 12518,  2165,  1019,   240,    16,    57,    18,    31, 28193,\n",
       "          8323, 12518,  2165,  1019,   240,    16,    52,    18, 14542,  4006,\n",
       "          4480,  1930, 14227,  5004,  4415, 16984,  1930, 10659,  2043,  4480,\n",
       "         13203,  1021,  3316,  2703,    17, 22248,  1927, 27041, 11638,  1036,\n",
       "            18,  8236,  5182,  1035,    16,    51,    18, 22719,    10,  4272,\n",
       "          9322,  1927, 26503,  4340,  7369,    12,    18,  5163,  3071,  1930,\n",
       "          6595,  4575, 18068,  1030,  2564,  1927,  2949,  1930,  2310, 11963,\n",
       "          1943,  1956, 14227,  5004,    12,  2689,  6285,  8846,  2629, 12492,\n",
       "          1024,    13, 19490,    18,  4415, 16984,    30,  9624,  2046, 18056,\n",
       "          1958,  4407,  2859,    18, 13297, 21783, 15777,  7446,  1012,    16,\n",
       "            56,    18,    31, 16080, 22284,  1029,    16,    45,    18,    31,\n",
       "         28374, 29834,    16,    52,    18,    31,  3009,  5002,    16,    57,\n",
       "            18,    31, 28098,    16,    55,    18,  5819,  6202,  2007,  4613,\n",
       "          4461,    30,    45,    18, 14227,  5004,  1019,  6691,  4072,  8147,\n",
       "         12709, 16527,    18,  8616,  1960,  7056,  1949,    16,    60,    18,\n",
       "            31,  8616,  1960,  7056,  1949,    16,    61,    18,    31,  8616,\n",
       "          1960,  7056,  1949,    16,    55,    18,    31, 26043,  5148,  3027,\n",
       "            16,    55,    18, 14542,  4006,  4480,    12,    43,  1574,  1216,\n",
       "          1021,  1793,  1062,  7399,   237, 27645,  2029,    31,    18,  3038,\n",
       "            13,    30,  2037,  1920,  4367,  1927,  6378,  5990,  1942,  1920,\n",
       "          4008, 25512, 20512,  1958,  1920,  5455,  1930,  2311,  1927,  7433,\n",
       "          3902,    18, 10021,  1930, 18659,  2455,  1927, 14542,  4006,  4480,\n",
       "          6691,    18, 15926,  3165, 16159, 11324,  2126,  6391,    18,    31,\n",
       "          9108,    16,    47,    18, 14542,  4006,  4480,  1930, 14227,  5004,\n",
       "          1966, 17186,  2062,  1922,  3069,    18,     3,    20,     3,    20,\n",
       "             3,    20,     3,    20,     3,    20,     3,    20,     3,    20,\n",
       "             3,    20,     3,    20,     3,    20,     3,    20,     3,    20,\n",
       "             3, 14227,  5004,  4415,  6691,  1977,  8929,  2251,  1922,  4407,\n",
       "          5715,  4461,  1942,  4087,  3326,  1920,  7818,  1927,  1920,  4407,\n",
       "            18,     3,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'claim': 'Myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.',\n",
       " 'evidences': '; UnkoviÄ‡, N.; DimkiÄ‡, I.; JanaÄ‡koviÄ‡, P.; GavriloviÄ‡, M.; StanojeviÄ‡, O.; VukojeviÄ‡, J. Frankincense and myrrh essential oils and burn incense fume against micro-inhabitants of sacral ambients.Shameem, I. Phytochemical & therapeutic potentials of Murr makki (.Oxidative stress and immunotoxic effects of lead and their amelioration with myrrh (Commiphora molmol) emulsion.Essential Oils: Magical Ingredients for Skin Care.Chakravarty, N.; Kellogg, C.; Alvarez, J.; Equils, O.; Morgan, M. UV Protection by Natural Products: C. myrrha Oil Versus Sunscreen.Hamidpour, R.; Hamidpour, S.; Hamidpour, M.; Shahlari, M. Frankincense (ä¹³é¦™ RÇ” XiÄ\\x81ng;.species): From the selection of traditional applications to the novel phytotherapy for the prevention and treatment of serious diseases.Chemistry and immunomodulatory activity of frankincense oil.Compositions containing Boswellia extracts.; Cooper, E. Frankincense and myrrh as remedies in children.[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0',\n",
       " 'label': tensor(1)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on device: cuda:0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='765' max='765' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [765/765 06:21, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.769200</td>\n",
       "      <td>0.778653</td>\n",
       "      <td>0.673118</td>\n",
       "      <td>0.411317</td>\n",
       "      <td>0.614406</td>\n",
       "      <td>0.673118</td>\n",
       "      <td>0.616006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.609900</td>\n",
       "      <td>0.960694</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.498322</td>\n",
       "      <td>0.668539</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.611579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.397200</td>\n",
       "      <td>1.084009</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.488621</td>\n",
       "      <td>0.651662</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.646281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.110800</td>\n",
       "      <td>1.788725</td>\n",
       "      <td>0.636559</td>\n",
       "      <td>0.499299</td>\n",
       "      <td>0.655535</td>\n",
       "      <td>0.636559</td>\n",
       "      <td>0.645274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.136800</td>\n",
       "      <td>1.750001</td>\n",
       "      <td>0.623656</td>\n",
       "      <td>0.510631</td>\n",
       "      <td>0.659152</td>\n",
       "      <td>0.623656</td>\n",
       "      <td>0.633301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.065900</td>\n",
       "      <td>2.233890</td>\n",
       "      <td>0.623656</td>\n",
       "      <td>0.508203</td>\n",
       "      <td>0.653175</td>\n",
       "      <td>0.623656</td>\n",
       "      <td>0.632314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.075600</td>\n",
       "      <td>1.887571</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.506686</td>\n",
       "      <td>0.659779</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.647941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.040900</td>\n",
       "      <td>2.402378</td>\n",
       "      <td>0.634409</td>\n",
       "      <td>0.510619</td>\n",
       "      <td>0.651119</td>\n",
       "      <td>0.634409</td>\n",
       "      <td>0.636411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.030700</td>\n",
       "      <td>2.780239</td>\n",
       "      <td>0.634409</td>\n",
       "      <td>0.539350</td>\n",
       "      <td>0.682690</td>\n",
       "      <td>0.634409</td>\n",
       "      <td>0.649622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.053100</td>\n",
       "      <td>2.660303</td>\n",
       "      <td>0.634409</td>\n",
       "      <td>0.528891</td>\n",
       "      <td>0.679165</td>\n",
       "      <td>0.634409</td>\n",
       "      <td>0.650835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>2.714435</td>\n",
       "      <td>0.634409</td>\n",
       "      <td>0.504550</td>\n",
       "      <td>0.657412</td>\n",
       "      <td>0.634409</td>\n",
       "      <td>0.644036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>2.776117</td>\n",
       "      <td>0.636559</td>\n",
       "      <td>0.524606</td>\n",
       "      <td>0.669103</td>\n",
       "      <td>0.636559</td>\n",
       "      <td>0.649669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>2.761516</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.508823</td>\n",
       "      <td>0.660122</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.650510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>2.733659</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.507360</td>\n",
       "      <td>0.656506</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.648258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>2.755736</td>\n",
       "      <td>0.636559</td>\n",
       "      <td>0.505618</td>\n",
       "      <td>0.656916</td>\n",
       "      <td>0.636559</td>\n",
       "      <td>0.645037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.4_pubmedbert/checkpoint-51\n",
      "Configuration saved in /home/elson/1.2.4_pubmedbert/checkpoint-51/config.json\n",
      "Model weights saved in /home/elson/1.2.4_pubmedbert/checkpoint-51/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.2.4_pubmedbert/checkpoint-765] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.4_pubmedbert/checkpoint-102\n",
      "Configuration saved in /home/elson/1.2.4_pubmedbert/checkpoint-102/config.json\n",
      "Model weights saved in /home/elson/1.2.4_pubmedbert/checkpoint-102/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.4_pubmedbert/checkpoint-153\n",
      "Configuration saved in /home/elson/1.2.4_pubmedbert/checkpoint-153/config.json\n",
      "Model weights saved in /home/elson/1.2.4_pubmedbert/checkpoint-153/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.2.4_pubmedbert/checkpoint-102] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.4_pubmedbert/checkpoint-204\n",
      "Configuration saved in /home/elson/1.2.4_pubmedbert/checkpoint-204/config.json\n",
      "Model weights saved in /home/elson/1.2.4_pubmedbert/checkpoint-204/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.2.4_pubmedbert/checkpoint-153] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.4_pubmedbert/checkpoint-255\n",
      "Configuration saved in /home/elson/1.2.4_pubmedbert/checkpoint-255/config.json\n",
      "Model weights saved in /home/elson/1.2.4_pubmedbert/checkpoint-255/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.2.4_pubmedbert/checkpoint-204] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.4_pubmedbert/checkpoint-306\n",
      "Configuration saved in /home/elson/1.2.4_pubmedbert/checkpoint-306/config.json\n",
      "Model weights saved in /home/elson/1.2.4_pubmedbert/checkpoint-306/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.2.4_pubmedbert/checkpoint-255] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.4_pubmedbert/checkpoint-357\n",
      "Configuration saved in /home/elson/1.2.4_pubmedbert/checkpoint-357/config.json\n",
      "Model weights saved in /home/elson/1.2.4_pubmedbert/checkpoint-357/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.2.4_pubmedbert/checkpoint-306] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.4_pubmedbert/checkpoint-408\n",
      "Configuration saved in /home/elson/1.2.4_pubmedbert/checkpoint-408/config.json\n",
      "Model weights saved in /home/elson/1.2.4_pubmedbert/checkpoint-408/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.2.4_pubmedbert/checkpoint-357] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.4_pubmedbert/checkpoint-459\n",
      "Configuration saved in /home/elson/1.2.4_pubmedbert/checkpoint-459/config.json\n",
      "Model weights saved in /home/elson/1.2.4_pubmedbert/checkpoint-459/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.2.4_pubmedbert/checkpoint-408] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.4_pubmedbert/checkpoint-510\n",
      "Configuration saved in /home/elson/1.2.4_pubmedbert/checkpoint-510/config.json\n",
      "Model weights saved in /home/elson/1.2.4_pubmedbert/checkpoint-510/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.2.4_pubmedbert/checkpoint-459] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.4_pubmedbert/checkpoint-561\n",
      "Configuration saved in /home/elson/1.2.4_pubmedbert/checkpoint-561/config.json\n",
      "Model weights saved in /home/elson/1.2.4_pubmedbert/checkpoint-561/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.2.4_pubmedbert/checkpoint-510] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.4_pubmedbert/checkpoint-612\n",
      "Configuration saved in /home/elson/1.2.4_pubmedbert/checkpoint-612/config.json\n",
      "Model weights saved in /home/elson/1.2.4_pubmedbert/checkpoint-612/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.2.4_pubmedbert/checkpoint-561] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.4_pubmedbert/checkpoint-663\n",
      "Configuration saved in /home/elson/1.2.4_pubmedbert/checkpoint-663/config.json\n",
      "Model weights saved in /home/elson/1.2.4_pubmedbert/checkpoint-663/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.2.4_pubmedbert/checkpoint-612] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.4_pubmedbert/checkpoint-714\n",
      "Configuration saved in /home/elson/1.2.4_pubmedbert/checkpoint-714/config.json\n",
      "Model weights saved in /home/elson/1.2.4_pubmedbert/checkpoint-714/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.2.4_pubmedbert/checkpoint-663] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.4_pubmedbert/checkpoint-765\n",
      "Configuration saved in /home/elson/1.2.4_pubmedbert/checkpoint-765/config.json\n",
      "Model weights saved in /home/elson/1.2.4_pubmedbert/checkpoint-765/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.2.4_pubmedbert/checkpoint-714] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/elson/1.2.4_pubmedbert/checkpoint-51 (score: 0.6731182795698925).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /home/elson/1.2.4_pubmedbert/best_model/config.json\n",
      "Model weights saved in /home/elson/1.2.4_pubmedbert/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/1.2.4_pubmedbert/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/1.2.4_pubmedbert/best_model/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/1.2.4_pubmedbert/best_model/tokenizer_config.json',\n",
       " '/home/elson/1.2.4_pubmedbert/best_model/special_tokens_map.json',\n",
       " '/home/elson/1.2.4_pubmedbert/best_model/vocab.txt',\n",
       " '/home/elson/1.2.4_pubmedbert/best_model/added_tokens.json',\n",
       " '/home/elson/1.2.4_pubmedbert/best_model/tokenizer.json')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/1.2.4_pubmedbert/',\n",
    "    num_train_epochs=15,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.1,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(\"cuda:0\"),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "print(f\"Model is on device: {next(model.parameters()).device}\")\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/1.2.4_pubmedbert/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/1.2.4_pubmedbert/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cdee1665",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/1.2.4_pubmedbert/best_model/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"/home/elson/1.2.4_pubmedbert/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"contradiction\",\n",
      "    \"1\": \"entailment\",\n",
      "    \"2\": \"neutral\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"contradiction\": 0,\n",
      "    \"entailment\": 1,\n",
      "    \"neutral\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file /home/elson/1.2.4_pubmedbert/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at /home/elson/1.2.4_pubmedbert/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 32\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/1.2.4_pubmedbert/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[-0.1777  ,  0.1895  , -0.3682  ],\n",
      "       [-1.72    ,  1.304   , -0.597   ],\n",
      "       [-0.68    ,  0.9062  , -0.8325  ],\n",
      "       [ 0.3716  ,  0.3489  , -0.93    ],\n",
      "       [-0.9585  ,  1.001   , -0.9014  ],\n",
      "       [-2.586   ,  2.822   , -1.54    ],\n",
      "       [-0.7295  ,  0.7524  , -0.4414  ],\n",
      "       [-2.504   ,  1.6045  ,  0.10187 ],\n",
      "       [-2.236   ,  2.342   , -1.353   ],\n",
      "       [-1.306   ,  1.079   , -0.3472  ],\n",
      "       [-0.7817  ,  1.138   , -0.9873  ],\n",
      "       [-1.22    ,  1.68    , -1.31    ],\n",
      "       [-2.217   ,  1.878   , -0.6606  ],\n",
      "       [-2.223   ,  1.508   , -0.0645  ],\n",
      "       [-1.494   ,  0.8784  , -0.1423  ],\n",
      "       [ 1.591   , -0.2465  , -1.23    ],\n",
      "       [-2.36    ,  2.066   , -0.7354  ],\n",
      "       [-1.702   ,  1.286   , -0.408   ],\n",
      "       [-1.8     ,  2.057   , -1.187   ],\n",
      "       [-1.585   ,  1.623   , -1.052   ],\n",
      "       [-1.468   ,  1.089   , -0.3594  ],\n",
      "       [-1.251   ,  0.6772  , -0.1995  ],\n",
      "       [-1.138   ,  0.8843  , -0.3296  ],\n",
      "       [-0.2334  ,  0.3745  , -0.6104  ],\n",
      "       [ 0.0128  ,  0.1595  , -0.4707  ],\n",
      "       [ 0.7495  ,  0.252   , -1.193   ],\n",
      "       [-2.463   ,  2.479   , -1.223   ],\n",
      "       [-1.135   ,  0.9204  , -0.518   ],\n",
      "       [-1.853   ,  1.577   , -0.5605  ],\n",
      "       [-0.649   ,  1.065   , -1.016   ],\n",
      "       [-0.04938 ,  0.188   , -0.2737  ],\n",
      "       [-2.484   ,  2.752   , -1.527   ],\n",
      "       [-1.252   ,  1.545   , -1.076   ],\n",
      "       [-1.42    ,  0.693   ,  0.1458  ],\n",
      "       [-0.506   ,  0.8164  , -0.9727  ],\n",
      "       [-2.732   ,  3.19    , -1.744   ],\n",
      "       [-1.663   ,  1.429   , -0.7314  ],\n",
      "       [-0.3862  ,  1.313   , -1.397   ],\n",
      "       [ 1.196   , -0.08276 , -1.187   ],\n",
      "       [-3.209   ,  3.008   , -1.166   ],\n",
      "       [ 0.1305  ,  0.5415  , -1.03    ],\n",
      "       [-2.105   ,  2.062   , -0.9824  ],\n",
      "       [-0.03354 ,  0.507   , -0.733   ],\n",
      "       [-0.55    ,  0.5747  , -0.4368  ],\n",
      "       [-0.6343  ,  0.5947  , -0.569   ],\n",
      "       [-1.643   ,  1.279   , -0.4912  ],\n",
      "       [-0.1669  ,  0.729   , -0.981   ],\n",
      "       [-0.8657  ,  0.8125  , -0.6196  ],\n",
      "       [-0.934   ,  1.043   , -0.6567  ],\n",
      "       [ 0.9995  , -0.1687  , -0.752   ],\n",
      "       [-1.312   ,  0.8438  , -0.3428  ],\n",
      "       [-0.7246  ,  0.695   , -0.3237  ],\n",
      "       [-0.4475  ,  0.4788  , -0.2515  ],\n",
      "       [-2.94    ,  3.004   , -1.441   ],\n",
      "       [-0.1122  ,  0.2761  , -0.4795  ],\n",
      "       [-1.202   ,  1.205   , -0.8945  ],\n",
      "       [-0.007668,  0.274   , -0.5454  ],\n",
      "       [-2.59    ,  2.293   , -0.882   ],\n",
      "       [-0.937   ,  0.863   , -0.7285  ],\n",
      "       [-1.475   ,  1.71    , -1.108   ],\n",
      "       [-0.882   ,  0.655   , -0.2207  ],\n",
      "       [ 0.792   , -0.069   , -0.6826  ],\n",
      "       [-1.69    ,  1.273   , -0.1995  ],\n",
      "       [-0.9     ,  1.412   , -1.456   ],\n",
      "       [-2.068   ,  2.121   , -1.105   ],\n",
      "       [-1.506   ,  1.582   , -0.8745  ],\n",
      "       [-2.025   ,  2.428   , -1.623   ],\n",
      "       [-2.322   ,  2.805   , -1.757   ],\n",
      "       [-1.26    ,  1.305   , -0.722   ],\n",
      "       [ 0.801   , -0.2122  , -0.7334  ],\n",
      "       [-1.762   ,  1.073   ,  0.0191  ],\n",
      "       [-1.52    ,  0.5396  ,  0.5327  ],\n",
      "       [-2.219   ,  1.66    , -0.3416  ],\n",
      "       [-1.261   ,  0.8374  , -0.1255  ],\n",
      "       [-0.1327  ,  0.44    , -0.7593  ],\n",
      "       [-0.05087 ,  0.3208  , -0.508   ],\n",
      "       [-2.322   ,  2.254   , -0.9946  ],\n",
      "       [-1.258   ,  1.13    , -0.5996  ],\n",
      "       [-2.354   ,  2.441   , -1.283   ],\n",
      "       [-0.7295  ,  0.8755  , -0.4602  ],\n",
      "       [-2.127   ,  2.555   , -1.638   ],\n",
      "       [-1.263   ,  1.289   , -0.8325  ],\n",
      "       [-1.675   ,  1.77    , -0.9404  ],\n",
      "       [-2.14    ,  2.793   , -1.751   ],\n",
      "       [-1.675   ,  1.97    , -1.248   ],\n",
      "       [-0.07056 ,  0.3088  , -0.5234  ],\n",
      "       [-1.632   ,  1.638   , -0.8506  ],\n",
      "       [ 0.2625  ,  0.352   , -1.058   ],\n",
      "       [-0.8257  ,  0.6113  , -0.4565  ],\n",
      "       [-1.838   ,  0.275   ,  0.9287  ],\n",
      "       [-0.793   ,  0.9443  , -0.9023  ],\n",
      "       [-1.937   ,  1.578   , -0.744   ],\n",
      "       [-0.6606  ,  0.6855  , -0.431   ],\n",
      "       [-1.35    ,  1.186   , -0.643   ],\n",
      "       [-0.89    ,  1.433   , -1.206   ],\n",
      "       [-0.542   ,  0.6465  , -0.509   ],\n",
      "       [ 0.01445 ,  0.1109  , -0.106   ],\n",
      "       [-0.9785  ,  1.344   , -0.951   ],\n",
      "       [-1.99    ,  1.788   , -0.8525  ],\n",
      "       [-1.935   ,  1.861   , -0.879   ],\n",
      "       [ 1.507   , -0.1583  , -1.248   ],\n",
      "       [-2.486   ,  1.978   , -0.589   ],\n",
      "       [-3.168   ,  2.367   , -0.4736  ],\n",
      "       [-1.409   ,  1.201   , -0.6523  ],\n",
      "       [-0.643   ,  0.02905 , -0.01721 ],\n",
      "       [-2.191   ,  2.293   , -1.341   ],\n",
      "       [-1.439   ,  1.488   , -0.8735  ],\n",
      "       [-0.1945  ,  0.4146  , -0.5596  ],\n",
      "       [-1.339   ,  1.57    , -1.197   ],\n",
      "       [-2.336   ,  2.72    , -1.57    ],\n",
      "       [-1.833   ,  1.944   , -1.055   ],\n",
      "       [-1.951   ,  1.26    , -0.0967  ],\n",
      "       [-1.875   ,  1.999   , -1.064   ],\n",
      "       [-2.559   ,  2.41    , -0.8936  ],\n",
      "       [-2.312   ,  1.883   , -0.7017  ],\n",
      "       [-1.388   ,  1.312   , -0.629   ],\n",
      "       [-2.428   ,  2.545   , -1.144   ],\n",
      "       [-0.3643  ,  0.3     , -0.3142  ],\n",
      "       [-0.686   ,  1.078   , -1.012   ],\n",
      "       [-1.156   ,  1.019   , -0.504   ],\n",
      "       [-1.5625  ,  1.652   , -0.8745  ],\n",
      "       [-1.8955  ,  1.823   , -0.9097  ],\n",
      "       [-2.553   ,  2.709   , -1.36    ],\n",
      "       [-2.426   ,  2.664   , -1.625   ],\n",
      "       [-0.4934  ,  0.8555  , -0.98    ],\n",
      "       [-1.838   ,  2.137   , -1.234   ],\n",
      "       [-1.491   ,  1.159   , -0.3022  ],\n",
      "       [-1.688   ,  1.605   , -0.9165  ],\n",
      "       [-1.609   ,  0.5938  ,  0.4814  ],\n",
      "       [-1.683   ,  1.279   , -0.4146  ],\n",
      "       [-0.4526  ,  0.374   , -0.3318  ],\n",
      "       [ 0.669   ,  0.1252  , -0.9673  ],\n",
      "       [-1.658   ,  1.537   , -0.5327  ],\n",
      "       [-0.7134  ,  0.478   , -0.1616  ],\n",
      "       [-1.693   ,  1.499   , -0.6743  ],\n",
      "       [-0.91    ,  0.311   ,  0.1752  ],\n",
      "       [-0.4983  ,  0.659   , -0.4692  ],\n",
      "       [-0.524   ,  0.6177  , -0.605   ],\n",
      "       [-0.548   ,  0.65    , -0.544   ],\n",
      "       [-2.732   ,  2.295   , -0.726   ],\n",
      "       [-1.802   ,  1.707   , -0.9854  ],\n",
      "       [-0.8267  ,  0.582   , -0.0337  ],\n",
      "       [-0.9204  ,  0.399   ,  0.1323  ],\n",
      "       [-2.365   ,  2.44    , -1.286   ],\n",
      "       [ 0.191   ,  0.08716 , -0.5034  ],\n",
      "       [-0.7607  ,  0.7627  , -0.513   ],\n",
      "       [ 0.5786  ,  0.1267  , -1.068   ],\n",
      "       [ 0.4568  ,  0.3196  , -1.029   ],\n",
      "       [-0.9766  ,  1.09    , -0.8447  ],\n",
      "       [-0.601   ,  0.646   , -0.4246  ],\n",
      "       [-2.121   ,  1.773   , -0.6846  ],\n",
      "       [-0.4358  ,  0.7705  , -0.8647  ],\n",
      "       [-2.287   ,  2.096   , -0.7427  ],\n",
      "       [-1.579   ,  1.207   , -0.3318  ],\n",
      "       [-2.463   ,  2.564   , -1.3     ],\n",
      "       [-1.833   ,  1.905   , -1.055   ],\n",
      "       [-1.294   ,  1.827   , -1.438   ],\n",
      "       [-0.7705  ,  0.4124  , -0.1688  ],\n",
      "       [-0.419   ,  0.3206  , -0.1815  ],\n",
      "       [-0.0383  ,  0.696   , -0.897   ],\n",
      "       [ 0.0743  ,  0.2192  , -0.574   ],\n",
      "       [ 1.444   , -0.1451  , -1.302   ],\n",
      "       [-1.534   ,  0.892   , -0.1194  ],\n",
      "       [-0.1394  ,  0.1677  , -0.5283  ],\n",
      "       [ 0.1763  , -0.0481  , -0.2395  ],\n",
      "       [-1.522   ,  1.069   , -0.4482  ],\n",
      "       [-1.149   ,  0.7417  , -0.2208  ],\n",
      "       [-0.0943  ,  0.0602  , -0.1606  ],\n",
      "       [-0.4814  ,  0.6377  , -0.487   ],\n",
      "       [-0.698   ,  0.682   , -0.4321  ],\n",
      "       [ 0.223   ,  0.3577  , -0.8384  ],\n",
      "       [-0.59    ,  0.5835  , -0.3425  ],\n",
      "       [-0.0739  ,  0.4731  , -0.778   ],\n",
      "       [-2.668   ,  2.076   , -0.5493  ],\n",
      "       [-2.045   ,  1.935   , -0.9214  ],\n",
      "       [-0.036   ,  0.3337  , -0.6265  ],\n",
      "       [-1.882   ,  1.938   , -1.136   ],\n",
      "       [-0.0724  ,  0.4546  , -0.6777  ],\n",
      "       [-0.2169  ,  0.8096  , -1.027   ],\n",
      "       [-0.4382  ,  0.695   , -0.6196  ],\n",
      "       [ 0.1992  ,  0.3647  , -0.8413  ],\n",
      "       [-0.9785  ,  1.054   , -0.8403  ],\n",
      "       [ 1.153   , -0.141   , -1.009   ],\n",
      "       [-0.6597  ,  0.0715  ,  0.1616  ],\n",
      "       [-1.405   ,  1.013   , -0.3977  ],\n",
      "       [-2.016   ,  2.027   , -1.129   ],\n",
      "       [-1.402   ,  1.216   , -0.4824  ],\n",
      "       [-2.846   ,  2.479   , -0.8154  ],\n",
      "       [-1.073   ,  1.334   , -1.161   ],\n",
      "       [-1.669   ,  1.6     , -0.9106  ],\n",
      "       [-0.981   ,  0.9565  , -0.92    ],\n",
      "       [-1.159   ,  1.315   , -0.9053  ],\n",
      "       [-1.1455  ,  1.828   , -1.272   ],\n",
      "       [-1.434   ,  0.7744  ,  0.1133  ],\n",
      "       [ 0.7876  ,  0.2123  , -1.254   ],\n",
      "       [-1.82    ,  2.156   , -1.343   ],\n",
      "       [-0.4832  ,  0.766   , -0.908   ],\n",
      "       [-3.197   ,  2.523   , -0.5723  ],\n",
      "       [-0.683   ,  0.8975  , -0.8477  ],\n",
      "       [-1.518   ,  0.6855  ,  0.3071  ],\n",
      "       [-1.173   ,  1.539   , -0.967   ],\n",
      "       [-2.81    ,  3.123   , -1.535   ],\n",
      "       [-0.07983 , -0.1506  , -0.0825  ],\n",
      "       [-1.848   ,  1.576   , -0.8003  ],\n",
      "       [-1.06    ,  1.459   , -1.384   ],\n",
      "       [-0.227   ,  0.4695  , -0.642   ],\n",
      "       [-1.703   ,  1.601   , -0.89    ],\n",
      "       [-1.482   ,  1.096   , -0.2482  ],\n",
      "       [-2.521   ,  2.758   , -1.486   ],\n",
      "       [-1.26    ,  1.111   , -0.5527  ],\n",
      "       [-2.877   ,  2.857   , -1.228   ],\n",
      "       [-1.638   ,  0.9585  ,  0.0944  ],\n",
      "       [-1.446   ,  1.17    , -0.59    ],\n",
      "       [-1.132   ,  1.429   , -0.967   ],\n",
      "       [-1.491   ,  1.767   , -1.318   ],\n",
      "       [-1.255   ,  0.7285  , -0.0952  ],\n",
      "       [-0.6343  ,  0.4639  , -0.243   ],\n",
      "       [-1.184   ,  1.007   , -0.3728  ],\n",
      "       [-1.709   ,  1.946   , -1.239   ],\n",
      "       [-0.3572  ,  0.764   , -0.7085  ],\n",
      "       [-2.602   ,  2.479   , -1.114   ],\n",
      "       [-0.949   ,  1.245   , -0.9756  ],\n",
      "       [ 0.326   ,  0.0879  , -0.6187  ],\n",
      "       [-1.754   ,  1.761   , -1.093   ],\n",
      "       [-1.091   ,  1.291   , -0.968   ],\n",
      "       [-2.066   ,  2.756   , -1.827   ],\n",
      "       [-2.033   ,  2.482   , -1.69    ],\n",
      "       [-0.0341  ,  0.2379  , -0.6104  ],\n",
      "       [-1.002   ,  0.7095  , -0.43    ],\n",
      "       [ 0.05844 ,  0.0648  , -0.3247  ],\n",
      "       [-2.072   ,  1.873   , -0.771   ],\n",
      "       [-0.748   ,  0.3584  , -0.084   ],\n",
      "       [-1.33    ,  1.036   , -0.385   ],\n",
      "       [ 0.587   ,  0.10986 , -0.8022  ]], dtype=float16), label_ids=array([1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 2, 2, 1, 2, 1, 1, 2, 2,\n",
      "       1, 2, 0, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 0, 2, 1, 1,\n",
      "       1, 2, 1, 1, 1, 0, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 0, 2, 1, 2, 0,\n",
      "       1, 1, 0, 0, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       0, 2, 1, 2, 0, 1, 1, 1, 1, 1, 1, 2, 0, 2, 1, 2, 1, 1, 1, 2, 1, 1,\n",
      "       2, 1, 2, 1, 2, 1, 1, 1, 0, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 2, 1, 2, 1, 1, 1, 2, 0, 2, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2,\n",
      "       1, 1, 1, 2, 1, 0, 0, 0, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1,\n",
      "       1, 0, 1, 1, 1, 1, 0, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 0, 2, 1, 1, 1,\n",
      "       1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 0, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 0]), metrics={'test_loss': 0.855206310749054, 'test_accuracy': 0.6923076923076923, 'test_balanced_accuracy': 0.49159569099433603, 'test_precision': 0.6520499515310485, 'test_recall': 0.6923076923076923, 'test_f1': 0.6017383613537459, 'test_runtime': 1.2579, 'test_samples_per_second': 186.024, 'test_steps_per_second': 6.36})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be81d0c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "probabilities = torch.softmax(torch.tensor(test_results.predictions).to(torch.float32), dim=-1)\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)\n",
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef4c67fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_save = []\n",
    "for idx in range(len(test_data)):\n",
    "    item = dataset['test'][idx]\n",
    "    actual_label = item['label']\n",
    "    predicted_label = predictions[idx]\n",
    "    claim = item['claim'] \n",
    "    premise = item['premise'] \n",
    "    category = item['category']\n",
    "    \n",
    "    # Append the information as a dictionary to the list\n",
    "    data_to_save.append({\n",
    "        'Claim': claim,\n",
    "        'Premise': premise,\n",
    "        'Actual Label': actual_label,\n",
    "        'Predicted Label': predicted_label,\n",
    "        'Category' : category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_to_save)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/home/elson/results/1.2.4_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a1a63a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correctly classified instances\n",
    "correctly_classified = df[df['Actual Label'] == df['Predicted Label']]\n",
    "\n",
    "# Calculate misclassified instances\n",
    "misclassified = df[df['Actual Label'] != df['Predicted Label']]\n",
    "\n",
    "# Count the number of correctly classified and misclassified by category\n",
    "correct_classification_counts = correctly_classified['Category'].value_counts()\n",
    "misclassification_counts = misclassified['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c4055e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           34\n",
       "Fitness                  13\n",
       "Bone health              13\n",
       "Diabetes                 12\n",
       "Cancer                   12\n",
       "Skin                     11\n",
       "Cardiovascular Health     9\n",
       "Hair                      9\n",
       "Throat                    9\n",
       "Neurological health       8\n",
       "Eye                       7\n",
       "Ear                       6\n",
       "Women' s Health           5\n",
       "Blood                     4\n",
       "COVID                     4\n",
       "Mental Health             2\n",
       "Muscles                   2\n",
       "Vascular                  1\n",
       "Men's health              1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "117a1d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           17\n",
       "Skin                     13\n",
       "Bone health               8\n",
       "Men's health              5\n",
       "Blood                     5\n",
       "Muscles                   4\n",
       "Hair                      3\n",
       "Dental Health             3\n",
       "Cardiovascular Health     3\n",
       "Eye                       2\n",
       "Fitness                   2\n",
       "Vascular                  2\n",
       "COVID                     2\n",
       "Women' s Health           1\n",
       "Neurological health       1\n",
       "Mental Health             1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
