{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f38bead8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr 10 13:16:29 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:61:00.0 Off |                    0 |\n",
      "| N/A   38C    P0    56W / 300W |   3333MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  Off  | 00000000:62:00.0 Off |                    0 |\n",
      "| N/A   40C    P0    71W / 300W |  14325MiB / 32768MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  Off  | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   37C    P0    58W / 300W |   3253MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  Off  | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   38C    P0    58W / 300W |   3269MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     11098      C   ...A-AVD/venv_ava/bin/python     1665MiB |\n",
      "|    0   N/A  N/A     17092      C   ...A-AVD/venv_ava/bin/python     1665MiB |\n",
      "|    1   N/A  N/A     11098      C   ...A-AVD/venv_ava/bin/python     1711MiB |\n",
      "|    1   N/A  N/A     11099      C   ...A-AVD/venv_ava/bin/python     2027MiB |\n",
      "|    1   N/A  N/A     11102      C   ...A-AVD/venv_ava/bin/python     1711MiB |\n",
      "|    1   N/A  N/A     11110      C   ...A-AVD/venv_ava/bin/python     1711MiB |\n",
      "|    1   N/A  N/A     17092      C   ...A-AVD/venv_ava/bin/python     1711MiB |\n",
      "|    1   N/A  N/A     17093      C   ...A-AVD/venv_ava/bin/python     2027MiB |\n",
      "|    1   N/A  N/A     17096      C   ...A-AVD/venv_ava/bin/python     1711MiB |\n",
      "|    1   N/A  N/A     17099      C   ...A-AVD/venv_ava/bin/python     1711MiB |\n",
      "|    2   N/A  N/A     11102      C   ...A-AVD/venv_ava/bin/python     1625MiB |\n",
      "|    2   N/A  N/A     17096      C   ...A-AVD/venv_ava/bin/python     1625MiB |\n",
      "|    3   N/A  N/A     11110      C   ...A-AVD/venv_ava/bin/python     1633MiB |\n",
      "|    3   N/A  N/A     17099      C   ...A-AVD/venv_ava/bin/python     1633MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-0de7fefb79c820f5\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-0de7fefb79c820f5/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 169.53it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('csv',data_files='dataset_sentenceattribution_nerfeatures_split.csv',delimiter=',',column_names=[\"claim\",\"premise\",\"label\",\"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\",\"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\",\"url\", \"entities\",\"entity_map\",\"gem_exp\",\"gem_label\",\"gpt_label\",\"gpt_exp\",\"gold_exp\",\"entity_map_ev\",\"entity_ev\",\"split\"],skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6af125ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-0de7fefb79c820f5/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-10a7ef6573a18fe9.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-0de7fefb79c820f5/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-c7793ce5cc7c7dec.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-0de7fefb79c820f5/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-faa37bce70c041de.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01252e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\"claim\", \"premise\", \"label\",\"category\"]\n",
    "all_columns = dataset[\"train\"].column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-0de7fefb79c820f5/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-633f288d73a64f3c.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-0de7fefb79c820f5/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-08a0f0f39c1b67f2.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-0de7fefb79c820f5/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-dac24ed9a5b0ebc4.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 0, 'entailment': 1, 'neutral': 2}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 0,\n",
    "    \"entailment\": 1,\n",
    "    \"neutral\": 2\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e15010ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='pritamdeka/PubMedBERT-MNLI-MedNLI'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "        # Extracting claim and evidence texts\n",
    "        category = item['category'].lower()\n",
    "        claim = item['claim'].lower() + \"[\"+category+\"]\"\n",
    "        evidences = item['premise'].lower()\n",
    "        item['premise']=evidences\n",
    "        item['claim']=claim\n",
    "        item['category']=category\n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "            evidences,claim,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "        item['input_ids'] = inputs['input_ids'].squeeze()  # Remove batch dimension\n",
    "        item['attention_mask']= inputs['attention_mask'].squeeze() # Remove batch dimension\n",
    "        \n",
    "        if 'label' in item:\n",
    "            item['labels'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62421eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"pritamdeka/PubMedBERT-MNLI-MedNLI\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=512)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=3, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    return {\"accuracy\": acc, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f5cf584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'claim': 'myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.[general health]',\n",
       " 'premise': 'additionally, laser doppler blood flow measurement showed that the frankincense and myrrh essential oil compound could promote the elimination of capillaries from skin epidermis to dermis by increasing skin blood flow.',\n",
       " 'label': 1,\n",
       " 'category': 'general health',\n",
       " 'input_ids': tensor([    2,  4950,    16,  6033, 12255,  2877,  3426,  4783,  2594,  1988,\n",
       "          1920, 14542,  4006,  4480,  1930, 14227,  5004,  4415,  6691,  3547,\n",
       "          2578,  5527,  1920,  9570,  1927, 16973,  2037,  4407, 14512,  1942,\n",
       "         20201,  2007,  3605,  4407,  2877,  3426,    18,     3, 14227,  5004,\n",
       "          4415,  6691,  1977,  8929,  2251,  1922,  4407,  5715,  4461,  1942,\n",
       "          4087,  3326,  1920,  7818,  1927,  1920,  4407,    18,    37,  3335,\n",
       "          2436,    39,     3,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'labels': tensor(1)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1020\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1020' max='1020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1020/1020 08:23, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.749800</td>\n",
       "      <td>0.824989</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.688380</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.658133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.400300</td>\n",
       "      <td>1.168751</td>\n",
       "      <td>0.619355</td>\n",
       "      <td>0.688091</td>\n",
       "      <td>0.619355</td>\n",
       "      <td>0.645707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.128200</td>\n",
       "      <td>1.564065</td>\n",
       "      <td>0.670968</td>\n",
       "      <td>0.676421</td>\n",
       "      <td>0.670968</td>\n",
       "      <td>0.673122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.134900</td>\n",
       "      <td>1.485632</td>\n",
       "      <td>0.679570</td>\n",
       "      <td>0.694454</td>\n",
       "      <td>0.679570</td>\n",
       "      <td>0.682173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.031700</td>\n",
       "      <td>2.435629</td>\n",
       "      <td>0.604301</td>\n",
       "      <td>0.711089</td>\n",
       "      <td>0.604301</td>\n",
       "      <td>0.632049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.070800</td>\n",
       "      <td>2.155091</td>\n",
       "      <td>0.658065</td>\n",
       "      <td>0.683544</td>\n",
       "      <td>0.658065</td>\n",
       "      <td>0.665954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.012800</td>\n",
       "      <td>2.576158</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.698649</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.661293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>2.763661</td>\n",
       "      <td>0.647312</td>\n",
       "      <td>0.682660</td>\n",
       "      <td>0.647312</td>\n",
       "      <td>0.657699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.017400</td>\n",
       "      <td>2.781224</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.687596</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.665448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>2.803412</td>\n",
       "      <td>0.640860</td>\n",
       "      <td>0.694519</td>\n",
       "      <td>0.640860</td>\n",
       "      <td>0.654280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.700547</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.671683</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.668597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>2.785045</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.693406</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.666300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.714412</td>\n",
       "      <td>0.673118</td>\n",
       "      <td>0.679950</td>\n",
       "      <td>0.673118</td>\n",
       "      <td>0.675246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.774163</td>\n",
       "      <td>0.664516</td>\n",
       "      <td>0.677808</td>\n",
       "      <td>0.664516</td>\n",
       "      <td>0.670653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.757596</td>\n",
       "      <td>0.668817</td>\n",
       "      <td>0.698227</td>\n",
       "      <td>0.668817</td>\n",
       "      <td>0.680304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.696438</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.688388</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.680206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.759970</td>\n",
       "      <td>0.679570</td>\n",
       "      <td>0.703203</td>\n",
       "      <td>0.679570</td>\n",
       "      <td>0.688027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.771625</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.702019</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.686164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>2.785255</td>\n",
       "      <td>0.670968</td>\n",
       "      <td>0.689447</td>\n",
       "      <td>0.670968</td>\n",
       "      <td>0.678024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.789689</td>\n",
       "      <td>0.668817</td>\n",
       "      <td>0.686593</td>\n",
       "      <td>0.668817</td>\n",
       "      <td>0.675698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.1.2_pubmedbert/checkpoint-51\n",
      "Configuration saved in /home/elson/1.1.2_pubmedbert/checkpoint-51/config.json\n",
      "Model weights saved in /home/elson/1.1.2_pubmedbert/checkpoint-51/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.1.2_pubmedbert/checkpoint-102\n",
      "Configuration saved in /home/elson/1.1.2_pubmedbert/checkpoint-102/config.json\n",
      "Model weights saved in /home/elson/1.1.2_pubmedbert/checkpoint-102/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.1.2_pubmedbert/checkpoint-153\n",
      "Configuration saved in /home/elson/1.1.2_pubmedbert/checkpoint-153/config.json\n",
      "Model weights saved in /home/elson/1.1.2_pubmedbert/checkpoint-153/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.1.2_pubmedbert/checkpoint-51] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/1.1.2_pubmedbert/checkpoint-102] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.1.2_pubmedbert/checkpoint-204\n",
      "Configuration saved in /home/elson/1.1.2_pubmedbert/checkpoint-204/config.json\n",
      "Model weights saved in /home/elson/1.1.2_pubmedbert/checkpoint-204/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.1.2_pubmedbert/checkpoint-153] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.1.2_pubmedbert/checkpoint-255\n",
      "Configuration saved in /home/elson/1.1.2_pubmedbert/checkpoint-255/config.json\n",
      "Model weights saved in /home/elson/1.1.2_pubmedbert/checkpoint-255/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.1.2_pubmedbert/checkpoint-306\n",
      "Configuration saved in /home/elson/1.1.2_pubmedbert/checkpoint-306/config.json\n",
      "Model weights saved in /home/elson/1.1.2_pubmedbert/checkpoint-306/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.1.2_pubmedbert/checkpoint-255] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.1.2_pubmedbert/checkpoint-357\n",
      "Configuration saved in /home/elson/1.1.2_pubmedbert/checkpoint-357/config.json\n",
      "Model weights saved in /home/elson/1.1.2_pubmedbert/checkpoint-357/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.1.2_pubmedbert/checkpoint-306] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.1.2_pubmedbert/checkpoint-408\n",
      "Configuration saved in /home/elson/1.1.2_pubmedbert/checkpoint-408/config.json\n",
      "Model weights saved in /home/elson/1.1.2_pubmedbert/checkpoint-408/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.1.2_pubmedbert/checkpoint-357] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.1.2_pubmedbert/checkpoint-459\n",
      "Configuration saved in /home/elson/1.1.2_pubmedbert/checkpoint-459/config.json\n",
      "Model weights saved in /home/elson/1.1.2_pubmedbert/checkpoint-459/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.1.2_pubmedbert/checkpoint-408] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.1.2_pubmedbert/checkpoint-510\n",
      "Configuration saved in /home/elson/1.1.2_pubmedbert/checkpoint-510/config.json\n",
      "Model weights saved in /home/elson/1.1.2_pubmedbert/checkpoint-510/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.1.2_pubmedbert/checkpoint-459] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.1.2_pubmedbert/checkpoint-561\n",
      "Configuration saved in /home/elson/1.1.2_pubmedbert/checkpoint-561/config.json\n",
      "Model weights saved in /home/elson/1.1.2_pubmedbert/checkpoint-561/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.1.2_pubmedbert/checkpoint-510] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.1.2_pubmedbert/checkpoint-612\n",
      "Configuration saved in /home/elson/1.1.2_pubmedbert/checkpoint-612/config.json\n",
      "Model weights saved in /home/elson/1.1.2_pubmedbert/checkpoint-612/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.1.2_pubmedbert/checkpoint-561] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.1.2_pubmedbert/checkpoint-663\n",
      "Configuration saved in /home/elson/1.1.2_pubmedbert/checkpoint-663/config.json\n",
      "Model weights saved in /home/elson/1.1.2_pubmedbert/checkpoint-663/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.1.2_pubmedbert/checkpoint-612] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.1.2_pubmedbert/checkpoint-714\n",
      "Configuration saved in /home/elson/1.1.2_pubmedbert/checkpoint-714/config.json\n",
      "Model weights saved in /home/elson/1.1.2_pubmedbert/checkpoint-714/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.1.2_pubmedbert/checkpoint-663] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.1.2_pubmedbert/checkpoint-765\n",
      "Configuration saved in /home/elson/1.1.2_pubmedbert/checkpoint-765/config.json\n",
      "Model weights saved in /home/elson/1.1.2_pubmedbert/checkpoint-765/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.1.2_pubmedbert/checkpoint-714] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.1.2_pubmedbert/checkpoint-816\n",
      "Configuration saved in /home/elson/1.1.2_pubmedbert/checkpoint-816/config.json\n",
      "Model weights saved in /home/elson/1.1.2_pubmedbert/checkpoint-816/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.1.2_pubmedbert/checkpoint-765] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.1.2_pubmedbert/checkpoint-867\n",
      "Configuration saved in /home/elson/1.1.2_pubmedbert/checkpoint-867/config.json\n",
      "Model weights saved in /home/elson/1.1.2_pubmedbert/checkpoint-867/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.1.2_pubmedbert/checkpoint-816] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.1.2_pubmedbert/checkpoint-918\n",
      "Configuration saved in /home/elson/1.1.2_pubmedbert/checkpoint-918/config.json\n",
      "Model weights saved in /home/elson/1.1.2_pubmedbert/checkpoint-918/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.1.2_pubmedbert/checkpoint-867] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.1.2_pubmedbert/checkpoint-969\n",
      "Configuration saved in /home/elson/1.1.2_pubmedbert/checkpoint-969/config.json\n",
      "Model weights saved in /home/elson/1.1.2_pubmedbert/checkpoint-969/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.1.2_pubmedbert/checkpoint-918] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.1.2_pubmedbert/checkpoint-1020\n",
      "Configuration saved in /home/elson/1.1.2_pubmedbert/checkpoint-1020/config.json\n",
      "Model weights saved in /home/elson/1.1.2_pubmedbert/checkpoint-1020/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.1.2_pubmedbert/checkpoint-969] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/elson/1.1.2_pubmedbert/checkpoint-204 (score: 0.6795698924731183).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /home/elson/1.1.2_pubmedbert/best_model/config.json\n",
      "Model weights saved in /home/elson/1.1.2_pubmedbert/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/1.1.2_pubmedbert/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/1.1.2_pubmedbert/best_model/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/1.1.2_pubmedbert/best_model/tokenizer_config.json',\n",
       " '/home/elson/1.1.2_pubmedbert/best_model/special_tokens_map.json',\n",
       " '/home/elson/1.1.2_pubmedbert/best_model/vocab.txt',\n",
       " '/home/elson/1.1.2_pubmedbert/best_model/added_tokens.json',\n",
       " '/home/elson/1.1.2_pubmedbert/best_model/tokenizer.json')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/1.1.2_pubmedbert/',\n",
    "    num_train_epochs=20,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.06,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/1.1.2_pubmedbert/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/1.1.2_pubmedbert/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63deaea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/1.1.2_pubmedbert/best_model/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"/home/elson/1.1.2_pubmedbert/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"contradiction\",\n",
      "    \"1\": \"entailment\",\n",
      "    \"2\": \"neutral\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"contradiction\": 0,\n",
      "    \"entailment\": 1,\n",
      "    \"neutral\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file /home/elson/1.1.2_pubmedbert/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at /home/elson/1.1.2_pubmedbert/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 32\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/1.1.2_pubmedbert/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[ 2.418   , -0.921   , -1.403   ],\n",
      "       [-2.863   ,  5.11    , -3.275   ],\n",
      "       [-1.993   ,  4.473   , -3.326   ],\n",
      "       [ 4.652   , -0.3079  , -3.459   ],\n",
      "       [ 1.73    ,  2.059   , -4.504   ],\n",
      "       [-2.729   ,  5.22    , -3.47    ],\n",
      "       [-2.814   ,  4.78    , -2.842   ],\n",
      "       [-3.143   ,  4.547   , -2.443   ],\n",
      "       [-3.055   ,  5.125   , -3.197   ],\n",
      "       [ 1.725   ,  1.75    , -3.6     ],\n",
      "       [ 0.2537  ,  2.7     , -3.484   ],\n",
      "       [-2.787   ,  5.223   , -3.367   ],\n",
      "       [-2.61    ,  4.84    , -3.043   ],\n",
      "       [-3.004   ,  4.9     , -2.824   ],\n",
      "       [-2.713   ,  5.227   , -3.33    ],\n",
      "       [ 1.863   ,  1.553   , -3.734   ],\n",
      "       [-3.684   ,  4.83    , -2.553   ],\n",
      "       [-1.705   ,  1.474   , -0.331   ],\n",
      "       [-2.703   ,  5.156   , -3.316   ],\n",
      "       [-3.23    ,  5.344   , -3.252   ],\n",
      "       [-2.1     ,  3.885   , -2.732   ],\n",
      "       [-1.291   ,  3.773   , -3.248   ],\n",
      "       [-0.4106  ,  2.146   , -2.047   ],\n",
      "       [ 3.67    , -0.02466 , -3.52    ],\n",
      "       [ 4.05    , -1.202   , -2.25    ],\n",
      "       [ 4.6     , -1.356   , -1.942   ],\n",
      "       [-2.516   ,  5.254   , -3.516   ],\n",
      "       [-3.418   ,  4.945   , -2.598   ],\n",
      "       [-2.156   ,  2.967   , -1.819   ],\n",
      "       [-2.922   ,  4.7     , -2.857   ],\n",
      "       [ 1.539   , -0.9136  , -0.547   ],\n",
      "       [-2.336   ,  4.83    , -3.342   ],\n",
      "       [-2.877   ,  5.223   , -3.254   ],\n",
      "       [-0.604   ,  0.06097 ,  0.1965  ],\n",
      "       [-1.723   ,  4.203   , -3.281   ],\n",
      "       [-3.469   ,  5.17    , -2.95    ],\n",
      "       [-2.682   ,  5.13    , -3.412   ],\n",
      "       [-2.904   ,  5.246   , -3.24    ],\n",
      "       [ 4.652   , -0.41    , -3.506   ],\n",
      "       [-3.854   ,  5.02    , -2.453   ],\n",
      "       [ 4.56    ,  0.014595, -4.01    ],\n",
      "       [-3.879   ,  3.51    , -1.042   ],\n",
      "       [-0.343   ,  3.395   , -3.645   ],\n",
      "       [ 4.54    , -0.6255  , -3.148   ],\n",
      "       [-1.603   ,  4.418   , -3.53    ],\n",
      "       [-3.191   ,  4.965   , -2.945   ],\n",
      "       [ 2.916   ,  0.9023  , -3.688   ],\n",
      "       [-3.203   ,  5.14    , -3.1     ],\n",
      "       [-2.094   ,  4.92    , -3.799   ],\n",
      "       [ 3.979   , -0.4983  , -2.611   ],\n",
      "       [-0.8467  ,  3.133   , -3.17    ],\n",
      "       [ 1.338   , -0.2162  , -0.999   ],\n",
      "       [ 0.5605  ,  3.027   , -4.027   ],\n",
      "       [-0.352   ,  1.343   , -1.408   ],\n",
      "       [ 4.742   , -1.067   , -2.824   ],\n",
      "       [-3.21    ,  5.324   , -3.23    ],\n",
      "       [ 2.314   ,  0.7407  , -3.09    ],\n",
      "       [-3.064   ,  3.432   , -1.71    ],\n",
      "       [-3.074   ,  5.277   , -3.328   ],\n",
      "       [-3.357   ,  5.35    , -3.088   ],\n",
      "       [-1.819   ,  4.11    , -3.242   ],\n",
      "       [ 4.52    , -0.2374  , -3.56    ],\n",
      "       [-1.205   ,  1.869   , -1.247   ],\n",
      "       [ 2.316   ,  1.677   , -4.297   ],\n",
      "       [-2.719   , -0.11285 ,  2.69    ],\n",
      "       [-2.053   ,  4.83    , -3.748   ],\n",
      "       [-2.455   ,  5.04    , -3.379   ],\n",
      "       [-2.805   ,  5.156   , -3.254   ],\n",
      "       [ 0.3276  ,  2.777   , -3.578   ],\n",
      "       [ 3.41    , -0.71    , -2.443   ],\n",
      "       [-1.52    ,  3.865   , -3.018   ],\n",
      "       [-2.68    ,  4.645   , -2.834   ],\n",
      "       [-3.566   ,  1.562   ,  1.292   ],\n",
      "       [-1.0625  ,  3.582   , -3.059   ],\n",
      "       [ 2.047   ,  1.083   , -3.066   ],\n",
      "       [-1.932   ,  4.57    , -3.51    ],\n",
      "       [-2.705   ,  5.32    , -3.416   ],\n",
      "       [-2.348   ,  4.664   , -3.117   ],\n",
      "       [-2.754   ,  5.21    , -3.387   ],\n",
      "       [-0.4097  ,  2.473   , -2.541   ],\n",
      "       [-2.578   ,  5.145   , -3.37    ],\n",
      "       [-2.436   ,  4.957   , -3.402   ],\n",
      "       [-3.021   ,  4.594   , -2.662   ],\n",
      "       [-2.496   ,  5.305   , -3.709   ],\n",
      "       [-2.441   ,  4.977   , -3.354   ],\n",
      "       [ 3.2     , -2.03    , -0.389   ],\n",
      "       [-2.22    ,  5.062   , -3.564   ],\n",
      "       [ 0.889   ,  2.688   , -4.12    ],\n",
      "       [-2.193   ,  4.258   , -3.107   ],\n",
      "       [-1.205   ,  1.869   , -1.247   ],\n",
      "       [-2.574   ,  4.83    , -3.219   ],\n",
      "       [-2.688   ,  5.06    , -3.357   ],\n",
      "       [ 4.77    , -0.521   , -3.383   ],\n",
      "       [-2.979   ,  5.08    , -3.076   ],\n",
      "       [-1.237   ,  4.285   , -3.576   ],\n",
      "       [-0.5015  ,  3.48    , -3.64    ],\n",
      "       [ 0.43    ,  2.875   , -3.77    ],\n",
      "       [ 2.203   ,  1.235   , -3.248   ],\n",
      "       [-1.998   ,  4.836   , -3.682   ],\n",
      "       [-3.258   ,  3.258   , -1.092   ],\n",
      "       [ 4.19    ,  0.185   , -3.623   ],\n",
      "       [-1.43    , -0.168   ,  1.278   ],\n",
      "       [-2.74    ,  5.33    , -3.424   ],\n",
      "       [-3.602   ,  0.7974  ,  2.318   ],\n",
      "       [-3.45    ,  5.14    , -2.736   ],\n",
      "       [-2.812   ,  5.098   , -3.25    ],\n",
      "       [ 0.6514  ,  2.914   , -4.344   ],\n",
      "       [-0.5312  ,  2.586   , -2.553   ],\n",
      "       [-2.717   ,  4.99    , -3.281   ],\n",
      "       [-2.145   ,  4.965   , -3.602   ],\n",
      "       [-1.692   ,  3.73    , -2.8     ],\n",
      "       [-3.055   ,  5.113   , -2.965   ],\n",
      "       [-3.328   ,  5.082   , -2.857   ],\n",
      "       [-2.781   ,  5.242   , -3.422   ],\n",
      "       [-3.754   ,  4.79    , -2.32    ],\n",
      "       [-2.52    ,  4.953   , -3.295   ],\n",
      "       [-2.76    ,  5.156   , -3.354   ],\n",
      "       [-1.134   ,  1.765   , -1.076   ],\n",
      "       [-0.4414  ,  3.314   , -3.6     ],\n",
      "       [-2.424   ,  4.97    , -3.521   ],\n",
      "       [-2.854   ,  4.793   , -3.025   ],\n",
      "       [-2.242   ,  4.914   , -3.48    ],\n",
      "       [-3.043   ,  2.99    , -1.2705  ],\n",
      "       [-2.734   ,  4.707   , -3.193   ],\n",
      "       [-3.146   ,  5.258   , -3.213   ],\n",
      "       [-1.727   ,  4.824   , -3.75    ],\n",
      "       [ 1.627   ,  0.4583  , -2.08    ],\n",
      "       [-3.451   ,  5.24    , -3.021   ],\n",
      "       [-1.599   ,  3.89    , -2.824   ],\n",
      "       [-0.3408  ,  2.814   , -2.822   ],\n",
      "       [ 2.396   ,  1.207   , -3.654   ],\n",
      "       [ 3.033   , -1.41    , -1.173   ],\n",
      "       [-2.217   ,  4.664   , -3.22    ],\n",
      "       [ 3.35    , -1.572   , -1.125   ],\n",
      "       [ 1.168   ,  1.274   , -2.879   ],\n",
      "       [-2.7     ,  5.01    , -3.309   ],\n",
      "       [ 0.845   ,  1.006   , -1.861   ],\n",
      "       [ 4.65    , -0.6455  , -3.186   ],\n",
      "       [ 3.32    ,  0.54    , -3.568   ],\n",
      "       [-3.209   ,  5.41    , -3.201   ],\n",
      "       [-2.895   ,  5.266   , -3.275   ],\n",
      "       [-0.0269  ,  1.662   , -1.954   ],\n",
      "       [ 0.01787 , -0.931   ,  0.899   ],\n",
      "       [-2.418   ,  5.11    , -3.508   ],\n",
      "       [ 2.648   ,  0.2069  , -2.44    ],\n",
      "       [-3.22    ,  4.133   , -2.166   ],\n",
      "       [ 3.574   ,  0.9365  , -4.266   ],\n",
      "       [ 3.234   ,  0.397   , -3.424   ],\n",
      "       [-2.729   ,  5.12    , -3.422   ],\n",
      "       [ 2.006   ,  1.569   , -3.857   ],\n",
      "       [ 1.076   ,  1.088   , -2.28    ],\n",
      "       [-2.412   ,  4.445   , -3.016   ],\n",
      "       [-3.662   ,  4.527   , -2.111   ],\n",
      "       [-3.322   ,  5.      , -2.775   ],\n",
      "       [-2.396   ,  4.938   , -3.494   ],\n",
      "       [-2.87    ,  5.16    , -3.3     ],\n",
      "       [-0.643   ,  4.1     , -4.11    ],\n",
      "       [-2.688   ,  4.977   , -3.309   ],\n",
      "       [ 1.877   , -1.591   ,  0.7134  ],\n",
      "       [ 3.865   ,  0.833   , -4.29    ],\n",
      "       [ 4.332   , -1.164   , -1.971   ],\n",
      "       [ 4.89    , -0.3943  , -3.51    ],\n",
      "       [-2.498   ,  4.91    , -3.338   ],\n",
      "       [ 2.623   , -0.308   , -2.094   ],\n",
      "       [-1.827   ,  4.242   , -3.152   ],\n",
      "       [-1.615   ,  2.87    , -2.262   ],\n",
      "       [-1.244   ,  3.73    , -3.145   ],\n",
      "       [ 3.264   ,  1.036   , -4.395   ],\n",
      "       [ 4.004   , -0.5244  , -2.727   ],\n",
      "       [ 0.888   ,  1.947   , -3.314   ],\n",
      "       [ 4.402   , -0.865   , -2.555   ],\n",
      "       [-0.8516  ,  3.648   , -3.377   ],\n",
      "       [ 1.647   , -0.579   , -0.8433  ],\n",
      "       [-3.193   ,  5.418   , -3.129   ],\n",
      "       [-2.049   ,  4.625   , -3.373   ],\n",
      "       [ 1.1     ,  0.7275  , -2.242   ],\n",
      "       [-2.432   ,  5.082   , -3.504   ],\n",
      "       [ 3.922   , -1.019   , -2.502   ],\n",
      "       [-1.952   ,  4.797   , -3.6     ],\n",
      "       [ 2.432   ,  0.9146  , -3.22    ],\n",
      "       [ 3.557   ,  0.773   , -4.1     ],\n",
      "       [ 1.357   ,  1.394   , -3.125   ],\n",
      "       [ 4.727   , -0.75    , -3.248   ],\n",
      "       [ 1.72    , -0.3423  , -1.485   ],\n",
      "       [-0.3127  ,  2.998   , -3.518   ],\n",
      "       [-2.666   ,  5.13    , -3.363   ],\n",
      "       [-2.191   ,  4.53    , -3.092   ],\n",
      "       [-2.904   ,  4.9     , -3.078   ],\n",
      "       [-0.28    ,  3.43    , -4.14    ],\n",
      "       [-3.28    ,  5.33    , -2.965   ],\n",
      "       [ 1.453   ,  1.415   , -3.475   ],\n",
      "       [-2.148   ,  3.646   , -2.244   ],\n",
      "       [-1.666   ,  3.992   , -2.857   ],\n",
      "       [-3.312   ,  3.498   , -1.375   ],\n",
      "       [ 4.29    , -0.03026 , -3.61    ],\n",
      "       [-2.537   ,  5.027   , -3.5     ],\n",
      "       [-2.232   ,  4.34    , -3.164   ],\n",
      "       [-3.111   ,  5.4     , -3.252   ],\n",
      "       [-2.373   ,  5.184   , -3.756   ],\n",
      "       [-2.533   ,  4.574   , -2.73    ],\n",
      "       [-2.064   ,  4.625   , -3.299   ],\n",
      "       [-2.639   ,  5.094   , -3.24    ],\n",
      "       [ 2.574   , -0.575   , -1.843   ],\n",
      "       [-3.375   ,  5.363   , -3.012   ],\n",
      "       [-1.376   ,  4.125   , -3.473   ],\n",
      "       [ 3.965   , -0.7686  , -2.754   ],\n",
      "       [-3.223   ,  5.305   , -3.188   ],\n",
      "       [-3.537   ,  3.973   , -1.358   ],\n",
      "       [-3.15    ,  5.39    , -3.361   ],\n",
      "       [-1.857   ,  4.312   , -3.002   ],\n",
      "       [-1.35    ,  3.531   , -2.715   ],\n",
      "       [-3.041   ,  4.883   , -2.752   ],\n",
      "       [-2.58    ,  5.184   , -3.484   ],\n",
      "       [-2.5     ,  4.836   , -3.354   ],\n",
      "       [-2.498   ,  5.12    , -3.48    ],\n",
      "       [ 2.16    , -1.142   , -0.5093  ],\n",
      "       [ 0.8945  , -0.08704 , -0.891   ],\n",
      "       [ 4.258   , -1.19    , -1.946   ],\n",
      "       [-2.633   ,  4.97    , -3.404   ],\n",
      "       [ 2.764   ,  0.3223  , -2.893   ],\n",
      "       [-2.643   ,  5.156   , -3.469   ],\n",
      "       [-2.842   ,  5.24    , -3.322   ],\n",
      "       [-1.002   ,  4.023   , -3.697   ],\n",
      "       [-2.535   ,  5.043   , -3.41    ],\n",
      "       [-2.357   ,  5.023   , -3.447   ],\n",
      "       [-2.69    ,  5.15    , -3.396   ],\n",
      "       [-2.637   ,  5.258   , -3.47    ],\n",
      "       [ 0.773   ,  1.808   , -3.268   ],\n",
      "       [ 0.5435  ,  0.788   , -2.12    ],\n",
      "       [-1.137   ,  1.921   , -1.279   ],\n",
      "       [-2.422   ,  5.22    , -3.602   ],\n",
      "       [-2.904   ,  4.914   , -3.057   ],\n",
      "       [-2.41    ,  5.008   , -3.44    ],\n",
      "       [ 4.75    , -1.308   , -2.166   ]], dtype=float16), label_ids=array([1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 0,\n",
      "       1, 2, 0, 0, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 0, 2, 1, 1,\n",
      "       1, 0, 1, 1, 0, 0, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 0, 2, 1, 2, 0,\n",
      "       1, 1, 0, 0, 1, 1, 2, 2, 1, 0, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1,\n",
      "       0, 2, 1, 1, 0, 1, 1, 1, 0, 1, 1, 2, 0, 2, 1, 2, 1, 1, 1, 2, 1, 1,\n",
      "       2, 1, 2, 1, 2, 1, 1, 1, 0, 0, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 2, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2,\n",
      "       1, 1, 1, 2, 1, 0, 0, 0, 1, 1, 1, 2, 1, 1, 0, 1, 0, 1, 2, 1, 1, 1,\n",
      "       1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 1, 2, 1, 1, 1, 1, 2, 2, 0, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 0, 1, 1, 0]), metrics={'test_loss': 1.7478407621383667, 'test_accuracy': 0.6367521367521367, 'test_precision': 0.6379468348868593, 'test_recall': 0.6367521367521367, 'test_f1': 0.5956834818999482, 'test_runtime': 1.1324, 'test_samples_per_second': 206.638, 'test_steps_per_second': 7.065})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd70dbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f647b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = torch.softmax(torch.tensor(test_results.predictions).to(torch.float32), dim=-1)\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f215e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "66aa90f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_save = []\n",
    "for idx in range(len(test_data)):\n",
    "    item = test_data.__getitem__(idx)\n",
    "    actual_label = item['label']\n",
    "    predicted_label = predictions[idx]\n",
    "    claim = item['claim'] \n",
    "    premise = item['premise'] \n",
    "    category = item['category']\n",
    "    \n",
    "    # Append the information as a dictionary to the list\n",
    "    data_to_save.append({\n",
    "        'Claim': claim,\n",
    "        'Premise': premise,\n",
    "        'Actual Label': actual_label,\n",
    "        'Predicted Label': predicted_label,\n",
    "        'Category' : category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_to_save)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/home/elson/results/1.1.2_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fba2eff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Claim</th>\n",
       "      <th>Premise</th>\n",
       "      <th>Actual Label</th>\n",
       "      <th>Predicted Label</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>covid-19 vaccines are safe &amp; were reviewed by ...</td>\n",
       "      <td>although covid-19 vaccines have been proven to...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>blood clots can be prevented.[blood]</td>\n",
       "      <td>prevent blood clots and improve survival.</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>blood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a platelet transfusion is a procedure in which...</td>\n",
       "      <td>platelet transfusion is a lifesaving procedure...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>blood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>osteoporosis is a condition that affects only ...</td>\n",
       "      <td>improvements have been made in detection and m...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bone health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nearly 1 in 5 people experience some type of a...</td>\n",
       "      <td>reported that women suffer from anxiety disord...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>fitness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Claim  \\\n",
       "0  covid-19 vaccines are safe & were reviewed by ...   \n",
       "1               blood clots can be prevented.[blood]   \n",
       "2  a platelet transfusion is a procedure in which...   \n",
       "3  osteoporosis is a condition that affects only ...   \n",
       "4  nearly 1 in 5 people experience some type of a...   \n",
       "\n",
       "                                             Premise  Actual Label  \\\n",
       "0  although covid-19 vaccines have been proven to...             1   \n",
       "1          prevent blood clots and improve survival.             2   \n",
       "2  platelet transfusion is a lifesaving procedure...             1   \n",
       "3  improvements have been made in detection and m...             0   \n",
       "4  reported that women suffer from anxiety disord...             1   \n",
       "\n",
       "   Predicted Label     Category  \n",
       "0                0        covid  \n",
       "1                1        blood  \n",
       "2                1        blood  \n",
       "3                0  bone health  \n",
       "4                1      fitness  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2b6dbb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correctly classified instances\n",
    "correctly_classified = df[df['Actual Label'] == df['Predicted Label']]\n",
    "\n",
    "# Calculate misclassified instances\n",
    "misclassified = df[df['Actual Label'] != df['Predicted Label']]\n",
    "\n",
    "# Count the number of correctly classified and misclassified by category\n",
    "correct_classification_counts = correctly_classified['Category'].value_counts()\n",
    "misclassification_counts = misclassified['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a98b515c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "general health           33\n",
       "bone health              15\n",
       "fitness                  13\n",
       "cardiovascular health    12\n",
       "cancer                   12\n",
       "throat                    8\n",
       "eye                       8\n",
       "skin                      8\n",
       "neurological health       7\n",
       "hair                      6\n",
       "ear                       6\n",
       "diabetes                  6\n",
       "mental health             3\n",
       "men's health              3\n",
       "women' s health           3\n",
       "blood                     3\n",
       "covid                     2\n",
       "dental health             1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5dfa8d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "general health         18\n",
       "skin                   16\n",
       "diabetes                6\n",
       "hair                    6\n",
       "bone health             6\n",
       "muscles                 6\n",
       "blood                   6\n",
       "covid                   4\n",
       "men's health            3\n",
       "women' s health         3\n",
       "vascular                3\n",
       "fitness                 2\n",
       "dental health           2\n",
       "neurological health     2\n",
       "eye                     1\n",
       "throat                  1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
