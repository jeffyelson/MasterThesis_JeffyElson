{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-022bc67e9c58e92d\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 217.02it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('csv',data_files='dataset_propositionattribution_nerfeatures.csv',delimiter=',',column_names=[\"claim\",\"premise\",\"label\",\"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\",\"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\",\"url\", \"entities\",\"entity_map\",\"entity_map_ev\",\"entities_ev\",\"gem_exp\",\"gem_label\",\"gpt_label\",\"gpt_exp\",\"gold_exp\",\"synonym\",\"voice\",\"split\"],skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "133f9357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-2b8e361375c0e153.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-0cc9bb699c2761fb.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-608a44ac65076739.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01252e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\"claim\", \"premise\", \"label\",\"category\"]\n",
    "all_columns = dataset[\"train\"].column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1623/1623 [00:00<00:00, 7013.36ex/s]\n",
      "100%|██████████| 465/465 [00:00<00:00, 7464.15ex/s]\n",
      "100%|██████████| 234/234 [00:00<00:00, 6870.04ex/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 0, 'entailment': 1, 'neutral': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 0,\n",
    "    \"entailment\": 1,\n",
    "    \"neutral\": 2\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='pritamdeka/PubMedBERT-MNLI-MedNLI'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "        # Extracting claim and evidence texts\n",
    "\n",
    "        claim = item['claim'].lower()\n",
    "        evidences = item['premise'].lower()\n",
    "        item['premise']=evidences\n",
    "        item['claim']=claim\n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "            evidences, claim,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "        item['input_ids'] = inputs['input_ids'].squeeze()  # Remove batch dimension\n",
    "        item['attention_mask']= inputs['attention_mask'].squeeze() # Remove batch dimension\n",
    "        \n",
    "        if 'label' in item:\n",
    "            item['labels'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62421eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"pritamdeka/PubMedBERT-MNLI-MedNLI\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=512)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=3, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    return {\"accuracy\": acc, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f5cf584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'claim': 'myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.',\n",
       " 'premise': 'the essential oils of frankincense and myrrh increase the fluidity of the lipid bilayer in the cuticle and change the orderly and dense structure to increase the permeability of the skin and decrease the barrier effect.',\n",
       " 'label': 1,\n",
       " 'category': 'General Health',\n",
       " 'input_ids': tensor([    2,  1920,  4415, 16984,  1927, 14542,  4006,  4480,  1930, 14227,\n",
       "          5004,  2760,  1920, 29555,  1927,  1920,  4486, 14269,  1922,  1920,\n",
       "         25420,  1930,  3185,  1920,  3238,  1954,  1930, 10472,  3170,  1942,\n",
       "          2760,  1920,  8828,  1927,  1920,  4407,  1930,  3714,  1920,  7104,\n",
       "          2495,    18,     3, 14227,  5004,  4415,  6691,  1977,  8929,  2251,\n",
       "          1922,  4407,  5715,  4461,  1942,  4087,  3326,  1920,  7818,  1927,\n",
       "          1920,  4407,    18,     3,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'labels': tensor(1)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1020\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1020' max='1020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1020/1020 08:20, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.838500</td>\n",
       "      <td>0.793729</td>\n",
       "      <td>0.647312</td>\n",
       "      <td>0.614435</td>\n",
       "      <td>0.647312</td>\n",
       "      <td>0.620473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.673400</td>\n",
       "      <td>0.950272</td>\n",
       "      <td>0.563441</td>\n",
       "      <td>0.656870</td>\n",
       "      <td>0.563441</td>\n",
       "      <td>0.592535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.391900</td>\n",
       "      <td>1.059528</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.639256</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.638444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.184500</td>\n",
       "      <td>1.346888</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.672874</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.633876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.234900</td>\n",
       "      <td>1.388367</td>\n",
       "      <td>0.610753</td>\n",
       "      <td>0.644720</td>\n",
       "      <td>0.610753</td>\n",
       "      <td>0.623139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.157000</td>\n",
       "      <td>1.690272</td>\n",
       "      <td>0.623656</td>\n",
       "      <td>0.631547</td>\n",
       "      <td>0.623656</td>\n",
       "      <td>0.626914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.113600</td>\n",
       "      <td>1.659551</td>\n",
       "      <td>0.627957</td>\n",
       "      <td>0.661051</td>\n",
       "      <td>0.627957</td>\n",
       "      <td>0.636480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.096700</td>\n",
       "      <td>1.853486</td>\n",
       "      <td>0.627957</td>\n",
       "      <td>0.674605</td>\n",
       "      <td>0.627957</td>\n",
       "      <td>0.644568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.062400</td>\n",
       "      <td>2.055904</td>\n",
       "      <td>0.627957</td>\n",
       "      <td>0.657280</td>\n",
       "      <td>0.627957</td>\n",
       "      <td>0.633175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.068200</td>\n",
       "      <td>2.102209</td>\n",
       "      <td>0.627957</td>\n",
       "      <td>0.660135</td>\n",
       "      <td>0.627957</td>\n",
       "      <td>0.639887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.062700</td>\n",
       "      <td>2.180704</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.649244</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.646110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.045600</td>\n",
       "      <td>2.321527</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.657087</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.645571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.016400</td>\n",
       "      <td>2.506276</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>0.653262</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>0.636974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.025200</td>\n",
       "      <td>2.552186</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.658412</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.653572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.017700</td>\n",
       "      <td>2.718505</td>\n",
       "      <td>0.623656</td>\n",
       "      <td>0.662830</td>\n",
       "      <td>0.623656</td>\n",
       "      <td>0.638262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>2.697586</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.653408</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.644970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>2.748299</td>\n",
       "      <td>0.632258</td>\n",
       "      <td>0.652485</td>\n",
       "      <td>0.632258</td>\n",
       "      <td>0.640386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>2.790257</td>\n",
       "      <td>0.634409</td>\n",
       "      <td>0.661199</td>\n",
       "      <td>0.634409</td>\n",
       "      <td>0.645355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>2.765861</td>\n",
       "      <td>0.636559</td>\n",
       "      <td>0.654096</td>\n",
       "      <td>0.636559</td>\n",
       "      <td>0.643742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>2.763245</td>\n",
       "      <td>0.636559</td>\n",
       "      <td>0.653989</td>\n",
       "      <td>0.636559</td>\n",
       "      <td>0.643768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.1_pubmedbert/checkpoint-51\n",
      "Configuration saved in /home/elson/1.4.1_pubmedbert/checkpoint-51/config.json\n",
      "Model weights saved in /home/elson/1.4.1_pubmedbert/checkpoint-51/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.1_pubmedbert/checkpoint-867] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/1.4.1_pubmedbert/checkpoint-1020] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.1_pubmedbert/checkpoint-102\n",
      "Configuration saved in /home/elson/1.4.1_pubmedbert/checkpoint-102/config.json\n",
      "Model weights saved in /home/elson/1.4.1_pubmedbert/checkpoint-102/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.1_pubmedbert/checkpoint-153\n",
      "Configuration saved in /home/elson/1.4.1_pubmedbert/checkpoint-153/config.json\n",
      "Model weights saved in /home/elson/1.4.1_pubmedbert/checkpoint-153/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.1_pubmedbert/checkpoint-102] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.1_pubmedbert/checkpoint-204\n",
      "Configuration saved in /home/elson/1.4.1_pubmedbert/checkpoint-204/config.json\n",
      "Model weights saved in /home/elson/1.4.1_pubmedbert/checkpoint-204/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.1_pubmedbert/checkpoint-153] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.1_pubmedbert/checkpoint-255\n",
      "Configuration saved in /home/elson/1.4.1_pubmedbert/checkpoint-255/config.json\n",
      "Model weights saved in /home/elson/1.4.1_pubmedbert/checkpoint-255/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.1_pubmedbert/checkpoint-204] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.1_pubmedbert/checkpoint-306\n",
      "Configuration saved in /home/elson/1.4.1_pubmedbert/checkpoint-306/config.json\n",
      "Model weights saved in /home/elson/1.4.1_pubmedbert/checkpoint-306/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.1_pubmedbert/checkpoint-255] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.1_pubmedbert/checkpoint-357\n",
      "Configuration saved in /home/elson/1.4.1_pubmedbert/checkpoint-357/config.json\n",
      "Model weights saved in /home/elson/1.4.1_pubmedbert/checkpoint-357/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.1_pubmedbert/checkpoint-306] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.1_pubmedbert/checkpoint-408\n",
      "Configuration saved in /home/elson/1.4.1_pubmedbert/checkpoint-408/config.json\n",
      "Model weights saved in /home/elson/1.4.1_pubmedbert/checkpoint-408/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.1_pubmedbert/checkpoint-357] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.1_pubmedbert/checkpoint-459\n",
      "Configuration saved in /home/elson/1.4.1_pubmedbert/checkpoint-459/config.json\n",
      "Model weights saved in /home/elson/1.4.1_pubmedbert/checkpoint-459/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.1_pubmedbert/checkpoint-408] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.1_pubmedbert/checkpoint-510\n",
      "Configuration saved in /home/elson/1.4.1_pubmedbert/checkpoint-510/config.json\n",
      "Model weights saved in /home/elson/1.4.1_pubmedbert/checkpoint-510/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.1_pubmedbert/checkpoint-459] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.1_pubmedbert/checkpoint-561\n",
      "Configuration saved in /home/elson/1.4.1_pubmedbert/checkpoint-561/config.json\n",
      "Model weights saved in /home/elson/1.4.1_pubmedbert/checkpoint-561/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.1_pubmedbert/checkpoint-510] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.1_pubmedbert/checkpoint-612\n",
      "Configuration saved in /home/elson/1.4.1_pubmedbert/checkpoint-612/config.json\n",
      "Model weights saved in /home/elson/1.4.1_pubmedbert/checkpoint-612/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.1_pubmedbert/checkpoint-561] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.1_pubmedbert/checkpoint-663\n",
      "Configuration saved in /home/elson/1.4.1_pubmedbert/checkpoint-663/config.json\n",
      "Model weights saved in /home/elson/1.4.1_pubmedbert/checkpoint-663/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.1_pubmedbert/checkpoint-612] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.1_pubmedbert/checkpoint-714\n",
      "Configuration saved in /home/elson/1.4.1_pubmedbert/checkpoint-714/config.json\n",
      "Model weights saved in /home/elson/1.4.1_pubmedbert/checkpoint-714/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.1_pubmedbert/checkpoint-51] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/1.4.1_pubmedbert/checkpoint-663] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.1_pubmedbert/checkpoint-765\n",
      "Configuration saved in /home/elson/1.4.1_pubmedbert/checkpoint-765/config.json\n",
      "Model weights saved in /home/elson/1.4.1_pubmedbert/checkpoint-765/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.1_pubmedbert/checkpoint-816\n",
      "Configuration saved in /home/elson/1.4.1_pubmedbert/checkpoint-816/config.json\n",
      "Model weights saved in /home/elson/1.4.1_pubmedbert/checkpoint-816/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.1_pubmedbert/checkpoint-765] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.1_pubmedbert/checkpoint-867\n",
      "Configuration saved in /home/elson/1.4.1_pubmedbert/checkpoint-867/config.json\n",
      "Model weights saved in /home/elson/1.4.1_pubmedbert/checkpoint-867/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.1_pubmedbert/checkpoint-816] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.1_pubmedbert/checkpoint-918\n",
      "Configuration saved in /home/elson/1.4.1_pubmedbert/checkpoint-918/config.json\n",
      "Model weights saved in /home/elson/1.4.1_pubmedbert/checkpoint-918/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.1_pubmedbert/checkpoint-867] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.1_pubmedbert/checkpoint-969\n",
      "Configuration saved in /home/elson/1.4.1_pubmedbert/checkpoint-969/config.json\n",
      "Model weights saved in /home/elson/1.4.1_pubmedbert/checkpoint-969/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.1_pubmedbert/checkpoint-918] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.1_pubmedbert/checkpoint-1020\n",
      "Configuration saved in /home/elson/1.4.1_pubmedbert/checkpoint-1020/config.json\n",
      "Model weights saved in /home/elson/1.4.1_pubmedbert/checkpoint-1020/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.1_pubmedbert/checkpoint-969] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading best model from /home/elson/1.4.1_pubmedbert/checkpoint-714 (score: 0.6494623655913978).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /home/elson/1.4.1_pubmedbert/best_model/config.json\n",
      "Model weights saved in /home/elson/1.4.1_pubmedbert/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/1.4.1_pubmedbert/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/1.4.1_pubmedbert/best_model/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/1.4.1_pubmedbert/best_model/tokenizer_config.json',\n",
       " '/home/elson/1.4.1_pubmedbert/best_model/special_tokens_map.json',\n",
       " '/home/elson/1.4.1_pubmedbert/best_model/vocab.txt',\n",
       " '/home/elson/1.4.1_pubmedbert/best_model/added_tokens.json',\n",
       " '/home/elson/1.4.1_pubmedbert/best_model/tokenizer.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/1.4.1_pubmedbert/',\n",
    "    num_train_epochs=20,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.1,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/1.4.1_pubmedbert/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/1.4.1_pubmedbert/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63deaea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/1.4.1_pubmedbert/best_model/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"/home/elson/1.4.1_pubmedbert/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"contradiction\",\n",
      "    \"1\": \"entailment\",\n",
      "    \"2\": \"neutral\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"contradiction\": 0,\n",
      "    \"entailment\": 1,\n",
      "    \"neutral\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file /home/elson/1.4.1_pubmedbert/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at /home/elson/1.4.1_pubmedbert/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 32\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/1.4.1_pubmedbert/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[-5.043  ,  1.32   ,  2.56   ],\n",
      "       [-3.945  ,  6.36   , -3.498  ],\n",
      "       [-3.727  ,  6.344  , -3.793  ],\n",
      "       [-2.465  ,  4.15   , -3.133  ],\n",
      "       [-3.635  ,  6.215  , -3.814  ],\n",
      "       [-3.383  ,  6.29   , -3.826  ],\n",
      "       [-3.955  ,  6.12   , -3.297  ],\n",
      "       [-5.25   ,  5.527  , -1.516  ],\n",
      "       [-4.035  ,  6.293  , -3.35   ],\n",
      "       [-4.11   ,  4.246  , -1.2295 ],\n",
      "       [-1.409  ,  1.358  , -0.5938 ],\n",
      "       [-3.547  ,  6.41   , -3.918  ],\n",
      "       [-4.023  ,  5.918  , -3.104  ],\n",
      "       [-3.936  ,  6.363  , -3.596  ],\n",
      "       [-4.02   ,  6.35   , -3.49   ],\n",
      "       [-3.967  , -1.615  ,  5.297  ],\n",
      "       [-3.53   ,  6.39   , -3.904  ],\n",
      "       [-3.496  ,  6.39   , -3.938  ],\n",
      "       [-3.543  ,  6.367  , -3.836  ],\n",
      "       [-3.992  ,  6.266  , -3.514  ],\n",
      "       [-5.14   ,  3.18   ,  0.3337 ],\n",
      "       [ 5.633  , -3.57   , -1.041  ],\n",
      "       [-3.764  ,  6.242  , -3.73   ],\n",
      "       [ 5.98   , -1.918  , -3.383  ],\n",
      "       [ 5.68   , -2.047  , -2.664  ],\n",
      "       [ 6.316  , -2.686  , -2.549  ],\n",
      "       [-3.516  ,  6.4    , -3.824  ],\n",
      "       [-4.92   ,  5.62   , -2.035  ],\n",
      "       [-3.861  ,  6.332  , -3.535  ],\n",
      "       [-3.865  ,  6.31   , -3.604  ],\n",
      "       [-1.782  , -3.55   ,  5.133  ],\n",
      "       [-3.686  ,  6.35   , -3.643  ],\n",
      "       [-4.082  ,  6.285  , -3.453  ],\n",
      "       [-2.56   , -0.2214 ,  2.133  ],\n",
      "       [-4.875  ,  4.21   , -0.4607 ],\n",
      "       [-3.414  ,  6.383  , -4.     ],\n",
      "       [-3.426  ,  6.324  , -3.988  ],\n",
      "       [-4.105  ,  6.21   , -3.32   ],\n",
      "       [ 1.973  ,  2.555  , -5.098  ],\n",
      "       [-3.459  ,  6.387  , -3.982  ],\n",
      "       [ 5.707  , -0.959  , -4.15   ],\n",
      "       [-4.27   , -1.856  ,  5.598  ],\n",
      "       [-2.22   , -1.157  ,  3.098  ],\n",
      "       [ 1.51   , -2.434  ,  1.126  ],\n",
      "       [-4.88   ,  1.545  ,  2.402  ],\n",
      "       [-3.252  ,  6.35   , -3.955  ],\n",
      "       [ 3.035  ,  0.99   , -4.066  ],\n",
      "       [-3.457  ,  6.38   , -3.982  ],\n",
      "       [-3.404  ,  6.35   , -4.035  ],\n",
      "       [ 6.305  , -2.736  , -2.404  ],\n",
      "       [-4.51   ,  4.293  , -1.177  ],\n",
      "       [-4.72   ,  2.7    ,  1.396  ],\n",
      "       [-2.838  ,  2.633  , -0.6245 ],\n",
      "       [-5.082  ,  5.78   , -1.951  ],\n",
      "       [ 6.066  , -1.849  , -3.277  ],\n",
      "       [-4.137  ,  6.312  , -3.379  ],\n",
      "       [-2.826  ,  4.355  , -2.598  ],\n",
      "       [-4.254  , -2.053  ,  5.844  ],\n",
      "       [-3.658  ,  6.402  , -3.875  ],\n",
      "       [-3.676  ,  6.35   , -3.854  ],\n",
      "       [-3.586  ,  6.332  , -3.84   ],\n",
      "       [ 5.062  , -2.787  , -1.651  ],\n",
      "       [-2.982  , -2.963  ,  6.027  ],\n",
      "       [-3.121  ,  5.902  , -4.07   ],\n",
      "       [-5.164  ,  3.795  ,  0.136  ],\n",
      "       [-3.127  ,  6.184  , -4.254  ],\n",
      "       [-3.553  ,  6.41   , -3.834  ],\n",
      "       [-4.1    ,  6.297  , -3.344  ],\n",
      "       [-3.299  , -0.349  ,  3.31   ],\n",
      "       [ 6.086  , -2.559  , -2.723  ],\n",
      "       [-3.764  ,  6.14   , -3.783  ],\n",
      "       [-2.477  ,  4.57   , -3.043  ],\n",
      "       [-4.043  ,  6.055  , -3.38   ],\n",
      "       [-3.607  ,  6.38   , -3.883  ],\n",
      "       [-5.055  ,  5.375  , -1.7705 ],\n",
      "       [-3.398  ,  6.223  , -4.086  ],\n",
      "       [-4.42   ,  6.074  , -2.99   ],\n",
      "       [-3.793  ,  6.28   , -3.795  ],\n",
      "       [-3.729  ,  6.36   , -3.834  ],\n",
      "       [-4.688  ,  5.28   , -2.254  ],\n",
      "       [-3.87   ,  6.35   , -3.69   ],\n",
      "       [-3.719  ,  6.37   , -3.734  ],\n",
      "       [-4.223  ,  6.25   , -3.314  ],\n",
      "       [-3.355  ,  6.36   , -4.113  ],\n",
      "       [-3.344  ,  6.355  , -4.027  ],\n",
      "       [-4.215  ,  5.516  , -2.506  ],\n",
      "       [-4.188  ,  5.887  , -2.893  ],\n",
      "       [ 2.521  ,  0.2113 , -2.766  ],\n",
      "       [-5.15   ,  4.938  , -1.213  ],\n",
      "       [-3.799  ,  6.344  , -3.67   ],\n",
      "       [-3.69   ,  6.375  , -3.832  ],\n",
      "       [-3.736  ,  6.336  , -3.69   ],\n",
      "       [ 4.336  , -1.169  , -2.887  ],\n",
      "       [-3.48   ,  6.42   , -3.97   ],\n",
      "       [-1.492  ,  5.203  , -4.83   ],\n",
      "       [-1.713  , -3.742  ,  5.63   ],\n",
      "       [-0.3413 ,  4.03   , -4.535  ],\n",
      "       [-3.633  ,  5.973  , -3.504  ],\n",
      "       [-3.574  ,  6.383  , -3.959  ],\n",
      "       [-4.055  ,  6.285  , -3.426  ],\n",
      "       [ 4.484  ,  0.0967 , -4.367  ],\n",
      "       [-3.43   ,  6.36   , -3.97   ],\n",
      "       [-3.66   ,  6.406  , -3.883  ],\n",
      "       [-4.566  ,  5.832  , -2.594  ],\n",
      "       [-4.13   ,  6.36   , -3.303  ],\n",
      "       [-3.732  ,  6.39   , -3.654  ],\n",
      "       [ 0.0944 ,  4.406  , -5.566  ],\n",
      "       [-1.689  ,  4.926  , -4.355  ],\n",
      "       [-3.89   ,  6.32   , -3.56   ],\n",
      "       [-4.324  ,  5.883  , -2.773  ],\n",
      "       [-4.25   ,  6.11   , -2.873  ],\n",
      "       [-4.18   ,  6.277  , -3.309  ],\n",
      "       [-4.37   ,  6.168  , -2.986  ],\n",
      "       [-4.547  ,  6.008  , -2.717  ],\n",
      "       [-4.25   , -1.594  ,  5.81   ],\n",
      "       [-4.32   ,  5.984  , -2.928  ],\n",
      "       [-3.77   ,  6.375  , -3.754  ],\n",
      "       [-4.13   ,  6.24   , -3.057  ],\n",
      "       [-4.926  ,  1.919  ,  2.34   ],\n",
      "       [-3.396  ,  6.105  , -3.922  ],\n",
      "       [-2.264  , -3.771  ,  6.16   ],\n",
      "       [-4.05   ,  6.03   , -3.094  ],\n",
      "       [-5.29   ,  3.586  ,  0.5327 ],\n",
      "       [-5.457  ,  1.589  ,  2.527  ],\n",
      "       [-2.74   , -3.373  ,  6.21   ],\n",
      "       [-3.482  ,  6.4    , -3.953  ],\n",
      "       [-3.705  , -0.3682 ,  3.32   ],\n",
      "       [-3.545  ,  6.395  , -3.904  ],\n",
      "       [-4.02   ,  5.94   , -3.4    ],\n",
      "       [-3.637  ,  6.17   , -3.729  ],\n",
      "       [-4.008  ,  6.246  , -3.436  ],\n",
      "       [ 4.043  , -3.08   , -0.286  ],\n",
      "       [-4.234  ,  6.13   , -3.049  ],\n",
      "       [ 4.844  , -3.973  ,  0.444  ],\n",
      "       [-3.285  ,  1.125  ,  1.518  ],\n",
      "       [-3.79   ,  6.08   , -3.572  ],\n",
      "       [-4.074  ,  6.11   , -3.4    ],\n",
      "       [-2.432  , -3.74   ,  6.234  ],\n",
      "       [-2.406  , -1.263  ,  3.027  ],\n",
      "       [-3.684  ,  6.402  , -3.828  ],\n",
      "       [-3.275  ,  6.336  , -3.918  ],\n",
      "       [ 5.55   , -1.492  , -3.41   ],\n",
      "       [-2.516  ,  0.2588 ,  1.701  ],\n",
      "       [-3.48   ,  6.418  , -3.941  ],\n",
      "       [-3.82   ,  6.27   , -3.717  ],\n",
      "       [-3.938  ,  1.781  ,  1.155  ],\n",
      "       [ 5.902  , -3.092  , -1.657  ],\n",
      "       [-0.8447 , -3.182  ,  3.9    ],\n",
      "       [-3.635  ,  6.32   , -3.887  ],\n",
      "       [-2.39   , -3.81   ,  6.18   ],\n",
      "       [-2.96   , -1.041  ,  3.375  ],\n",
      "       [-3.598  ,  6.383  , -3.88   ],\n",
      "       [-2.973  , -3.146  ,  6.242  ],\n",
      "       [-4.03   ,  6.234  , -3.502  ],\n",
      "       [-3.875  ,  6.227  , -3.58   ],\n",
      "       [-3.635  ,  6.305  , -3.877  ],\n",
      "       [-3.418  ,  6.367  , -4.08   ],\n",
      "       [-3.482  ,  6.31   , -3.943  ],\n",
      "       [-3.104  , -2.326  ,  5.016  ],\n",
      "       [ 6.457  , -2.504  , -2.934  ],\n",
      "       [ 6.285  , -2.566  , -2.773  ],\n",
      "       [ 5.613  , -1.591  , -3.377  ],\n",
      "       [-4.035  ,  6.246  , -3.5    ],\n",
      "       [ 5.035  , -1.457  , -3.057  ],\n",
      "       [-2.572  , -1.878  ,  4.3    ],\n",
      "       [-5.258  ,  4.812  , -0.846  ],\n",
      "       [-3.8    ,  6.105  , -3.693  ],\n",
      "       [-2.514  ,  4.652  , -3.498  ],\n",
      "       [-3.496  , -1.207  ,  4.195  ],\n",
      "       [-2.379  , -2.723  ,  4.742  ],\n",
      "       [ 6.06   , -2.242  , -2.824  ],\n",
      "       [ 1.797  ,  0.2233 , -1.912  ],\n",
      "       [-1.035  ,  4.844  , -4.75   ],\n",
      "       [-3.96   ,  6.336  , -3.457  ],\n",
      "       [-3.535  ,  6.336  , -3.775  ],\n",
      "       [-4.57   ,  3.777  , -0.5312 ],\n",
      "       [-4.684  ,  5.86   , -2.387  ],\n",
      "       [ 5.63   , -1.81   , -3.104  ],\n",
      "       [-2.135  ,  5.4    , -4.3    ],\n",
      "       [-3.227  , -2.598  ,  5.53   ],\n",
      "       [-4.332  ,  3.564  , -0.57   ],\n",
      "       [ 4.203  ,  0.3423 , -4.477  ],\n",
      "       [ 5.527  , -1.085  , -4.105  ],\n",
      "       [-5.098  ,  1.548  ,  2.312  ],\n",
      "       [-0.2045 , -2.52   ,  2.238  ],\n",
      "       [-3.285  ,  6.277  , -4.105  ],\n",
      "       [-3.506  ,  6.402  , -3.93   ],\n",
      "       [-3.717  ,  6.33   , -3.76   ],\n",
      "       [-4.094  ,  6.12   , -3.307  ],\n",
      "       [-3.564  ,  6.367  , -3.895  ],\n",
      "       [-4.195  ,  5.3    , -2.494  ],\n",
      "       [-4.152  ,  6.062  , -3.129  ],\n",
      "       [-3.943  ,  6.312  , -3.498  ],\n",
      "       [-5.62   ,  4.4    ,  0.12177],\n",
      "       [ 3.953  ,  0.1881 , -4.117  ],\n",
      "       [-3.59   ,  6.35   , -3.908  ],\n",
      "       [-4.496  ,  1.397  ,  2.215  ],\n",
      "       [-3.771  ,  6.4    , -3.715  ],\n",
      "       [-3.578  ,  6.23   , -3.902  ],\n",
      "       [-4.363  ,  0.0857 ,  3.36   ],\n",
      "       [-3.982  ,  6.29   , -3.48   ],\n",
      "       [-3.557  ,  6.22   , -3.74   ],\n",
      "       [-4.242  ,  3.041  ,  0.10443],\n",
      "       [-3.963  ,  6.34   , -3.418  ],\n",
      "       [-4.25   , -0.7627 ,  4.137  ],\n",
      "       [-2.273  , -0.515  ,  1.841  ],\n",
      "       [-3.703  ,  6.41   , -3.76   ],\n",
      "       [-3.71   , -2.602  ,  5.87   ],\n",
      "       [-3.361  ,  6.36   , -3.969  ],\n",
      "       [-4.285  ,  6.2    , -3.191  ],\n",
      "       [-5.19   ,  1.143  ,  3.475  ],\n",
      "       [-4.938  ,  3.604  ,  0.198  ],\n",
      "       [-3.89   ,  6.34   , -3.533  ],\n",
      "       [-3.84   ,  6.336  , -3.613  ],\n",
      "       [-3.627  ,  6.39   , -3.803  ],\n",
      "       [ 4.32   , -3.129  , -0.2045 ],\n",
      "       [ 3.453  , -2.604  , -0.198  ],\n",
      "       [-3.793  ,  5.855  , -3.479  ],\n",
      "       [-3.902  ,  6.344  , -3.602  ],\n",
      "       [-3.186  , -1.936  ,  4.53   ],\n",
      "       [-3.385  ,  6.375  , -3.955  ],\n",
      "       [-3.52   ,  6.348  , -3.902  ],\n",
      "       [ 3.117  ,  0.949  , -4.152  ],\n",
      "       [-3.596  ,  6.363  , -3.896  ],\n",
      "       [-2.84   ,  5.984  , -4.145  ],\n",
      "       [-3.684  ,  6.15   , -3.482  ],\n",
      "       [-3.576  ,  6.406  , -3.873  ],\n",
      "       [-4.29   ,  0.1431 ,  3.328  ],\n",
      "       [-3.377  ,  5.023  , -3.223  ],\n",
      "       [ 5.555  , -2.69   , -1.795  ],\n",
      "       [-3.271  ,  6.36   , -3.941  ],\n",
      "       [-4.03   ,  5.914  , -3.322  ],\n",
      "       [-1.838  ,  4.22   , -3.568  ],\n",
      "       [ 5.516  , -1.84   , -2.86   ]], dtype=float16), label_ids=array([1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1,\n",
      "       1, 2, 0, 0, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 0, 1, 0, 2, 1, 1,\n",
      "       2, 0, 1, 1, 1, 0, 2, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 0, 2, 1, 2, 1,\n",
      "       1, 2, 0, 0, 1, 1, 2, 2, 2, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1,\n",
      "       1, 2, 1, 1, 2, 1, 2, 2, 0, 1, 1, 2, 0, 2, 1, 2, 1, 1, 1, 2, 1, 1,\n",
      "       2, 0, 1, 1, 2, 1, 1, 1, 2, 0, 2, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2,\n",
      "       1, 2, 1, 2, 1, 1, 2, 1, 0, 1, 1, 1, 2, 2, 0, 2, 1, 1, 1, 1, 2, 2,\n",
      "       0, 1, 1, 2, 1, 0, 0, 0, 2, 1, 1, 2, 1, 2, 0, 1, 0, 1, 2, 1, 1, 1,\n",
      "       1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 0, 0, 1, 2, 1,\n",
      "       1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 2, 0, 1, 1,\n",
      "       1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 0, 1, 1, 2]), metrics={'test_loss': 2.838538646697998, 'test_accuracy': 0.6025641025641025, 'test_precision': 0.5809107559107558, 'test_recall': 0.6025641025641025, 'test_f1': 0.5812152796627038, 'test_runtime': 1.0908, 'test_samples_per_second': 214.527, 'test_steps_per_second': 7.334})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d4e861c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjQAAAG5CAYAAACZTa6YAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAni0lEQVR4nO3dd7gdZbX48e9KAtICaZTQgzQRaXK5iIogKt2AIl0Bgag06aByaV6VpoIFMTRDlarUCyJSBBESqnQQRAIJCQkJXQis3x97wu8QkpOTwz5n75n5fp5nnrOn7Jm1D+fJXqz1vjORmUiSJJVZn1YHIEmS9GGZ0EiSpNIzoZEkSaVnQiNJkkrPhEaSJJWeCY0kSSo9ExqpJCJi3oi4KiKmRsQlH+I8O0XEn5oZWytExP9FxC6tjkNSezChkZosInaMiDER8WpEjCu+eD/ThFNvAywKDM7Mr3X3JJl5fmZ+qQnxvE9EbBARGRF/mGH76sX2m7t4nqMj4rzZHZeZm2bmqG6GK6liTGikJoqIA4GTgR/TSD6WBk4Fhjfh9MsAj2fmtCacq6dMBD4VEYM7bNsFeLxZF4gG/+2S9D7+oyA1SUQsBBwL7J2Zl2fma5n5dmZelZmHFMd8JCJOjojni+XkiPhIsW+DiBgbEQdFxISiurNbse8Y4Ehgu6Lys/uMlYyIWLaohPQr1neNiKci4pWIeDoiduqw/bYO71svIkYXrazREbFeh303R8QPI+L24jx/ioghnfwa3gL+CGxfvL8vsB1w/gy/q1Mi4tmIeDki7o6IzxbbNwG+3+Fz3t8hjh9FxO3A68ByxbY9iv2/iYjLOpz/+Ii4MSKiq//9JJWbCY3UPJ8C5gH+0MkxPwDWBdYAVgfWAY7osH8xYCFgCWB34NcRMTAzj6JR9bkoMxfIzDM7CyQi5gd+AWyamf2B9YD7ZnLcIOCa4tjBwM+Aa2aosOwI7AYsAswNHNzZtYFzgG8UrzcGHgSen+GY0TR+B4OAC4BLImKezLxuhs+5eof3fB0YAfQHnpnhfAcBnyiStc/S+N3tkj7bRaoNExqpeQYDL86mJbQTcGxmTsjMicAxNL6op3u72P92Zl4LvAqs1M143gVWjYh5M3NcZj40k2M2B57IzHMzc1pmXgg8CmzZ4ZizM/PxzHwDuJhGIjJLmfk3YFBErEQjsTlnJsecl5mTimv+FPgIs/+cv8vMh4r3vD3D+V6n8Xv8GXAesG9mjp3N+SRViAmN1DyTgCHTWz6zsDjvry48U2x77xwzJESvAwvMaSCZ+RqNVs+3gXERcU1ErNyFeKbHtESH9fHdiOdcYB9gQ2ZSsYqIgyPikaLNNYVGVaqzVhbAs53tzMw7gaeAoJF4SaoRExqpee4A/gNs1ckxz9MY3Dvd0nywHdNVrwHzdVhfrOPOzLw+M78IDKVRdTm9C/FMj+m5bsY03bnAXsC1RfXkPUVL6FBgW2BgZg4AptJIRABm1SbqtH0UEXvTqPQ8X5xfUo2Y0EhNkplTaQzc/XVEbBUR80XEXBGxaUScUBx2IXBERCxcDK49kkaLpDvuA9aPiKWLAcnfm74jIhaNiOHFWJr/0GhdvTuTc1wLrFhMNe8XEdsBqwBXdzMmADLzaeBzNMYMzag/MI3GjKh+EXEksGCH/S8Ay87JTKaIWBH4X2BnGq2nQyNije5FL6mMTGikJirGgxxIY6DvRBptkn1ozPyBxpfuGOAB4B/APcW27lzrBuCi4lx38/4kpE8Rx/PAZBrJxXdmco5JwBY0BtVOolHZ2CIzX+xOTDOc+7bMnFn16XrgOhpTuZ8B3uT97aTpNw2cFBH3zO46RYvvPOD4zLw/M5+gMVPq3OkzyCRVXzgJQJIklZ0VGkmSVHomNJIkqfRMaCRJUumZ0EiSpNLr7AZgLfXvyf9xtLKaau6+5u9qngHzz9XqEFRB8/SjV58/Nu+a+zTtu/aNe3/V0men+S+8JEkqvbat0EiSpB7W9ftXtr3qfBJJklRbVmgkSaqraOmwl6YyoZEkqa5sOUmSJLUPKzSSJNWVLSdJklR6tpwkSZLahxUaSZLqypaTJEkqPVtOkiRJ7cMKjSRJdWXLSZIklZ4tJ0mSpPZhhUaSpLqy5SRJkkrPlpMkSVL7sEIjSVJd2XKSJEmlZ8tJkiSpfVihkSSpripUoTGhkSSprvpUZwxNdVIzSZJUW1ZoJEmqK1tOkiSp9Co0bbs6qZkkSaotKzSSJNVVhVpO1fkkkiRpzkQ0b5ntpeKsiJgQEQ922DYoIm6IiCeKnwOL7RERv4iIJyPigYhYa3bnN6GRJEm94XfAJjNsOxy4MTNXAG4s1gE2BVYolhHAb2Z3chMaSZLqKvo0b5mNzLwVmDzD5uHAqOL1KGCrDtvPyYa/AwMiYmhn5zehkSSprprYcoqIERExpsMyogsRLJqZ44rX44FFi9dLAM92OG5ssW2WHBQsSVJdNXFQcGaOBEZ+iPdnRGR332+FRpIktcoL01tJxc8JxfbngKU6HLdksW2WTGgkSaqrXpzlNAtXArsUr3cBruiw/RvFbKd1gakdWlMzZctJkqS66sX70ETEhcAGwJCIGAscBRwHXBwRuwPPANsWh18LbAY8CbwO7Da785vQSJKkHpeZO8xi10YzOTaBvefk/CY0kiTVVYWe5WRCI0lSXfnoA0mSpPZhhUaSpLqqUIXGhEaSpLqq0Bia6qRmkiSptqzQSJJUV7acJElS6dlykiRJah9WaCRJqitbTpIkqfRsOUmSJLUPKzSSJNVUVKhCY0IjSVJNVSmhseUkSZJKzwqNJEl1VZ0CjQmNJEl1ZctJkiSpjVihkSSppqpUoTGhkSSppqqU0NhykiRJpWeFRpKkmrJCo5Y46X+P5GubfY49d9r6A/suuWAUX/zUakyd8lILIlNZHffDIxi+8frsuv1W72276c/Xs8t2w9ngvz/Bow8/2LrgVHrjx41j912/ztZbbsbWX96c888d1eqQNKNo4tJiJjQl8qXNv8yPf/6bD2yf8MJ47r7rDhZZbGgLolKZbbr5Vpx4ymnv2zbso8vzwxNOZvU1P9miqFQVffv15eBDD+cPV13LeRdexO8vvIB/Pvlkq8NSRZnQlMhqa65N/wUX+sD20045gT33PoBohxRZpbL6Wh/8m1p22EdZeplhLYpIVbLwwovwsVU+DsD88y/Acsstx4QJL7Q4KnUUEU1bWq3HxtBExMrAcGCJYtNzwJWZ+UhPXbOO/nbrTQxeeBE+usJKrQ5FkmbpuefG8ugjj/CJ1VZvdSjqoB0SkWbpkQpNRBwG/J5GV+2uYgngwog4vJP3jYiIMREx5oJRZ/REaJXy5ptvcOGo09l1z71bHYokzdLrr73GQfvvxyGHf58FFlig1eGoonqqQrM78PHMfLvjxoj4GfAQcNzM3pSZI4GRAP+e/J/sodgqY9zYZxk/7jm+9fWvATBx4gt8Z9ft+NWZFzBo8JAWRydJ8Pbbb3Pg/vux2eZb8oUvfqnV4WgGVarQ9FRC8y6wOPDMDNuHFvvUBMOWX5FLrr3lvfWdt96EX599IQsNGNjCqCSpITM5+sgfsNxyy/GNXXdrdTiaCROa2dsfuDEingCeLbYtDSwP7NND16y8Hx15KA/cM4apU6aww5e/wDf22ItNv/yVVoelEjvmiEO47+7RTJ0yhW222Ijd9tyL/gsuxC9++hOmvDSZww/ci+VXWJmTfjmy1aGqhO69526uvvIKVlhxRbb9ynAA9t3/QD67/udaHJmqKDJ7prMTEX2AdXj/oODRmflOV95vy0nNNndfJ/WpeQbMP1erQ1AFzdOvd6erDt7lwqZ9104atUNLyz09NsspM98F/t5T55ckSR9OlVpO/i+rJEkqPZ/lJElSTVWpQmNCI0lSTVUpobHlJEmSSs8KjSRJdVWdAo0JjSRJdWXLSZIkqY1YoZEkqaaqVKExoZEkqaaqlNDYcpIkSaVnhUaSpJqqUoXGhEaSpLqqTj5jy0mSJJWfFRpJkmrKlpMkSSq9KiU0tpwkSVLpWaGRJKmmqlShMaGRJKmuqpPPmNBIklRXVarQOIZGkiSVnhUaSZJqqkoVGhMaSZJqqkoJjS0nSZJUelZoJEmqqSpVaExoJEmqq+rkM7acJElS+VmhkSSppmw5SZKk0qtSQmPLSZIklZ4VGkmSaqpCBRorNJIk1VVENG3pwrUOiIiHIuLBiLgwIuaJiGERcWdEPBkRF0XE3N39LCY0kiSpR0XEEsB+wNqZuSrQF9geOB74eWYuD7wE7N7da5jQSJJUUxHNW7qgHzBvRPQD5gPGAZ8HLi32jwK26u5nMaGRJKmmmtlyiogRETGmwzJi+nUy8zngJODfNBKZqcDdwJTMnFYcNhZYorufxUHBkiTpQ8vMkcDIme2LiIHAcGAYMAW4BNikmdc3oZEkqaZ6cZbTF4CnM3Ni47pxOfBpYEBE9CuqNEsCz3X3AracJEmqqT59omnLbPwbWDci5ovGlKiNgIeBm4BtimN2Aa7o9mfp7hslSZK6IjPvpDH49x7gHzTyj5HAYcCBEfEkMBg4s7vXsOUkSVJN9eaN9TLzKOCoGTY/BazTjPOb0EiSVFM+y0mSJKmNWKGRJKmmKlSgMaGRJKmubDlJkiS1ESs0kiTVVJUqNCY0kiTVVIXyGVtOkiSp/KzQSJJUU7acJElS6VUon7HlJEmSys8KjSRJNWXLSZIklV6F8hlbTpIkqfys0EiSVFO2nCRJUulVKJ+x5SRJksrPCo0kSTVly6kXzDt331aHoIpZ+rP7tzoEVcg91xzf6hBUQR9bfP5evV6F8hlbTpIkqfzatkIjSZJ6li0nSZJUehXKZ2w5SZKk8rNCI0lSTdlykiRJpVehfMaWkyRJKj8rNJIk1ZQtJ0mSVHpVSmhsOUmSpNKzQiNJUk1VqEBjQiNJUl3ZcpIkSWojVmgkSaqpChVoTGgkSaqrKrWcTGgkSaqpCuUzjqGRJEnlZ4VGkqSa6lOhEo0JjSRJNVWhfMaWkyRJKj8rNJIk1ZSznCRJUun1qU4+Y8tJkiSVnxUaSZJqypaTJEkqvQrlM7acJElS+VmhkSSppoLqlGhMaCRJqilnOUmSJLURKzSSJNWUs5wkSVLpVSifseUkSZLKzwqNJEk11adCJRoTGkmSaqpC+cysE5qI+CWQs9qfmfv1SESSJElzqLMKzZhei0KSJPW6WsxyysxRHdcjYr7MfL3nQ5IkSb2hQvnM7Gc5RcSnIuJh4NFiffWIOLXHI5MkSeqirgwKPhnYGLgSIDPvj4j1ezIoSZLU82o3yykzn52hz/ZOz4QjSZJ6S3XSma4lNM9GxHpARsRcwHeBR3o2LEmSpK7rSkLzbeAUYAngeeB6YO+eDEqSJPW8Wsxymi4zXwR26oVYJElSL+pTnXymS7OclouIqyJiYkRMiIgrImK53ghOkiRVQ0QMiIhLI+LRiHikmEU9KCJuiIgnip8Du3v+rjyc8gLgYmAosDhwCXBhdy8oSZLaQ0Q0bemCU4DrMnNlYHUa43EPB27MzBWAG4v1bulKQjNfZp6bmdOK5Txgnu5eUJIktYeI5i2dXycWAtYHzgTIzLcycwowHJh+I99RwFbd/SyzTGiKMtAg4P8i4vCIWDYilomIQ4Fru3tBSZJUO8OAicDZEXFvRJwREfMDi2bmuOKY8cCi3b1AZ4OC76bxcMrpede3OuxL4HvdvagkSWq9Zs5yiogRwIgOm0Zm5sjidT9gLWDfzLwzIk5hhvZSZmZEzPKh2LPT2bOchnX3pJIkqf01c5ZTkbyMnMXuscDYzLyzWL+URkLzQkQMzcxxETEUmNDd63fpTsERsSqwCh3GzmTmOd29qCRJqo/MHB8Rz0bESpn5GLAR8HCx7AIcV/y8orvXmG1CExFHARvQSGiuBTYFbgNMaCRJKrFevrHevsD5ETE38BSwG42xvBdHxO7AM8C23T15Vyo029CYXnVvZu4WEYsC53X3gpIkqT30ZjqTmfcBa89k10bNOH9Xpm2/kZnvAtMiYkEa/a2lmnFxSZKkZuhKhWZMRAwATqcx8+lV4I6eDEqSJPW8PjV7ltNexcvTIuI6YEHgxR6NSpIk9bgK5TNdm+U0XWb+CyAi/g0s3RMBSZIkzak5Smg6qFBOJ0lSPfXyLKce1d2Eptt38pMkSe2hQvnMrBOaiPglM09cAhjQUwGp6y6+4Fyu+uOlZCZf3nobtt3xG60OSSVw2lE7sen6qzJx8ius/bUfAzBwwfk49/hvsszig3jm+cnsfOiZTHnlDQb0n5ffHr0zw5Ycwn/eeptvHX0+D/9z3GyuoDqbOGE8p/zkSKa8NIkg+NIWX2HLbXbklZenctKxhzNh/PMsstjiHHLU8SzQf8FWh6sK6Wza9hgas5pmXMbQuDmOWuipJ5/gqj9eyumjfs/vLryc2/96C2OffabVYakEzr3q7wzf+9fv23bwbl/k5rse4xPDj+Xmux7j4N2+BMChu2/M/Y+NZZ3tfsLu/3MuJx2yTStCVon07duX3b5zAL/63WWccOoo/u+Ki3n2X09x2QVns9pa6/Cb865gtbXW4bILzm51qKIxy6lZS6vNMqHJzFGdLb0ZpD7oX08/xSqrrsY8885Lv379WHOttbnlL39udVgqgdvv+SeTp77+vm1bbLAa513VeMTKeVfdyZYbrgbAysstxi2jHwfg8X+9wDKLD2KRQf17N2CVyqDBC/PRFT8GwLzzzc+SSw9j0osTuOtvt7DhxlsAsOHGW3Dn7Te3MEpNF9G8pdW6cmM9taHlll+e+++9m6lTpvDmG29wx+1/ZcIL41sdlkpqkcH9Gf/iywCMf/FlFhncSFr+8fhzDP/86gCs/fFlWHroIJZYdECrwlTJvDD+eZ568jFW/NiqTJk8iUGDFwZg4KAhTJk8qcXRqWq6OyhYLbbssI+y8y67c8DeezLvvPOywoor06eP+amaI4vRcyedfQMnHbINf//94Tz0xPPc/9hY3nnn3dYGp1J4443XOf7Ig9l974OYb/4F3rcvIio1u6bMqvTfode/ASNit072jYiIMREx5pyzTu/NsEppi62+ylnnX8KvzziH/gsuyFJLL9vqkFRSEya9wmJDGgM0FxuyIBMnvwLAK6+9ybeOPo91tz+O3f/nHIYMXICnn/P/rNW5adPe5vgjD+ZzX9iMT63feEzPgEGDmTxpIgCTJ01koYGDWhmiCn2auLRad2Y5AZCZ+3XzmscAMx0NlpkjgZEAE1+d5tTw2Xhp8iQGDhrM+HHPc8tf/sxvR13Q6pBUUtfc8g923vK/OensG9h5y//m6psfAGChBebl9Tff4u1p77Db1utx2z1P8sprb7Y4WrWzzORXJxzLkssMY/i2O7+3fZ311uem66/mqzvuxk3XX806632uhVGqijprOY3p7kkj4oFZ7QIW7e559X4/OGR/Xp46hb79+nHg4UfQ3ymQ6oJRP9mVz35yBYYMWIAnr/shPzztWk46+wbOO/6b7LLVp/j3uMnsfOhZQGNQ8OnHfp3M5JF/juPbx5zf4ujV7h558D5uvuEallluefbfY3sAdt5jH76yw26ceMxh/PnaP7LwokM55KjjWxypoFotp8hsfiEkIl4ANgZemnEX8LfMXHx257BCo2Zb+rP7tzoEVcg91/iFrOb72OLz92qGsf8Vjzbtu/bk4Su3NDua7aDgiFgYOAxYBZhn+vbM/Hwnb7saWCAz75vJ+W6e4yglSVLT9alOgaZL43jOBx4BhtEY//IvYHRnb8jM3TPztlns23EOY5QkSepUVxKawZl5JvB2Zt6Smd8EOqvOSJKkEpg+hb4ZS6t15T40bxc/x0XE5sDzgPPtJEkquSq1nLqS0PxvRCwEHAT8ElgQOKBHo5IkSZoDs01oMvPq4uVUYMOeDUeSJPWWNugUNU1XZjmdzUxusFeMpZEkSSXVDk/JbpautJyu7vB6HmBrGuNoJEmS2kJXWk6XdVyPiAuBmU7JliRJ5dEOz2Bqlu48bXsFYJFmByJJknpXhTpOXRpD8wrvH0MznsadgyVJktpCV1pO/XsjEEmS1LuqNCh4tu2ziLixK9skSVK5RDRvabVZVmgiYh5gPmBIRAyk8aRsaNxYb4leiE2SJKlLOms5fQvYH1gcuJv/n9C8DPyqZ8OSJEk9rRaPPsjMU4BTImLfzPxlL8YkSZJ6Qa3G0ADvRsSA6SsRMTAi9uq5kCRJkuZMVxKaPTNzyvSVzHwJ2LPHIpIkSb2iFoOCO+gbEZGZCRARfYG5ezYsSZLU02oxhqaD64CLIuK3xfq3im2SJEltoSsJzWHACOA7xfoNwOk9FpEkSeoVQXVKNLMdQ5OZ72bmaZm5TWZuAzwMOOtJkqSS6xPNW1qtSw+njIg1gR2AbYGngct7MihJkqQ50dmdglekkcTsALwIXAREZm7YS7FJkqQe1A6VlWbprELzKPBXYIvMfBIgIg7olagkSVKPi3aYb90knY2h+QowDrgpIk6PiI2gQqOHJElSZcwyocnMP2bm9sDKwE00nuu0SET8JiK+1EvxSZKkHlKlQcFdmeX0WmZekJlbAksC99KYyi1JkkqsSncK7sqjD96TmS9l5sjM3KinApIkSZpTXZq2LUmSqqdKT9s2oZEkqabaYexLs8xRy0mSJKkdWaGRJKmmKtRxMqGRJKmu+lTo9nK2nCRJUulZoZEkqaZsOUmSpNJzlpMkSVIbsUIjSVJNeWM9SZJUehXKZ2w5SZKk8rNCI0lSTdlykiRJpVehfMaWkyRJKj8rNJIk1VSVqhomNJIk1VRUqOdUpeRMkiTVlBUaSZJqqjr1GSs0kiTVVp+Ipi1dERF9I+LeiLi6WB8WEXdGxJMRcVFEzN3tz9LdN0qSJM2h7wKPdFg/Hvh5Zi4PvATs3t0Tm9BIklRT0cRltteKWBLYHDijWA/g88ClxSGjgK26+1lMaCRJqqmIZi4xIiLGdFhGzHC5k4FDgXeL9cHAlMycVqyPBZbo7mdxULAkSfrQMnMkMHJm+yJiC2BCZt4dERv0xPVNaCRJqqlevA/Np4EvR8RmwDzAgsApwICI6FdUaZYEnuvuBWw5SZJUU32auHQmM7+XmUtm5rLA9sBfMnMn4CZgm+KwXYArPsxnkSRJNRQRTVu66TDgwIh4ksaYmjO7eyJbTpIkqddk5s3AzcXrp4B1mnFeExpJkmqqSncKbtuE5t13s9UhqGJ+e/phrQ5BFdK3b5W+ClRXPpxSkiSpjbRthUaSJPWsKlU1TGgkSaopW06SJEltxAqNJEk1VZ36jAmNJEm1VaGOky0nSZJUflZoJEmqqT4VajqZ0EiSVFO2nCRJktqIFRpJkmoqbDlJkqSys+UkSZLURqzQSJJUU85ykiRJpWfLSZIkqY1YoZEkqaaqVKExoZEkqaaqNG3blpMkSSo9KzSSJNVUn+oUaExoJEmqK1tOkiRJbcQKjSRJNeUsJ0mSVHq2nCRJktqIFRpJkmrKWU6SJKn0bDlJkiS1ESs0kiTVlLOcJElS6VUon7HlJEmSys8KjSRJNdWnQj0nExpJkmqqOumMLSdJklQBVmgkSaqrCpVoTGgkSaopb6wnSZLURqzQSJJUUxWa5GRCI0lSXVUon7HlJEmSys8KjSRJdVWhEo0JjSRJNeUsJ0mSpDZihUaSpJpylpMkSSq9CuUztpwkSVL5WaGRJKmuKlSiMaGRJKmmnOUkSZLURqzQSJJUU85ykiRJpVehfMaERpKk2qpQRuMYGkmSVHpWaCRJqqkqzXIyoZEkqaaqNCjYlpMkSSo9KzSSJNVUhQo0JjSSJNVWhTIaW06SJKn0rNCUyHHHHsHfbruVgQMHMeqiPwLw8tSpHP39gxg37nmGDl2cY37yU/ovuFBrA1XpvPvuO5x1xF70HziE7Q75EaP/9EdGX3c5L73wPAecdhnz9fdvSl1zynFHM/pvt7LQwEH8etSlADz1xGOc+tMf8dZb/6Fv375854Dvs+Iqq7Y4UkG1ZjlZoSmRTbbYihN/cdr7tp0/6gzW+q91ufDya1nrv9blvFFntig6ldno6/7AkMWXfm99qRU/zo7fO4GFhizawqhURhttsiVHn/jr9207+zcns/2uI/jFWRex0ze/w9mnndya4PQBEc1bOr9OLBURN0XEwxHxUER8t9g+KCJuiIgnip8Du/tZTGhKZI211mbBGaovt91yE5tsMRyATbYYzm03/6UVoanEXp40kSfvu5M1NtzsvW2LLbsCAxZerIVRqaxWXeOTH6gSRwRvvPYaAK+99iqDhizcitDUWtOAgzJzFWBdYO+IWAU4HLgxM1cAbizWu6XHWk4RsTKwBHBnZr7aYfsmmXldT123bl6aPIkhxT8OgwcP4aXJk1ockcrmhnNP5fM77Mlbb7ze6lBUUXvuezBHHrw3Z536c97Ndznx1N+1OiQVeqvhlJnjgHHF61ci4hEaOcJwYIPisFHAzcBh3blGj1RoImI/4ApgX+DBiBjeYfePO3nfiIgYExFjzj37jJ4IrdKiK3U/qYMn7vk78y00gKHDVmx1KKqwa6+4hD32OYizL7uOPfY5mF8cf0yrQ9J00byl43d4sYyY6SUjlgXWBO4EFi2SHYDxQLf73D1VodkT+GRmvloEfmlELJuZp9BJQpiZI4GRAC+8/Hb2UGyVMnDQYF58cSJDhizMiy9OZODAQa0OSSUy9vEHeeLuO/jnfXcx7e23+M8br3PFqT9h+F7fa3VoqpC/XHc1I/Y7FIDPbPhFfnnCsS2OSD2h43f4rETEAsBlwP6Z+XJ0+J/wzMyI6PZ3f08lNH2mt5ky818RsQGNpGYZKjXrvfU+vf4GXHf1Fey86x5cd/UVfOZzG7Y6JJXIhtvvwYbb7wHAMw/fx9+vucRkRk03aPDCPHjf3XxizbV54J67WHzJpWf/JvWK3pzlFBFz0Uhmzs/My4vNL0TE0MwcFxFDgQndPX9PJTQvRMQamXkfQFGp2QI4C/hED12z8o75wSHce/dopk6Zwlc334jdRuzFTrvswVHfO4hrrrycxRZrTNuWPqzR1/2BO66+iFenTub0w0fw0TXWYYs9D2p1WCqBE485nH/cezcvT53Crl/dmB13+zb7HPo/nP6LE3nnnWnMPfdH2OeQI1odpgq9NUohGqWYM4FHMvNnHXZdCewCHFf8vKLb18hsfmcnIpYEpmXm+Jns+3Rm3j67c9hyUrNd//gH/hylblt3qcGtDkEVtOKi8/VqF+Ox8a837bt2pcVmHXtEfAb4K/AP4N1i8/dpjKO5GFgaeAbYNjMnd+f6PVKhycyxneybbTIjSZJ6Xi/Ocrqtk8tt1IxreKdgSZLqqkKjWr2xniRJKj0rNJIk1VSVnuVkQiNJUk1V6V6stpwkSVLpWaGRJKmmKlSgMaGRJKm2KpTR2HKSJEmlZ4VGkqSacpaTJEkqPWc5SZIktRErNJIk1VSFCjQmNJIk1VaFMhpbTpIkqfSs0EiSVFPOcpIkSaXnLCdJkqQ2YoVGkqSaqlCBxoRGkqS6suUkSZLURqzQSJJUW9Up0ZjQSJJUU7acJEmS2ogVGkmSaqpCBRoTGkmS6sqWkyRJUhuxQiNJUk35LCdJklR+1clnbDlJkqTys0IjSVJNVahAY0IjSVJdOctJkiSpjVihkSSpppzlJEmSyq86+YwtJ0mSVH5WaCRJqqkKFWhMaCRJqqsqzXIyoZEkqaaqNCjYMTSSJKn0rNBIklRTVWo5WaGRJEmlZ0IjSZJKz5aTJEk1VaWWkwmNJEk15SwnSZKkNmKFRpKkmrLlJEmSSq9C+YwtJ0mSVH5WaCRJqqsKlWhMaCRJqilnOUmSJLURKzSSJNWUs5wkSVLpVSifseUkSZLKzwqNJEl1VaESjQmNJEk15SwnSZKkNmKFRpKkmqrSLKfIzFbHoA8pIkZk5shWx6Fq8O9JzebflHqDLadqGNHqAFQp/j2p2fybUo8zoZEkSaVnQiNJkkrPhKYa7E2rmfx7UrP5N6Ue56BgSZJUelZoJElS6ZnQSJKk0jOhKbGI2CQiHouIJyPi8FbHo3KLiLMiYkJEPNjqWFQNEbFURNwUEQ9HxEMR8d1Wx6TqcgxNSUVEX+Bx4IvAWGA0sENmPtzSwFRaEbE+8CpwTmau2up4VH4RMRQYmpn3RER/4G5gK/+dUk+wQlNe6wBPZuZTmfkW8HtgeItjUoll5q3A5FbHoerIzHGZeU/x+hXgEWCJ1kalqjKhKa8lgGc7rI/FfygktamIWBZYE7izxaGookxoJEk9KiIWAC4D9s/Ml1sdj6rJhKa8ngOW6rC+ZLFNktpGRMxFI5k5PzMvb3U8qi4TmvIaDawQEcMiYm5ge+DKFsckSe+JiADOBB7JzJ+1Oh5VmwlNSWXmNGAf4HoaA+0uzsyHWhuVyiwiLgTuAFaKiLERsXurY1LpfRr4OvD5iLivWDZrdVCqJqdtS5Kk0rNCI0mSSs+ERpIklZ4JjSRJKj0TGkmSVHomNJIkqfRMaKQWioh3iqmsD0bEJREx34c41+8iYpvi9RkRsUonx24QEet14xr/ioghXd0+i3PsGhG/asZ1JWk6Exqptd7IzDWKp1u/BXy7486I6Nedk2bmHrN5ovEGwBwnNJLUrkxopPbxV2D5onry14i4Eng4IvpGxIkRMToiHoiIb0HjLqwR8auIeCwi/gwsMv1EEXFzRKxdvN4kIu6JiPsj4sbiIYHfBg4oqkOfjYiFI+Ky4hqjI+LTxXsHR8SfIuKhiDgDiK5+mIhYJyLuiIh7I+JvEbFSh91LFTE+ERFHdXjPzhFxVxHXbyOib/d/nZLqpFv/9yepuYpKzKbAdcWmtYBVM/PpiBgBTM3M/4qIjwC3R8SfaDy5eCVgFWBR4GHgrBnOuzBwOrB+ca5BmTk5Ik4DXs3Mk4rjLgB+npm3RcTSNO5A/THgKOC2zDw2IjYH5uTuwY8Cn83MaRHxBeDHwFeLfesAqwKvA6Mj4hrgNWA74NOZ+XZEnArsBJwzB9eUVFMmNFJrzRsR9xWv/0rjuTfrAXdl5tPF9i8Bq00fHwMsBKwArA9cmJnvAM9HxF9mcv51gVunnyszJ88iji8AqzQevQPAgsUTktcHvlK895qIeGkOPttCwKiIWAFIYK4O+27IzEkAEXE58BlgGvBJGgkOwLzAhDm4nqQaM6GRWuuNzFyj44biy/y1jpuAfTPz+hmOa+YzcfoA62bmmzOJpbt+CNyUmVsXba6bO+yb8ZkrSeNzjsrM732Yi0qqJ8fQSO3veuA7ETEXQESsGBHzA7cC2xVjbIYCG87kvX8H1o+IYcV7BxXbXwH6dzjuT8C+01ciYo3i5a3AjsW2TYGBcxD3QsBzxetdZ9j3xYgYFBHzAlsBtwM3AttExCLTY42IZebgepJqzIRGan9n0Bgfc09EPAj8lkZ19Q/AE8W+c2g8Kft9MnMiMAK4PCLuBy4qdl0FbD19UDCwH7B2Mej4Yf7/bKtjaCRED9FoPf27kzgfKJ7SPTYifgacAPwkIu7lg9Xgu4DLgAeAyzJzTDEr6wjgTxHxAHADMLSLvyNJNefTtiVJUulZoZEkSaVnQiNJkkrPhEaSJJWeCY0kSSo9ExpJklR6JjSSJKn0TGgkSVLp/T8gLhDDFZCDTgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "probabilities = torch.softmax(torch.tensor(test_results.predictions).to(torch.float32), dim=-1)\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)\n",
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1747566",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_save = []\n",
    "for idx in range(len(test_data)):\n",
    "    item = dataset['test'][idx]\n",
    "    actual_label = item['label']\n",
    "    predicted_label = predictions[idx]\n",
    "    claim = item['claim'] \n",
    "    premise = item['premise'] \n",
    "    category = item['category']\n",
    "    \n",
    "    # Append the information as a dictionary to the list\n",
    "    data_to_save.append({\n",
    "        'Claim': claim,\n",
    "        'Premise': premise,\n",
    "        'Actual Label': actual_label,\n",
    "        'Predicted Label': predicted_label,\n",
    "        'Category' : category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_to_save)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/home/elson/results/1.4.1_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f40c56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correctly classified instances\n",
    "correctly_classified = df[df['Actual Label'] == df['Predicted Label']]\n",
    "\n",
    "# Calculate misclassified instances\n",
    "misclassified = df[df['Actual Label'] != df['Predicted Label']]\n",
    "\n",
    "# Count the number of correctly classified and misclassified by category\n",
    "correct_classification_counts = correctly_classified['Category'].value_counts()\n",
    "misclassification_counts = misclassified['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61d30750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           40\n",
       "Bone health              15\n",
       "Fitness                  12\n",
       "Cardiovascular Health     9\n",
       "Diabetes                  9\n",
       "Cancer                    9\n",
       "Skin                      9\n",
       "Throat                    7\n",
       "Ear                       6\n",
       "Neurological health       4\n",
       "Blood                     4\n",
       "Eye                       4\n",
       "Men's health              3\n",
       "Mental Health             3\n",
       "Women' s Health           2\n",
       "COVID                     2\n",
       "Vascular                  1\n",
       "Hair                      1\n",
       "Muscles                   1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "670ffadf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Skin                     15\n",
       "Hair                     11\n",
       "General Health           11\n",
       "Bone health               6\n",
       "Blood                     5\n",
       "Eye                       5\n",
       "Muscles                   5\n",
       "Neurological health       5\n",
       "Women' s Health           4\n",
       "COVID                     4\n",
       "Cancer                    3\n",
       "Fitness                   3\n",
       "Dental Health             3\n",
       "Men's health              3\n",
       "Cardiovascular Health     3\n",
       "Diabetes                  3\n",
       "Vascular                  2\n",
       "Throat                    2\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
