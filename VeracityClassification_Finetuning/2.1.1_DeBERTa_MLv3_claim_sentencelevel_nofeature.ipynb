{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f38bead8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jul 28 17:12:51 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:61:00.0 Off |                    0 |\n",
      "| N/A   41C    P0    56W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  Off  | 00000000:62:00.0 Off |                    0 |\n",
      "| N/A   43C    P0    57W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  Off  | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   43C    P0    61W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  Off  | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   43C    P0    59W / 300W |      0MiB / 32768MiB |      2%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-cfbf7584a6bb7c13\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 207.79it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('csv',data_files='dataset_sentenceattribution_nerfeatures_split.csv',delimiter=',',column_names=[\"claim\",\"premise\",\"label\",\"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\",\"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\",\"url\", \"entities\",\"entity_map\",\"gem_exp\",\"gem_label\",\"gpt_label\",\"gpt_exp\",\"gold_exp\",\"entity_map_ev\",\"entity_ev\",\"synonym\",\"voice\",\"split\"],skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6af125ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-aa1fd4d2889f655e.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-9cd628f4430f2ace.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-df968f39da4ad12a.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01252e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\"claim\", \"premise\", \"label\",\"category\"]\n",
    "all_columns = dataset[\"train\"].column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-ab3c8fa265c0f20f.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-f395a7570b738078.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-90ab1fd7f46a781a.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 2, 'entailment': 0, 'neutral': 1}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 2,\n",
    "    \"entailment\": 0,\n",
    "    \"neutral\": 1\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e15010ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "\n",
    "        claim = item['claim']\n",
    "        evidences = item['premise']\n",
    "        item['premise']=evidences\n",
    "        item['claim']=claim\n",
    "\n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "            evidences,claim,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "        item['input_ids'] = inputs['input_ids'].squeeze()  # Remove batch dimension\n",
    "        item['attention_mask']= inputs['attention_mask'].squeeze() # Remove batch dimension\n",
    "        \n",
    "        if 'label' in item:\n",
    "            item['labels'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62421eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DebertaV2ForSequenceClassification(\n",
       "  (deberta): DebertaV2Model(\n",
       "    (embeddings): DebertaV2Embeddings(\n",
       "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaV2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (1): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (2): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (3): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (4): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (5): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (6): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (7): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (8): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (9): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (10): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (11): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (pooler): ContextPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): StableDropout()\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       "  (dropout): StableDropout()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=512)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=3, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    return {\"accuracy\": acc, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f5cf584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'claim': 'Myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.',\n",
       " 'premise': 'Additionally, laser doppler blood flow measurement showed that the frankincense and myrrh essential oil compound could promote the elimination of capillaries from skin epidermis to dermis by increasing skin blood flow.',\n",
       " 'label': 1,\n",
       " 'category': 'General Health',\n",
       " 'input_ids': tensor([    1,  4081,   261,  5042,   333, 73325,  1452,  2155,  6116,  1938,\n",
       "           272,   262, 88609,   263, 98237,  1830,  1080,  7355,   387,  2655,\n",
       "           262, 12682,   265, 65008,   292,  1158, 53245,   264, 75840,   293,\n",
       "          2376,  1158,  1452,  2155,   260,     2,   573, 52341,  1830,  1080,\n",
       "           269,  1359,   427,   267, 17847,   633,   264,   408,  1300,   262,\n",
       "          2658,   265,   262,  1158,   260,     2,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'labels': tensor(1)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 765\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='765' max='765' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [765/765 11:32, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.942700</td>\n",
       "      <td>1.030794</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.652165</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.648157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.649500</td>\n",
       "      <td>0.783251</td>\n",
       "      <td>0.660215</td>\n",
       "      <td>0.663035</td>\n",
       "      <td>0.660215</td>\n",
       "      <td>0.661567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.443400</td>\n",
       "      <td>0.841067</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.671796</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.674109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.263000</td>\n",
       "      <td>1.080500</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.654457</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.655797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.197400</td>\n",
       "      <td>1.211739</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.661255</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.650574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.232300</td>\n",
       "      <td>1.331444</td>\n",
       "      <td>0.636559</td>\n",
       "      <td>0.641113</td>\n",
       "      <td>0.636559</td>\n",
       "      <td>0.637669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.141700</td>\n",
       "      <td>1.447184</td>\n",
       "      <td>0.668817</td>\n",
       "      <td>0.686906</td>\n",
       "      <td>0.668817</td>\n",
       "      <td>0.675779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.176600</td>\n",
       "      <td>1.393937</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>0.637679</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>0.629627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.087100</td>\n",
       "      <td>1.476684</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.672319</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.659864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.132100</td>\n",
       "      <td>1.597541</td>\n",
       "      <td>0.621505</td>\n",
       "      <td>0.659216</td>\n",
       "      <td>0.621505</td>\n",
       "      <td>0.632109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.097000</td>\n",
       "      <td>1.701124</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.658943</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.655334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.043900</td>\n",
       "      <td>2.015845</td>\n",
       "      <td>0.640860</td>\n",
       "      <td>0.647184</td>\n",
       "      <td>0.640860</td>\n",
       "      <td>0.643808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.012800</td>\n",
       "      <td>2.110044</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.660972</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.649163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>2.215142</td>\n",
       "      <td>0.634409</td>\n",
       "      <td>0.645392</td>\n",
       "      <td>0.634409</td>\n",
       "      <td>0.639275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>2.235152</td>\n",
       "      <td>0.634409</td>\n",
       "      <td>0.644065</td>\n",
       "      <td>0.634409</td>\n",
       "      <td>0.638756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.1.1_deberta/checkpoint-51\n",
      "Configuration saved in /home/elson/2.1.1_deberta/checkpoint-51/config.json\n",
      "Model weights saved in /home/elson/2.1.1_deberta/checkpoint-51/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.1.1_deberta/checkpoint-357] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/2.1.1_deberta/checkpoint-765] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.1.1_deberta/checkpoint-102\n",
      "Configuration saved in /home/elson/2.1.1_deberta/checkpoint-102/config.json\n",
      "Model weights saved in /home/elson/2.1.1_deberta/checkpoint-102/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.1.1_deberta/checkpoint-51] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.1.1_deberta/checkpoint-153\n",
      "Configuration saved in /home/elson/2.1.1_deberta/checkpoint-153/config.json\n",
      "Model weights saved in /home/elson/2.1.1_deberta/checkpoint-153/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.1.1_deberta/checkpoint-102] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.1.1_deberta/checkpoint-204\n",
      "Configuration saved in /home/elson/2.1.1_deberta/checkpoint-204/config.json\n",
      "Model weights saved in /home/elson/2.1.1_deberta/checkpoint-204/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.1.1_deberta/checkpoint-255\n",
      "Configuration saved in /home/elson/2.1.1_deberta/checkpoint-255/config.json\n",
      "Model weights saved in /home/elson/2.1.1_deberta/checkpoint-255/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.1.1_deberta/checkpoint-204] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.1.1_deberta/checkpoint-306\n",
      "Configuration saved in /home/elson/2.1.1_deberta/checkpoint-306/config.json\n",
      "Model weights saved in /home/elson/2.1.1_deberta/checkpoint-306/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.1.1_deberta/checkpoint-255] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.1.1_deberta/checkpoint-357\n",
      "Configuration saved in /home/elson/2.1.1_deberta/checkpoint-357/config.json\n",
      "Model weights saved in /home/elson/2.1.1_deberta/checkpoint-357/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.1.1_deberta/checkpoint-306] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.1.1_deberta/checkpoint-408\n",
      "Configuration saved in /home/elson/2.1.1_deberta/checkpoint-408/config.json\n",
      "Model weights saved in /home/elson/2.1.1_deberta/checkpoint-408/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.1.1_deberta/checkpoint-357] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.1.1_deberta/checkpoint-459\n",
      "Configuration saved in /home/elson/2.1.1_deberta/checkpoint-459/config.json\n",
      "Model weights saved in /home/elson/2.1.1_deberta/checkpoint-459/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.1.1_deberta/checkpoint-408] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.1.1_deberta/checkpoint-510\n",
      "Configuration saved in /home/elson/2.1.1_deberta/checkpoint-510/config.json\n",
      "Model weights saved in /home/elson/2.1.1_deberta/checkpoint-510/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.1.1_deberta/checkpoint-459] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.1.1_deberta/checkpoint-561\n",
      "Configuration saved in /home/elson/2.1.1_deberta/checkpoint-561/config.json\n",
      "Model weights saved in /home/elson/2.1.1_deberta/checkpoint-561/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.1.1_deberta/checkpoint-510] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.1.1_deberta/checkpoint-612\n",
      "Configuration saved in /home/elson/2.1.1_deberta/checkpoint-612/config.json\n",
      "Model weights saved in /home/elson/2.1.1_deberta/checkpoint-612/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.1.1_deberta/checkpoint-561] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.1.1_deberta/checkpoint-663\n",
      "Configuration saved in /home/elson/2.1.1_deberta/checkpoint-663/config.json\n",
      "Model weights saved in /home/elson/2.1.1_deberta/checkpoint-663/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.1.1_deberta/checkpoint-612] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.1.1_deberta/checkpoint-714\n",
      "Configuration saved in /home/elson/2.1.1_deberta/checkpoint-714/config.json\n",
      "Model weights saved in /home/elson/2.1.1_deberta/checkpoint-714/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.1.1_deberta/checkpoint-663] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/2.1.1_deberta/checkpoint-765\n",
      "Configuration saved in /home/elson/2.1.1_deberta/checkpoint-765/config.json\n",
      "Model weights saved in /home/elson/2.1.1_deberta/checkpoint-765/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.1.1_deberta/checkpoint-714] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/elson/2.1.1_deberta/checkpoint-153 (score: 0.6774193548387096).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /home/elson/2.1.1_deberta/best_model/config.json\n",
      "Model weights saved in /home/elson/2.1.1_deberta/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/2.1.1_deberta/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/2.1.1_deberta/best_model/special_tokens_map.json\n",
      "added tokens file saved in /home/elson/2.1.1_deberta/best_model/added_tokens.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/2.1.1_deberta/best_model/tokenizer_config.json',\n",
       " '/home/elson/2.1.1_deberta/best_model/special_tokens_map.json',\n",
       " '/home/elson/2.1.1_deberta/best_model/spm.model',\n",
       " '/home/elson/2.1.1_deberta/best_model/added_tokens.json')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/2.1.1_deberta/',\n",
    "    num_train_epochs=15,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.6,\n",
    "    weight_decay=0.1,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/2.1.1_deberta/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/2.1.1_deberta/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63deaea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/2.1.1_deberta/best_model/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"/home/elson/2.1.1_deberta/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"entailment\",\n",
      "    \"1\": \"neutral\",\n",
      "    \"2\": \"contradiction\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"contradiction\": 2,\n",
      "    \"entailment\": 0,\n",
      "    \"neutral\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file /home/elson/2.1.1_deberta/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at /home/elson/2.1.1_deberta/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 32\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/2.1.1_deberta/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[ 8.7891e-01,  2.3965e+00, -3.5254e+00],\n",
      "       [ 2.8301e+00, -1.3159e-01, -2.6914e+00],\n",
      "       [ 2.9414e+00, -5.9033e-01, -2.3320e+00],\n",
      "       [ 1.3525e-01,  5.4883e-01, -7.5830e-01],\n",
      "       [ 2.7695e+00, -7.6953e-01, -1.8936e+00],\n",
      "       [ 3.6230e+00, -7.8711e-01, -2.6816e+00],\n",
      "       [ 2.8770e+00, -7.1289e-01, -2.1074e+00],\n",
      "       [ 3.9180e+00, -1.4766e+00, -2.3262e+00],\n",
      "       [ 3.0820e+00, -3.4766e-01, -2.5977e+00],\n",
      "       [ 8.8477e-01,  1.0254e+00, -1.9795e+00],\n",
      "       [-1.2959e+00, -7.3438e-01,  2.0098e+00],\n",
      "       [ 4.3906e+00, -1.7598e+00, -2.4492e+00],\n",
      "       [ 1.3193e+00,  3.7079e-02, -1.3838e+00],\n",
      "       [ 3.6133e+00, -1.1953e+00, -2.2734e+00],\n",
      "       [-2.4329e-01,  1.6240e+00, -1.4814e+00],\n",
      "       [-9.0967e-01,  1.1006e+00, -4.4220e-02],\n",
      "       [ 3.2988e+00, -5.6494e-01, -2.6328e+00],\n",
      "       [ 2.0059e+00, -2.9077e-01, -1.7109e+00],\n",
      "       [ 4.2266e+00, -1.2686e+00, -2.7500e+00],\n",
      "       [ 2.6289e+00,  1.4917e-01, -2.7676e+00],\n",
      "       [ 1.2559e+00,  9.8633e-01, -2.4102e+00],\n",
      "       [ 5.4785e-01,  1.0049e+00, -1.6367e+00],\n",
      "       [ 7.7344e-01,  1.9375e+00, -2.9922e+00],\n",
      "       [-8.9551e-01,  1.3594e+00, -3.8086e-01],\n",
      "       [-3.1958e-01, -1.2225e-01,  4.0430e-01],\n",
      "       [-2.2285e+00, -7.1973e-01,  2.9824e+00],\n",
      "       [ 4.4883e+00, -1.4268e+00, -2.7891e+00],\n",
      "       [ 8.3594e-01,  7.3730e-01, -1.6533e+00],\n",
      "       [ 3.1445e+00, -7.9980e-01, -2.2109e+00],\n",
      "       [ 2.5464e-01,  2.4744e-01, -5.5615e-01],\n",
      "       [ 1.2324e+00,  5.7568e-01, -1.8594e+00],\n",
      "       [ 3.3809e+00, -3.8574e-01, -2.8555e+00],\n",
      "       [ 3.2773e+00, -8.5840e-01, -2.2910e+00],\n",
      "       [ 2.7520e+00, -9.2236e-01, -1.7217e+00],\n",
      "       [-5.0732e-01,  1.7236e+00, -1.2793e+00],\n",
      "       [ 2.5469e+00, -8.2336e-02, -2.4434e+00],\n",
      "       [ 8.6963e-01,  9.5020e-01, -1.8672e+00],\n",
      "       [ 3.4180e+00, -2.2253e-01, -3.0469e+00],\n",
      "       [-1.2900e+00,  7.2449e-02,  1.3203e+00],\n",
      "       [ 3.0293e+00, -5.0098e-01, -2.3574e+00],\n",
      "       [-2.3999e-01,  1.8359e+00, -1.7666e+00],\n",
      "       [ 1.2676e+00,  1.1035e+00, -2.5293e+00],\n",
      "       [ 2.1055e+00, -1.5576e-01, -1.9336e+00],\n",
      "       [-2.2188e+00,  9.1064e-01,  1.5986e+00],\n",
      "       [-3.8110e-01,  1.6699e+00, -1.2500e+00],\n",
      "       [ 1.0273e+00,  1.1270e+00, -2.3809e+00],\n",
      "       [-4.8169e-01,  2.6445e+00, -2.2852e+00],\n",
      "       [ 2.4746e+00, -7.0117e-01, -1.7109e+00],\n",
      "       [ 3.3730e+00, -5.8252e-01, -2.6387e+00],\n",
      "       [-2.8076e-01, -3.6816e-01,  6.1523e-01],\n",
      "       [ 1.7451e+00,  5.1465e-01, -2.3789e+00],\n",
      "       [ 2.6836e+00, -8.5840e-01, -1.7070e+00],\n",
      "       [ 1.3301e+00,  1.4395e+00, -2.9805e+00],\n",
      "       [ 1.4990e+00,  2.2742e-01, -1.7529e+00],\n",
      "       [-5.4492e-01,  2.1875e+00, -1.9375e+00],\n",
      "       [ 2.6055e+00, -2.8735e-01, -2.2949e+00],\n",
      "       [ 5.3613e-01,  6.8652e-01, -1.3252e+00],\n",
      "       [ 1.8896e+00,  1.0869e+00, -3.1172e+00],\n",
      "       [ 2.6719e+00, -2.0312e-01, -2.4043e+00],\n",
      "       [ 3.6387e+00, -8.7451e-01, -2.5957e+00],\n",
      "       [ 2.6934e+00, -6.3818e-01, -1.9609e+00],\n",
      "       [-1.1377e+00, -4.1650e-01,  1.5830e+00],\n",
      "       [ 3.0723e+00, -3.9429e-01, -2.5273e+00],\n",
      "       [ 1.2705e+00,  1.6924e+00, -3.1484e+00],\n",
      "       [-1.3896e+00,  1.2939e+00,  2.6245e-01],\n",
      "       [ 3.8203e+00, -8.2178e-01, -2.7793e+00],\n",
      "       [ 2.6001e-01,  1.1279e+00, -1.4492e+00],\n",
      "       [ 3.1055e+00, -4.5898e-01, -2.5059e+00],\n",
      "       [-4.2188e-01,  1.0840e+00, -5.5029e-01],\n",
      "       [-8.0518e-01, -8.9722e-02,  9.1357e-01],\n",
      "       [ 2.2598e+00, -5.8533e-02, -2.1582e+00],\n",
      "       [-9.8633e-01,  1.8086e+00, -7.1826e-01],\n",
      "       [ 2.6294e-01,  1.3184e+00, -1.7939e+00],\n",
      "       [ 8.7549e-01, -2.0422e-01, -7.1973e-01],\n",
      "       [-3.6694e-01,  1.4514e-01,  2.5293e-01],\n",
      "       [ 1.1611e+00,  1.2920e+00, -2.7031e+00],\n",
      "       [ 2.8477e+00, -7.9297e-01, -1.9844e+00],\n",
      "       [ 1.5508e+00,  2.6685e-01, -1.8389e+00],\n",
      "       [ 3.6953e+00, -1.0889e+00, -2.4297e+00],\n",
      "       [ 1.7783e+00, -3.9697e-01, -1.4004e+00],\n",
      "       [ 3.3906e+00, -7.3682e-01, -2.4922e+00],\n",
      "       [ 1.3633e+00,  1.0508e+00, -2.6191e+00],\n",
      "       [ 2.8379e+00, -3.0273e-01, -2.5020e+00],\n",
      "       [ 3.3320e+00, -8.5352e-01, -2.3438e+00],\n",
      "       [ 2.1699e+00,  3.4082e-01, -2.5469e+00],\n",
      "       [-1.0811e+00, -1.0139e-02,  1.1006e+00],\n",
      "       [ 3.8867e+00, -1.2998e+00, -2.4473e+00],\n",
      "       [ 7.5879e-01,  1.7891e+00, -2.7109e+00],\n",
      "       [ 1.4795e+00,  1.4326e+00, -3.0664e+00],\n",
      "       [ 3.1367e+00, -5.2490e-01, -2.4512e+00],\n",
      "       [ 2.8594e+00, -4.7705e-01, -2.3574e+00],\n",
      "       [ 2.8105e+00, -2.2827e-01, -2.5605e+00],\n",
      "       [-7.3926e-01,  5.0098e-01,  3.2104e-01],\n",
      "       [ 2.8398e+00, -2.0410e-01, -2.5449e+00],\n",
      "       [ 8.1055e-01,  1.8643e+00, -2.9316e+00],\n",
      "       [ 2.2832e+00, -3.2471e-01, -1.9160e+00],\n",
      "       [ 1.6172e+00, -4.1602e-01, -1.3018e+00],\n",
      "       [ 7.3193e-01,  1.6084e+00, -2.5820e+00],\n",
      "       [ 3.6504e+00, -9.8926e-01, -2.4785e+00],\n",
      "       [ 3.4629e+00, -6.8311e-01, -2.6172e+00],\n",
      "       [-1.0727e-02, -4.2816e-02,  9.8724e-03],\n",
      "       [ 9.0186e-01,  1.2227e+00, -2.3906e+00],\n",
      "       [ 3.4512e+00, -7.4268e-01, -2.5195e+00],\n",
      "       [ 7.1582e-01,  1.4668e+00, -2.4102e+00],\n",
      "       [ 7.6074e-01,  8.5840e-01, -1.7305e+00],\n",
      "       [ 2.5195e+00,  3.5938e-01, -2.8945e+00],\n",
      "       [ 7.0312e-01,  2.1250e+00, -3.0137e+00],\n",
      "       [-2.1753e-01,  1.1494e+00, -1.0029e+00],\n",
      "       [ 2.6738e+00, -1.4600e-01, -2.5332e+00],\n",
      "       [ 2.1758e+00, -2.3608e-01, -1.8896e+00],\n",
      "       [ 1.7090e+00,  5.7910e-01, -2.3789e+00],\n",
      "       [ 4.1562e+00, -1.2305e+00, -2.6973e+00],\n",
      "       [ 2.4473e+00, -4.0332e-01, -2.0234e+00],\n",
      "       [ 1.5127e+00, -1.9714e-01, -1.3604e+00],\n",
      "       [ 2.8105e+00,  2.9488e-03, -2.7910e+00],\n",
      "       [ 3.1465e+00, -1.4053e-02, -3.0352e+00],\n",
      "       [ 4.2969e+00, -1.4141e+00, -2.6758e+00],\n",
      "       [ 3.1641e+00, -6.6357e-01, -2.3672e+00],\n",
      "       [ 1.7305e+00,  7.4561e-01, -2.5566e+00],\n",
      "       [ 2.7656e+00, -2.5421e-02, -2.6348e+00],\n",
      "       [ 3.7344e+00, -8.7793e-01, -2.6641e+00],\n",
      "       [ 1.9648e+00, -5.0928e-01, -1.4658e+00],\n",
      "       [ 2.9004e+00, -8.0200e-02, -2.6699e+00],\n",
      "       [ 6.0742e-01,  1.3594e+00, -2.2402e+00],\n",
      "       [ 6.9336e-01,  7.7832e-01, -1.5986e+00],\n",
      "       [ 1.0098e+00,  6.1230e-01, -1.7266e+00],\n",
      "       [-1.0605e+00,  1.8613e+00, -8.4717e-01],\n",
      "       [ 3.6738e+00, -8.0127e-01, -2.6953e+00],\n",
      "       [ 2.4844e+00, -3.8843e-01, -2.0586e+00],\n",
      "       [ 9.3701e-01,  1.2119e+00, -2.3887e+00],\n",
      "       [ 1.2275e+00,  7.0654e-01, -2.0762e+00],\n",
      "       [-2.6245e-01,  1.1494e+00, -9.0479e-01],\n",
      "       [ 2.6133e+00,  8.7207e-01, -3.5859e+00],\n",
      "       [-1.6660e+00,  1.6768e+00,  1.7615e-01],\n",
      "       [ 1.7344e+00,  2.7832e-01, -2.1191e+00],\n",
      "       [-2.9565e-01,  2.0801e+00, -1.9150e+00],\n",
      "       [ 2.6680e+00, -8.0469e-01, -1.8311e+00],\n",
      "       [-7.8955e-01,  1.6768e+00, -9.8242e-01],\n",
      "       [-6.1914e-01,  2.3184e+00, -1.9814e+00],\n",
      "       [ 2.2305e+00,  4.8584e-01, -2.8340e+00],\n",
      "       [ 2.1582e+00,  5.1041e-03, -2.1465e+00],\n",
      "       [ 1.6084e+00,  1.1064e+00, -2.7949e+00],\n",
      "       [ 3.0156e+00, -5.7080e-01, -2.3535e+00],\n",
      "       [ 4.2852e+00, -1.4658e+00, -2.6191e+00],\n",
      "       [ 1.9287e+00, -6.7773e-01, -1.2666e+00],\n",
      "       [ 1.0566e+00,  2.0752e-01, -1.3750e+00],\n",
      "       [ 5.2197e-01,  1.3789e+00, -2.0996e+00],\n",
      "       [ 3.0176e-01,  5.6348e-01, -9.0771e-01],\n",
      "       [ 2.1289e+00,  3.2959e-01, -2.5215e+00],\n",
      "       [ 9.9609e-01,  6.0938e-01, -1.7207e+00],\n",
      "       [-1.2656e+00,  2.5801e+00, -1.4639e+00],\n",
      "       [ 2.9609e+00, -9.0674e-01, -1.9795e+00],\n",
      "       [ 3.2793e+00, -3.7988e-01, -2.7871e+00],\n",
      "       [ 2.5859e+00, -3.5376e-01, -2.1719e+00],\n",
      "       [ 2.9395e+00,  1.6296e-01, -3.0391e+00],\n",
      "       [ 4.3125e+00, -1.5273e+00, -2.5938e+00],\n",
      "       [ 2.8555e+00, -7.3779e-01, -2.0508e+00],\n",
      "       [-2.1802e-01,  2.1895e+00, -2.1309e+00],\n",
      "       [ 1.4297e+00, -1.5125e-01, -1.3281e+00],\n",
      "       [-1.2500e+00,  1.5586e+00, -1.6312e-02],\n",
      "       [-1.9072e+00, -4.9011e-02,  2.0527e+00],\n",
      "       [-1.4414e+00, -1.0869e+00,  2.5254e+00],\n",
      "       [ 4.2188e+00, -1.2559e+00, -2.7363e+00],\n",
      "       [-1.0801e+00, -2.0215e-01,  1.2998e+00],\n",
      "       [ 8.5596e-01, -2.3230e-01, -6.4209e-01],\n",
      "       [ 2.4336e+00,  3.6353e-01, -2.8613e+00],\n",
      "       [ 2.4414e+00,  1.7163e-01, -2.5781e+00],\n",
      "       [-1.5107e+00,  1.9375e+00, -3.3984e-01],\n",
      "       [-1.4209e+00,  4.2651e-01,  1.1250e+00],\n",
      "       [ 5.3436e-02, -1.3545e+00,  1.0225e+00],\n",
      "       [-2.1387e+00, -7.8369e-01,  2.9492e+00],\n",
      "       [ 2.0918e+00, -1.6516e-01, -1.9385e+00],\n",
      "       [-2.1582e-01,  1.3125e+00, -1.1719e+00],\n",
      "       [ 3.4863e+00, -8.7305e-01, -2.4707e+00],\n",
      "       [ 2.8926e+00, -3.0298e-01, -2.4961e+00],\n",
      "       [-1.0620e-01,  1.1035e+00, -9.8438e-01],\n",
      "       [ 3.6484e+00, -9.8145e-01, -2.4434e+00],\n",
      "       [-2.2388e-01, -5.6396e-01,  6.9189e-01],\n",
      "       [ 2.5273e+00, -7.8796e-02, -2.3887e+00],\n",
      "       [ 4.1016e-01, -4.8730e-01, -4.5013e-02],\n",
      "       [-5.9766e-01,  1.2432e+00, -6.0791e-01],\n",
      "       [-9.0088e-02, -2.4490e-02,  3.5492e-02],\n",
      "       [-5.4492e-01,  8.2812e-01, -1.9250e-01],\n",
      "       [ 9.8291e-01,  2.5195e+00, -3.7793e+00],\n",
      "       [-4.3359e-01,  1.7441e+00, -1.4434e+00],\n",
      "       [ 4.1758e+00, -1.2559e+00, -2.7285e+00],\n",
      "       [ 2.0156e+00, -1.6113e-01, -1.8506e+00],\n",
      "       [ 2.3320e+00,  8.8867e-01, -3.3516e+00],\n",
      "       [ 2.2520e+00,  5.5225e-01, -2.8457e+00],\n",
      "       [ 3.4609e+00, -8.8037e-01, -2.4277e+00],\n",
      "       [-6.4307e-01,  1.6709e+00, -1.0605e+00],\n",
      "       [ 8.9941e-01,  1.8311e+00, -3.0117e+00],\n",
      "       [ 1.7803e+00,  4.1846e-01, -2.3184e+00],\n",
      "       [ 7.6416e-01,  2.9272e-01, -1.1865e+00],\n",
      "       [-1.1445e+00, -1.5686e-01,  1.3369e+00],\n",
      "       [ 4.2109e+00, -1.1992e+00, -2.8203e+00],\n",
      "       [ 3.7031e+00, -7.0703e-01, -2.8105e+00],\n",
      "       [ 3.0137e+00, -2.6196e-01, -2.6445e+00],\n",
      "       [ 2.9004e+00, -4.3018e-01, -2.3906e+00],\n",
      "       [ 1.4267e-02,  1.6152e+00, -1.7549e+00],\n",
      "       [ 3.4199e+00, -9.3359e-01, -2.3574e+00],\n",
      "       [ 3.1172e+00,  6.8817e-03, -3.0527e+00],\n",
      "       [ 2.2617e+00,  1.1162e+00, -3.5176e+00],\n",
      "       [ 2.3516e+00,  1.7249e-01, -2.5723e+00],\n",
      "       [-1.0166e+00,  1.1104e+00,  5.2216e-02],\n",
      "       [-6.4160e-01,  1.8115e+00, -1.2734e+00],\n",
      "       [ 3.3516e+00, -5.4297e-01, -2.7246e+00],\n",
      "       [ 2.4492e+00, -3.2568e-01, -2.0840e+00],\n",
      "       [ 3.9082e+00, -8.9014e-01, -2.8008e+00],\n",
      "       [ 1.2295e+00,  1.0303e+00, -2.4375e+00],\n",
      "       [ 2.0312e+00,  4.7217e-01, -2.5918e+00],\n",
      "       [-3.4839e-01, -1.0089e-01,  4.2505e-01],\n",
      "       [ 3.9961e+00, -1.0859e+00, -2.6934e+00],\n",
      "       [ 7.5830e-01,  1.9971e+00, -2.8848e+00],\n",
      "       [ 2.5254e+00,  1.4880e-01, -2.6641e+00],\n",
      "       [-3.9893e-01,  1.6445e+00, -1.3740e+00],\n",
      "       [-5.5664e-01,  1.7295e+00, -1.2490e+00],\n",
      "       [ 1.1689e+00, -1.0781e+00, -2.1802e-01],\n",
      "       [ 4.0977e+00, -1.0703e+00, -2.8418e+00],\n",
      "       [-5.8203e-01, -5.2002e-01,  1.0576e+00],\n",
      "       [ 4.0547e+00, -1.2197e+00, -2.6602e+00],\n",
      "       [ 2.9980e+00, -4.9512e-01, -2.4180e+00],\n",
      "       [ 3.5312e+00, -9.7510e-01, -2.4004e+00],\n",
      "       [ 3.2676e+00, -6.7041e-01, -2.4395e+00],\n",
      "       [ 2.3125e+00,  2.9541e-01, -2.5938e+00],\n",
      "       [ 3.9258e+00, -6.7334e-01, -3.0488e+00],\n",
      "       [ 3.4863e+00, -6.6846e-01, -2.6641e+00],\n",
      "       [-1.4902e+00,  1.8477e+00, -3.0005e-01],\n",
      "       [-6.2012e-01, -1.2091e-01,  6.7676e-01],\n",
      "       [ 3.1484e+00, -6.4209e-01, -2.3750e+00],\n",
      "       [ 2.9062e+00, -4.2090e-01, -2.4062e+00],\n",
      "       [ 3.6680e+00, -6.1133e-01, -2.8164e+00],\n",
      "       [ 2.3926e+00,  3.9600e-01, -2.8184e+00],\n",
      "       [ 2.2266e+00, -1.2148e+00, -1.0381e+00]], dtype=float16), label_ids=array([1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 2, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n",
      "       1, 1, 1, 2, 0, 2, 1, 0, 0, 0, 0, 0, 1, 1, 2, 0, 2, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 2, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 2, 1, 0, 1, 0,\n",
      "       1, 0, 2, 1, 0, 1, 1, 1, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "       1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 2, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
      "       1, 0, 0, 0, 1, 0, 0, 0, 2, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
      "       0, 1, 0, 1, 0, 0, 1, 0, 2, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
      "       0, 0, 0, 1, 0, 0, 2, 2, 0, 2, 0, 1, 0, 1, 1, 0, 2, 0, 1, 0, 0, 1,\n",
      "       0, 1, 0, 0, 1, 2, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 2,\n",
      "       0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 2, 0, 0, 2]), metrics={'test_loss': 0.8237763047218323, 'test_accuracy': 0.7094017094017094, 'test_precision': 0.7137822844344583, 'test_recall': 0.7094017094017094, 'test_f1': 0.7003325401415266, 'test_runtime': 1.9593, 'test_samples_per_second': 119.428, 'test_steps_per_second': 4.083})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd70dbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f647b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = torch.softmax(torch.tensor(test_results.predictions).to(torch.float32), dim=-1)\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f215e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66aa90f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_save = []\n",
    "for idx in range(len(test_data)):\n",
    "    item = test_data.__getitem__(idx)\n",
    "    actual_label = item['label']\n",
    "    predicted_label = predictions[idx]\n",
    "    claim = item['claim'] \n",
    "    premise = item['premise'] \n",
    "    category = item['category']\n",
    "    \n",
    "    # Append the information as a dictionary to the list\n",
    "    data_to_save.append({\n",
    "        'Claim': claim,\n",
    "        'Premise': premise,\n",
    "        'Actual Label': actual_label,\n",
    "        'Predicted Label': predicted_label,\n",
    "        'Category' : category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_to_save)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/home/elson/results/2.1.1_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fba2eff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Claim</th>\n",
       "      <th>Premise</th>\n",
       "      <th>Actual Label</th>\n",
       "      <th>Predicted Label</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COVID-19 vaccines are safe &amp; were reviewed by ...</td>\n",
       "      <td>Although COVID-19 vaccines have been proven to...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>COVID</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Blood clots can be prevented.</td>\n",
       "      <td>Prevent blood clots and improve survival.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Blood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A platelet transfusion is a procedure in which...</td>\n",
       "      <td>Platelet transfusion is a lifesaving procedure...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Blood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Osteoporosis is a condition that affects only ...</td>\n",
       "      <td>Improvements have been made in detection and m...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bone health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nearly 1 in 5 people experience some type of a...</td>\n",
       "      <td>reported that women suffer from anxiety disord...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Fitness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Claim  \\\n",
       "0  COVID-19 vaccines are safe & were reviewed by ...   \n",
       "1                      Blood clots can be prevented.   \n",
       "2  A platelet transfusion is a procedure in which...   \n",
       "3  Osteoporosis is a condition that affects only ...   \n",
       "4  Nearly 1 in 5 people experience some type of a...   \n",
       "\n",
       "                                             Premise  Actual Label  \\\n",
       "0  Although COVID-19 vaccines have been proven to...             1   \n",
       "1          Prevent blood clots and improve survival.             1   \n",
       "2  Platelet transfusion is a lifesaving procedure...             0   \n",
       "3  Improvements have been made in detection and m...             1   \n",
       "4  reported that women suffer from anxiety disord...             1   \n",
       "\n",
       "   Predicted Label     Category  \n",
       "0                1        COVID  \n",
       "1                0        Blood  \n",
       "2                0        Blood  \n",
       "3                1  Bone health  \n",
       "4                0      Fitness  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b6dbb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correctly classified instances\n",
    "correctly_classified = df[df['Actual Label'] == df['Predicted Label']]\n",
    "\n",
    "# Calculate misclassified instances\n",
    "misclassified = df[df['Actual Label'] != df['Predicted Label']]\n",
    "\n",
    "# Count the number of correctly classified and misclassified by category\n",
    "correct_classification_counts = correctly_classified['Category'].value_counts()\n",
    "misclassification_counts = misclassified['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a98b515c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           36\n",
       "Bone health              16\n",
       "Fitness                  12\n",
       "Cancer                   12\n",
       "Skin                     11\n",
       "Diabetes                 11\n",
       "Neurological health       8\n",
       "Hair                      8\n",
       "Throat                    7\n",
       "Eye                       7\n",
       "Cardiovascular Health     6\n",
       "Ear                       6\n",
       "COVID                     5\n",
       "Blood                     5\n",
       "Muscles                   4\n",
       "Mental Health             3\n",
       "Men's health              3\n",
       "Women' s Health           3\n",
       "Vascular                  2\n",
       "Dental Health             1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5dfa8d3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           15\n",
       "Skin                     13\n",
       "Cardiovascular Health     6\n",
       "Bone health               5\n",
       "Blood                     4\n",
       "Hair                      4\n",
       "Fitness                   3\n",
       "Men's health              3\n",
       "Women' s Health           3\n",
       "Dental Health             2\n",
       "Throat                    2\n",
       "Muscles                   2\n",
       "Eye                       2\n",
       "COVID                     1\n",
       "Vascular                  1\n",
       "Diabetes                  1\n",
       "Neurological health       1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
