{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-cfbf7584a6bb7c13\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 361.24it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('csv',data_files='dataset_sentenceattribution_nerfeatures_split.csv',delimiter=',',column_names=[\"claim\",\"premise\",\"label\",\"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\",\"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\",\"url\", \"entities\",\"entity_map\",\"gem_exp\",\"gem_label\",\"gpt_label\",\"gpt_exp\",\"gold_exp\",\"entity_map_ev\",\"entity_ev\",\"synonym\",\"voice\",\"split\"],skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "133f9357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-aa1fd4d2889f655e.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-9cd628f4430f2ace.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-df968f39da4ad12a.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01252e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\"claim\", \"premise\", \"label\",\"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\",\"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\"]\n",
    "all_columns = dataset[\"train\"].column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-3939f688401dfd1d.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-6e3e675e2ac00106.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-ec7578b7af56fb7d.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 2, 'entailment': 0, 'neutral': 1}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 2,\n",
    "    \"entailment\": 0,\n",
    "    \"neutral\": 1\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e15010ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name=\"bioformers/bioformer-8L-mnli\"):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "        # Extracting claim and evidence texts\n",
    "        claim = item['claim'] \n",
    "        evidences = item['premise']\n",
    "        item['premise']=evidences\n",
    "        item['claim']=claim\n",
    "        additional_features = [\n",
    "            \"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\"]\n",
    "    \n",
    "        for feature in additional_features:\n",
    "            if feature in item:\n",
    "                evidences += \"[SEP]\" + str(item[feature])\n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "            evidences, claim,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "         # Construct the output item\n",
    "        output_item = {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),  # Remove batch dimension\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),  # Remove batch dimension\n",
    "            'claim': claim,  # Include augmented claim text\n",
    "            'evidences': evidences  # Include original evidence text\n",
    "        }\n",
    "        \n",
    "        if 'label' in item:\n",
    "            output_item['label'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return output_item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62421eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(32768, 512, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 512)\n",
       "      (token_type_embeddings): Embedding(2, 512)\n",
       "      (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=512, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"bioformers/bioformer-8L-mnli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=512)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=3, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    return {\"accuracy\": acc, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f5cf584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  101,  4916,   117,  5545,  5029,  8349,  2290,  3047,  4506,  1975,\n",
       "          1488,  1425,  2132,  4765,  2848,  9507,  1111,  1435,  2573,  1109,\n",
       "          4258,  3720,  6187,  3004,  2076,  4989,  1425,  8635,  1431, 17188,\n",
       "          1560,  3550, 14180,  1446, 19612,  1520,  2911,  3550,  2290,  3047,\n",
       "           119,   102,   121,   102,   121,   102,   121,   102,   121,   102,\n",
       "           121,   102,   121,   102,   121,   102,   121,   102,   121,   102,\n",
       "           121,   102,   121,   102,   121,   102, 31487,  4258,  3720,  6187,\n",
       "          1478,  8811,  1822,  1427,  3550,  5183,  4030,  1446,  3346,  2520,\n",
       "          1425,  6875,  1431,  1425,  3550,   119,   102,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'claim': 'Myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.',\n",
       " 'evidences': 'Additionally, laser doppler blood flow measurement showed that the frankincense and myrrh essential oil compound could promote the elimination of capillaries from skin epidermis to dermis by increasing skin blood flow.[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0',\n",
       " 'label': tensor(1)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 765\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='765' max='765' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [765/765 02:59, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.728300</td>\n",
       "      <td>0.903474</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.577434</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.563043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.649900</td>\n",
       "      <td>0.839004</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.619164</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.623247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.380300</td>\n",
       "      <td>0.956364</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.621424</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.627735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.284900</td>\n",
       "      <td>1.162364</td>\n",
       "      <td>0.640860</td>\n",
       "      <td>0.632653</td>\n",
       "      <td>0.640860</td>\n",
       "      <td>0.635536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.272200</td>\n",
       "      <td>1.245507</td>\n",
       "      <td>0.623656</td>\n",
       "      <td>0.641006</td>\n",
       "      <td>0.623656</td>\n",
       "      <td>0.630194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.182900</td>\n",
       "      <td>1.341134</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.648485</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.645295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>1.494808</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.638742</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.638662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.097200</td>\n",
       "      <td>1.635426</td>\n",
       "      <td>0.619355</td>\n",
       "      <td>0.623415</td>\n",
       "      <td>0.619355</td>\n",
       "      <td>0.620957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.054600</td>\n",
       "      <td>1.725008</td>\n",
       "      <td>0.630108</td>\n",
       "      <td>0.626107</td>\n",
       "      <td>0.630108</td>\n",
       "      <td>0.626730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.046700</td>\n",
       "      <td>1.828573</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>0.622938</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>0.624320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.034900</td>\n",
       "      <td>1.878680</td>\n",
       "      <td>0.630108</td>\n",
       "      <td>0.623376</td>\n",
       "      <td>0.630108</td>\n",
       "      <td>0.626210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.041900</td>\n",
       "      <td>1.920811</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>0.619386</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>0.622350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>1.955851</td>\n",
       "      <td>0.621505</td>\n",
       "      <td>0.618019</td>\n",
       "      <td>0.621505</td>\n",
       "      <td>0.619441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>1.976764</td>\n",
       "      <td>0.627957</td>\n",
       "      <td>0.627533</td>\n",
       "      <td>0.627957</td>\n",
       "      <td>0.626909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>1.980917</td>\n",
       "      <td>0.623656</td>\n",
       "      <td>0.623532</td>\n",
       "      <td>0.623656</td>\n",
       "      <td>0.623349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.4_bioformer/checkpoint-51\n",
      "Configuration saved in /home/elson/11.1.4_bioformer/checkpoint-51/config.json\n",
      "Model weights saved in /home/elson/11.1.4_bioformer/checkpoint-51/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.4_bioformer/checkpoint-102\n",
      "Configuration saved in /home/elson/11.1.4_bioformer/checkpoint-102/config.json\n",
      "Model weights saved in /home/elson/11.1.4_bioformer/checkpoint-102/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.1.4_bioformer/checkpoint-51] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.4_bioformer/checkpoint-153\n",
      "Configuration saved in /home/elson/11.1.4_bioformer/checkpoint-153/config.json\n",
      "Model weights saved in /home/elson/11.1.4_bioformer/checkpoint-153/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.4_bioformer/checkpoint-204\n",
      "Configuration saved in /home/elson/11.1.4_bioformer/checkpoint-204/config.json\n",
      "Model weights saved in /home/elson/11.1.4_bioformer/checkpoint-204/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.1.4_bioformer/checkpoint-102] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/11.1.4_bioformer/checkpoint-153] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.4_bioformer/checkpoint-255\n",
      "Configuration saved in /home/elson/11.1.4_bioformer/checkpoint-255/config.json\n",
      "Model weights saved in /home/elson/11.1.4_bioformer/checkpoint-255/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.4_bioformer/checkpoint-306\n",
      "Configuration saved in /home/elson/11.1.4_bioformer/checkpoint-306/config.json\n",
      "Model weights saved in /home/elson/11.1.4_bioformer/checkpoint-306/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.1.4_bioformer/checkpoint-204] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/11.1.4_bioformer/checkpoint-255] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.4_bioformer/checkpoint-357\n",
      "Configuration saved in /home/elson/11.1.4_bioformer/checkpoint-357/config.json\n",
      "Model weights saved in /home/elson/11.1.4_bioformer/checkpoint-357/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.4_bioformer/checkpoint-408\n",
      "Configuration saved in /home/elson/11.1.4_bioformer/checkpoint-408/config.json\n",
      "Model weights saved in /home/elson/11.1.4_bioformer/checkpoint-408/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.1.4_bioformer/checkpoint-357] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.4_bioformer/checkpoint-459\n",
      "Configuration saved in /home/elson/11.1.4_bioformer/checkpoint-459/config.json\n",
      "Model weights saved in /home/elson/11.1.4_bioformer/checkpoint-459/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.1.4_bioformer/checkpoint-408] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.4_bioformer/checkpoint-510\n",
      "Configuration saved in /home/elson/11.1.4_bioformer/checkpoint-510/config.json\n",
      "Model weights saved in /home/elson/11.1.4_bioformer/checkpoint-510/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.1.4_bioformer/checkpoint-459] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.4_bioformer/checkpoint-561\n",
      "Configuration saved in /home/elson/11.1.4_bioformer/checkpoint-561/config.json\n",
      "Model weights saved in /home/elson/11.1.4_bioformer/checkpoint-561/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.1.4_bioformer/checkpoint-510] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.4_bioformer/checkpoint-612\n",
      "Configuration saved in /home/elson/11.1.4_bioformer/checkpoint-612/config.json\n",
      "Model weights saved in /home/elson/11.1.4_bioformer/checkpoint-612/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.1.4_bioformer/checkpoint-561] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.4_bioformer/checkpoint-663\n",
      "Configuration saved in /home/elson/11.1.4_bioformer/checkpoint-663/config.json\n",
      "Model weights saved in /home/elson/11.1.4_bioformer/checkpoint-663/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.1.4_bioformer/checkpoint-612] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.4_bioformer/checkpoint-714\n",
      "Configuration saved in /home/elson/11.1.4_bioformer/checkpoint-714/config.json\n",
      "Model weights saved in /home/elson/11.1.4_bioformer/checkpoint-714/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.1.4_bioformer/checkpoint-663] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.4_bioformer/checkpoint-765\n",
      "Configuration saved in /home/elson/11.1.4_bioformer/checkpoint-765/config.json\n",
      "Model weights saved in /home/elson/11.1.4_bioformer/checkpoint-765/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.1.4_bioformer/checkpoint-714] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/elson/11.1.4_bioformer/checkpoint-306 (score: 0.6430107526881721).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /home/elson/11.1.4_bioformer/best_model/config.json\n",
      "Model weights saved in /home/elson/11.1.4_bioformer/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/11.1.4_bioformer/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/11.1.4_bioformer/best_model/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/11.1.4_bioformer/best_model/tokenizer_config.json',\n",
       " '/home/elson/11.1.4_bioformer/best_model/special_tokens_map.json',\n",
       " '/home/elson/11.1.4_bioformer/best_model/vocab.txt',\n",
       " '/home/elson/11.1.4_bioformer/best_model/added_tokens.json',\n",
       " '/home/elson/11.1.4_bioformer/best_model/tokenizer.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/11.1.4_bioformer/',\n",
    "    num_train_epochs=15,\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.06,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/11.1.4_bioformer/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/11.1.4_bioformer/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63deaea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/11.1.4_bioformer/best_model/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"/home/elson/11.1.4_bioformer/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"finetuning_task\": \"mnli\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 512,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"entailment\",\n",
      "    \"1\": \"neutral\",\n",
      "    \"2\": \"contradiction\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2048,\n",
      "  \"label2id\": {\n",
      "    \"contradiction\": 2,\n",
      "    \"entailment\": 0,\n",
      "    \"neutral\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 8,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32768\n",
      "}\n",
      "\n",
      "loading weights file /home/elson/11.1.4_bioformer/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at /home/elson/11.1.4_bioformer/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 32\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/11.1.4_bioformer/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[ 2.25   ,  0.6675 , -3.195  ],\n",
      "       [ 4.22   , -1.648  , -2.838  ],\n",
      "       [ 2.537  ,  0.2227 , -3.023  ],\n",
      "       [-2.605  ,  2.482  ,  0.3777 ],\n",
      "       [ 2.379  ,  0.759  , -3.13   ],\n",
      "       [ 4.05   , -1.738  , -2.512  ],\n",
      "       [ 4.     , -2.143  , -2.201  ],\n",
      "       [ 4.094  , -1.874  , -2.459  ],\n",
      "       [ 2.572  ,  0.1106 , -3.08   ],\n",
      "       [ 1.399  ,  1.032  , -2.697  ],\n",
      "       [ 3.799  , -2.867  , -1.187  ],\n",
      "       [ 4.223  , -2.129  , -2.336  ],\n",
      "       [-3.693  ,  0.7983 ,  3.195  ],\n",
      "       [ 4.05   , -1.807  , -2.445  ],\n",
      "       [ 0.348  ,  0.1815 , -0.488  ],\n",
      "       [-1.866  ,  1.88   , -0.194  ],\n",
      "       [ 4.2    , -1.638  , -2.855  ],\n",
      "       [ 4.105  , -1.318  , -2.95   ],\n",
      "       [ 4.195  , -2.219  , -2.27   ],\n",
      "       [ 4.133  , -1.862  , -2.545  ],\n",
      "       [ 2.373  , -0.548  , -2.102  ],\n",
      "       [ 3.285  , -0.479  , -3.307  ],\n",
      "       [-1.059  ,  3.557  , -2.484  ],\n",
      "       [-0.1327 ,  1.741  , -1.799  ],\n",
      "       [-1.018  , -0.984  ,  2.158  ],\n",
      "       [-3.738  ,  1.272  ,  2.883  ],\n",
      "       [ 4.285  , -1.588  , -2.734  ],\n",
      "       [ 0.823  ,  1.133  , -2.367  ],\n",
      "       [-1.331  , -0.301  ,  1.757  ],\n",
      "       [ 2.723  , -2.26   , -0.548  ],\n",
      "       [ 1.297  ,  1.188  , -2.51   ],\n",
      "       [ 3.979  , -1.362  , -2.926  ],\n",
      "       [ 3.66   , -1.763  , -2.258  ],\n",
      "       [ 1.359  ,  1.336  , -2.645  ],\n",
      "       [ 1.833  ,  1.161  , -3.496  ],\n",
      "       [ 3.016  ,  0.03079, -3.506  ],\n",
      "       [ 3.441  ,  0.1688 , -3.71   ],\n",
      "       [ 3.719  , -1.312  , -2.713  ],\n",
      "       [-3.146  ,  1.384  ,  1.847  ],\n",
      "       [ 3.498  , -0.976  , -3.04   ],\n",
      "       [-1.928  ,  3.707  , -1.751  ],\n",
      "       [ 2.453  ,  1.297  , -4.08   ],\n",
      "       [ 3.818  , -1.898  , -2.14   ],\n",
      "       [-2.748  ,  3.045  , -0.01784],\n",
      "       [-1.051  ,  2.662  , -1.794  ],\n",
      "       [ 0.7954 ,  2.72   , -3.785  ],\n",
      "       [ 2.252  , -0.12354, -2.736  ],\n",
      "       [ 3.709  , -0.672  , -3.303  ],\n",
      "       [ 4.     , -1.567  , -2.613  ],\n",
      "       [-0.2983 , -0.603  ,  1.154  ],\n",
      "       [ 0.9805 , -1.146  , -0.05936],\n",
      "       [ 2.553  ,  0.4375 , -3.15   ],\n",
      "       [ 2.824  ,  0.1254 , -3.262  ],\n",
      "       [ 0.4053 ,  1.918  , -2.582  ],\n",
      "       [-2.701  ,  1.478  ,  1.228  ],\n",
      "       [ 4.273  , -2.201  , -2.26   ],\n",
      "       [-2.734  ,  1.558  ,  1.25   ],\n",
      "       [ 0.1702 ,  3.07   , -3.521  ],\n",
      "       [ 3.809  , -1.147  , -3.012  ],\n",
      "       [ 4.17   , -1.249  , -3.117  ],\n",
      "       [ 4.098  , -2.08   , -2.248  ],\n",
      "       [-3.23   ,  0.3145 ,  3.062  ],\n",
      "       [-1.65   ,  3.707  , -1.803  ],\n",
      "       [ 1.672  ,  1.795  , -3.53   ],\n",
      "       [ 0.1823 ,  2.857  , -3.285  ],\n",
      "       [ 3.752  , -1.339  , -2.617  ],\n",
      "       [ 3.492  , -0.6475 , -3.17   ],\n",
      "       [ 3.668  , -1.528  , -2.426  ],\n",
      "       [ 2.555  , -1.185  , -1.693  ],\n",
      "       [-1.139  , -0.536  ,  1.684  ],\n",
      "       [ 3.62   , -1.214  , -2.797  ],\n",
      "       [ 1.408  , -0.04965, -1.665  ],\n",
      "       [ 1.777  ,  1.54   , -3.729  ],\n",
      "       [-3.53   ,  0.469  ,  3.328  ],\n",
      "       [ 2.54   ,  0.1616 , -3.129  ],\n",
      "       [ 0.321  ,  2.4    , -2.78   ],\n",
      "       [ 1.286  ,  0.7705 , -2.066  ],\n",
      "       [ 4.027  , -1.243  , -3.002  ],\n",
      "       [ 3.82   , -1.604  , -2.553  ],\n",
      "       [ 3.713  , -1.564  , -2.477  ],\n",
      "       [ 3.895  , -2.04   , -2.111  ],\n",
      "       [ 2.617  ,  0.362  , -3.293  ],\n",
      "       [ 4.04   , -1.889  , -2.418  ],\n",
      "       [ 3.97   , -2.457  , -1.737  ],\n",
      "       [ 4.04   , -1.618  , -2.701  ],\n",
      "       [-2.357  ,  2.854  , -0.1976 ],\n",
      "       [ 3.146  , -0.2368 , -3.04   ],\n",
      "       [ 0.776  ,  1.698  , -2.762  ],\n",
      "       [ 3.506  , -0.989  , -2.998  ],\n",
      "       [-1.254  ,  3.91   , -2.57   ],\n",
      "       [ 3.764  , -1.772  , -2.29   ],\n",
      "       [ 4.117  , -1.928  , -2.422  ],\n",
      "       [-2.963  , -0.697  ,  3.88   ],\n",
      "       [ 3.482  , -1.063  , -2.723  ],\n",
      "       [ 4.09   , -2.06   , -2.41   ],\n",
      "       [ 3.662  , -1.953  , -1.909  ],\n",
      "       [ 1.455  , -0.333  , -1.727  ],\n",
      "       [ 0.7686 ,  0.8467 , -1.891  ],\n",
      "       [ 3.414  , -0.1301 , -3.455  ],\n",
      "       [ 4.176  , -1.534  , -2.824  ],\n",
      "       [ 0.5845 , -1.687  ,  1.311  ],\n",
      "       [ 1.674  ,  1.987  , -3.986  ],\n",
      "       [ 4.234  , -1.775  , -2.584  ],\n",
      "       [ 2.02   ,  1.344  , -3.86   ],\n",
      "       [ 1.733  ,  1.177  , -3.17   ],\n",
      "       [ 3.037  , -0.633  , -2.7    ],\n",
      "       [ 3.133  , -0.2028 , -3.111  ],\n",
      "       [-2.309  ,  3.967  , -1.381  ],\n",
      "       [ 4.227  , -1.972  , -2.453  ],\n",
      "       [ 0.0493 ,  1.775  , -2.209  ],\n",
      "       [ 1.955  ,  0.537  , -2.861  ],\n",
      "       [ 4.016  , -1.814  , -2.469  ],\n",
      "       [ 4.105  , -2.139  , -2.303  ],\n",
      "       [ 3.592  , -1.083  , -2.754  ],\n",
      "       [ 4.227  , -1.419  , -2.992  ],\n",
      "       [ 2.467  ,  0.03613, -2.953  ],\n",
      "       [ 4.21   , -2.28   , -2.111  ],\n",
      "       [ 2.625  , -0.919  , -1.899  ],\n",
      "       [ 1.972  , -0.8433 , -1.525  ],\n",
      "       [ 4.03   , -1.076  , -3.033  ],\n",
      "       [ 0.822  ,  2.662  , -3.63   ],\n",
      "       [ 1.582  ,  0.5757 , -2.514  ],\n",
      "       [ 0.703  ,  2.053  , -3.27   ],\n",
      "       [ 2.045  ,  1.727  , -3.857  ],\n",
      "       [-1.341  ,  2.463  , -0.95   ],\n",
      "       [ 4.023  , -1.682  , -2.604  ],\n",
      "       [-0.442  ,  3.117  , -2.607  ],\n",
      "       [ 3.92   , -1.007  , -3.145  ],\n",
      "       [ 3.67   , -1.159  , -2.9    ],\n",
      "       [ 0.8926 ,  1.463  , -2.904  ],\n",
      "       [ 2.258  , -1.34   , -1.083  ],\n",
      "       [-1.643  ,  1.6875 ,  0.1858 ],\n",
      "       [ 3.049  , -0.4277 , -2.984  ],\n",
      "       [-2.695  ,  2.012  ,  0.438  ],\n",
      "       [ 3.658  , -0.3052 , -3.44   ],\n",
      "       [ 3.572  ,  0.06384, -3.67   ],\n",
      "       [ 3.34   , -1.449  , -2.379  ],\n",
      "       [-2.596  ,  2.848  ,  0.01461],\n",
      "       [-0.3838 ,  1.513  , -1.173  ],\n",
      "       [ 3.96   , -1.095  , -2.92   ],\n",
      "       [ 3.111  , -0.2708 , -3.176  ],\n",
      "       [ 0.3503 ,  2.303  , -2.795  ],\n",
      "       [ 3.127  , -1.534  , -1.815  ],\n",
      "       [ 4.234  , -2.043  , -2.332  ],\n",
      "       [ 0.9106 ,  1.36   , -2.49   ],\n",
      "       [-1.59   ,  3.986  , -2.238  ],\n",
      "       [-0.08307,  2.643  , -2.605  ],\n",
      "       [-0.06216,  0.1847 , -0.2742 ],\n",
      "       [ 3.066  ,  0.497  , -3.541  ],\n",
      "       [-0.02946,  1.104  , -1.476  ],\n",
      "       [-0.6895 ,  3.34   , -2.744  ],\n",
      "       [ 3.844  , -2.8    , -1.379  ],\n",
      "       [ 4.227  , -1.398  , -2.984  ],\n",
      "       [ 4.156  , -1.56   , -2.838  ],\n",
      "       [ 3.732  , -0.993  , -2.977  ],\n",
      "       [ 4.02   , -2.611  , -1.567  ],\n",
      "       [ 3.982  , -1.719  , -2.473  ],\n",
      "       [ 3.494  ,  0.07764, -3.648  ],\n",
      "       [-0.4768 ,  1.436  , -0.932  ],\n",
      "       [-2.814  ,  0.1048 ,  2.97   ],\n",
      "       [-2.805  ,  1.219  ,  1.848  ],\n",
      "       [-3.166  , -0.3665 ,  3.576  ],\n",
      "       [ 2.324  , -2.186  , -0.4568 ],\n",
      "       [-0.2356 ,  0.11096,  0.013  ],\n",
      "       [ 3.76   , -1.565  , -2.541  ],\n",
      "       [ 2.918  , -1.337  , -1.93   ],\n",
      "       [ 2.256  ,  0.4832 , -3.3    ],\n",
      "       [-3.438  ,  2.797  ,  0.664  ],\n",
      "       [-2.832  ,  1.251  ,  1.662  ],\n",
      "       [ 2.766  , -1.29   , -1.555  ],\n",
      "       [-3.697  ,  0.8325 ,  3.08   ],\n",
      "       [ 3.936  , -1.637  , -2.41   ],\n",
      "       [-2.184  ,  4.035  , -1.529  ],\n",
      "       [ 4.2    , -1.635  , -2.65   ],\n",
      "       [ 3.445  , -0.854  , -2.867  ],\n",
      "       [-1.523  ,  3.379  , -1.537  ],\n",
      "       [ 4.203  , -2.064  , -2.434  ],\n",
      "       [ 0.6235 , -1.534  ,  0.9673 ],\n",
      "       [ 2.78   ,  0.1284 , -3.36   ],\n",
      "       [ 0.5547 ,  2.488  , -2.95   ],\n",
      "       [-2.992  ,  2.715  ,  0.2295 ],\n",
      "       [ 1.74   , -0.2269 , -1.655  ],\n",
      "       [-2.729  ,  1.111  ,  1.878  ],\n",
      "       [ 3.264  ,  0.1796 , -3.588  ],\n",
      "       [-2.662  ,  3.664  , -0.731  ],\n",
      "       [ 4.3    , -2.268  , -2.215  ],\n",
      "       [ 3.76   , -0.768  , -3.17   ],\n",
      "       [ 3.86   , -1.269  , -2.904  ],\n",
      "       [ 0.735  ,  1.35   , -1.9795 ],\n",
      "       [ 4.02   , -1.604  , -2.662  ],\n",
      "       [-3.818  ,  2.625  ,  1.43   ],\n",
      "       [-0.711  ,  3.293  , -2.584  ],\n",
      "       [ 1.741  , -0.1215 , -2.15   ],\n",
      "       [ 0.2646 ,  1.2    , -1.726  ],\n",
      "       [-1.945  , -0.6396 ,  2.768  ],\n",
      "       [ 4.227  , -1.95   , -2.48   ],\n",
      "       [ 1.7705 ,  1.476  , -3.719  ],\n",
      "       [ 4.05   , -1.539  , -2.682  ],\n",
      "       [ 3.906  , -1.817  , -2.273  ],\n",
      "       [ 2.543  ,  0.3958 , -3.16   ],\n",
      "       [ 4.062  , -2.34   , -1.984  ],\n",
      "       [ 3.863  , -0.8125 , -3.21   ],\n",
      "       [ 2.012  ,  1.069  , -3.328  ],\n",
      "       [ 4.168  , -1.52   , -2.742  ],\n",
      "       [-0.817  ,  2.83   , -2.242  ],\n",
      "       [-1.672  ,  0.968  ,  0.5815 ],\n",
      "       [ 4.332  , -1.753  , -2.75   ],\n",
      "       [ 3.531  , -1.16   , -2.814  ],\n",
      "       [ 4.043  , -1.421  , -2.799  ],\n",
      "       [ 3.822  , -1.388  , -2.943  ],\n",
      "       [ 0.3638 ,  1.459  , -1.978  ],\n",
      "       [-0.1233 , -0.3032 ,  0.512  ],\n",
      "       [-2.39   , -0.7134 ,  3.254  ],\n",
      "       [ 0.8306 ,  2.197  , -3.242  ],\n",
      "       [ 4.04   , -1.852  , -2.494  ],\n",
      "       [-1.484  ,  3.043  , -1.504  ],\n",
      "       [-2.572  ,  3.549  , -0.7515 ],\n",
      "       [ 0.2498 ,  0.9077 , -1.027  ],\n",
      "       [ 4.258  , -1.955  , -2.465  ],\n",
      "       [-1.045  ,  2.666  , -1.406  ],\n",
      "       [ 4.18   , -1.6455 , -2.732  ],\n",
      "       [ 2.244  ,  0.8916 , -3.414  ],\n",
      "       [ 1.352  , -2.195  ,  0.599  ],\n",
      "       [ 3.96   , -1.718  , -2.549  ],\n",
      "       [ 3.258  , -0.5444 , -3.133  ],\n",
      "       [ 4.145  , -1.522  , -2.809  ],\n",
      "       [ 3.855  , -1.658  , -2.463  ],\n",
      "       [-0.0834 ,  0.1814 , -0.348  ],\n",
      "       [-0.8467 ,  1.116  , -0.4824 ],\n",
      "       [ 2.736  , -1.204  , -1.675  ],\n",
      "       [ 3.084  , -1.19   , -2.377  ],\n",
      "       [ 4.13   , -1.445  , -2.832  ],\n",
      "       [ 3.621  , -0.842  , -3.102  ],\n",
      "       [-1.751  ,  1.126  ,  0.8145 ]], dtype=float16), label_ids=array([1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 2, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n",
      "       1, 1, 1, 2, 0, 2, 1, 0, 0, 0, 0, 0, 1, 1, 2, 0, 2, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 2, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 2, 1, 0, 1, 0,\n",
      "       1, 0, 2, 1, 0, 1, 1, 1, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "       1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 2, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
      "       1, 0, 0, 0, 1, 0, 0, 0, 2, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
      "       0, 1, 0, 1, 0, 0, 1, 0, 2, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
      "       0, 0, 0, 1, 0, 0, 2, 2, 0, 2, 0, 1, 0, 1, 1, 0, 2, 0, 1, 0, 0, 1,\n",
      "       0, 1, 0, 0, 1, 2, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 2,\n",
      "       0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 2, 0, 0, 2]), metrics={'test_loss': 1.241792917251587, 'test_accuracy': 0.6623931623931624, 'test_precision': 0.6567155067155067, 'test_recall': 0.6623931623931624, 'test_f1': 0.6489345245001353, 'test_runtime': 0.5664, 'test_samples_per_second': 413.146, 'test_steps_per_second': 14.125})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "808dd68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48fb2163",
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = torch.softmax(torch.tensor(test_results.predictions).to(torch.float32), dim=-1)\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed6cfde2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")  # Adjust xticklabels and yticklabels as needed\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "346c6d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_save = []\n",
    "for idx in range(len(test_data)):\n",
    "    item = dataset['test'][idx]\n",
    "    actual_label = item['label']\n",
    "    predicted_label = predictions[idx]\n",
    "    claim = item['claim'] \n",
    "    premise = item['premise'] \n",
    "    category = item['category']\n",
    "    \n",
    "    # Append the information as a dictionary to the list\n",
    "    data_to_save.append({\n",
    "        'Claim': claim,\n",
    "        'Premise': premise,\n",
    "        'Actual Label': actual_label,\n",
    "        'Predicted Label': predicted_label,\n",
    "        'Category' : category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_to_save)\n",
    "\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/home/elson/results/11.1.4_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4543aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correctly classified instances\n",
    "correctly_classified = df[df['Actual Label'] == df['Predicted Label']]\n",
    "\n",
    "# Calculate misclassified instances\n",
    "misclassified = df[df['Actual Label'] != df['Predicted Label']]\n",
    "\n",
    "# Count the number of correctly classified and misclassified by category\n",
    "correct_classification_counts = correctly_classified['Category'].value_counts()\n",
    "misclassification_counts = misclassified['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad099d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           37\n",
       "Skin                     14\n",
       "Bone health              13\n",
       "Diabetes                 11\n",
       "Cancer                   11\n",
       "Fitness                   9\n",
       "Cardiovascular Health     8\n",
       "Hair                      7\n",
       "Eye                       7\n",
       "Ear                       6\n",
       "Neurological health       6\n",
       "Throat                    5\n",
       "COVID                     4\n",
       "Blood                     4\n",
       "Mental Health             3\n",
       "Men's health              3\n",
       "Vascular                  2\n",
       "Women' s Health           2\n",
       "Muscles                   2\n",
       "Dental Health             1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d45817c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           14\n",
       "Skin                     10\n",
       "Bone health               8\n",
       "Fitness                   6\n",
       "Blood                     5\n",
       "Hair                      5\n",
       "Women' s Health           4\n",
       "Muscles                   4\n",
       "Throat                    4\n",
       "Cardiovascular Health     4\n",
       "Neurological health       3\n",
       "Men's health              3\n",
       "Eye                       2\n",
       "Dental Health             2\n",
       "COVID                     2\n",
       "Vascular                  1\n",
       "Cancer                    1\n",
       "Diabetes                  1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
