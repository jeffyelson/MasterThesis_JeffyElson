{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-cfbf7584a6bb7c13\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 212.69it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('csv',data_files='dataset_sentenceattribution_nerfeatures_split.csv',delimiter=',',column_names=[\"claim\",\"premise\",\"label\",\"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\",\"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\",\"url\", \"entities\",\"entity_map\",\"gem_exp\",\"gem_label\",\"gpt_label\",\"gpt_exp\",\"gold_exp\",\"entity_map_ev\",\"entity_ev\",\"synonym\",\"voice\",\"split\"],skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "133f9357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-aa1fd4d2889f655e.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-9cd628f4430f2ace.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-df968f39da4ad12a.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01252e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\"claim\", \"premise\", \"label\", \"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\"]\n",
    "all_columns = dataset[\"train\"].column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-b638575a29a2a369.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-c40e649fdc04fbe6.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-b1db050fd6262d30.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 2, 'entailment': 0, 'neutral': 1}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 2,\n",
    "    \"entailment\": 0,\n",
    "    \"neutral\": 1\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e15010ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='bioformers/bioformer-8L-mnli'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "        # Extracting claim and evidence texts\n",
    "        claim = item['claim'] \n",
    "        evidences = item['premise']\n",
    "        item['premise']=evidences\n",
    "        item['claim']=claim\n",
    "        additional_features = [\n",
    "            \"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\"]\n",
    "    \n",
    "        for feature in additional_features:\n",
    "            if feature in item:\n",
    "                claim += \"[SEP]\" + str(item[feature])\n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "            evidences,claim,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "         # Construct the output item\n",
    "        output_item = {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),  # Remove batch dimension\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),  # Remove batch dimension\n",
    "            'claim': claim,  # Include augmented claim text\n",
    "            'evidences': evidences  # Include original evidence text\n",
    "        }\n",
    "        \n",
    "        if 'label' in item:\n",
    "            output_item['label'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return output_item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62421eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(32768, 512, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 512)\n",
       "      (token_type_embeddings): Embedding(2, 512)\n",
       "      (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=512, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"bioformers/bioformer-8L-mnli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=512)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=3, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    return {\"accuracy\": acc, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f5cf584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  101,  4916,   117,  5545,  5029,  8349,  2290,  3047,  4506,  1975,\n",
       "          1488,  1425,  2132,  4765,  2848,  9507,  1111,  1435,  2573,  1109,\n",
       "          4258,  3720,  6187,  3004,  2076,  4989,  1425,  8635,  1431, 17188,\n",
       "          1560,  3550, 14180,  1446, 19612,  1520,  2911,  3550,  2290,  3047,\n",
       "           119,   102, 31487,  4258,  3720,  6187,  1478,  8811,  1822,  1427,\n",
       "          3550,  5183,  4030,  1446,  3346,  2520,  1425,  6875,  1431,  1425,\n",
       "          3550,   119,   102,   121,   102,   121,   102,   121,   102,   121,\n",
       "           102,   121,   102,   121,   102,   121,   102,   121,   102,   121,\n",
       "           102,   121,   102,   121,   102,   121,   102,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'claim': 'Myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0',\n",
       " 'evidences': 'Additionally, laser doppler blood flow measurement showed that the frankincense and myrrh essential oil compound could promote the elimination of capillaries from skin epidermis to dermis by increasing skin blood flow.',\n",
       " 'label': tensor(1)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 765\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='765' max='765' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [765/765 03:00, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.738400</td>\n",
       "      <td>0.924772</td>\n",
       "      <td>0.619355</td>\n",
       "      <td>0.581930</td>\n",
       "      <td>0.619355</td>\n",
       "      <td>0.538343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.660100</td>\n",
       "      <td>0.884880</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.632434</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.635017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.407600</td>\n",
       "      <td>0.984979</td>\n",
       "      <td>0.664516</td>\n",
       "      <td>0.652871</td>\n",
       "      <td>0.664516</td>\n",
       "      <td>0.656291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.288000</td>\n",
       "      <td>1.193845</td>\n",
       "      <td>0.640860</td>\n",
       "      <td>0.622590</td>\n",
       "      <td>0.640860</td>\n",
       "      <td>0.628447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.229400</td>\n",
       "      <td>1.250018</td>\n",
       "      <td>0.623656</td>\n",
       "      <td>0.619240</td>\n",
       "      <td>0.623656</td>\n",
       "      <td>0.619441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.200200</td>\n",
       "      <td>1.347161</td>\n",
       "      <td>0.660215</td>\n",
       "      <td>0.649267</td>\n",
       "      <td>0.660215</td>\n",
       "      <td>0.650986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.121900</td>\n",
       "      <td>1.503206</td>\n",
       "      <td>0.640860</td>\n",
       "      <td>0.634967</td>\n",
       "      <td>0.640860</td>\n",
       "      <td>0.636574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.102900</td>\n",
       "      <td>1.660452</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.638615</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.640234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.076800</td>\n",
       "      <td>1.717991</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.648069</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.644852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.067200</td>\n",
       "      <td>1.801184</td>\n",
       "      <td>0.640860</td>\n",
       "      <td>0.638994</td>\n",
       "      <td>0.640860</td>\n",
       "      <td>0.636638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.039300</td>\n",
       "      <td>1.795130</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.650723</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.652920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.020500</td>\n",
       "      <td>1.867531</td>\n",
       "      <td>0.647312</td>\n",
       "      <td>0.642149</td>\n",
       "      <td>0.647312</td>\n",
       "      <td>0.644482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.022200</td>\n",
       "      <td>1.906589</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.651484</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.653530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>1.925054</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.640269</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.643408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.036600</td>\n",
       "      <td>1.937127</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.637118</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.639432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.3_bioformer/checkpoint-51\n",
      "Configuration saved in /home/elson/11.1.3_bioformer/checkpoint-51/config.json\n",
      "Model weights saved in /home/elson/11.1.3_bioformer/checkpoint-51/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.3_bioformer/checkpoint-102\n",
      "Configuration saved in /home/elson/11.1.3_bioformer/checkpoint-102/config.json\n",
      "Model weights saved in /home/elson/11.1.3_bioformer/checkpoint-102/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.1.3_bioformer/checkpoint-51] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.3_bioformer/checkpoint-153\n",
      "Configuration saved in /home/elson/11.1.3_bioformer/checkpoint-153/config.json\n",
      "Model weights saved in /home/elson/11.1.3_bioformer/checkpoint-153/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.1.3_bioformer/checkpoint-102] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.3_bioformer/checkpoint-204\n",
      "Configuration saved in /home/elson/11.1.3_bioformer/checkpoint-204/config.json\n",
      "Model weights saved in /home/elson/11.1.3_bioformer/checkpoint-204/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.3_bioformer/checkpoint-255\n",
      "Configuration saved in /home/elson/11.1.3_bioformer/checkpoint-255/config.json\n",
      "Model weights saved in /home/elson/11.1.3_bioformer/checkpoint-255/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.1.3_bioformer/checkpoint-204] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.3_bioformer/checkpoint-306\n",
      "Configuration saved in /home/elson/11.1.3_bioformer/checkpoint-306/config.json\n",
      "Model weights saved in /home/elson/11.1.3_bioformer/checkpoint-306/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.1.3_bioformer/checkpoint-255] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.3_bioformer/checkpoint-357\n",
      "Configuration saved in /home/elson/11.1.3_bioformer/checkpoint-357/config.json\n",
      "Model weights saved in /home/elson/11.1.3_bioformer/checkpoint-357/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.1.3_bioformer/checkpoint-306] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.3_bioformer/checkpoint-408\n",
      "Configuration saved in /home/elson/11.1.3_bioformer/checkpoint-408/config.json\n",
      "Model weights saved in /home/elson/11.1.3_bioformer/checkpoint-408/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.1.3_bioformer/checkpoint-357] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.3_bioformer/checkpoint-459\n",
      "Configuration saved in /home/elson/11.1.3_bioformer/checkpoint-459/config.json\n",
      "Model weights saved in /home/elson/11.1.3_bioformer/checkpoint-459/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.1.3_bioformer/checkpoint-408] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.3_bioformer/checkpoint-510\n",
      "Configuration saved in /home/elson/11.1.3_bioformer/checkpoint-510/config.json\n",
      "Model weights saved in /home/elson/11.1.3_bioformer/checkpoint-510/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.1.3_bioformer/checkpoint-459] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.3_bioformer/checkpoint-561\n",
      "Configuration saved in /home/elson/11.1.3_bioformer/checkpoint-561/config.json\n",
      "Model weights saved in /home/elson/11.1.3_bioformer/checkpoint-561/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.1.3_bioformer/checkpoint-510] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.3_bioformer/checkpoint-612\n",
      "Configuration saved in /home/elson/11.1.3_bioformer/checkpoint-612/config.json\n",
      "Model weights saved in /home/elson/11.1.3_bioformer/checkpoint-612/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.1.3_bioformer/checkpoint-561] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.3_bioformer/checkpoint-663\n",
      "Configuration saved in /home/elson/11.1.3_bioformer/checkpoint-663/config.json\n",
      "Model weights saved in /home/elson/11.1.3_bioformer/checkpoint-663/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.1.3_bioformer/checkpoint-612] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.3_bioformer/checkpoint-714\n",
      "Configuration saved in /home/elson/11.1.3_bioformer/checkpoint-714/config.json\n",
      "Model weights saved in /home/elson/11.1.3_bioformer/checkpoint-714/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.1.3_bioformer/checkpoint-663] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.3_bioformer/checkpoint-765\n",
      "Configuration saved in /home/elson/11.1.3_bioformer/checkpoint-765/config.json\n",
      "Model weights saved in /home/elson/11.1.3_bioformer/checkpoint-765/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.1.3_bioformer/checkpoint-714] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/elson/11.1.3_bioformer/checkpoint-153 (score: 0.6645161290322581).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /home/elson/11.1.3_bioformer/best_model/config.json\n",
      "Model weights saved in /home/elson/11.1.3_bioformer/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/11.1.3_bioformer/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/11.1.3_bioformer/best_model/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/11.1.3_bioformer/best_model/tokenizer_config.json',\n",
       " '/home/elson/11.1.3_bioformer/best_model/special_tokens_map.json',\n",
       " '/home/elson/11.1.3_bioformer/best_model/vocab.txt',\n",
       " '/home/elson/11.1.3_bioformer/best_model/added_tokens.json',\n",
       " '/home/elson/11.1.3_bioformer/best_model/tokenizer.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/11.1.3_bioformer/',\n",
    "    num_train_epochs=15,\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.06,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/11.1.3_bioformer/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/11.1.3_bioformer/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63deaea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/11.1.3_bioformer/best_model/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"/home/elson/11.1.3_bioformer/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"finetuning_task\": \"mnli\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 512,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"entailment\",\n",
      "    \"1\": \"neutral\",\n",
      "    \"2\": \"contradiction\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2048,\n",
      "  \"label2id\": {\n",
      "    \"contradiction\": 2,\n",
      "    \"entailment\": 0,\n",
      "    \"neutral\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 8,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32768\n",
      "}\n",
      "\n",
      "loading weights file /home/elson/11.1.3_bioformer/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at /home/elson/11.1.3_bioformer/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 32\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/11.1.3_bioformer/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[ 2.3633e+00, -1.6708e-03, -2.6016e+00],\n",
      "       [ 2.3613e+00, -1.4307e-01, -2.4512e+00],\n",
      "       [ 3.1621e+00, -1.1475e+00, -2.4238e+00],\n",
      "       [-1.0557e+00,  8.9844e-01,  2.2473e-01],\n",
      "       [ 1.9580e+00,  7.3828e-01, -2.6230e+00],\n",
      "       [ 3.5664e+00, -6.7432e-01, -3.1230e+00],\n",
      "       [ 3.5039e+00, -1.0293e+00, -2.8008e+00],\n",
      "       [ 3.3438e+00, -5.6982e-01, -3.0840e+00],\n",
      "       [ 2.7285e+00, -1.5503e-01, -2.9180e+00],\n",
      "       [ 5.3809e-01,  1.0254e+00, -1.6748e+00],\n",
      "       [ 3.3574e+00, -1.3252e+00, -2.3438e+00],\n",
      "       [ 3.6309e+00, -1.1123e+00, -2.8125e+00],\n",
      "       [ 2.5078e+00,  4.3652e-01, -3.1992e+00],\n",
      "       [ 3.4023e+00, -6.4648e-01, -3.0742e+00],\n",
      "       [ 6.3379e-01, -3.8989e-01, -3.7891e-01],\n",
      "       [ 2.9468e-01,  1.5002e-01, -9.0332e-01],\n",
      "       [ 3.0195e+00, -6.5796e-02, -3.3887e+00],\n",
      "       [ 2.4395e+00, -3.7262e-02, -2.6504e+00],\n",
      "       [ 3.6289e+00, -1.1113e+00, -2.8535e+00],\n",
      "       [ 3.2148e+00, -7.3584e-01, -2.9121e+00],\n",
      "       [ 1.9355e+00, -3.0786e-01, -1.9365e+00],\n",
      "       [ 1.7178e+00,  5.6738e-01, -2.6055e+00],\n",
      "       [-8.3545e-01,  2.4102e+00, -1.5547e+00],\n",
      "       [-4.0454e-01,  1.0879e+00, -8.4375e-01],\n",
      "       [-5.3857e-01,  4.9927e-02,  4.0942e-01],\n",
      "       [-9.5264e-01, -2.3148e-02,  1.1025e+00],\n",
      "       [ 3.6602e+00, -6.3037e-01, -3.0449e+00],\n",
      "       [ 1.3057e+00, -9.9854e-02, -1.4492e+00],\n",
      "       [ 1.9756e+00, -7.8674e-02, -2.2363e+00],\n",
      "       [ 1.0215e+00, -6.6504e-01, -3.0664e-01],\n",
      "       [ 2.1445e+00, -2.5732e-01, -2.0547e+00],\n",
      "       [ 3.0918e+00, -1.7090e-01, -3.2637e+00],\n",
      "       [ 2.8184e+00, -4.6655e-01, -2.7070e+00],\n",
      "       [ 2.1094e+00,  1.4734e-01, -2.3438e+00],\n",
      "       [ 3.0371e+00, -3.0518e-01, -3.1270e+00],\n",
      "       [ 1.8154e+00,  1.5986e+00, -3.7402e+00],\n",
      "       [ 3.1289e+00,  9.8328e-02, -3.3672e+00],\n",
      "       [ 3.2930e+00, -6.1133e-01, -3.0547e+00],\n",
      "       [-1.6758e+00,  5.2979e-01,  1.1738e+00],\n",
      "       [ 2.4023e+00,  4.7388e-01, -3.3633e+00],\n",
      "       [-8.6084e-01,  2.0117e+00, -1.3301e+00],\n",
      "       [ 2.2305e+00,  1.0049e+00, -3.5117e+00],\n",
      "       [ 1.8721e+00, -6.7090e-01, -1.3350e+00],\n",
      "       [ 6.6797e-01,  6.1182e-01, -1.7021e+00],\n",
      "       [ 2.0000e+00,  5.2246e-01, -3.0352e+00],\n",
      "       [ 1.8828e+00,  6.1426e-01, -2.7109e+00],\n",
      "       [-2.1521e-01,  2.2207e+00, -2.2832e+00],\n",
      "       [ 2.5430e+00,  2.1497e-01, -2.9512e+00],\n",
      "       [ 3.4727e+00, -6.1865e-01, -3.0469e+00],\n",
      "       [ 7.7295e-01, -7.2217e-01,  2.6031e-02],\n",
      "       [ 1.7471e+00, -7.3828e-01, -1.5068e+00],\n",
      "       [ 1.6133e+00,  3.4912e-01, -2.0586e+00],\n",
      "       [ 1.2617e+00,  7.3535e-01, -2.2012e+00],\n",
      "       [ 5.1953e-01,  1.2764e+00, -2.1211e+00],\n",
      "       [-7.3193e-01,  5.4834e-01,  8.1360e-02],\n",
      "       [ 3.6855e+00, -1.0518e+00, -2.9258e+00],\n",
      "       [-8.0225e-01,  8.3838e-01, -1.1871e-01],\n",
      "       [ 1.2451e+00,  1.2842e+00, -2.7988e+00],\n",
      "       [ 2.4961e+00,  6.5308e-02, -2.9570e+00],\n",
      "       [ 3.1387e+00, -2.9640e-03, -3.3223e+00],\n",
      "       [ 3.1680e+00, -6.2842e-01, -2.6602e+00],\n",
      "       [-1.2598e+00, -1.4648e-01,  1.5732e+00],\n",
      "       [ 3.6713e-02,  1.5879e+00, -1.6836e+00],\n",
      "       [ 2.1738e+00,  5.7568e-01, -2.6348e+00],\n",
      "       [ 1.8389e+00,  1.0098e+00, -3.3027e+00],\n",
      "       [ 3.3926e+00, -3.4448e-01, -3.1172e+00],\n",
      "       [ 3.1113e+00, -2.0361e-01, -3.2832e+00],\n",
      "       [ 3.2070e+00, -4.0063e-01, -3.1602e+00],\n",
      "       [ 2.4629e+00, -7.2852e-01, -1.9746e+00],\n",
      "       [-1.0684e+00, -7.1106e-02,  1.0244e+00],\n",
      "       [ 8.3789e-01,  3.0615e-01, -1.6699e+00],\n",
      "       [ 4.3896e-01,  7.8857e-01, -1.4727e+00],\n",
      "       [ 2.1133e+00,  9.2871e-01, -3.4688e+00],\n",
      "       [ 2.2949e+00,  5.0000e-01, -3.0703e+00],\n",
      "       [ 2.1797e+00, -6.6943e-01, -1.9561e+00],\n",
      "       [ 1.0410e+00,  1.6711e-01, -1.3818e+00],\n",
      "       [ 2.1992e+00, -1.9580e-01, -2.2832e+00],\n",
      "       [ 3.1875e+00, -2.1375e-01, -2.9453e+00],\n",
      "       [ 3.2422e+00, -9.5752e-01, -2.5801e+00],\n",
      "       [ 2.7266e+00, -6.8994e-01, -2.4004e+00],\n",
      "       [ 3.4219e+00, -8.4424e-01, -2.9219e+00],\n",
      "       [ 3.1348e+00, -3.9722e-01, -3.0664e+00],\n",
      "       [ 3.3887e+00, -7.4756e-01, -2.9785e+00],\n",
      "       [ 3.5742e+00, -1.0918e+00, -2.7402e+00],\n",
      "       [ 3.0410e+00, -8.5205e-02, -3.2832e+00],\n",
      "       [ 4.9390e-01,  8.5156e-01, -1.5605e+00],\n",
      "       [ 1.7412e+00, -1.3196e-01, -1.9336e+00],\n",
      "       [ 1.4961e+00,  2.2278e-01, -1.9600e+00],\n",
      "       [ 2.1250e+00,  1.3770e-01, -2.7285e+00],\n",
      "       [ 7.2949e-01,  1.4434e+00, -2.3418e+00],\n",
      "       [ 3.2246e+00, -1.2256e+00, -2.3789e+00],\n",
      "       [ 2.9766e+00, -3.6694e-01, -2.9043e+00],\n",
      "       [-2.6660e+00, -1.7078e-01,  2.9121e+00],\n",
      "       [ 2.3613e+00,  2.1338e-01, -2.7129e+00],\n",
      "       [ 2.8320e+00, -5.9180e-01, -2.6680e+00],\n",
      "       [ 1.6504e+00, -5.3369e-01, -1.2725e+00],\n",
      "       [ 2.1887e-01,  5.9766e-01, -1.2881e+00],\n",
      "       [ 1.7910e+00,  3.0566e-01, -2.4414e+00],\n",
      "       [ 3.1719e+00, -4.1479e-01, -2.9609e+00],\n",
      "       [ 3.3516e+00, -6.8066e-01, -2.9707e+00],\n",
      "       [ 9.0942e-03, -1.1123e+00,  1.1973e+00],\n",
      "       [ 1.6943e+00,  4.8730e-01, -2.5527e+00],\n",
      "       [ 3.4707e+00, -6.1182e-01, -3.0977e+00],\n",
      "       [ 1.7773e+00,  1.1758e+00, -3.4023e+00],\n",
      "       [ 2.1367e+00,  6.7090e-01, -3.0508e+00],\n",
      "       [ 1.7725e+00,  1.2201e-01, -2.2168e+00],\n",
      "       [ 2.7852e+00, -1.1981e-01, -2.7910e+00],\n",
      "       [ 9.9609e-02,  1.3604e+00, -1.5693e+00],\n",
      "       [ 3.3516e+00, -5.8350e-01, -2.9453e+00],\n",
      "       [-5.6488e-02,  1.1279e+00, -1.2441e+00],\n",
      "       [ 1.5488e+00,  1.5215e+00, -3.2754e+00],\n",
      "       [ 3.3086e+00, -5.3369e-01, -3.1328e+00],\n",
      "       [ 3.3945e+00, -7.5195e-01, -3.0059e+00],\n",
      "       [ 2.3359e+00, -2.7756e-02, -2.6465e+00],\n",
      "       [ 2.9863e+00, -9.4543e-02, -3.1777e+00],\n",
      "       [ 3.0742e+00, -1.9324e-01, -3.2422e+00],\n",
      "       [ 3.7793e+00, -1.2715e+00, -2.7461e+00],\n",
      "       [ 1.8486e+00, -3.0420e-01, -1.7188e+00],\n",
      "       [ 2.9922e+00, -8.8428e-01, -2.3789e+00],\n",
      "       [ 3.3184e+00, -3.0615e-01, -3.0801e+00],\n",
      "       [ 9.8730e-01,  1.3213e+00, -2.5840e+00],\n",
      "       [-4.5557e-01,  1.7090e+00, -1.1787e+00],\n",
      "       [ 1.5635e+00,  9.9902e-01, -2.9414e+00],\n",
      "       [ 2.6934e+00,  6.3574e-01, -3.4512e+00],\n",
      "       [-7.1387e-01,  6.9385e-01, -1.3710e-02],\n",
      "       [ 3.3633e+00, -1.2656e+00, -2.4570e+00],\n",
      "       [ 7.4219e-01,  7.8418e-01, -1.8750e+00],\n",
      "       [ 3.3027e+00, -2.8491e-01, -3.2734e+00],\n",
      "       [ 2.0059e+00,  2.1088e-02, -2.5684e+00],\n",
      "       [-1.2471e+00,  1.0127e+00, -1.1421e-02],\n",
      "       [ 1.9551e+00, -6.5137e-01, -1.3857e+00],\n",
      "       [-1.2119e+00,  3.7207e-01,  8.4180e-01],\n",
      "       [ 3.1250e+00, -7.1045e-02, -3.3711e+00],\n",
      "       [-1.0166e+00,  1.0498e+00, -3.1445e-01],\n",
      "       [ 2.6230e+00,  2.9736e-01, -3.1289e+00],\n",
      "       [ 2.6094e+00,  8.4717e-01, -3.4688e+00],\n",
      "       [ 2.1133e+00, -3.2007e-01, -2.1973e+00],\n",
      "       [ 1.3516e+00,  4.7510e-01, -2.3672e+00],\n",
      "       [ 6.1963e-01,  7.4316e-01, -1.3848e+00],\n",
      "       [ 3.3867e+00,  3.1342e-02, -3.4375e+00],\n",
      "       [ 2.0469e+00,  1.5381e-01, -2.4824e+00],\n",
      "       [ 5.6738e-01,  1.5850e+00, -2.3848e+00],\n",
      "       [ 1.2422e+00,  4.9170e-01, -1.8535e+00],\n",
      "       [ 3.7012e+00, -8.8281e-01, -2.9492e+00],\n",
      "       [ 6.7444e-02,  1.7148e+00, -1.9590e+00],\n",
      "       [ 3.0918e+00, -7.4365e-01, -2.8555e+00],\n",
      "       [-8.0225e-01,  2.0664e+00, -1.3428e+00],\n",
      "       [ 6.7920e-01,  5.3802e-02, -6.6064e-01],\n",
      "       [ 1.9932e+00,  5.7568e-01, -2.6445e+00],\n",
      "       [ 2.0630e-01,  6.1523e-01, -1.2188e+00],\n",
      "       [ 2.1445e+00,  6.2500e-01, -3.0918e+00],\n",
      "       [ 2.8945e+00, -1.2275e+00, -2.0586e+00],\n",
      "       [ 3.0996e+00, -6.1066e-02, -3.2871e+00],\n",
      "       [ 3.5078e+00, -6.2500e-01, -3.1113e+00],\n",
      "       [ 3.2793e+00,  3.0670e-02, -3.5020e+00],\n",
      "       [ 3.3418e+00, -1.2139e+00, -2.3184e+00],\n",
      "       [ 3.5449e+00, -8.6719e-01, -2.8301e+00],\n",
      "       [ 2.6465e+00,  7.1094e-01, -3.3906e+00],\n",
      "       [-2.7612e-01,  1.1895e+00, -1.1396e+00],\n",
      "       [-2.4102e+00, -5.5566e-01,  3.0547e+00],\n",
      "       [-5.9131e-01,  2.7246e-01,  3.1128e-01],\n",
      "       [-2.5820e+00, -9.3018e-01,  3.4980e+00],\n",
      "       [-1.4678e+00, -9.9854e-01,  2.3301e+00],\n",
      "       [ 1.3389e+00, -2.8336e-02, -1.4912e+00],\n",
      "       [ 2.2988e+00, -5.4492e-01, -1.9277e+00],\n",
      "       [ 2.0312e+00, -5.0977e-01, -1.9229e+00],\n",
      "       [ 9.3213e-01,  3.3740e-01, -1.6406e+00],\n",
      "       [-2.1973e+00,  1.6660e+00,  3.3105e-01],\n",
      "       [-1.7148e+00,  2.3047e-01,  1.4961e+00],\n",
      "       [ 2.2266e+00, -1.0492e-01, -2.1777e+00],\n",
      "       [-1.0010e+00,  8.9844e-02,  9.3555e-01],\n",
      "       [ 2.1230e+00,  5.9998e-02, -2.2910e+00],\n",
      "       [ 1.7383e-01,  1.4180e+00, -1.6201e+00],\n",
      "       [ 3.5879e+00, -5.0684e-01, -3.1836e+00],\n",
      "       [ 3.4414e+00, -8.0420e-01, -2.9316e+00],\n",
      "       [ 1.4375e+00,  4.7827e-01, -2.0840e+00],\n",
      "       [ 3.1602e+00, -6.2891e-01, -2.8086e+00],\n",
      "       [ 1.7371e-01, -3.0371e-01,  8.7524e-02],\n",
      "       [ 2.2188e+00,  4.0112e-01, -3.0059e+00],\n",
      "       [ 1.1221e+00,  1.0244e+00, -2.0938e+00],\n",
      "       [-6.8213e-01,  1.2178e+00, -8.7988e-01],\n",
      "       [ 2.1348e+00, -2.6587e-01, -2.0859e+00],\n",
      "       [-1.6436e+00,  3.8965e-01,  1.3682e+00],\n",
      "       [ 2.5469e+00,  3.3569e-02, -2.7539e+00],\n",
      "       [ 7.7734e-01,  1.3887e+00, -2.5039e+00],\n",
      "       [ 3.6191e+00, -1.0430e+00, -2.8613e+00],\n",
      "       [ 2.5547e+00,  8.5693e-02, -2.8398e+00],\n",
      "       [ 3.3984e+00, -4.5142e-01, -3.2500e+00],\n",
      "       [ 1.2744e+00,  6.0205e-01, -1.8506e+00],\n",
      "       [ 2.8379e+00, -4.4214e-01, -2.6406e+00],\n",
      "       [-8.1250e-01,  7.5098e-01, -2.0312e-01],\n",
      "       [-3.6670e-01,  2.0527e+00, -1.7646e+00],\n",
      "       [ 2.3203e+00, -9.2651e-02, -2.5898e+00],\n",
      "       [ 2.2754e+00, -4.8926e-01, -2.3633e+00],\n",
      "       [-1.7354e+00, -3.0957e-01,  2.2031e+00],\n",
      "       [ 3.5234e+00, -6.8506e-01, -3.0527e+00],\n",
      "       [ 1.5791e+00,  7.8760e-01, -2.8301e+00],\n",
      "       [ 3.4727e+00, -4.8804e-01, -3.1934e+00],\n",
      "       [ 3.5410e+00, -9.3018e-01, -2.7969e+00],\n",
      "       [ 1.8037e+00,  6.1328e-01, -2.5078e+00],\n",
      "       [ 2.8164e+00, -8.5059e-01, -2.2715e+00],\n",
      "       [ 3.1602e+00, -1.5601e-01, -3.2402e+00],\n",
      "       [ 2.0918e+00,  4.7925e-01, -2.7949e+00],\n",
      "       [ 3.0723e+00,  9.0027e-02, -3.3594e+00],\n",
      "       [ 2.1719e+00,  3.3105e-01, -2.9082e+00],\n",
      "       [-7.2998e-01,  9.4629e-01, -3.6572e-01],\n",
      "       [ 3.6152e+00, -6.8848e-01, -3.1328e+00],\n",
      "       [ 2.7598e+00, -7.1582e-01, -2.3906e+00],\n",
      "       [ 2.9727e+00, -3.5669e-01, -2.8770e+00],\n",
      "       [ 1.5781e+00,  6.4502e-01, -2.8242e+00],\n",
      "       [ 7.7148e-01,  1.1631e+00, -1.9189e+00],\n",
      "       [ 2.3413e-01,  9.0771e-01, -1.3496e+00],\n",
      "       [-2.3809e+00, -4.7510e-01,  2.7812e+00],\n",
      "       [ 1.1680e+00,  1.0830e+00, -2.4590e+00],\n",
      "       [ 3.1895e+00, -4.3164e-01, -3.1211e+00],\n",
      "       [-4.9512e-01,  1.5752e+00, -1.1816e+00],\n",
      "       [-5.8984e-01,  1.9541e+00, -1.4102e+00],\n",
      "       [ 3.6450e-01,  5.4443e-01, -8.6719e-01],\n",
      "       [ 3.6211e+00, -6.8604e-01, -3.0957e+00],\n",
      "       [-4.9756e-01,  1.1387e+00, -5.9229e-01],\n",
      "       [ 3.5059e+00, -5.5127e-01, -3.1621e+00],\n",
      "       [ 2.7266e+00, -6.5552e-02, -3.0156e+00],\n",
      "       [-1.6235e-01,  4.5197e-02, -1.5088e-01],\n",
      "       [ 2.9258e+00, -2.6489e-01, -2.9355e+00],\n",
      "       [ 2.0449e+00,  1.6907e-01, -2.4688e+00],\n",
      "       [ 3.4629e+00, -4.1284e-01, -3.2637e+00],\n",
      "       [ 3.4941e+00, -6.4111e-01, -3.1289e+00],\n",
      "       [-3.7549e-01,  4.7852e-01, -2.2290e-01],\n",
      "       [-4.0186e-01,  1.2863e-02,  1.0095e-01],\n",
      "       [ 1.8359e+00, -3.8037e-01, -1.6113e+00],\n",
      "       [ 2.7656e+00, -1.3342e-01, -2.9551e+00],\n",
      "       [ 3.1172e+00, -2.8320e-01, -2.8926e+00],\n",
      "       [ 2.7246e+00, -1.1658e-01, -2.8223e+00],\n",
      "       [-7.8125e-01,  7.3877e-01, -4.2542e-02]], dtype=float16), label_ids=array([1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 2, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n",
      "       1, 1, 1, 2, 0, 2, 1, 0, 0, 0, 0, 0, 1, 1, 2, 0, 2, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 2, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 2, 1, 0, 1, 0,\n",
      "       1, 0, 2, 1, 0, 1, 1, 1, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "       1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 2, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
      "       1, 0, 0, 0, 1, 0, 0, 0, 2, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
      "       0, 1, 0, 1, 0, 0, 1, 0, 2, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
      "       0, 0, 0, 1, 0, 0, 2, 2, 0, 2, 0, 1, 0, 1, 1, 0, 2, 0, 1, 0, 0, 1,\n",
      "       0, 1, 0, 0, 1, 2, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 2,\n",
      "       0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 2, 0, 0, 2]), metrics={'test_loss': 1.0196533203125, 'test_accuracy': 0.6452991452991453, 'test_precision': 0.6600689758584495, 'test_recall': 0.6452991452991453, 'test_f1': 0.6181888929141676, 'test_runtime': 0.5826, 'test_samples_per_second': 401.645, 'test_steps_per_second': 13.731})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "808dd68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48fb2163",
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = torch.softmax(torch.tensor(test_results.predictions).to(torch.float32), dim=-1)\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed6cfde2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")  # Adjust xticklabels and yticklabels as needed\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "346c6d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_save = []\n",
    "for idx in range(len(test_data)):\n",
    "    item = dataset['test'][idx]\n",
    "    actual_label = item['label']\n",
    "    predicted_label = predictions[idx]\n",
    "    claim = item['claim'] \n",
    "    premise = item['premise'] \n",
    "    category = item['category']\n",
    "    \n",
    "    # Append the information as a dictionary to the list\n",
    "    data_to_save.append({\n",
    "        'Claim': claim,\n",
    "        'Premise': premise,\n",
    "        'Actual Label': actual_label,\n",
    "        'Predicted Label': predicted_label,\n",
    "        'Category' : category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_to_save)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/home/elson/results/11.1.3_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4543aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correctly classified instances\n",
    "correctly_classified = df[df['Actual Label'] == df['Predicted Label']]\n",
    "\n",
    "# Calculate misclassified instances\n",
    "misclassified = df[df['Actual Label'] != df['Predicted Label']]\n",
    "\n",
    "# Count the number of correctly classified and misclassified by category\n",
    "correct_classification_counts = correctly_classified['Category'].value_counts()\n",
    "misclassification_counts = misclassified['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad099d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           36\n",
       "Bone health              16\n",
       "Skin                     11\n",
       "Cancer                   10\n",
       "Fitness                  10\n",
       "Cardiovascular Health     9\n",
       "Diabetes                  9\n",
       "Throat                    7\n",
       "Neurological health       7\n",
       "Hair                      6\n",
       "Ear                       6\n",
       "COVID                     4\n",
       "Blood                     4\n",
       "Mental Health             3\n",
       "Muscles                   3\n",
       "Men's health              3\n",
       "Eye                       3\n",
       "Women' s Health           2\n",
       "Vascular                  2\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d45817c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           15\n",
       "Skin                     13\n",
       "Eye                       6\n",
       "Hair                      6\n",
       "Blood                     5\n",
       "Bone health               5\n",
       "Fitness                   5\n",
       "Women' s Health           4\n",
       "Muscles                   3\n",
       "Cardiovascular Health     3\n",
       "Dental Health             3\n",
       "Men's health              3\n",
       "Diabetes                  3\n",
       "Cancer                    2\n",
       "COVID                     2\n",
       "Throat                    2\n",
       "Neurological health       2\n",
       "Vascular                  1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
