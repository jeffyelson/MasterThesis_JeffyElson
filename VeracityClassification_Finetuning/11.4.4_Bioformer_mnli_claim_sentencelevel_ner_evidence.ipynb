{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-022bc67e9c58e92d\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 333.86it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('csv',data_files='dataset_propositionattribution_nerfeatures.csv',delimiter=',',column_names=[\"claim\",\"premise\",\"label\",\"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\",\"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\",\"url\", \"entities\",\"entity_map\",\"entity_map_ev\",\"entities_ev\",\"gem_exp\",\"gem_label\",\"gpt_label\",\"gpt_exp\",\"gold_exp\",\"synonym\",\"voice\",\"split\"],skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "133f9357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-2b8e361375c0e153.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-0cc9bb699c2761fb.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-608a44ac65076739.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01252e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\"claim\", \"premise\", \"label\", \"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\"]\n",
    "all_columns = dataset[\"train\"].column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-18f96bf5c6176fc5.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-6db4f01ca05878d4.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-1a61e2b1bf2efa35.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 2, 'entailment': 0, 'neutral': 1}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 2,\n",
    "    \"entailment\": 0,\n",
    "    \"neutral\": 1\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e15010ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='bioformers/bioformer-8L-mnli'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "        # Extracting claim and evidence texts\n",
    "        claim = item['claim'] \n",
    "        evidences = item['premise']\n",
    "        item['premise']=evidences\n",
    "        item['claim']=claim\n",
    "        additional_features = [\n",
    "            \"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\"]\n",
    "    \n",
    "        for feature in additional_features:\n",
    "            if feature in item:\n",
    "                evidences += \"[SEP]\" + str(item[feature])\n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "            evidences, claim,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "         # Construct the output item\n",
    "        output_item = {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),  # Remove batch dimension\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),  # Remove batch dimension\n",
    "            'claim': claim,  # Include augmented claim text\n",
    "            'evidences': evidences  # Include original evidence text\n",
    "        }\n",
    "        \n",
    "        if 'label' in item:\n",
    "            output_item['label'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return output_item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62421eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(32768, 512, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 512)\n",
       "      (token_type_embeddings): Embedding(2, 512)\n",
       "      (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=512, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"bioformers/bioformer-8L-mnli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=512)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=3, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    return {\"accuracy\": acc, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f5cf584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  101,  1480,  3720, 15658,  1431,  2132,  4765,  2848,  9507,  1111,\n",
       "          1435,  2573,  1109,  4258,  2161,  1425, 26267,  1431,  1425,  3460,\n",
       "         14360,  1427,  1425, 26669,  1435,  2731,  1425,  2784,  1456,  1435,\n",
       "         10036,  2700,  1446,  2161,  1425,  7805,  1431,  1425,  3550,  1435,\n",
       "          3026,  1425,  6245,  1997,   119,   102, 31487,  4258,  3720,  6187,\n",
       "          1478,  8811,  1822,  1427,  3550,  5183,  4030,  1446,  3346,  2520,\n",
       "          1425,  6875,  1431,  1425,  3550,   119,   102,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'claim': 'Myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.',\n",
       " 'evidences': 'The essential oils of frankincense and myrrh increase the fluidity of the lipid bilayer in the cuticle and change the orderly and dense structure to increase the permeability of the skin and decrease the barrier effect.',\n",
       " 'label': tensor(0)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1530\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1530' max='1530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1530/1530 03:21, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.860200</td>\n",
       "      <td>0.810700</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.610067</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.613419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.598600</td>\n",
       "      <td>0.918428</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.638342</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.615299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.367600</td>\n",
       "      <td>1.074302</td>\n",
       "      <td>0.634409</td>\n",
       "      <td>0.620267</td>\n",
       "      <td>0.634409</td>\n",
       "      <td>0.620184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.168700</td>\n",
       "      <td>1.341421</td>\n",
       "      <td>0.608602</td>\n",
       "      <td>0.646743</td>\n",
       "      <td>0.608602</td>\n",
       "      <td>0.623852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.226600</td>\n",
       "      <td>1.342105</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.637937</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.634955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.149300</td>\n",
       "      <td>1.531881</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.627386</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.634491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.040900</td>\n",
       "      <td>1.709950</td>\n",
       "      <td>0.634409</td>\n",
       "      <td>0.629242</td>\n",
       "      <td>0.634409</td>\n",
       "      <td>0.631720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.092800</td>\n",
       "      <td>1.842507</td>\n",
       "      <td>0.647312</td>\n",
       "      <td>0.651712</td>\n",
       "      <td>0.647312</td>\n",
       "      <td>0.648658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>2.013170</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.625821</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.627832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>2.075166</td>\n",
       "      <td>0.640860</td>\n",
       "      <td>0.649879</td>\n",
       "      <td>0.640860</td>\n",
       "      <td>0.644114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.039700</td>\n",
       "      <td>2.129631</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.622147</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.630941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.020500</td>\n",
       "      <td>2.181947</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.634235</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.638132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>2.258893</td>\n",
       "      <td>0.636559</td>\n",
       "      <td>0.633623</td>\n",
       "      <td>0.636559</td>\n",
       "      <td>0.634967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>2.251967</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.647191</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.645776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>2.244458</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.649621</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.649172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.4_bioformer/checkpoint-102\n",
      "Configuration saved in /home/elson/11.4.4_bioformer/checkpoint-102/config.json\n",
      "Model weights saved in /home/elson/11.4.4_bioformer/checkpoint-102/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.4_bioformer/checkpoint-51] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/11.4.4_bioformer/checkpoint-765] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.4_bioformer/checkpoint-204\n",
      "Configuration saved in /home/elson/11.4.4_bioformer/checkpoint-204/config.json\n",
      "Model weights saved in /home/elson/11.4.4_bioformer/checkpoint-204/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.4_bioformer/checkpoint-306\n",
      "Configuration saved in /home/elson/11.4.4_bioformer/checkpoint-306/config.json\n",
      "Model weights saved in /home/elson/11.4.4_bioformer/checkpoint-306/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.4_bioformer/checkpoint-204] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.4_bioformer/checkpoint-408\n",
      "Configuration saved in /home/elson/11.4.4_bioformer/checkpoint-408/config.json\n",
      "Model weights saved in /home/elson/11.4.4_bioformer/checkpoint-408/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.4_bioformer/checkpoint-306] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.4_bioformer/checkpoint-510\n",
      "Configuration saved in /home/elson/11.4.4_bioformer/checkpoint-510/config.json\n",
      "Model weights saved in /home/elson/11.4.4_bioformer/checkpoint-510/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.4_bioformer/checkpoint-408] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.4_bioformer/checkpoint-612\n",
      "Configuration saved in /home/elson/11.4.4_bioformer/checkpoint-612/config.json\n",
      "Model weights saved in /home/elson/11.4.4_bioformer/checkpoint-612/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.4_bioformer/checkpoint-102] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/11.4.4_bioformer/checkpoint-510] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.4_bioformer/checkpoint-714\n",
      "Configuration saved in /home/elson/11.4.4_bioformer/checkpoint-714/config.json\n",
      "Model weights saved in /home/elson/11.4.4_bioformer/checkpoint-714/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.4_bioformer/checkpoint-816\n",
      "Configuration saved in /home/elson/11.4.4_bioformer/checkpoint-816/config.json\n",
      "Model weights saved in /home/elson/11.4.4_bioformer/checkpoint-816/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.4_bioformer/checkpoint-714] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.4_bioformer/checkpoint-918\n",
      "Configuration saved in /home/elson/11.4.4_bioformer/checkpoint-918/config.json\n",
      "Model weights saved in /home/elson/11.4.4_bioformer/checkpoint-918/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.4_bioformer/checkpoint-816] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.4_bioformer/checkpoint-1020\n",
      "Configuration saved in /home/elson/11.4.4_bioformer/checkpoint-1020/config.json\n",
      "Model weights saved in /home/elson/11.4.4_bioformer/checkpoint-1020/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.4_bioformer/checkpoint-918] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.4_bioformer/checkpoint-1122\n",
      "Configuration saved in /home/elson/11.4.4_bioformer/checkpoint-1122/config.json\n",
      "Model weights saved in /home/elson/11.4.4_bioformer/checkpoint-1122/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.4_bioformer/checkpoint-1020] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.4_bioformer/checkpoint-1224\n",
      "Configuration saved in /home/elson/11.4.4_bioformer/checkpoint-1224/config.json\n",
      "Model weights saved in /home/elson/11.4.4_bioformer/checkpoint-1224/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.4_bioformer/checkpoint-1122] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.4_bioformer/checkpoint-1326\n",
      "Configuration saved in /home/elson/11.4.4_bioformer/checkpoint-1326/config.json\n",
      "Model weights saved in /home/elson/11.4.4_bioformer/checkpoint-1326/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.4_bioformer/checkpoint-1224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.4_bioformer/checkpoint-1428\n",
      "Configuration saved in /home/elson/11.4.4_bioformer/checkpoint-1428/config.json\n",
      "Model weights saved in /home/elson/11.4.4_bioformer/checkpoint-1428/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.4_bioformer/checkpoint-1326] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/11.4.4_bioformer/checkpoint-1530\n",
      "Configuration saved in /home/elson/11.4.4_bioformer/checkpoint-1530/config.json\n",
      "Model weights saved in /home/elson/11.4.4_bioformer/checkpoint-1530/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.4.4_bioformer/checkpoint-1428] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/elson/11.4.4_bioformer/checkpoint-612 (score: 0.6559139784946236).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /home/elson/11.4.4_bioformer/best_model/config.json\n",
      "Model weights saved in /home/elson/11.4.4_bioformer/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/11.4.4_bioformer/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/11.4.4_bioformer/best_model/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/11.4.4_bioformer/best_model/tokenizer_config.json',\n",
       " '/home/elson/11.4.4_bioformer/best_model/special_tokens_map.json',\n",
       " '/home/elson/11.4.4_bioformer/best_model/vocab.txt',\n",
       " '/home/elson/11.4.4_bioformer/best_model/added_tokens.json',\n",
       " '/home/elson/11.4.4_bioformer/best_model/tokenizer.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/11.4.4_bioformer/',\n",
    "    num_train_epochs=15,\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.1,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/11.4.4_bioformer/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/11.4.4_bioformer/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63deaea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/11.4.4_bioformer/best_model/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"/home/elson/11.4.4_bioformer/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"finetuning_task\": \"mnli\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 512,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"entailment\",\n",
      "    \"1\": \"neutral\",\n",
      "    \"2\": \"contradiction\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2048,\n",
      "  \"label2id\": {\n",
      "    \"contradiction\": 2,\n",
      "    \"entailment\": 0,\n",
      "    \"neutral\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 8,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32768\n",
      "}\n",
      "\n",
      "loading weights file /home/elson/11.4.4_bioformer/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at /home/elson/11.4.4_bioformer/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 16\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/11.4.4_bioformer/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[ 4.48   , -2.123  , -2.459  ],\n",
      "       [ 3.611  ,  0.4985 , -4.26   ],\n",
      "       [ 4.414  , -2.244  , -2.346  ],\n",
      "       [-2.81   , -1.7    ,  4.72   ],\n",
      "       [ 4.293  , -1.823  , -2.486  ],\n",
      "       [ 4.754  , -2.04   , -2.72   ],\n",
      "       [ 4.625  , -2.46   , -2.303  ],\n",
      "       [ 4.44   , -1.387  , -3.135  ],\n",
      "       [ 2.748  , -1.565  , -1.397  ],\n",
      "       [ 3.752  , -1.962  , -1.854  ],\n",
      "       [ 4.395  , -2.955  , -1.617  ],\n",
      "       [ 4.72   , -2.367  , -2.4    ],\n",
      "       [ 4.664  , -1.489  , -3.205  ],\n",
      "       [ 4.72   , -1.693  , -3.125  ],\n",
      "       [ 4.777  , -1.765  , -3.096  ],\n",
      "       [ 0.726  ,  0.612  , -2.062  ],\n",
      "       [ 4.73   , -1.754  , -3.025  ],\n",
      "       [ 4.76   , -1.953  , -2.875  ],\n",
      "       [ 3.639  , -1.227  , -2.66   ],\n",
      "       [ 4.727  , -2.273  , -2.484  ],\n",
      "       [ 0.5317 , -1.743  ,  0.6113 ],\n",
      "       [ 2.963  , -0.612  , -2.709  ],\n",
      "       [ 4.3    , -2.498  , -1.972  ],\n",
      "       [-2.215  , -1.996  ,  4.234  ],\n",
      "       [-1.674  , -2.133  ,  3.668  ],\n",
      "       [-0.725  ,  1.032  , -0.4065 ],\n",
      "       [ 4.76   , -1.992  , -2.807  ],\n",
      "       [-1.068  ,  4.37   , -2.84   ],\n",
      "       [ 4.547  , -0.928  , -3.674  ],\n",
      "       [ 3.725  , -2.865  , -0.9556 ],\n",
      "       [ 3.334  , -0.7354 , -2.857  ],\n",
      "       [ 4.65   , -1.585  , -3.117  ],\n",
      "       [ 3.78   , -0.22   , -3.805  ],\n",
      "       [-0.811  , -1.2705 ,  2.281  ],\n",
      "       [ 3.684  , -1.352  , -2.66   ],\n",
      "       [ 4.53   , -1.114  , -3.527  ],\n",
      "       [ 4.598  , -2.213  , -2.46   ],\n",
      "       [ 4.523  , -1.452  , -3.145  ],\n",
      "       [ 1.032  , -2.746  ,  1.904  ],\n",
      "       [ 4.168  , -0.5684 , -3.787  ],\n",
      "       [ 0.535  , -1.026  ,  0.2544 ],\n",
      "       [-0.03757,  3.508  , -3.58   ],\n",
      "       [ 0.261  , -1.182  ,  0.5073 ],\n",
      "       [ 3.188  , -3.041  , -0.424  ],\n",
      "       [ 4.227  , -1.455  , -3.07   ],\n",
      "       [ 4.727  , -1.6455 , -3.121  ],\n",
      "       [ 4.027  , -0.93   , -3.332  ],\n",
      "       [ 4.543  , -0.8613 , -3.695  ],\n",
      "       [ 4.523  , -2.453  , -2.225  ],\n",
      "       [-1.613  , -2.117  ,  3.887  ],\n",
      "       [ 3.256  , -2.402  , -1.3125 ],\n",
      "       [-1.404  ,  2.773  , -1.146  ],\n",
      "       [ 3.469  , -0.7935 , -2.963  ],\n",
      "       [ 2.67   ,  0.68   , -3.504  ],\n",
      "       [-1.945  , -0.0911 ,  1.827  ],\n",
      "       [-0.4785 ,  2.092  , -1.421  ],\n",
      "       [ 0.1831 ,  2.148  , -2.22   ],\n",
      "       [ 1.02   ,  2.656  , -3.885  ],\n",
      "       [ 2.873  , -1.032  , -2.26   ],\n",
      "       [ 4.547  , -2.248  , -2.564  ],\n",
      "       [ 4.703  , -1.992  , -2.762  ],\n",
      "       [-1.746  , -2.117  ,  3.967  ],\n",
      "       [ 2.357  ,  1.84   , -4.2    ],\n",
      "       [ 4.027  , -0.6206 , -3.303  ],\n",
      "       [ 4.117  , -0.3564 , -3.947  ],\n",
      "       [ 4.63   , -2.2    , -2.465  ],\n",
      "       [ 4.703  , -1.981  , -2.81   ],\n",
      "       [ 4.492  , -1.996  , -2.66   ],\n",
      "       [ 4.336  , -2.977  , -1.5625 ],\n",
      "       [-0.5986 , -1.93   ,  2.285  ],\n",
      "       [ 4.457  , -1.344  , -3.273  ],\n",
      "       [ 3.568  , -1.468  , -2.363  ],\n",
      "       [ 4.668  , -1.544  , -3.244  ],\n",
      "       [ 4.637  , -1.385  , -3.227  ],\n",
      "       [ 2.947  , -1.526  , -1.937  ],\n",
      "       [ 2.273  , -2.65   , -0.03275],\n",
      "       [ 4.605  , -2.244  , -2.496  ],\n",
      "       [ 4.465  , -1.429  , -3.174  ],\n",
      "       [ 4.336  , -2.336  , -2.195  ],\n",
      "       [ 4.15   , -2.87   , -1.562  ],\n",
      "       [ 4.395  , -1.738  , -2.768  ],\n",
      "       [ 4.664  , -1.862  , -2.97   ],\n",
      "       [ 4.203  , -1.202  , -3.314  ],\n",
      "       [ 4.6    , -2.582  , -2.15   ],\n",
      "       [ 4.64   , -2.055  , -2.697  ],\n",
      "       [ 4.387  , -1.568  , -2.943  ],\n",
      "       [ 4.46   , -2.568  , -2.02   ],\n",
      "       [ 3.936  , -1.192  , -3.016  ],\n",
      "       [ 3.348  ,  0.4768 , -3.963  ],\n",
      "       [ 2.219  ,  1.819  , -4.133  ],\n",
      "       [ 4.543  , -2.3    , -2.383  ],\n",
      "       [ 4.684  , -1.487  , -3.215  ],\n",
      "       [-2.32   , -1.462  ,  3.994  ],\n",
      "       [ 4.758  , -1.526  , -3.266  ],\n",
      "       [-0.4688 ,  1.643  , -1.201  ],\n",
      "       [ 0.633  , -0.306  , -0.6353 ],\n",
      "       [-0.538  , -2.64   ,  2.754  ],\n",
      "       [ 3.389  , -1.075  , -2.742  ],\n",
      "       [ 4.637  , -1.316  , -3.361  ],\n",
      "       [ 4.742  , -1.701  , -3.111  ],\n",
      "       [ 1.842  , -3.756  ,  1.855  ],\n",
      "       [ 4.78   , -1.776  , -3.031  ],\n",
      "       [ 4.746  , -2.059  , -2.732  ],\n",
      "       [ 3.428  ,  0.815  , -4.4    ],\n",
      "       [ 4.516  , -1.622  , -2.93   ],\n",
      "       [ 4.66   , -1.704  , -3.037  ],\n",
      "       [ 4.195  , -2.531  , -1.765  ],\n",
      "       [ 2.617  , -2.08   , -0.628  ],\n",
      "       [ 4.29   , -0.765  , -3.672  ],\n",
      "       [ 4.56   , -1.43   , -3.215  ],\n",
      "       [ 2.447  ,  1.413  , -4.145  ],\n",
      "       [ 4.465  , -1.714  , -2.82   ],\n",
      "       [ 4.105  , -1.622  , -2.791  ],\n",
      "       [ 4.586  , -2.219  , -2.488  ],\n",
      "       [ 2.074  ,  0.967  , -3.4    ],\n",
      "       [ 4.242  , -1.65   , -2.727  ],\n",
      "       [ 4.703  , -2.297  , -2.504  ],\n",
      "       [ 2.787  , -3.318  ,  0.7266 ],\n",
      "       [ 4.39   , -2.521  , -2.049  ],\n",
      "       [ 4.688  , -1.723  , -3.03   ],\n",
      "       [ 2.166  ,  1.931  , -4.03   ],\n",
      "       [ 4.438  , -1.1045 , -3.447  ],\n",
      "       [ 3.799  ,  0.1454 , -4.04   ],\n",
      "       [ 3.256  ,  0.575  , -3.861  ],\n",
      "       [ 0.58   ,  2.705  , -3.225  ],\n",
      "       [ 4.723  , -1.807  , -3.092  ],\n",
      "       [ 4.453  , -1.202  , -3.367  ],\n",
      "       [ 4.66   , -2.248  , -2.541  ],\n",
      "       [ 4.566  , -1.846  , -2.871  ],\n",
      "       [ 4.367  , -1.832  , -2.887  ],\n",
      "       [ 0.885  , -1.693  ,  0.7773 ],\n",
      "       [-2.574  , -0.8975 ,  3.234  ],\n",
      "       [ 4.59   , -1.591  , -3.025  ],\n",
      "       [ 1.418  , -2.639  ,  0.58   ],\n",
      "       [ 4.445  , -1.015  , -3.463  ],\n",
      "       [ 4.547  , -2.172  , -2.506  ],\n",
      "       [ 4.51   , -2.363  , -2.31   ],\n",
      "       [ 0.2092 ,  2.45   , -2.738  ],\n",
      "       [-1.04   ,  1.912  , -0.5845 ],\n",
      "       [ 4.754  , -2.057  , -2.74   ],\n",
      "       [ 4.74   , -1.793  , -2.99   ],\n",
      "       [-1.6045 , -1.771  ,  3.363  ],\n",
      "       [-2.13   ,  2.88   , -0.4382 ],\n",
      "       [ 4.72   , -1.748  , -2.979  ],\n",
      "       [ 4.242  , -2.043  , -2.404  ],\n",
      "       [ 1.879  ,  0.757  , -3.053  ],\n",
      "       [-2.654  , -1.38   ,  4.285  ],\n",
      "       [ 0.371  , -1.108  ,  0.735  ],\n",
      "       [ 4.703  , -1.491  , -3.277  ],\n",
      "       [ 1.753  ,  1.794  , -3.738  ],\n",
      "       [ 4.62   , -1.55   , -3.137  ],\n",
      "       [ 4.508  , -2.293  , -2.385  ],\n",
      "       [ 3.486  , -0.8735 , -3.045  ],\n",
      "       [ 4.598  , -2.014  , -2.758  ],\n",
      "       [ 4.73   , -1.97   , -2.81   ],\n",
      "       [ 4.645  , -2.553  , -2.156  ],\n",
      "       [ 4.457  , -2.766  , -1.849  ],\n",
      "       [ 4.668  , -2.117  , -2.643  ],\n",
      "       [-2.459  ,  2.629  ,  0.3682 ],\n",
      "       [-1.985  , -2.043  ,  4.215  ],\n",
      "       [-2.064  , -1.977  ,  4.21   ],\n",
      "       [-1.958  , -2.148  ,  4.363  ],\n",
      "       [ 3.695  , -1.748  , -2.424  ],\n",
      "       [-1.547  , -1.205  ,  2.31   ],\n",
      "       [-0.4504 ,  1.071  , -0.997  ],\n",
      "       [ 4.152  , -2.402  , -2.045  ],\n",
      "       [ 4.55   , -1.974  , -2.748  ],\n",
      "       [ 0.9224 , -1.823  ,  0.2424 ],\n",
      "       [ 1.377  , -1.991  ,  0.5493 ],\n",
      "       [-0.6562 , -1.522  ,  2.451  ],\n",
      "       [-2.65   ,  0.2666 ,  2.363  ],\n",
      "       [ 0.989  , -1.671  ,  0.943  ],\n",
      "       [ 3.676  , -2.326  , -1.654  ],\n",
      "       [ 4.46   , -1.484  , -3.027  ],\n",
      "       [ 4.703  , -2.08   , -2.64   ],\n",
      "       [ 3.963  , -0.7876 , -3.352  ],\n",
      "       [ 4.695  , -1.976  , -2.822  ],\n",
      "       [ 1.657  , -2.61   ,  1.061  ],\n",
      "       [ 4.566  , -2.059  , -2.555  ],\n",
      "       [ 1.121  ,  1.414  , -2.006  ],\n",
      "       [ 2.176  , -0.9937 , -1.831  ],\n",
      "       [ 4.098  , -2.502  , -1.824  ],\n",
      "       [ 0.3408 , -2.441  ,  2.184  ],\n",
      "       [ 4.617  , -1.925  , -2.584  ],\n",
      "       [ 0.626  ,  0.0951 , -0.8066 ],\n",
      "       [ 4.625  , -2.377  , -2.387  ],\n",
      "       [ 4.773  , -1.829  , -2.922  ],\n",
      "       [ 4.758  , -1.792  , -2.98   ],\n",
      "       [ 3.53   , -0.03986, -3.465  ],\n",
      "       [ 4.58   , -1.582  , -3.105  ],\n",
      "       [ 3.205  ,  0.515  , -3.822  ],\n",
      "       [ 2.588  , -1.409  , -1.275  ],\n",
      "       [ 2.799  , -2.527  , -0.3535 ],\n",
      "       [ 2.307  ,  1.586  , -4.01   ],\n",
      "       [-2.125  , -1.508  ,  3.938  ],\n",
      "       [ 4.723  , -2.053  , -2.729  ],\n",
      "       [ 4.22   , -1.007  , -3.398  ],\n",
      "       [ 4.758  , -2.014  , -2.756  ],\n",
      "       [ 4.48   , -2.66   , -1.954  ],\n",
      "       [ 3.201  , -0.5884 , -3.     ],\n",
      "       [ 4.688  , -2.494  , -2.248  ],\n",
      "       [ 4.723  , -1.851  , -2.883  ],\n",
      "       [ 3.955  , -2.297  , -1.661  ],\n",
      "       [ 4.34   , -1.276  , -3.12   ],\n",
      "       [ 4.094  , -1.17   , -3.242  ],\n",
      "       [-1.515  , -1.25   ,  2.672  ],\n",
      "       [ 4.66   , -2.42   , -2.371  ],\n",
      "       [ 3.729  , -0.1357 , -3.828  ],\n",
      "       [ 4.508  , -1.995  , -2.674  ],\n",
      "       [ 3.672  , -1.296  , -2.95   ],\n",
      "       [ 2.416  ,  1.626  , -4.188  ],\n",
      "       [ 3.61   , -1.242  , -2.742  ],\n",
      "       [ 3.64   , -1.59   , -2.46   ],\n",
      "       [ 4.19   , -1.041  , -3.293  ],\n",
      "       [ 4.707  , -2.033  , -2.756  ],\n",
      "       [-1.929  , -2.281  ,  4.113  ],\n",
      "       [ 0.0364 , -2.736  ,  2.037  ],\n",
      "       [ 3.879  , -2.486  , -1.615  ],\n",
      "       [ 4.703  , -1.829  , -2.94   ],\n",
      "       [ 0.02988,  1.961  , -1.754  ],\n",
      "       [ 4.543  , -1.213  , -3.36   ],\n",
      "       [ 2.207  ,  1.786  , -4.273  ],\n",
      "       [ 0.7217 , -2.443  ,  1.335  ],\n",
      "       [ 4.6    , -1.715  , -3.004  ],\n",
      "       [ 4.5    , -2.107  , -2.465  ],\n",
      "       [ 4.754  , -1.818  , -2.945  ],\n",
      "       [ 4.566  , -1.941  , -2.727  ],\n",
      "       [-2.135  , -1.14   ,  3.225  ],\n",
      "       [ 1.07   , -1.322  ,  0.3108 ],\n",
      "       [-1.09   ,  0.02097,  1.464  ],\n",
      "       [ 4.746  , -1.858  , -2.914  ],\n",
      "       [ 4.625  , -1.4375 , -3.217  ],\n",
      "       [ 4.36   , -2.648  , -1.765  ],\n",
      "       [ 2.77   , -2.617  , -0.10736]], dtype=float16), label_ids=array([0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
      "       0, 1, 2, 2, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 2, 0, 2, 1, 0, 0,\n",
      "       1, 2, 0, 0, 0, 2, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 2, 1, 0, 1, 0,\n",
      "       0, 1, 2, 2, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
      "       0, 1, 0, 0, 1, 0, 1, 1, 2, 0, 0, 1, 2, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "       1, 2, 0, 0, 1, 0, 0, 0, 1, 2, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
      "       0, 1, 0, 1, 0, 0, 1, 0, 2, 0, 0, 0, 1, 1, 2, 1, 0, 0, 0, 0, 1, 1,\n",
      "       2, 0, 0, 1, 0, 2, 2, 2, 1, 0, 0, 1, 0, 1, 2, 0, 2, 0, 1, 0, 0, 0,\n",
      "       0, 2, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 2, 2, 0, 1, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 2, 0, 0,\n",
      "       0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 2, 0, 0, 1]), metrics={'test_loss': 1.7804009914398193, 'test_accuracy': 0.6025641025641025, 'test_precision': 0.5398593871020342, 'test_recall': 0.6025641025641025, 'test_f1': 0.5374952567524178, 'test_runtime': 0.5816, 'test_samples_per_second': 402.304, 'test_steps_per_second': 25.789})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "808dd68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48fb2163",
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = torch.softmax(torch.tensor(test_results.predictions).to(torch.float32), dim=-1)\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed6cfde2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")  # Adjust xticklabels and yticklabels as needed\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "346c6d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_save = []\n",
    "for idx in range(len(test_data)):\n",
    "    item = dataset['test'][idx]\n",
    "    actual_label = item['label']\n",
    "    predicted_label = predictions[idx]\n",
    "    claim = item['claim'] \n",
    "    premise = item['premise'] \n",
    "    category = item['category']\n",
    "    \n",
    "    # Append the information as a dictionary to the list\n",
    "    data_to_save.append({\n",
    "        'Claim': claim,\n",
    "        'Premise': premise,\n",
    "        'Actual Label': actual_label,\n",
    "        'Predicted Label': predicted_label,\n",
    "        'Category' : category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_to_save)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/home/elson/results/11.4.4_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4543aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correctly classified instances\n",
    "correctly_classified = df[df['Actual Label'] == df['Predicted Label']]\n",
    "\n",
    "# Calculate misclassified instances\n",
    "misclassified = df[df['Actual Label'] != df['Predicted Label']]\n",
    "\n",
    "# Count the number of correctly classified and misclassified by category\n",
    "correct_classification_counts = correctly_classified['Category'].value_counts()\n",
    "misclassification_counts = misclassified['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad099d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           37\n",
       "Fitness                  13\n",
       "Bone health              13\n",
       "Diabetes                  9\n",
       "Cancer                    9\n",
       "Throat                    9\n",
       "Cardiovascular Health     8\n",
       "Skin                      7\n",
       "Ear                       6\n",
       "Hair                      5\n",
       "Blood                     5\n",
       "Women' s Health           4\n",
       "COVID                     4\n",
       "Mental Health             3\n",
       "Neurological health       3\n",
       "Men's health              3\n",
       "Muscles                   2\n",
       "Eye                       1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d45817c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Skin                     17\n",
       "General Health           14\n",
       "Bone health               8\n",
       "Eye                       8\n",
       "Hair                      7\n",
       "Neurological health       6\n",
       "Muscles                   4\n",
       "Cardiovascular Health     4\n",
       "Blood                     4\n",
       "Diabetes                  3\n",
       "Dental Health             3\n",
       "Men's health              3\n",
       "Vascular                  3\n",
       "Cancer                    3\n",
       "COVID                     2\n",
       "Fitness                   2\n",
       "Women' s Health           2\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
