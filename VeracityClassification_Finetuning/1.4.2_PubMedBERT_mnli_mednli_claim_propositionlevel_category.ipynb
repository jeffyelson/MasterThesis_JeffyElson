{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-927ab0163adb9fdb\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-927ab0163adb9fdb/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 225.20it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('csv',data_files='dataset_propositionattribution_nerfeatures.csv',delimiter=',',column_names=[\"claim\",\"premise\",\"label\",\"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\",\"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\",\"url\", \"entities\",\"entity_map\",\"gem_exp\",\"gem_label\",\"gpt_label\",\"gpt_exp\",\"gold_exp\",\"entity_map_ev\",\"entity_ev\",\"split\"],skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "133f9357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-927ab0163adb9fdb/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-d013d5114fa105ab.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-927ab0163adb9fdb/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-16f9acbdd82fea07.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-927ab0163adb9fdb/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-47c7de469e4087a2.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01252e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\"claim\", \"premise\", \"label\",\"category\"]\n",
    "all_columns = dataset[\"train\"].column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-927ab0163adb9fdb/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-a0ade6057eafd020.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-927ab0163adb9fdb/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-c809019fdbb6b1ab.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-927ab0163adb9fdb/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-1b131fbcc3716578.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 0, 'entailment': 1, 'neutral': 2}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 0,\n",
    "    \"entailment\": 1,\n",
    "    \"neutral\": 2\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='pritamdeka/PubMedBERT-MNLI-MedNLI'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "        # Extracting claim and evidence texts\n",
    "\n",
    "        claim = item['claim'] + \"[SEP]\"+ item['category']\n",
    "        evidences = item['premise']\n",
    "        item['premise']=evidences\n",
    "        item['claim']=claim\n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "            evidences, claim,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "        item['input_ids'] = inputs['input_ids'].squeeze()  # Remove batch dimension\n",
    "        item['attention_mask']= inputs['attention_mask'].squeeze() # Remove batch dimension\n",
    "        \n",
    "        if 'label' in item:\n",
    "            item['labels'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62421eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"pritamdeka/PubMedBERT-MNLI-MedNLI\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=512)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=3, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    return {\"accuracy\": acc, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f5cf584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'claim': 'Myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.[SEP]General Health',\n",
       " 'premise': 'The essential oils of frankincense and myrrh increase the fluidity of the lipid bilayer in the cuticle and change the orderly and dense structure to increase the permeability of the skin and decrease the barrier effect.',\n",
       " 'label': 1,\n",
       " 'category': 'General Health',\n",
       " 'input_ids': tensor([    2,  1920,  4415, 16984,  1927, 14542,  4006,  4480,  1930, 14227,\n",
       "          5004,  2760,  1920, 29555,  1927,  1920,  4486, 14269,  1922,  1920,\n",
       "         25420,  1930,  3185,  1920,  3238,  1954,  1930, 10472,  3170,  1942,\n",
       "          2760,  1920,  8828,  1927,  1920,  4407,  1930,  3714,  1920,  7104,\n",
       "          2495,    18,     3, 14227,  5004,  4415,  6691,  1977,  8929,  2251,\n",
       "          1922,  4407,  5715,  4461,  1942,  4087,  3326,  1920,  7818,  1927,\n",
       "          1920,  4407,    18,     3,  3335,  2436,     3,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'labels': tensor(1)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 2040\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2040' max='2040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2040/2040 09:19, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.761500</td>\n",
       "      <td>0.744627</td>\n",
       "      <td>0.701075</td>\n",
       "      <td>0.652587</td>\n",
       "      <td>0.701075</td>\n",
       "      <td>0.674448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.308800</td>\n",
       "      <td>1.493035</td>\n",
       "      <td>0.593548</td>\n",
       "      <td>0.691545</td>\n",
       "      <td>0.593548</td>\n",
       "      <td>0.631547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.132900</td>\n",
       "      <td>1.768199</td>\n",
       "      <td>0.673118</td>\n",
       "      <td>0.686414</td>\n",
       "      <td>0.673118</td>\n",
       "      <td>0.679282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.026600</td>\n",
       "      <td>2.047672</td>\n",
       "      <td>0.658065</td>\n",
       "      <td>0.699693</td>\n",
       "      <td>0.658065</td>\n",
       "      <td>0.673221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.117600</td>\n",
       "      <td>2.180363</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.694378</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.667247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.038200</td>\n",
       "      <td>2.119816</td>\n",
       "      <td>0.670968</td>\n",
       "      <td>0.701985</td>\n",
       "      <td>0.670968</td>\n",
       "      <td>0.678692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.091300</td>\n",
       "      <td>2.289762</td>\n",
       "      <td>0.701075</td>\n",
       "      <td>0.698288</td>\n",
       "      <td>0.701075</td>\n",
       "      <td>0.699663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.606069</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.693943</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.669900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>2.662397</td>\n",
       "      <td>0.679570</td>\n",
       "      <td>0.702105</td>\n",
       "      <td>0.679570</td>\n",
       "      <td>0.689077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.734014</td>\n",
       "      <td>0.662366</td>\n",
       "      <td>0.683420</td>\n",
       "      <td>0.662366</td>\n",
       "      <td>0.669366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.024400</td>\n",
       "      <td>2.897628</td>\n",
       "      <td>0.668817</td>\n",
       "      <td>0.700369</td>\n",
       "      <td>0.668817</td>\n",
       "      <td>0.682535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.859604</td>\n",
       "      <td>0.679570</td>\n",
       "      <td>0.686883</td>\n",
       "      <td>0.679570</td>\n",
       "      <td>0.683102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.945879</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.695016</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.684661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.967981</td>\n",
       "      <td>0.679570</td>\n",
       "      <td>0.696276</td>\n",
       "      <td>0.679570</td>\n",
       "      <td>0.686500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.989017</td>\n",
       "      <td>0.679570</td>\n",
       "      <td>0.696276</td>\n",
       "      <td>0.679570</td>\n",
       "      <td>0.686500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.008575</td>\n",
       "      <td>0.679570</td>\n",
       "      <td>0.696276</td>\n",
       "      <td>0.679570</td>\n",
       "      <td>0.686500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.024417</td>\n",
       "      <td>0.679570</td>\n",
       "      <td>0.696276</td>\n",
       "      <td>0.679570</td>\n",
       "      <td>0.686500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.019458</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.691357</td>\n",
       "      <td>0.675269</td>\n",
       "      <td>0.681824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.027689</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.695016</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.684661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.028465</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.695016</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.684661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/1.4.2_pubmedbert/checkpoint-102\n",
      "Configuration saved in /home/elson/1.4.2_pubmedbert/checkpoint-102/config.json\n",
      "Model weights saved in /home/elson/1.4.2_pubmedbert/checkpoint-102/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/1.4.2_pubmedbert/checkpoint-204\n",
      "Configuration saved in /home/elson/1.4.2_pubmedbert/checkpoint-204/config.json\n",
      "Model weights saved in /home/elson/1.4.2_pubmedbert/checkpoint-204/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/1.4.2_pubmedbert/checkpoint-306\n",
      "Configuration saved in /home/elson/1.4.2_pubmedbert/checkpoint-306/config.json\n",
      "Model weights saved in /home/elson/1.4.2_pubmedbert/checkpoint-306/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.2_pubmedbert/checkpoint-204] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/1.4.2_pubmedbert/checkpoint-408\n",
      "Configuration saved in /home/elson/1.4.2_pubmedbert/checkpoint-408/config.json\n",
      "Model weights saved in /home/elson/1.4.2_pubmedbert/checkpoint-408/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.2_pubmedbert/checkpoint-306] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/1.4.2_pubmedbert/checkpoint-510\n",
      "Configuration saved in /home/elson/1.4.2_pubmedbert/checkpoint-510/config.json\n",
      "Model weights saved in /home/elson/1.4.2_pubmedbert/checkpoint-510/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.2_pubmedbert/checkpoint-408] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/1.4.2_pubmedbert/checkpoint-612\n",
      "Configuration saved in /home/elson/1.4.2_pubmedbert/checkpoint-612/config.json\n",
      "Model weights saved in /home/elson/1.4.2_pubmedbert/checkpoint-612/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.2_pubmedbert/checkpoint-510] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/1.4.2_pubmedbert/checkpoint-714\n",
      "Configuration saved in /home/elson/1.4.2_pubmedbert/checkpoint-714/config.json\n",
      "Model weights saved in /home/elson/1.4.2_pubmedbert/checkpoint-714/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.2_pubmedbert/checkpoint-612] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/1.4.2_pubmedbert/checkpoint-816\n",
      "Configuration saved in /home/elson/1.4.2_pubmedbert/checkpoint-816/config.json\n",
      "Model weights saved in /home/elson/1.4.2_pubmedbert/checkpoint-816/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.2_pubmedbert/checkpoint-714] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/1.4.2_pubmedbert/checkpoint-918\n",
      "Configuration saved in /home/elson/1.4.2_pubmedbert/checkpoint-918/config.json\n",
      "Model weights saved in /home/elson/1.4.2_pubmedbert/checkpoint-918/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.2_pubmedbert/checkpoint-816] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/1.4.2_pubmedbert/checkpoint-1020\n",
      "Configuration saved in /home/elson/1.4.2_pubmedbert/checkpoint-1020/config.json\n",
      "Model weights saved in /home/elson/1.4.2_pubmedbert/checkpoint-1020/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.2_pubmedbert/checkpoint-918] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/1.4.2_pubmedbert/checkpoint-1122\n",
      "Configuration saved in /home/elson/1.4.2_pubmedbert/checkpoint-1122/config.json\n",
      "Model weights saved in /home/elson/1.4.2_pubmedbert/checkpoint-1122/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.2_pubmedbert/checkpoint-1020] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/1.4.2_pubmedbert/checkpoint-1224\n",
      "Configuration saved in /home/elson/1.4.2_pubmedbert/checkpoint-1224/config.json\n",
      "Model weights saved in /home/elson/1.4.2_pubmedbert/checkpoint-1224/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.2_pubmedbert/checkpoint-1122] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/1.4.2_pubmedbert/checkpoint-1326\n",
      "Configuration saved in /home/elson/1.4.2_pubmedbert/checkpoint-1326/config.json\n",
      "Model weights saved in /home/elson/1.4.2_pubmedbert/checkpoint-1326/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.2_pubmedbert/checkpoint-1224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/1.4.2_pubmedbert/checkpoint-1428\n",
      "Configuration saved in /home/elson/1.4.2_pubmedbert/checkpoint-1428/config.json\n",
      "Model weights saved in /home/elson/1.4.2_pubmedbert/checkpoint-1428/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.2_pubmedbert/checkpoint-1326] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/1.4.2_pubmedbert/checkpoint-1530\n",
      "Configuration saved in /home/elson/1.4.2_pubmedbert/checkpoint-1530/config.json\n",
      "Model weights saved in /home/elson/1.4.2_pubmedbert/checkpoint-1530/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.2_pubmedbert/checkpoint-1428] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/1.4.2_pubmedbert/checkpoint-1632\n",
      "Configuration saved in /home/elson/1.4.2_pubmedbert/checkpoint-1632/config.json\n",
      "Model weights saved in /home/elson/1.4.2_pubmedbert/checkpoint-1632/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.2_pubmedbert/checkpoint-1530] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/1.4.2_pubmedbert/checkpoint-1734\n",
      "Configuration saved in /home/elson/1.4.2_pubmedbert/checkpoint-1734/config.json\n",
      "Model weights saved in /home/elson/1.4.2_pubmedbert/checkpoint-1734/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.2_pubmedbert/checkpoint-1632] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/1.4.2_pubmedbert/checkpoint-1836\n",
      "Configuration saved in /home/elson/1.4.2_pubmedbert/checkpoint-1836/config.json\n",
      "Model weights saved in /home/elson/1.4.2_pubmedbert/checkpoint-1836/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.2_pubmedbert/checkpoint-1734] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/1.4.2_pubmedbert/checkpoint-1938\n",
      "Configuration saved in /home/elson/1.4.2_pubmedbert/checkpoint-1938/config.json\n",
      "Model weights saved in /home/elson/1.4.2_pubmedbert/checkpoint-1938/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.2_pubmedbert/checkpoint-1836] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/1.4.2_pubmedbert/checkpoint-2040\n",
      "Configuration saved in /home/elson/1.4.2_pubmedbert/checkpoint-2040/config.json\n",
      "Model weights saved in /home/elson/1.4.2_pubmedbert/checkpoint-2040/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.2_pubmedbert/checkpoint-1938] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/elson/1.4.2_pubmedbert/checkpoint-102 (score: 0.7010752688172043).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /home/elson/1.4.2_pubmedbert/best_model/config.json\n",
      "Model weights saved in /home/elson/1.4.2_pubmedbert/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/1.4.2_pubmedbert/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/1.4.2_pubmedbert/best_model/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/1.4.2_pubmedbert/best_model/tokenizer_config.json',\n",
       " '/home/elson/1.4.2_pubmedbert/best_model/special_tokens_map.json',\n",
       " '/home/elson/1.4.2_pubmedbert/best_model/vocab.txt',\n",
       " '/home/elson/1.4.2_pubmedbert/best_model/added_tokens.json',\n",
       " '/home/elson/1.4.2_pubmedbert/best_model/tokenizer.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/1.4.2_pubmedbert/',\n",
    "    num_train_epochs=20,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.06,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/1.4.2_pubmedbert/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/1.4.2_pubmedbert/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63deaea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/1.4.2_pubmedbert/best_model/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"/home/elson/1.4.2_pubmedbert/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"contradiction\",\n",
      "    \"1\": \"entailment\",\n",
      "    \"2\": \"neutral\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"contradiction\": 0,\n",
      "    \"entailment\": 1,\n",
      "    \"neutral\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file /home/elson/1.4.2_pubmedbert/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at /home/elson/1.4.2_pubmedbert/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 16\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/1.4.2_pubmedbert/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[-9.1211e-01,  9.4189e-01, -8.6816e-01],\n",
      "       [-1.9551e+00,  2.4766e+00, -1.0146e+00],\n",
      "       [-4.3872e-01,  1.7139e+00, -1.4980e+00],\n",
      "       [-2.6077e-02,  7.4219e-01, -1.2793e+00],\n",
      "       [-6.3428e-01,  8.3984e-01, -8.7500e-01],\n",
      "       [-1.7129e+00,  2.3496e+00, -1.1768e+00],\n",
      "       [-1.3975e+00,  1.4268e+00, -5.3809e-01],\n",
      "       [-1.7451e+00,  1.8213e+00, -5.4102e-01],\n",
      "       [-1.0420e+00,  1.6963e+00, -1.1934e+00],\n",
      "       [-1.1250e+00,  1.1992e+00, -5.3125e-01],\n",
      "       [-9.4922e-01,  1.3545e+00, -6.5918e-01],\n",
      "       [-1.7812e+00,  2.6055e+00, -1.4229e+00],\n",
      "       [-1.1885e+00,  1.6904e+00, -8.7451e-01],\n",
      "       [-2.1484e+00,  2.4258e+00, -7.9834e-01],\n",
      "       [-1.4854e+00,  1.8506e+00, -7.3535e-01],\n",
      "       [-9.9258e-03,  5.5469e-01, -9.6631e-01],\n",
      "       [-2.0117e+00,  2.2598e+00, -8.6426e-01],\n",
      "       [-1.3203e+00,  1.1494e+00, -3.7305e-01],\n",
      "       [-1.4854e+00,  2.1348e+00, -1.0547e+00],\n",
      "       [-1.9658e+00,  2.2676e+00, -9.1602e-01],\n",
      "       [-1.0840e+00,  6.3086e-01,  2.3926e-02],\n",
      "       [-1.2578e+00,  8.1055e-01, -1.6223e-01],\n",
      "       [-8.1396e-01,  1.0244e+00, -4.0405e-01],\n",
      "       [ 1.1162e+00,  4.6875e-01, -1.7324e+00],\n",
      "       [ 1.1582e+00,  3.7207e-01, -1.7998e+00],\n",
      "       [ 1.4014e+00, -3.3765e-01, -1.0117e+00],\n",
      "       [-2.3164e+00,  3.0977e+00, -1.4131e+00],\n",
      "       [-1.9180e+00,  2.1152e+00, -7.9736e-01],\n",
      "       [-1.7412e+00,  1.7490e+00, -6.9824e-01],\n",
      "       [-1.3301e+00,  1.8701e+00, -1.1377e+00],\n",
      "       [ 5.6445e-01,  6.8787e-02, -7.2461e-01],\n",
      "       [-1.3389e+00,  1.4297e+00, -7.5977e-01],\n",
      "       [-1.4365e+00,  1.5098e+00, -6.0596e-01],\n",
      "       [-1.6621e+00,  2.0703e+00, -8.6523e-01],\n",
      "       [ 2.7246e-01,  7.2510e-01, -1.2305e+00],\n",
      "       [-1.9912e+00,  2.0977e+00, -7.2070e-01],\n",
      "       [-2.2012e+00,  2.2070e+00, -8.6865e-01],\n",
      "       [-1.3848e+00,  2.3008e+00, -1.2725e+00],\n",
      "       [ 2.9746e+00, -7.8247e-02, -2.4473e+00],\n",
      "       [-1.8799e+00,  1.7910e+00, -5.2344e-01],\n",
      "       [ 8.0371e-01,  8.2031e-01, -1.9766e+00],\n",
      "       [-1.2715e+00,  1.4307e+00, -6.7969e-01],\n",
      "       [ 2.9761e-01,  2.7539e-01, -7.0020e-01],\n",
      "       [-6.5479e-01,  1.4648e+00, -1.2969e+00],\n",
      "       [-9.2346e-02,  9.5215e-01, -1.2744e+00],\n",
      "       [-2.0762e+00,  2.2617e+00, -9.4971e-01],\n",
      "       [ 9.7461e-01,  1.0283e+00, -2.1953e+00],\n",
      "       [-1.3184e+00,  2.0410e+00, -1.3643e+00],\n",
      "       [-1.8164e+00,  2.3281e+00, -9.9414e-01],\n",
      "       [ 1.4316e+00,  5.5859e-01, -2.0645e+00],\n",
      "       [-8.3740e-01,  6.1914e-01, -1.1163e-01],\n",
      "       [-1.0869e+00,  1.1807e+00, -2.2681e-01],\n",
      "       [-8.2422e-01,  9.3359e-01, -5.5908e-01],\n",
      "       [-1.7852e+00,  1.3174e+00, -4.5593e-02],\n",
      "       [ 1.3135e+00,  4.2651e-01, -1.8193e+00],\n",
      "       [-2.0098e+00,  2.4180e+00, -1.0107e+00],\n",
      "       [-8.6523e-01,  5.4980e-01,  2.2009e-01],\n",
      "       [-1.1709e+00,  1.3457e+00, -5.6885e-01],\n",
      "       [-2.2520e+00,  2.9941e+00, -1.3594e+00],\n",
      "       [-1.8193e+00,  1.8125e+00, -5.8057e-01],\n",
      "       [-1.1787e+00,  1.2686e+00, -6.5234e-01],\n",
      "       [ 1.1006e+00,  2.4438e-01, -1.5791e+00],\n",
      "       [-1.0127e+00,  1.1592e+00, -5.4395e-01],\n",
      "       [-5.0879e-01,  5.9131e-01, -6.7383e-01],\n",
      "       [-1.7139e+00,  1.8135e+00, -6.1914e-01],\n",
      "       [-1.4443e+00,  1.9824e+00, -9.9658e-01],\n",
      "       [-2.0254e+00,  3.1758e+00, -1.7930e+00],\n",
      "       [-1.8955e+00,  3.1250e+00, -1.6768e+00],\n",
      "       [-1.0645e+00,  2.1855e+00, -1.4707e+00],\n",
      "       [ 7.7588e-01,  2.8467e-01, -1.6396e+00],\n",
      "       [-1.2012e+00,  9.7559e-01, -4.5557e-01],\n",
      "       [-1.0742e+00,  1.2607e+00, -6.5332e-01],\n",
      "       [-1.7461e+00,  1.9521e+00, -7.0850e-01],\n",
      "       [-1.7275e+00,  2.2871e+00, -1.0088e+00],\n",
      "       [-9.4360e-02,  4.0186e-01, -5.0391e-01],\n",
      "       [-8.9844e-01,  1.4365e+00, -9.4873e-01],\n",
      "       [-1.2852e+00,  2.0117e+00, -1.0156e+00],\n",
      "       [-9.3604e-01,  8.0908e-01, -3.3887e-01],\n",
      "       [-1.9629e+00,  2.7461e+00, -1.5215e+00],\n",
      "       [-3.5547e-01,  3.1079e-01, -3.4937e-01],\n",
      "       [-1.9717e+00,  3.0488e+00, -1.5469e+00],\n",
      "       [-1.7168e+00,  1.6338e+00, -3.7915e-01],\n",
      "       [-1.0049e+00,  1.1348e+00, -4.6460e-01],\n",
      "       [-8.3398e-01,  1.8857e+00, -1.4043e+00],\n",
      "       [-1.6582e+00,  2.6914e+00, -1.5791e+00],\n",
      "       [-2.4194e-01,  9.3604e-01, -7.7686e-01],\n",
      "       [-1.5635e+00,  1.9658e+00, -8.3301e-01],\n",
      "       [ 1.1484e+00,  9.1504e-01, -2.1895e+00],\n",
      "       [-8.3545e-01,  7.5146e-01, -5.2734e-01],\n",
      "       [-1.6738e+00,  1.4062e+00, -2.1606e-01],\n",
      "       [-1.3379e+00,  2.1055e+00, -1.1719e+00],\n",
      "       [-1.8301e+00,  2.1992e+00, -9.5703e-01],\n",
      "       [ 5.5176e-01,  4.8828e-01, -1.5264e+00],\n",
      "       [-1.1768e+00,  1.9502e+00, -1.3965e+00],\n",
      "       [-7.9407e-02,  1.0234e+00, -1.2910e+00],\n",
      "       [ 2.1399e-01,  2.2302e-01, -5.0049e-01],\n",
      "       [-1.7029e-02,  8.6230e-01, -1.2256e+00],\n",
      "       [-9.7363e-01,  1.0342e+00, -3.8159e-01],\n",
      "       [-1.8467e+00,  2.8906e+00, -1.7100e+00],\n",
      "       [-1.2314e+00,  9.5117e-01, -2.3999e-01],\n",
      "       [ 1.4824e+00,  5.3320e-01, -2.2051e+00],\n",
      "       [-1.9053e+00,  1.8828e+00, -7.3193e-01],\n",
      "       [-2.1738e+00,  2.3906e+00, -7.8027e-01],\n",
      "       [-1.3154e+00,  1.5713e+00, -6.4990e-01],\n",
      "       [-1.0283e+00,  1.5273e+00, -7.8223e-01],\n",
      "       [-1.9746e+00,  2.4570e+00, -1.1289e+00],\n",
      "       [ 6.0010e-01,  1.1113e+00, -1.9717e+00],\n",
      "       [ 1.2708e-01,  4.4727e-01, -4.5264e-01],\n",
      "       [-1.6455e+00,  1.8701e+00, -6.7529e-01],\n",
      "       [-1.5684e+00,  2.0215e+00, -8.9453e-01],\n",
      "       [-1.4600e+00,  1.2373e+00, -3.6475e-01],\n",
      "       [-1.9307e+00,  2.3184e+00, -8.0029e-01],\n",
      "       [-1.2852e+00,  1.6162e+00, -5.9961e-01],\n",
      "       [-1.6162e+00,  2.1582e+00, -8.1250e-01],\n",
      "       [-1.6748e+00,  1.6387e+00, -5.8350e-01],\n",
      "       [-1.4121e+00,  2.6992e+00, -1.5459e+00],\n",
      "       [-1.4160e+00,  1.6113e+00, -5.9326e-01],\n",
      "       [-3.9990e-01,  5.9033e-01, -3.9551e-01],\n",
      "       [-1.2070e+00,  2.1426e+00, -1.4268e+00],\n",
      "       [-1.2324e+00,  1.5625e+00, -6.2207e-01],\n",
      "       [-1.1611e+00,  1.2344e+00, -4.8364e-01],\n",
      "       [-1.8447e+00,  2.6133e+00, -1.2900e+00],\n",
      "       [-1.0439e+00,  1.3887e+00, -7.8662e-01],\n",
      "       [ 6.0400e-01,  5.7666e-01, -1.4229e+00],\n",
      "       [-1.1533e+00,  1.5449e+00, -7.7979e-01],\n",
      "       [-1.4727e+00,  1.4385e+00, -3.4814e-01],\n",
      "       [-1.0713e+00,  1.5508e+00, -8.7158e-01],\n",
      "       [-1.9189e+00,  2.1055e+00, -8.2959e-01],\n",
      "       [-8.8477e-01,  8.3154e-01, -4.3408e-01],\n",
      "       [-8.8086e-01,  9.1309e-01, -4.7363e-01],\n",
      "       [-1.0371e+00,  1.2871e+00, -7.0020e-01],\n",
      "       [ 1.9082e+00,  1.5894e-01, -2.2363e+00],\n",
      "       [-1.2920e+00,  2.4824e+00, -1.5635e+00],\n",
      "       [ 1.2119e+00,  2.6855e-01, -1.4199e+00],\n",
      "       [-1.0234e+00,  1.6162e+00, -9.0381e-01],\n",
      "       [-1.9160e+00,  1.8623e+00, -6.2842e-01],\n",
      "       [-7.3145e-01,  5.6055e-01, -2.0642e-01],\n",
      "       [-2.1191e-01,  1.1836e+00, -1.2051e+00],\n",
      "       [ 8.6328e-01, -1.0704e-02, -9.1943e-01],\n",
      "       [-2.4668e+00,  2.5840e+00, -8.2373e-01],\n",
      "       [-2.1387e+00,  2.4707e+00, -1.0098e+00],\n",
      "       [ 8.4473e-02,  2.6489e-01, -6.8359e-01],\n",
      "       [-9.5898e-01,  1.1758e+00, -4.3042e-01],\n",
      "       [-2.1172e+00,  2.3926e+00, -8.8330e-01],\n",
      "       [-6.3281e-01,  9.5361e-01, -6.0156e-01],\n",
      "       [-9.1650e-01,  1.0762e+00, -5.8057e-01],\n",
      "       [ 3.4082e-01,  3.5107e-01, -1.0596e+00],\n",
      "       [ 5.2197e-01,  1.9250e-01, -1.2578e+00],\n",
      "       [-1.4238e+00,  1.8213e+00, -1.0088e+00],\n",
      "       [-1.5674e+00,  1.8057e+00, -8.5889e-01],\n",
      "       [-1.0850e+00,  1.4805e+00, -7.6318e-01],\n",
      "       [-1.4854e+00,  2.2363e+00, -1.1973e+00],\n",
      "       [-1.6035e+00,  1.4307e+00, -5.0684e-01],\n",
      "       [-1.0059e+00,  1.2891e+00, -6.3916e-01],\n",
      "       [-2.1699e+00,  2.9043e+00, -1.4404e+00],\n",
      "       [-2.0586e+00,  3.0039e+00, -1.7334e+00],\n",
      "       [-1.3633e+00,  2.3555e+00, -1.4375e+00],\n",
      "       [-2.1367e+00,  2.2852e+00, -1.0625e+00],\n",
      "       [-1.3501e-01,  4.6753e-01, -4.6045e-01],\n",
      "       [ 1.1934e+00,  7.6709e-01, -2.0449e+00],\n",
      "       [ 2.1113e+00, -6.7236e-01, -1.1182e+00],\n",
      "       [ 2.7930e+00,  2.2388e-01, -2.7070e+00],\n",
      "       [-1.5801e+00,  1.6455e+00, -5.1465e-01],\n",
      "       [ 4.6191e-01,  5.8789e-01, -1.4297e+00],\n",
      "       [ 4.9780e-01,  2.5830e-01, -7.3975e-01],\n",
      "       [-1.3789e+00,  9.3018e-01,  4.9500e-02],\n",
      "       [-1.1592e+00,  8.7744e-01, -3.4546e-01],\n",
      "       [ 4.3652e-01,  5.2002e-01, -1.2148e+00],\n",
      "       [ 3.0835e-01,  6.1182e-01, -1.3174e+00],\n",
      "       [-9.3652e-01,  1.1211e+00, -6.0693e-01],\n",
      "       [ 1.5635e+00, -3.1348e-01, -1.2061e+00],\n",
      "       [-7.0703e-01,  7.5928e-01, -4.6167e-01],\n",
      "       [ 7.7686e-01,  4.0283e-01, -9.8682e-01],\n",
      "       [-1.0020e+00,  1.3838e+00, -7.3486e-01],\n",
      "       [-2.4062e+00,  3.0625e+00, -1.4707e+00],\n",
      "       [ 2.9144e-03,  6.9482e-01, -8.7549e-01],\n",
      "       [-1.6914e+00,  2.2598e+00, -1.1025e+00],\n",
      "       [ 1.1699e+00, -5.5969e-02, -1.4102e+00],\n",
      "       [-1.4043e+00,  1.8984e+00, -9.6289e-01],\n",
      "       [-9.4922e-01,  1.2637e+00, -8.3398e-01],\n",
      "       [-1.8530e-01,  3.6816e-01, -6.2354e-01],\n",
      "       [ 1.9946e-01,  7.4072e-01, -1.1221e+00],\n",
      "       [ 2.7344e+00, -1.0246e-02, -2.6016e+00],\n",
      "       [-4.8682e-01,  6.0303e-01, -8.5449e-01],\n",
      "       [ 1.6426e+00,  4.1565e-02, -1.8076e+00],\n",
      "       [-1.8242e+00,  2.2969e+00, -1.0264e+00],\n",
      "       [-1.6230e+00,  2.1816e+00, -9.9561e-01],\n",
      "       [-2.5664e+00,  2.6172e+00, -9.1357e-01],\n",
      "       [-2.7637e-01,  8.2422e-01, -1.0439e+00],\n",
      "       [-1.9893e+00,  2.5957e+00, -1.2920e+00],\n",
      "       [ 2.7808e-01,  7.8564e-01, -1.6299e+00],\n",
      "       [-8.8086e-01,  9.7168e-01, -3.8159e-01],\n",
      "       [-7.2266e-01,  1.2217e+00, -6.7188e-01],\n",
      "       [-1.3418e+00,  1.1680e+00, -1.1511e-01],\n",
      "       [ 2.7617e+00, -3.5645e-02, -2.4043e+00],\n",
      "       [-1.4863e+00,  1.6299e+00, -7.3779e-01],\n",
      "       [-1.0596e+00,  1.0273e+00, -5.0293e-01],\n",
      "       [-2.5156e+00,  2.5000e+00, -6.8359e-01],\n",
      "       [-1.1357e+00,  2.0215e+00, -1.2207e+00],\n",
      "       [-8.9355e-01,  9.7217e-01, -3.2520e-01],\n",
      "       [-9.9658e-01,  1.1699e+00, -4.6851e-01],\n",
      "       [-1.4492e+00,  2.1016e+00, -1.1445e+00],\n",
      "       [ 7.4196e-03,  1.4709e-01, -7.8320e-01],\n",
      "       [-8.1689e-01,  8.8281e-01, -5.0098e-01],\n",
      "       [-3.7915e-01,  1.0811e+00, -1.1172e+00],\n",
      "       [ 4.0259e-01,  1.0168e-01, -7.7832e-01],\n",
      "       [-2.2598e+00,  2.7051e+00, -1.1953e+00],\n",
      "       [-1.3105e+00,  1.6113e+00, -7.0703e-01],\n",
      "       [-1.7363e+00,  2.4746e+00, -1.4365e+00],\n",
      "       [-1.0137e+00,  1.7031e+00, -9.3750e-01],\n",
      "       [-1.0986e+00,  1.1270e+00, -4.7021e-01],\n",
      "       [-1.0820e+00,  1.0957e+00, -3.4741e-01],\n",
      "       [-1.7676e+00,  1.5332e+00, -2.8760e-01],\n",
      "       [-9.7168e-01,  1.7578e+00, -1.2607e+00],\n",
      "       [-1.8311e+00,  3.0879e+00, -1.8105e+00],\n",
      "       [ 1.2910e+00,  3.7915e-01, -1.5918e+00],\n",
      "       [ 4.8975e-01,  5.8936e-01, -1.0293e+00],\n",
      "       [ 5.1611e-01,  3.0054e-01, -8.7451e-01],\n",
      "       [-1.6592e+00,  1.5674e+00, -4.6924e-01],\n",
      "       [-6.4746e-01,  7.1094e-01, -4.3604e-01],\n",
      "       [-2.1504e+00,  2.0684e+00, -4.0747e-01],\n",
      "       [-1.9727e+00,  2.6289e+00, -1.3086e+00],\n",
      "       [ 5.3760e-01,  8.4229e-01, -1.5996e+00],\n",
      "       [-1.6582e+00,  2.1758e+00, -1.1396e+00],\n",
      "       [-1.7607e+00,  2.2793e+00, -1.1182e+00],\n",
      "       [-1.7578e+00,  2.3828e+00, -1.2139e+00],\n",
      "       [-2.2539e+00,  3.5527e+00, -1.8672e+00],\n",
      "       [ 2.3535e-01,  1.3550e-01, -6.6357e-01],\n",
      "       [-4.0796e-01,  9.5605e-01, -6.7822e-01],\n",
      "       [ 9.1357e-01, -4.4727e-01, -5.3955e-01],\n",
      "       [-2.0801e+00,  2.2656e+00, -9.0186e-01],\n",
      "       [-1.0605e+00,  1.1230e+00, -4.7095e-01],\n",
      "       [-1.1025e+00,  1.6523e+00, -1.1162e+00],\n",
      "       [ 1.4482e+00, -1.3086e-01, -1.3301e+00]], dtype=float16), label_ids=array([1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 0,\n",
      "       1, 2, 0, 0, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 0, 2, 1, 1,\n",
      "       1, 0, 1, 1, 0, 0, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 0, 2, 1, 2, 0,\n",
      "       1, 1, 0, 0, 1, 1, 2, 2, 1, 0, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1,\n",
      "       0, 2, 1, 1, 0, 1, 1, 1, 0, 1, 1, 2, 0, 2, 1, 2, 1, 1, 1, 2, 1, 1,\n",
      "       2, 1, 2, 1, 2, 1, 1, 1, 0, 0, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 2, 1, 2, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2,\n",
      "       1, 1, 1, 2, 1, 0, 0, 0, 1, 1, 1, 2, 1, 1, 0, 1, 0, 1, 2, 1, 1, 1,\n",
      "       1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 1, 2, 1, 1, 1, 1, 2, 2, 0, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 0, 1, 1, 0]), metrics={'test_loss': 0.8671920895576477, 'test_accuracy': 0.6837606837606838, 'test_precision': 0.5522247360482655, 'test_recall': 0.6837606837606838, 'test_f1': 0.6062271062271061, 'test_runtime': 1.1545, 'test_samples_per_second': 202.687, 'test_steps_per_second': 12.993})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d4e861c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "probabilities = torch.softmax(torch.tensor(test_results.predictions).to(torch.float32), dim=-1)\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)\n",
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1747566",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_save = []\n",
    "for idx in range(len(test_data)):\n",
    "    item = dataset['test'][idx]\n",
    "    actual_label = item['label']\n",
    "    predicted_label = predictions[idx]\n",
    "    claim = item['claim'] \n",
    "    premise = item['premise'] \n",
    "    category = item['category']\n",
    "    \n",
    "    # Append the information as a dictionary to the list\n",
    "    data_to_save.append({\n",
    "        'Claim': claim,\n",
    "        'Premise': premise,\n",
    "        'Actual Label': actual_label,\n",
    "        'Predicted Label': predicted_label,\n",
    "        'Category' : category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_to_save)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/home/elson/results/1.4.2_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f40c56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correctly classified instances\n",
    "correctly_classified = df[df['Actual Label'] == df['Predicted Label']]\n",
    "\n",
    "# Calculate misclassified instances\n",
    "misclassified = df[df['Actual Label'] != df['Predicted Label']]\n",
    "\n",
    "# Count the number of correctly classified and misclassified by category\n",
    "correct_classification_counts = correctly_classified['Category'].value_counts()\n",
    "misclassification_counts = misclassified['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61d30750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           34\n",
       "Fitness                  15\n",
       "Bone health              14\n",
       "Cancer                   12\n",
       "Diabetes                 11\n",
       "Cardiovascular Health     9\n",
       "Skin                      9\n",
       "Hair                      9\n",
       "Throat                    8\n",
       "Neurological health       7\n",
       "Ear                       6\n",
       "Eye                       6\n",
       "COVID                     5\n",
       "Men's health              3\n",
       "Women' s Health           3\n",
       "Muscles                   3\n",
       "Mental Health             3\n",
       "Blood                     3\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "670ffadf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           17\n",
       "Skin                     15\n",
       "Bone health               7\n",
       "Blood                     6\n",
       "Vascular                  3\n",
       "Cardiovascular Health     3\n",
       "Hair                      3\n",
       "Dental Health             3\n",
       "Eye                       3\n",
       "Muscles                   3\n",
       "Men's health              3\n",
       "Women' s Health           3\n",
       "Neurological health       2\n",
       "Diabetes                  1\n",
       "Throat                    1\n",
       "COVID                     1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
