{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score,balanced_accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82806f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jul 29 19:46:17 2024       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:61:00.0 Off |                    0 |\r\n",
      "| N/A   40C    P0    56W / 300W |      0MiB / 32768MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla V100-SXM2...  Off  | 00000000:62:00.0 Off |                    0 |\r\n",
      "| N/A   62C    P0   254W / 300W |  25522MiB / 32768MiB |    100%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   2  Tesla V100-SXM2...  Off  | 00000000:89:00.0 Off |                    0 |\r\n",
      "| N/A   53C    P0   223W / 300W |  15162MiB / 32768MiB |     99%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   3  Tesla V100-SXM2...  Off  | 00000000:8A:00.0 Off |                    0 |\r\n",
      "| N/A   40C    P0    58W / 300W |      0MiB / 32768MiB |      2%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    1   N/A  N/A     39308      C   ...son/factcheck/bin/python3    25519MiB |\r\n",
      "|    2   N/A  N/A     39906      C   ...son/factcheck/bin/python3    15159MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-31dfe7adddcf5ced\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 231.54it/s]\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-ad71be204b279b28.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-e7b6b615907c24ca.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-bee802838a3bfaea.arrow\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset from the CSV file\n",
    "dataset = load_dataset(\n",
    "    'csv',\n",
    "    data_files='dataset_semanticattribution_nerfeatures_split.csv',\n",
    "    delimiter=',',\n",
    "    column_names=[\n",
    "        \"claim\", \"premise\", \"label\", \"category\", \"count_bf\", \"count_ca\", \"count_dis\",\n",
    "        \"count_food\", \"count_lipid\", \"count_treat\", \"pres_bf\", \"pres_ca\", \"pres_dis\",\n",
    "        \"pres_food\", \"pres_lipid\", \"pres_treat\", \"counte_bf\", \"counte_ca\", \"counte_dis\",\n",
    "        \"counte_food\", \"counte_lipid\", \"counte_treat\", \"prese_bf\", \"prese_ca\", \"prese_dis\",\n",
    "        \"prese_food\", \"prese_lipid\", \"prese_treat\", \"url\", \"entities\", \"entity_map\",\n",
    "        \"gold_exp\", \"gemini_exp\", \"gemini_label\",\"entity_ev\",\"entity_map_ev\", \"split\"\n",
    "    ],\n",
    "    skiprows=1\n",
    ")\n",
    "\n",
    "# Assuming 'split' column contains strings 'train', 'validation', 'test'\n",
    "# Filter the loaded dataset into subsets\n",
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'gold_exp', 'gemini_exp', 'gemini_label', 'entity_ev', 'entity_map_ev', 'split'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f3e71be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41f1db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['claim', 'premise', 'label','category','count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat','counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat']\n",
    "all_columns = train_dataset.column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-2b0030fb2dfa4c5c.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-2af2b7abf1a08f75.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-0bbf36fdf8be1d2b.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 0, 'entailment': 1, 'neutral': 2}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 0,\n",
    "    \"entailment\": 1,\n",
    "    \"neutral\": 2\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b5bb17f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "465"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['val']['claim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "        # Extracting claim and evidence texts\n",
    "        category = item['category']\n",
    "\n",
    "        claim = item['claim'].lower() + \"[\" + category + \"]\"\n",
    "        premise = item['premise'].lower().replace('\\n', '').replace('[','').replace(']','')\n",
    "        \n",
    "        additional_features = [\n",
    "            \"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\"]\n",
    "    \n",
    "        for feature in additional_features:\n",
    "            if feature in item:\n",
    "                claim += \"[SEP]\" + str(item[feature])\n",
    "        \n",
    "        additional_features_ev = [\n",
    "            'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat']\n",
    "    \n",
    "        for feature_ev in additional_features_ev:\n",
    "            if feature_ev in item:\n",
    "                premise += \"[SEP]\" + str(item[feature])\n",
    "        item['claim']=claim\n",
    "        item['premise']=premise        \n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "             premise, claim,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "        item['input_ids'] = inputs['input_ids'].squeeze()  # Remove batch dimension\n",
    "        item['attention_mask']= inputs['attention_mask'].squeeze() # Remove batch dimension\n",
    "        \n",
    "        output_item = {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),  # Remove batch dimension\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),  # Remove batch dimension\n",
    "            'claim': claim,  # Include augmented claim text\n",
    "            'evidences': premise  # Include original evidence text\n",
    "        }\n",
    "        \n",
    "        if 'label' in item:\n",
    "            output_item['label'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return output_item\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62421eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=3, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f72c5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model is on device: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    bal_accuracy = balanced_accuracy_score(labels,preds)\n",
    "\n",
    "    return {\"accuracy\": acc, \"balanced_accuracy\":bal_accuracy, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17c5e0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([     1,   2600,   1655,  16876,    667,  15726,  61593,    261,   2030,\n",
       "            260,    346,  15302,   6848,  15726,  61593,    261,    584,    260,\n",
       "            346,  33770,    452,  15726,  61593,  16876,    667,  15726,  61593,\n",
       "            261,    845,    260,    346,  14033,   2179,  24360,  34984,  15726,\n",
       "          61593,    261,   1917,    260,    346,  51194,  73907,   8007,  15726,\n",
       "          61593,    261,   2673,    260,    346,   1942,   3359,  73907,   8007,\n",
       "          15726,  61593,    261,   4402,    260,  88609,    263,  98237,   1830,\n",
       "           6725,    263,   5134,  30055,  77487,    532,   4014,    271,    547,\n",
       "          52263,  16224,    265,  86207,  14178,    268,    260,  62713,   4379,\n",
       "            261,    584,    260,  41529,  23399,    429,   8068,   1068,    268,\n",
       "            265,  42543,    834,   1917, 110269,    287,    260, 116367,   2148,\n",
       "            263,  25348,  20413,   1563,    265,    917,    263,    308,    266,\n",
       "          84530,  62542,    275,  98237,    287,    549,   6177,  65073,  44845,\n",
       "          22317,    285,  36774,    260,  30689,   6725,    294,   6162,   2731,\n",
       "            270,   1158,    599,    260,  46362,  41546,  71547,    261,   2030,\n",
       "            260,    346,  10918,    436,  80984,    261,   2285,    260,    346,\n",
       "            266,  46177,  28220,    261,   4402,    260,    346,  56545,  15150,\n",
       "            261,   2673,    260,    346,  95311,    261,   1917,    260,  54761,\n",
       "           1856,    293,   1008,    633,    294,   2285,    260,  98237,    452,\n",
       "           1080,   4796,  18839,    260,   5720,   4765,  39151,    261,   3638,\n",
       "            260,    346,  11965,   4765,  39151,    261,   1550,    260,    346,\n",
       "          11965,   4765,  39151,    261,   1917,    260,    346,  93607,  60641,\n",
       "            261,   1917,    260,  88609,    287,  15726,   2209,   5858,  25499,\n",
       "           3004,   3638,  27197,    318,  58813,  15726,    198,    133,   5900,\n",
       "            346,    260,  43427,    285,    294,    292,    262,   1857,    265,\n",
       "           1471,   1567,    264,    262,   2626,  41529,  28479,    270,    262,\n",
       "           5937,    263,   1035,    265,   1721,   4253,    260,  35753,    263,\n",
       "         121470,   1506,    265,  88609,   1080,    260,  99352,    268,   4086,\n",
       "          75371,   4191,   2767,  15808,    260,    346,  62510,    261,    865,\n",
       "            260,  88609,    263,  98237,    283,  11882,    267,    572,    260,\n",
       "              2,    767,      2,    767,      2,    767,      2,    767,      2,\n",
       "            767,      2,    767,      2,    767,      2,    767,      2,    767,\n",
       "              2,    767,      2,    767,      2,    767,      2,  98237,   1830,\n",
       "           1080,    269,   1359,    427,    267,  17847,    633,    264,    408,\n",
       "           1300,    262,   2658,    265,    262,   1158,    260,   2550,  12082,\n",
       "           1516,    592,      2,    767,      2,    767,      2,    767,      2,\n",
       "            767,      2,    767,      2,    767,      2,    767,      2,    767,\n",
       "              2,    767,      2,    767,      2,    767,      2,    767,      2,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'claim': 'myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.[General Health][SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0',\n",
       " 'evidences': '; unkoviä‡, n.; dimkiä‡, i.; janaä‡koviä‡, p.; gavriloviä‡, m.; stanojeviä‡, o.; vukojeviä‡, j. frankincense and myrrh essential oils and burn incense fume against micro-inhabitants of sacral ambients.shameem, i. phytochemical & therapeutic potentials of murr makki (.oxidative stress and immunotoxic effects of lead and their amelioration with myrrh (commiphora molmol) emulsion.essential oils: magical ingredients for skin care.chakravarty, n.; kellogg, c.; alvarez, j.; equils, o.; morgan, m. uv protection by natural products: c. myrrha oil versus sunscreen.hamidpour, r.; hamidpour, s.; hamidpour, m.; shahlari, m. frankincense (ä¹³é¦™ rç” xiä\\x81ng;.species): from the selection of traditional applications to the novel phytotherapy for the prevention and treatment of serious diseases.chemistry and immunomodulatory activity of frankincense oil.compositions containing boswellia extracts.; cooper, e. frankincense and myrrh as remedies in children.[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0',\n",
       " 'label': tensor(1)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on device: cuda:0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1530' max='1530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1530/1530 12:36, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.843100</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>0.679570</td>\n",
       "      <td>0.394819</td>\n",
       "      <td>0.613653</td>\n",
       "      <td>0.679570</td>\n",
       "      <td>0.607571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.553700</td>\n",
       "      <td>0.943013</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.482351</td>\n",
       "      <td>0.648072</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.618946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.406800</td>\n",
       "      <td>1.263578</td>\n",
       "      <td>0.608602</td>\n",
       "      <td>0.485193</td>\n",
       "      <td>0.664144</td>\n",
       "      <td>0.608602</td>\n",
       "      <td>0.627493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.213100</td>\n",
       "      <td>1.371326</td>\n",
       "      <td>0.627957</td>\n",
       "      <td>0.456584</td>\n",
       "      <td>0.636784</td>\n",
       "      <td>0.627957</td>\n",
       "      <td>0.626277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.295100</td>\n",
       "      <td>1.374289</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.475516</td>\n",
       "      <td>0.642129</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.645676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.791294</td>\n",
       "      <td>0.632258</td>\n",
       "      <td>0.497412</td>\n",
       "      <td>0.654392</td>\n",
       "      <td>0.632258</td>\n",
       "      <td>0.641804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.113100</td>\n",
       "      <td>2.165871</td>\n",
       "      <td>0.647312</td>\n",
       "      <td>0.480798</td>\n",
       "      <td>0.660645</td>\n",
       "      <td>0.647312</td>\n",
       "      <td>0.649093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.058100</td>\n",
       "      <td>2.297239</td>\n",
       "      <td>0.664516</td>\n",
       "      <td>0.496379</td>\n",
       "      <td>0.653951</td>\n",
       "      <td>0.664516</td>\n",
       "      <td>0.658672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.086200</td>\n",
       "      <td>2.431414</td>\n",
       "      <td>0.660215</td>\n",
       "      <td>0.486461</td>\n",
       "      <td>0.650665</td>\n",
       "      <td>0.660215</td>\n",
       "      <td>0.654948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>2.595320</td>\n",
       "      <td>0.662366</td>\n",
       "      <td>0.499700</td>\n",
       "      <td>0.660601</td>\n",
       "      <td>0.662366</td>\n",
       "      <td>0.661424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>2.702757</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.495821</td>\n",
       "      <td>0.664994</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.657786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>2.741679</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.505024</td>\n",
       "      <td>0.660942</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.658208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>2.813967</td>\n",
       "      <td>0.660215</td>\n",
       "      <td>0.509837</td>\n",
       "      <td>0.668265</td>\n",
       "      <td>0.660215</td>\n",
       "      <td>0.663741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>2.838364</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.498893</td>\n",
       "      <td>0.657914</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.653523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>2.852707</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.506238</td>\n",
       "      <td>0.663272</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.659435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.2.5_deberta/checkpoint-102\n",
      "Configuration saved in /home/elson/2.2.5_deberta/checkpoint-102/config.json\n",
      "Model weights saved in /home/elson/2.2.5_deberta/checkpoint-102/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.2.5_deberta/checkpoint-204\n",
      "Configuration saved in /home/elson/2.2.5_deberta/checkpoint-204/config.json\n",
      "Model weights saved in /home/elson/2.2.5_deberta/checkpoint-204/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.2.5_deberta/checkpoint-306\n",
      "Configuration saved in /home/elson/2.2.5_deberta/checkpoint-306/config.json\n",
      "Model weights saved in /home/elson/2.2.5_deberta/checkpoint-306/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.5_deberta/checkpoint-204] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.2.5_deberta/checkpoint-408\n",
      "Configuration saved in /home/elson/2.2.5_deberta/checkpoint-408/config.json\n",
      "Model weights saved in /home/elson/2.2.5_deberta/checkpoint-408/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.5_deberta/checkpoint-306] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.2.5_deberta/checkpoint-510\n",
      "Configuration saved in /home/elson/2.2.5_deberta/checkpoint-510/config.json\n",
      "Model weights saved in /home/elson/2.2.5_deberta/checkpoint-510/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.5_deberta/checkpoint-408] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.2.5_deberta/checkpoint-612\n",
      "Configuration saved in /home/elson/2.2.5_deberta/checkpoint-612/config.json\n",
      "Model weights saved in /home/elson/2.2.5_deberta/checkpoint-612/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.5_deberta/checkpoint-510] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.2.5_deberta/checkpoint-714\n",
      "Configuration saved in /home/elson/2.2.5_deberta/checkpoint-714/config.json\n",
      "Model weights saved in /home/elson/2.2.5_deberta/checkpoint-714/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.5_deberta/checkpoint-612] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.2.5_deberta/checkpoint-816\n",
      "Configuration saved in /home/elson/2.2.5_deberta/checkpoint-816/config.json\n",
      "Model weights saved in /home/elson/2.2.5_deberta/checkpoint-816/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.5_deberta/checkpoint-714] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.2.5_deberta/checkpoint-918\n",
      "Configuration saved in /home/elson/2.2.5_deberta/checkpoint-918/config.json\n",
      "Model weights saved in /home/elson/2.2.5_deberta/checkpoint-918/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.5_deberta/checkpoint-816] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.2.5_deberta/checkpoint-1020\n",
      "Configuration saved in /home/elson/2.2.5_deberta/checkpoint-1020/config.json\n",
      "Model weights saved in /home/elson/2.2.5_deberta/checkpoint-1020/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.5_deberta/checkpoint-918] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.2.5_deberta/checkpoint-1122\n",
      "Configuration saved in /home/elson/2.2.5_deberta/checkpoint-1122/config.json\n",
      "Model weights saved in /home/elson/2.2.5_deberta/checkpoint-1122/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.5_deberta/checkpoint-1020] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.2.5_deberta/checkpoint-1224\n",
      "Configuration saved in /home/elson/2.2.5_deberta/checkpoint-1224/config.json\n",
      "Model weights saved in /home/elson/2.2.5_deberta/checkpoint-1224/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.5_deberta/checkpoint-1122] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.2.5_deberta/checkpoint-1326\n",
      "Configuration saved in /home/elson/2.2.5_deberta/checkpoint-1326/config.json\n",
      "Model weights saved in /home/elson/2.2.5_deberta/checkpoint-1326/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.5_deberta/checkpoint-1224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.2.5_deberta/checkpoint-1428\n",
      "Configuration saved in /home/elson/2.2.5_deberta/checkpoint-1428/config.json\n",
      "Model weights saved in /home/elson/2.2.5_deberta/checkpoint-1428/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.5_deberta/checkpoint-1326] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.2.5_deberta/checkpoint-1530\n",
      "Configuration saved in /home/elson/2.2.5_deberta/checkpoint-1530/config.json\n",
      "Model weights saved in /home/elson/2.2.5_deberta/checkpoint-1530/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.5_deberta/checkpoint-1428] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/elson/2.2.5_deberta/checkpoint-102 (score: 0.6795698924731183).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /home/elson/2.2.5_deberta/best_model/config.json\n",
      "Model weights saved in /home/elson/2.2.5_deberta/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/2.2.5_deberta/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/2.2.5_deberta/best_model/special_tokens_map.json\n",
      "added tokens file saved in /home/elson/2.2.5_deberta/best_model/added_tokens.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/2.2.5_deberta/best_model/tokenizer_config.json',\n",
       " '/home/elson/2.2.5_deberta/best_model/special_tokens_map.json',\n",
       " '/home/elson/2.2.5_deberta/best_model/spm.model',\n",
       " '/home/elson/2.2.5_deberta/best_model/added_tokens.json')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/2.2.5_deberta/',\n",
    "    num_train_epochs=15,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.06,\n",
    "    weight_decay=0.1,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(\"cuda:0\"),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "print(f\"Model is on device: {next(model.parameters()).device}\")\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/2.2.5_deberta/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/2.2.5_deberta/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cdee1665",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/2.2.5_deberta/best_model/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"/home/elson/2.2.5_deberta/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"entailment\",\n",
      "    \"1\": \"neutral\",\n",
      "    \"2\": \"contradiction\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"contradiction\": 2,\n",
      "    \"entailment\": 0,\n",
      "    \"neutral\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file /home/elson/2.2.5_deberta/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at /home/elson/2.2.5_deberta/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 16\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/2.2.5_deberta/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[-0.2404  ,  0.9336  , -0.7095  ],\n",
      "       [-1.028   ,  1.692   , -0.7075  ],\n",
      "       [-0.929   ,  1.982   , -1.088   ],\n",
      "       [ 0.04828 ,  0.555   , -0.6895  ],\n",
      "       [-0.1476  ,  0.9214  , -0.827   ],\n",
      "       [-1.23    ,  2.377   , -1.231   ],\n",
      "       [-0.5537  ,  1.424   , -0.9536  ],\n",
      "       [-1.228   ,  2.13    , -0.9805  ],\n",
      "       [-0.96    ,  2.076   , -1.108   ],\n",
      "       [-0.463   ,  1.463   , -1.047   ],\n",
      "       [-0.633   ,  1.366   , -0.8076  ],\n",
      "       [-0.7134  ,  1.921   , -1.342   ],\n",
      "       [-0.8135  ,  1.776   , -0.976   ],\n",
      "       [-1.213   ,  2.256   , -1.141   ],\n",
      "       [-1.047   ,  1.9     , -0.944   ],\n",
      "       [-0.0807  ,  0.692   , -0.657   ],\n",
      "       [-0.854   ,  1.327   , -0.4746  ],\n",
      "       [-0.6147  ,  1.161   , -0.586   ],\n",
      "       [-0.9243  ,  1.966   , -1.15    ],\n",
      "       [-0.785   ,  1.753   , -1.076   ],\n",
      "       [-0.3516  ,  0.6514  , -0.3452  ],\n",
      "       [-0.444   ,  1.169   , -0.7856  ],\n",
      "       [-0.644   ,  1.432   , -0.832   ],\n",
      "       [ 0.1048  ,  0.1074  , -0.3125  ],\n",
      "       [ 0.01176 ,  0.49    , -0.5547  ],\n",
      "       [-0.05206 , -0.548   ,  0.4114  ],\n",
      "       [-0.853   ,  2.129   , -1.362   ],\n",
      "       [-1.071   ,  1.856   , -0.8223  ],\n",
      "       [-1.047   ,  1.979   , -0.9604  ],\n",
      "       [-0.5425  ,  1.623   , -1.154   ],\n",
      "       [-0.1427  ,  0.4255  , -0.3657  ],\n",
      "       [-1.249   ,  2.271   , -1.113   ],\n",
      "       [-1.014   ,  2.271   , -1.373   ],\n",
      "       [-0.7544  ,  1.746   , -1.038   ],\n",
      "       [-0.604   ,  1.268   , -0.7153  ],\n",
      "       [-0.6904  ,  1.227   , -0.537   ],\n",
      "       [-0.567   ,  1.399   , -0.8604  ],\n",
      "       [-0.611   ,  1.722   , -1.06    ],\n",
      "       [ 0.1322  ,  0.199   , -0.447   ],\n",
      "       [-0.535   ,  1.013   , -0.4756  ],\n",
      "       [-0.04718 ,  0.4795  , -0.4893  ],\n",
      "       [-0.903   ,  1.914   , -1.069   ],\n",
      "       [-0.1139  ,  0.3489  , -0.2883  ],\n",
      "       [-0.2471  ,  0.827   , -0.6523  ],\n",
      "       [-0.437   ,  1.025   , -0.6606  ],\n",
      "       [-1.336   ,  2.16    , -0.9023  ],\n",
      "       [-1.238   ,  2.23    , -1.047   ],\n",
      "       [-0.5967  ,  1.321   , -0.761   ],\n",
      "       [-0.7554  ,  1.793   , -1.1045  ],\n",
      "       [ 0.2274  , -0.0882  , -0.2869  ],\n",
      "       [-0.126   ,  0.475   , -0.403   ],\n",
      "       [-0.798   ,  1.717   , -0.9697  ],\n",
      "       [-0.1992  ,  1.118   , -0.951   ],\n",
      "       [-1.085   ,  1.742   , -0.686   ],\n",
      "       [-0.443   ,  1.156   , -0.7637  ],\n",
      "       [-0.9287  ,  1.84    , -1.001   ],\n",
      "       [-0.1382  ,  0.5874  , -0.514   ],\n",
      "       [-0.937   ,  1.908   , -1.072   ],\n",
      "       [-0.95    ,  1.916   , -1.07    ],\n",
      "       [-0.524   ,  1.364   , -0.8994  ],\n",
      "       [-0.4792  ,  1.135   , -0.702   ],\n",
      "       [ 0.302   , -0.1715  , -0.2361  ],\n",
      "       [-0.8325  ,  1.547   , -0.7505  ],\n",
      "       [-0.1477  ,  0.912   , -0.805   ],\n",
      "       [-0.7446  ,  1.413   , -0.6855  ],\n",
      "       [-0.7554  ,  1.58    , -0.8516  ],\n",
      "       [-1.417   ,  2.428   , -1.067   ],\n",
      "       [-1.016   ,  1.973   , -1.028   ],\n",
      "       [-0.966   ,  1.87    , -0.981   ],\n",
      "       [-0.1354  ,  0.6357  , -0.5825  ],\n",
      "       [-0.788   ,  1.635   , -0.877   ],\n",
      "       [-0.6514  ,  1.163   , -0.52    ],\n",
      "       [-0.7925  ,  1.344   , -0.5703  ],\n",
      "       [-0.799   ,  1.593   , -0.787   ],\n",
      "       [-0.08356 ,  0.6147  , -0.58    ],\n",
      "       [-0.1686  ,  0.697   , -0.5654  ],\n",
      "       [-0.472   ,  1.283   , -0.841   ],\n",
      "       [-0.7905  ,  1.927   , -1.231   ],\n",
      "       [-1.133   ,  2.209   , -1.184   ],\n",
      "       [-0.09265 ,  0.8125  , -0.782   ],\n",
      "       [-0.9536  ,  1.967   , -1.087   ],\n",
      "       [-1.263   ,  2.17    , -0.9893  ],\n",
      "       [-0.9585  ,  1.784   , -0.9023  ],\n",
      "       [-0.99    ,  2.14    , -1.226   ],\n",
      "       [-1.18    ,  2.1     , -0.9526  ],\n",
      "       [-0.1888  ,  0.969   , -0.8706  ],\n",
      "       [-0.4277  ,  1.315   , -0.893   ],\n",
      "       [-0.998   ,  2.062   , -1.092   ],\n",
      "       [-0.3635  ,  1.009   , -0.6978  ],\n",
      "       [-0.8213  ,  1.621   , -0.8247  ],\n",
      "       [-0.815   ,  1.897   , -1.093   ],\n",
      "       [-0.779   ,  1.57    , -0.8286  ],\n",
      "       [-0.09814 ,  0.573   , -0.5674  ],\n",
      "       [-0.6406  ,  1.446   , -0.8745  ],\n",
      "       [-0.612   ,  1.241   , -0.7036  ],\n",
      "       [-0.2368  ,  0.5464  , -0.356   ],\n",
      "       [-0.32    ,  0.9575  , -0.6665  ],\n",
      "       [-0.6133  ,  1.163   , -0.62    ],\n",
      "       [-1.037   ,  2.13    , -1.1875  ],\n",
      "       [-0.746   ,  1.555   , -0.849   ],\n",
      "       [ 0.1956  , -0.568   ,  0.1829  ],\n",
      "       [-0.845   ,  1.671   , -0.888   ],\n",
      "       [-1.176   ,  1.967   , -0.8125  ],\n",
      "       [-0.845   ,  1.523   , -0.695   ],\n",
      "       [-0.0508  , -0.3147  ,  0.2417  ],\n",
      "       [-0.4668  ,  1.296   , -0.8306  ],\n",
      "       [-1.076   ,  2.037   , -0.9844  ],\n",
      "       [-0.0592  ,  0.4675  , -0.4968  ],\n",
      "       [-0.665   ,  1.472   , -0.8145  ],\n",
      "       [-1.212   ,  2.219   , -1.081   ],\n",
      "       [-1.006   ,  1.509   , -0.5117  ],\n",
      "       [-1.308   ,  2.264   , -1.041   ],\n",
      "       [-0.9873  ,  1.715   , -0.791   ],\n",
      "       [-0.337   ,  1.157   , -0.8374  ],\n",
      "       [-1.075   ,  1.9375  , -0.9004  ],\n",
      "       [-0.749   ,  1.902   , -1.124   ],\n",
      "       [-1.134   ,  2.207   , -1.1875  ],\n",
      "       [-0.2086  ,  0.875   , -0.722   ],\n",
      "       [-0.659   ,  1.394   , -0.8086  ],\n",
      "       [-0.801   ,  1.858   , -1.152   ],\n",
      "       [-0.83    ,  1.8125  , -1.052   ],\n",
      "       [-1.103   ,  2.082   , -1.031   ],\n",
      "       [-1.031   ,  1.985   , -1.053   ],\n",
      "       [-0.556   ,  1.23    , -0.729   ],\n",
      "       [-0.8164  ,  1.489   , -0.7163  ],\n",
      "       [-1.073   ,  2.045   , -1.074   ],\n",
      "       [-0.4255  ,  1.017   , -0.6235  ],\n",
      "       [-0.769   ,  1.706   , -1.036   ],\n",
      "       [-0.7124  ,  1.629   , -0.9624  ],\n",
      "       [-1.032   ,  1.786   , -0.792   ],\n",
      "       [-0.604   ,  1.429   , -0.888   ],\n",
      "       [ 0.0672  ,  0.2058  , -0.412   ],\n",
      "       [-0.755   ,  1.927   , -1.148   ],\n",
      "       [-0.5503  ,  1.366   , -0.8916  ],\n",
      "       [-0.8613  ,  1.777   , -0.9917  ],\n",
      "       [-0.564   ,  1.153   , -0.612   ],\n",
      "       [-0.08093 ,  0.6323  , -0.609   ],\n",
      "       [-0.1963  ,  0.7197  , -0.6265  ],\n",
      "       [-0.4004  ,  1.133   , -0.774   ],\n",
      "       [-1.216   ,  1.852   , -0.629   ],\n",
      "       [-1.32    ,  2.291   , -1.067   ],\n",
      "       [-0.4907  ,  1.164   , -0.736   ],\n",
      "       [-0.8145  ,  1.745   , -0.983   ],\n",
      "       [-0.4429  ,  1.848   , -1.548   ],\n",
      "       [-0.3352  ,  0.641   , -0.2292  ],\n",
      "       [-0.7656  ,  1.163   , -0.4182  ],\n",
      "       [ 0.0601  ,  0.4895  , -0.6055  ],\n",
      "       [ 0.014626,  0.3396  , -0.471   ],\n",
      "       [-0.7036  ,  1.397   , -0.7524  ],\n",
      "       [-0.2937  ,  0.91    , -0.692   ],\n",
      "       [-0.789   ,  1.628   , -0.8813  ],\n",
      "       [-0.7954  ,  1.867   , -1.089   ],\n",
      "       [-0.947   ,  2.012   , -1.109   ],\n",
      "       [-0.7686  ,  1.379   , -0.654   ],\n",
      "       [-1.176   ,  2.125   , -1.031   ],\n",
      "       [-0.8955  ,  1.775   , -0.9375  ],\n",
      "       [-1.059   ,  2.14    , -1.144   ],\n",
      "       [-0.65    ,  1.184   , -0.588   ],\n",
      "       [-0.03406 ,  0.836   , -0.8823  ],\n",
      "       [ 0.05713 ,  0.1995  , -0.31    ],\n",
      "       [-0.01027 , -0.756   ,  0.5664  ],\n",
      "       [ 0.1521  ,  0.0881  , -0.3425  ],\n",
      "       [-1.155   ,  1.979   , -0.8735  ],\n",
      "       [-0.6826  ,  1.44    , -0.8154  ],\n",
      "       [-0.0943  ,  0.347   , -0.3071  ],\n",
      "       [-0.1134  ,  0.607   , -0.5396  ],\n",
      "       [-0.5444  ,  1.609   , -1.11    ],\n",
      "       [-0.1542  ,  1.042   , -0.988   ],\n",
      "       [ 0.04572 ,  0.2385  , -0.4143  ],\n",
      "       [-0.1197  ,  0.8965  , -0.8237  ],\n",
      "       [-0.05222 , -0.3882  ,  0.2808  ],\n",
      "       [-0.137   ,  1.239   , -1.192   ],\n",
      "       [-0.08954 ,  0.4856  , -0.4817  ],\n",
      "       [-0.5327  ,  1.497   , -1.0625  ],\n",
      "       [-1.077   ,  2.062   , -1.058   ],\n",
      "       [-0.0809  ,  0.2238  , -0.2382  ],\n",
      "       [-1.14    ,  2.145   , -1.059   ],\n",
      "       [ 0.007114,  0.4475  , -0.5464  ],\n",
      "       [-0.5854  ,  1.546   , -0.9854  ],\n",
      "       [-0.02002 ,  0.6904  , -0.7344  ],\n",
      "       [-0.0466  ,  0.1271  , -0.1688  ],\n",
      "       [-0.652   ,  1.148   , -0.4895  ],\n",
      "       [ 0.0813  ,  0.2228  , -0.4263  ],\n",
      "       [-0.3967  ,  1.185   , -0.782   ],\n",
      "       [-0.1721  ,  0.7046  , -0.6055  ],\n",
      "       [-0.7427  ,  1.821   , -1.186   ],\n",
      "       [-0.691   ,  1.643   , -0.9727  ],\n",
      "       [-0.9766  ,  1.875   , -0.9604  ],\n",
      "       [-0.1327  ,  0.8457  , -0.7476  ],\n",
      "       [-0.5654  ,  1.94    , -1.516   ],\n",
      "       [-0.507   ,  1.167   , -0.711   ],\n",
      "       [-0.4126  ,  1.217   , -0.8716  ],\n",
      "       [-0.106   ,  1.243   , -1.217   ],\n",
      "       [-0.929   ,  1.617   , -0.713   ],\n",
      "       [ 0.1259  ,  0.2174  , -0.4734  ],\n",
      "       [-1.018   ,  2.23    , -1.319   ],\n",
      "       [-0.3828  ,  1.101   , -0.7905  ],\n",
      "       [-1.209   ,  2.057   , -0.8877  ],\n",
      "       [-1.07    ,  1.965   , -0.9697  ],\n",
      "       [-0.6904  ,  1.266   , -0.5757  ],\n",
      "       [-0.3218  ,  1.466   , -1.211   ],\n",
      "       [-1.107   ,  2.297   , -1.301   ],\n",
      "       [-0.2803  ,  1.041   , -0.803   ],\n",
      "       [-0.742   ,  1.433   , -0.7324  ],\n",
      "       [-0.6587  ,  1.422   , -0.8184  ],\n",
      "       [-0.011536,  0.3667  , -0.434   ],\n",
      "       [-0.6035  ,  1.805   , -1.323   ],\n",
      "       [-0.927   ,  1.641   , -0.7617  ],\n",
      "       [-0.9863  ,  2.098   , -1.114   ],\n",
      "       [-0.7803  ,  1.443   , -0.7446  ],\n",
      "       [-1.206   ,  2.088   , -0.921   ],\n",
      "       [-0.51    ,  1.037   , -0.5205  ],\n",
      "       [-0.825   ,  1.967   , -1.265   ],\n",
      "       [-0.842   ,  1.903   , -1.013   ],\n",
      "       [-1.258   ,  2.223   , -0.9717  ],\n",
      "       [-0.3489  ,  0.95    , -0.6763  ],\n",
      "       [-0.2742  ,  0.705   , -0.507   ],\n",
      "       [-0.4983  ,  1.371   , -0.8945  ],\n",
      "       [-1.156   ,  2.287   , -1.214   ],\n",
      "       [-0.2169  ,  1.046   , -0.8794  ],\n",
      "       [-0.71    ,  2.031   , -1.425   ],\n",
      "       [-1.013   ,  2.352   , -1.486   ],\n",
      "       [-0.09436 ,  0.3225  , -0.2786  ],\n",
      "       [-1.079   ,  2.154   , -1.172   ],\n",
      "       [-0.5264  ,  1.433   , -0.9277  ],\n",
      "       [-1.151   ,  2.273   , -1.212   ],\n",
      "       [-0.887   ,  1.926   , -1.127   ],\n",
      "       [ 0.003593,  0.2905  , -0.3867  ],\n",
      "       [-0.613   ,  1.227   , -0.6616  ],\n",
      "       [ 0.01692 ,  0.432   , -0.5195  ],\n",
      "       [-1.431   ,  2.46    , -1.136   ],\n",
      "       [-0.689   ,  1.562   , -0.9106  ],\n",
      "       [-0.5513  ,  1.432   , -0.8955  ],\n",
      "       [-0.296   ,  0.8765  , -0.5376  ]], dtype=float16), label_ids=array([1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 2, 2, 1, 2, 1, 1, 2, 2,\n",
      "       1, 2, 0, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 0, 2, 1, 1,\n",
      "       1, 2, 1, 1, 1, 0, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 0, 2, 1, 2, 0,\n",
      "       1, 1, 0, 0, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       0, 2, 1, 2, 0, 1, 1, 1, 1, 1, 1, 2, 0, 2, 1, 2, 1, 1, 1, 2, 1, 1,\n",
      "       2, 1, 2, 1, 2, 1, 1, 1, 0, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 2, 1, 2, 1, 1, 1, 2, 0, 2, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2,\n",
      "       1, 1, 1, 2, 1, 0, 0, 0, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1,\n",
      "       1, 0, 1, 1, 1, 1, 0, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 0, 2, 1, 1, 1,\n",
      "       1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 0, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 0]), metrics={'test_loss': 0.8861412405967712, 'test_accuracy': 0.6581196581196581, 'test_balanced_accuracy': 0.3810681732962315, 'test_precision': 0.6070645185689434, 'test_recall': 0.6581196581196581, 'test_f1': 0.5480788982115242, 'test_runtime': 2.3599, 'test_samples_per_second': 99.156, 'test_steps_per_second': 6.356})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be81d0c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "probabilities = torch.softmax(torch.tensor(test_results.predictions).to(torch.float32), dim=-1)\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)\n",
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef4c67fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_save = []\n",
    "for idx in range(len(test_data)):\n",
    "    item = dataset['test'][idx]\n",
    "    actual_label = item['label']\n",
    "    predicted_label = predictions[idx]\n",
    "    claim = item['claim'] \n",
    "    premise = item['premise'] \n",
    "    category = item['category']\n",
    "    \n",
    "    # Append the information as a dictionary to the list\n",
    "    data_to_save.append({\n",
    "        'Claim': claim,\n",
    "        'Premise': premise,\n",
    "        'Actual Label': actual_label,\n",
    "        'Predicted Label': predicted_label,\n",
    "        'Category' : category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_to_save)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/home/elson/results/2.2.5_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a1a63a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correctly classified instances\n",
    "correctly_classified = df[df['Actual Label'] == df['Predicted Label']]\n",
    "\n",
    "# Calculate misclassified instances\n",
    "misclassified = df[df['Actual Label'] != df['Predicted Label']]\n",
    "\n",
    "# Count the number of correctly classified and misclassified by category\n",
    "correct_classification_counts = correctly_classified['Category'].value_counts()\n",
    "misclassification_counts = misclassified['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c4055e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           34\n",
       "Fitness                  13\n",
       "Diabetes                 12\n",
       "Bone health              12\n",
       "Cancer                   12\n",
       "Skin                     10\n",
       "Neurological health       9\n",
       "Hair                      9\n",
       "Throat                    9\n",
       "Ear                       6\n",
       "Cardiovascular Health     6\n",
       "COVID                     6\n",
       "Eye                       5\n",
       "Blood                     4\n",
       "Mental Health             2\n",
       "Women' s Health           2\n",
       "Muscles                   2\n",
       "Vascular                  1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "117a1d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           17\n",
       "Skin                     14\n",
       "Bone health               9\n",
       "Men's health              6\n",
       "Cardiovascular Health     6\n",
       "Blood                     5\n",
       "Women' s Health           4\n",
       "Muscles                   4\n",
       "Eye                       4\n",
       "Hair                      3\n",
       "Dental Health             3\n",
       "Fitness                   2\n",
       "Vascular                  2\n",
       "Mental Health             1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
