{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-022bc67e9c58e92d\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 192.59it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('csv',data_files='dataset_propositionattribution_nerfeatures.csv',delimiter=',',column_names=[\"claim\",\"premise\",\"label\",\"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\",\"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\",\"url\", \"entities\",\"entity_map\",\"entity_map_ev\",\"entities_ev\",\"gem_exp\",\"gem_label\",\"gpt_label\",\"gpt_exp\",\"gold_exp\",\"synonym\",\"voice\",\"split\"],skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "133f9357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-2b8e361375c0e153.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-0cc9bb699c2761fb.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-608a44ac65076739.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01252e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\"claim\", \"premise\", \"label\", \"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\"]\n",
    "all_columns = dataset[\"train\"].column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-09e6c9d5e8174284.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-92dc2d7bd9b3606b.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-022bc67e9c58e92d/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-9085af503aa35035.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 0, 'entailment': 1, 'neutral': 2}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 0,\n",
    "    \"entailment\": 1,\n",
    "    \"neutral\": 2\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='pritamdeka/PubMedBERT-MNLI-MedNLI'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "        # Extracting claim and evidence texts\n",
    "        claim = item['claim'] \n",
    "        evidences = item['premise']\n",
    "        item['premise']=evidences\n",
    "        item['claim']=claim\n",
    "        additional_features = [\n",
    "            \"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\"]\n",
    "    \n",
    "        for feature in additional_features:\n",
    "            if feature in item:\n",
    "                claim += \"[SEP]\" + str(item[feature])\n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "            evidences,claim,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "         # Construct the output item\n",
    "        output_item = {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),  # Remove batch dimension\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),  # Remove batch dimension\n",
    "            'claim': claim,  # Include augmented claim text\n",
    "            'evidences': evidences  # Include original evidence text\n",
    "        }\n",
    "        \n",
    "        if 'label' in item:\n",
    "            output_item['label'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return output_item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62421eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"pritamdeka/PubMedBERT-MNLI-MedNLI\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=512)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=3, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    return {\"accuracy\": acc, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f5cf584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([    2,  1920,  4415, 16984,  1927, 14542,  4006,  4480,  1930, 14227,\n",
       "          5004,  2760,  1920, 29555,  1927,  1920,  4486, 14269,  1922,  1920,\n",
       "         25420,  1930,  3185,  1920,  3238,  1954,  1930, 10472,  3170,  1942,\n",
       "          2760,  1920,  8828,  1927,  1920,  4407,  1930,  3714,  1920,  7104,\n",
       "          2495,    18,     3, 14227,  5004,  4415,  6691,  1977,  8929,  2251,\n",
       "          1922,  4407,  5715,  4461,  1942,  4087,  3326,  1920,  7818,  1927,\n",
       "          1920,  4407,    18,     3,    20,     3,    20,     3,    20,     3,\n",
       "            20,     3,    20,     3,    20,     3,    20,     3,    20,     3,\n",
       "            20,     3,    20,     3,    20,     3,    20,     3,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'claim': 'Myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0',\n",
       " 'evidences': 'The essential oils of frankincense and myrrh increase the fluidity of the lipid bilayer in the cuticle and change the orderly and dense structure to increase the permeability of the skin and decrease the barrier effect.',\n",
       " 'label': tensor(1)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1020\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1020' max='1020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1020/1020 08:18, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.838300</td>\n",
       "      <td>0.827092</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.639047</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.640917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.674900</td>\n",
       "      <td>0.956239</td>\n",
       "      <td>0.559140</td>\n",
       "      <td>0.673916</td>\n",
       "      <td>0.559140</td>\n",
       "      <td>0.587575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.440900</td>\n",
       "      <td>1.156332</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>0.616533</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>0.615732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.225500</td>\n",
       "      <td>1.285227</td>\n",
       "      <td>0.610753</td>\n",
       "      <td>0.674748</td>\n",
       "      <td>0.610753</td>\n",
       "      <td>0.632521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.293500</td>\n",
       "      <td>1.119357</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.668195</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.658967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.239600</td>\n",
       "      <td>1.490329</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.666013</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.631434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.092700</td>\n",
       "      <td>1.762197</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.669365</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.653105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.129500</td>\n",
       "      <td>1.639976</td>\n",
       "      <td>0.660215</td>\n",
       "      <td>0.635758</td>\n",
       "      <td>0.660215</td>\n",
       "      <td>0.645145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.050800</td>\n",
       "      <td>2.132267</td>\n",
       "      <td>0.632258</td>\n",
       "      <td>0.635022</td>\n",
       "      <td>0.632258</td>\n",
       "      <td>0.628736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>2.130069</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.654300</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.647173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.052200</td>\n",
       "      <td>2.221491</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.671653</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.662886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.013700</td>\n",
       "      <td>2.357303</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.655795</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.656198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.051800</td>\n",
       "      <td>2.310805</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.675446</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.669420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>2.395407</td>\n",
       "      <td>0.660215</td>\n",
       "      <td>0.665317</td>\n",
       "      <td>0.660215</td>\n",
       "      <td>0.662443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>2.578379</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.664879</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.651896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>2.533175</td>\n",
       "      <td>0.662366</td>\n",
       "      <td>0.674370</td>\n",
       "      <td>0.662366</td>\n",
       "      <td>0.667581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>2.560781</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.678015</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.671410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>2.598525</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.669819</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.657896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>2.595917</td>\n",
       "      <td>0.647312</td>\n",
       "      <td>0.666618</td>\n",
       "      <td>0.647312</td>\n",
       "      <td>0.655276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>2.599026</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.669775</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.657825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.3_pubmedbert/checkpoint-51\n",
      "Configuration saved in /home/elson/1.4.3_pubmedbert/checkpoint-51/config.json\n",
      "Model weights saved in /home/elson/1.4.3_pubmedbert/checkpoint-51/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.3_pubmedbert/checkpoint-510] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/1.4.3_pubmedbert/checkpoint-1530] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.3_pubmedbert/checkpoint-102\n",
      "Configuration saved in /home/elson/1.4.3_pubmedbert/checkpoint-102/config.json\n",
      "Model weights saved in /home/elson/1.4.3_pubmedbert/checkpoint-102/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.3_pubmedbert/checkpoint-153\n",
      "Configuration saved in /home/elson/1.4.3_pubmedbert/checkpoint-153/config.json\n",
      "Model weights saved in /home/elson/1.4.3_pubmedbert/checkpoint-153/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.3_pubmedbert/checkpoint-102] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.3_pubmedbert/checkpoint-204\n",
      "Configuration saved in /home/elson/1.4.3_pubmedbert/checkpoint-204/config.json\n",
      "Model weights saved in /home/elson/1.4.3_pubmedbert/checkpoint-204/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.3_pubmedbert/checkpoint-153] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.3_pubmedbert/checkpoint-255\n",
      "Configuration saved in /home/elson/1.4.3_pubmedbert/checkpoint-255/config.json\n",
      "Model weights saved in /home/elson/1.4.3_pubmedbert/checkpoint-255/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.3_pubmedbert/checkpoint-51] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/1.4.3_pubmedbert/checkpoint-204] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.3_pubmedbert/checkpoint-306\n",
      "Configuration saved in /home/elson/1.4.3_pubmedbert/checkpoint-306/config.json\n",
      "Model weights saved in /home/elson/1.4.3_pubmedbert/checkpoint-306/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.3_pubmedbert/checkpoint-357\n",
      "Configuration saved in /home/elson/1.4.3_pubmedbert/checkpoint-357/config.json\n",
      "Model weights saved in /home/elson/1.4.3_pubmedbert/checkpoint-357/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.3_pubmedbert/checkpoint-306] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.3_pubmedbert/checkpoint-408\n",
      "Configuration saved in /home/elson/1.4.3_pubmedbert/checkpoint-408/config.json\n",
      "Model weights saved in /home/elson/1.4.3_pubmedbert/checkpoint-408/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.3_pubmedbert/checkpoint-255] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/1.4.3_pubmedbert/checkpoint-357] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.3_pubmedbert/checkpoint-459\n",
      "Configuration saved in /home/elson/1.4.3_pubmedbert/checkpoint-459/config.json\n",
      "Model weights saved in /home/elson/1.4.3_pubmedbert/checkpoint-459/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.3_pubmedbert/checkpoint-510\n",
      "Configuration saved in /home/elson/1.4.3_pubmedbert/checkpoint-510/config.json\n",
      "Model weights saved in /home/elson/1.4.3_pubmedbert/checkpoint-510/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.3_pubmedbert/checkpoint-459] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.3_pubmedbert/checkpoint-561\n",
      "Configuration saved in /home/elson/1.4.3_pubmedbert/checkpoint-561/config.json\n",
      "Model weights saved in /home/elson/1.4.3_pubmedbert/checkpoint-561/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.3_pubmedbert/checkpoint-510] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.3_pubmedbert/checkpoint-612\n",
      "Configuration saved in /home/elson/1.4.3_pubmedbert/checkpoint-612/config.json\n",
      "Model weights saved in /home/elson/1.4.3_pubmedbert/checkpoint-612/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.3_pubmedbert/checkpoint-408] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/1.4.3_pubmedbert/checkpoint-561] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.3_pubmedbert/checkpoint-663\n",
      "Configuration saved in /home/elson/1.4.3_pubmedbert/checkpoint-663/config.json\n",
      "Model weights saved in /home/elson/1.4.3_pubmedbert/checkpoint-663/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.3_pubmedbert/checkpoint-714\n",
      "Configuration saved in /home/elson/1.4.3_pubmedbert/checkpoint-714/config.json\n",
      "Model weights saved in /home/elson/1.4.3_pubmedbert/checkpoint-714/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.3_pubmedbert/checkpoint-663] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.3_pubmedbert/checkpoint-765\n",
      "Configuration saved in /home/elson/1.4.3_pubmedbert/checkpoint-765/config.json\n",
      "Model weights saved in /home/elson/1.4.3_pubmedbert/checkpoint-765/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.3_pubmedbert/checkpoint-714] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.3_pubmedbert/checkpoint-816\n",
      "Configuration saved in /home/elson/1.4.3_pubmedbert/checkpoint-816/config.json\n",
      "Model weights saved in /home/elson/1.4.3_pubmedbert/checkpoint-816/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.3_pubmedbert/checkpoint-765] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.3_pubmedbert/checkpoint-867\n",
      "Configuration saved in /home/elson/1.4.3_pubmedbert/checkpoint-867/config.json\n",
      "Model weights saved in /home/elson/1.4.3_pubmedbert/checkpoint-867/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.3_pubmedbert/checkpoint-816] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.3_pubmedbert/checkpoint-918\n",
      "Configuration saved in /home/elson/1.4.3_pubmedbert/checkpoint-918/config.json\n",
      "Model weights saved in /home/elson/1.4.3_pubmedbert/checkpoint-918/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.3_pubmedbert/checkpoint-867] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.3_pubmedbert/checkpoint-969\n",
      "Configuration saved in /home/elson/1.4.3_pubmedbert/checkpoint-969/config.json\n",
      "Model weights saved in /home/elson/1.4.3_pubmedbert/checkpoint-969/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.3_pubmedbert/checkpoint-918] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.4.3_pubmedbert/checkpoint-1020\n",
      "Configuration saved in /home/elson/1.4.3_pubmedbert/checkpoint-1020/config.json\n",
      "Model weights saved in /home/elson/1.4.3_pubmedbert/checkpoint-1020/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.4.3_pubmedbert/checkpoint-969] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading best model from /home/elson/1.4.3_pubmedbert/checkpoint-612 (score: 0.6666666666666666).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /home/elson/1.4.3_pubmedbert/best_model/config.json\n",
      "Model weights saved in /home/elson/1.4.3_pubmedbert/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/1.4.3_pubmedbert/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/1.4.3_pubmedbert/best_model/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/1.4.3_pubmedbert/best_model/tokenizer_config.json',\n",
       " '/home/elson/1.4.3_pubmedbert/best_model/special_tokens_map.json',\n",
       " '/home/elson/1.4.3_pubmedbert/best_model/vocab.txt',\n",
       " '/home/elson/1.4.3_pubmedbert/best_model/added_tokens.json',\n",
       " '/home/elson/1.4.3_pubmedbert/best_model/tokenizer.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/1.4.3_pubmedbert/',\n",
    "    num_train_epochs=20,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.1,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/1.4.3_pubmedbert/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/1.4.3_pubmedbert/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63deaea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/1.4.3_pubmedbert/best_model/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"/home/elson/1.4.3_pubmedbert/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"contradiction\",\n",
      "    \"1\": \"entailment\",\n",
      "    \"2\": \"neutral\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"contradiction\": 0,\n",
      "    \"entailment\": 1,\n",
      "    \"neutral\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file /home/elson/1.4.3_pubmedbert/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at /home/elson/1.4.3_pubmedbert/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 32\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/1.4.3_pubmedbert/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[-3.375  ,  3.262  , -1.203  ],\n",
      "       [-4.2    ,  5.766  , -2.863  ],\n",
      "       [-2.72   ,  4.766  , -3.52   ],\n",
      "       [ 5.355  , -1.795  , -2.84   ],\n",
      "       [-3.424  ,  5.69   , -3.543  ],\n",
      "       [-3.531  ,  5.848  , -3.451  ],\n",
      "       [-3.96   ,  5.8    , -3.162  ],\n",
      "       [-5.34   ,  4.637  , -0.709  ],\n",
      "       [-4.54   ,  4.953  , -1.987  ],\n",
      "       [-2.562  ,  5.11   , -3.941  ],\n",
      "       [ 2.57   , -0.9756 , -1.1875 ],\n",
      "       [-3.873  ,  5.87   , -3.184  ],\n",
      "       [-4.19   ,  5.46   , -2.613  ],\n",
      "       [-3.99   ,  5.836  , -3.076  ],\n",
      "       [-4.145  ,  5.74   , -2.973  ],\n",
      "       [ 1.437  ,  2.46   , -4.465  ],\n",
      "       [-3.8    ,  5.883  , -3.354  ],\n",
      "       [-3.785  ,  5.87   , -3.35   ],\n",
      "       [-3.773  ,  5.598  , -3.197  ],\n",
      "       [-3.883  ,  5.527  , -3.104  ],\n",
      "       [-4.156  ,  5.41   , -2.754  ],\n",
      "       [ 0.7607 ,  2.543  , -4.25   ],\n",
      "       [-3.697  ,  5.72   , -3.426  ],\n",
      "       [ 4.54   , -0.01602, -4.49   ],\n",
      "       [ 6.223  , -1.949  , -3.287  ],\n",
      "       [ 6.117  , -2.914  , -1.866  ],\n",
      "       [-3.602  ,  5.9    , -3.424  ],\n",
      "       [-4.47   ,  5.527  , -2.508  ],\n",
      "       [-4.414  ,  5.625  , -2.584  ],\n",
      "       [-4.086  ,  5.83   , -3.07   ],\n",
      "       [-3.32   ,  4.547  , -2.484  ],\n",
      "       [-4.07   ,  4.92   , -2.166  ],\n",
      "       [-4.152  ,  5.816  , -2.982  ],\n",
      "       [ 0.355  ,  3.027  , -3.977  ],\n",
      "       [-1.703  , -1.224  ,  2.271  ],\n",
      "       [-3.924  ,  5.816  , -3.23   ],\n",
      "       [-3.889  ,  5.703  , -3.15   ],\n",
      "       [-4.453  ,  5.7    , -2.576  ],\n",
      "       [ 3.75   ,  1.253  , -4.98   ],\n",
      "       [-3.746  ,  5.777  , -3.389  ],\n",
      "       [ 6.137  , -1.433  , -3.9    ],\n",
      "       [-4.516  ,  5.19   , -2.297  ],\n",
      "       [-1.448  , -3.309  ,  5.14   ],\n",
      "       [-2.773  , -3.129  ,  5.777  ],\n",
      "       [-4.438  ,  2.254  ,  1.154  ],\n",
      "       [-3.305  ,  5.867  , -3.527  ],\n",
      "       [ 3.094  , -0.2289 , -2.736  ],\n",
      "       [-3.646  ,  5.87   , -3.47   ],\n",
      "       [-3.652  ,  5.906  , -3.375  ],\n",
      "       [ 6.055  , -1.286  , -3.742  ],\n",
      "       [-4.434  ,  4.9    , -1.946  ],\n",
      "       [-2.414  ,  2.598  , -0.5625 ],\n",
      "       [-3.047  ,  4.895  , -3.225  ],\n",
      "       [-4.715  ,  4.94   , -1.73   ],\n",
      "       [ 5.598  , -0.9233 , -3.758  ],\n",
      "       [-3.479  ,  5.676  , -3.621  ],\n",
      "       [ 1.168  , -1.812  ,  1.391  ],\n",
      "       [-4.656  ,  5.17   , -2.1    ],\n",
      "       [-3.748  ,  5.83   , -3.41   ],\n",
      "       [-3.63   ,  5.625  , -3.441  ],\n",
      "       [-4.133  ,  5.69   , -2.945  ],\n",
      "       [ 5.344  , -0.7305 , -4.055  ],\n",
      "       [-1.408  , -2.031  ,  3.45   ],\n",
      "       [-3.355  ,  5.305  , -3.352  ],\n",
      "       [-4.887  ,  2.58   ,  1.145  ],\n",
      "       [-3.36   ,  5.59   , -3.611  ],\n",
      "       [-3.848  ,  5.875  , -3.25   ],\n",
      "       [-4.97   ,  4.996  , -1.375  ],\n",
      "       [-2.975  ,  1.437  ,  0.808  ],\n",
      "       [ 6.105  , -1.8545 , -3.31   ],\n",
      "       [-3.945  ,  5.05   , -2.623  ],\n",
      "       [-2.139  ,  4.34   , -3.545  ],\n",
      "       [-3.742  ,  5.434  , -3.148  ],\n",
      "       [-1.427  ,  4.234  , -3.719  ],\n",
      "       [-3.662  ,  5.28   , -2.854  ],\n",
      "       [-3.463  ,  5.805  , -3.57   ],\n",
      "       [-4.094  ,  5.83   , -2.977  ],\n",
      "       [-3.275  ,  5.586  , -3.592  ],\n",
      "       [-4.05   ,  5.883  , -3.033  ],\n",
      "       [-2.252  ,  4.746  , -3.826  ],\n",
      "       [-4.47   ,  5.29   , -2.229  ],\n",
      "       [-3.668  ,  5.832  , -3.41   ],\n",
      "       [-4.113  ,  5.695  , -3.018  ],\n",
      "       [-3.428  ,  5.832  , -3.516  ],\n",
      "       [-3.63   ,  5.785  , -3.393  ],\n",
      "       [-4.344  ,  5.484  , -2.514  ],\n",
      "       [-3.654  ,  5.79   , -3.195  ],\n",
      "       [ 4.195  , -1.478  , -2.184  ],\n",
      "       [-4.695  ,  5.145  , -1.994  ],\n",
      "       [-2.096  ,  3.555  , -2.373  ],\n",
      "       [-3.986  ,  5.586  , -3.062  ],\n",
      "       [-3.98   ,  5.47   , -3.025  ],\n",
      "       [ 6.26   , -2.39   , -2.748  ],\n",
      "       [-3.748  ,  5.875  , -3.412  ],\n",
      "       [ 2.45   ,  0.983  , -3.51   ],\n",
      "       [ 2.883  , -4.277  ,  2.564  ],\n",
      "       [ 3.4    ,  0.924  , -3.998  ],\n",
      "       [-3.6    ,  5.535  , -3.328  ],\n",
      "       [-3.803  ,  5.895  , -3.201  ],\n",
      "       [-3.434  ,  5.758  , -3.625  ],\n",
      "       [ 2.832  ,  2.037  , -5.004  ],\n",
      "       [-3.602  ,  5.91   , -3.408  ],\n",
      "       [-4.062  ,  5.855  , -3.035  ],\n",
      "       [-4.227  ,  5.086  , -2.469  ],\n",
      "       [-4.418  ,  5.723  , -2.707  ],\n",
      "       [-4.34   ,  5.477  , -2.623  ],\n",
      "       [-2.766  ,  5.562  , -3.889  ],\n",
      "       [-1.5205 ,  4.72   , -4.234  ],\n",
      "       [-4.21   ,  5.168  , -2.672  ],\n",
      "       [-4.426  ,  5.44   , -2.234  ],\n",
      "       [-4.543  ,  3.758  , -0.565  ],\n",
      "       [-3.936  ,  5.76   , -3.072  ],\n",
      "       [-3.998  ,  5.82   , -3.105  ],\n",
      "       [-3.994  ,  5.848  , -2.943  ],\n",
      "       [-4.656  , -0.4553 ,  4.74   ],\n",
      "       [-4.86   ,  5.26   , -1.682  ],\n",
      "       [-3.762  ,  5.855  , -3.277  ],\n",
      "       [-4.75   ,  5.516  , -2.107  ],\n",
      "       [-4.266  ,  4.855  , -1.895  ],\n",
      "       [-3.543  ,  5.652  , -3.363  ],\n",
      "       [-2.582  , -2.436  ,  5.22   ],\n",
      "       [-3.482  ,  5.867  , -3.445  ],\n",
      "       [-4.42   ,  5.49   , -2.61   ],\n",
      "       [-4.406  , -1.135  ,  4.43   ],\n",
      "       [-3.72   , -1.658  ,  5.293  ],\n",
      "       [-3.736  ,  5.87   , -3.293  ],\n",
      "       [-1.742  , -1.484  ,  2.947  ],\n",
      "       [-3.605  ,  5.715  , -3.469  ],\n",
      "       [ 1.164  ,  2.28   , -4.297  ],\n",
      "       [-3.955  ,  5.145  , -2.754  ],\n",
      "       [-3.469  ,  5.65   , -3.598  ],\n",
      "       [ 5.67   , -2.062  , -2.625  ],\n",
      "       [-4.555  ,  5.664  , -2.438  ],\n",
      "       [ 0.185  , -3.889  ,  4.35   ],\n",
      "       [ 3.123  ,  0.03796, -3.     ],\n",
      "       [-3.768  ,  5.527  , -3.215  ],\n",
      "       [-2.85   ,  5.53   , -3.746  ],\n",
      "       [-3.477  , -2.498  ,  5.984  ],\n",
      "       [-0.6045 , -2.436  ,  2.93   ],\n",
      "       [-4.11   ,  5.84   , -2.97   ],\n",
      "       [-3.45   ,  5.88   , -3.414  ],\n",
      "       [ 5.555  , -2.355  , -2.068  ],\n",
      "       [-2.863  ,  4.668  , -2.963  ],\n",
      "       [-3.602  ,  5.918  , -3.467  ],\n",
      "       [-4.098  ,  5.57   , -2.982  ],\n",
      "       [ 4.99   , -1.856  , -2.39   ],\n",
      "       [ 6.434  , -2.293  , -2.965  ],\n",
      "       [ 3.982  ,  0.4434 , -4.188  ],\n",
      "       [-3.877  ,  5.85   , -3.291  ],\n",
      "       [-4.258  , -1.555  ,  5.395  ],\n",
      "       [-2.504  ,  1.971  , -0.516  ],\n",
      "       [-3.938  ,  5.566  , -3.107  ],\n",
      "       [-4.84   , -0.3013 ,  4.83   ],\n",
      "       [-4.086  ,  5.688  , -3.03   ],\n",
      "       [-4.418  ,  4.84   , -1.855  ],\n",
      "       [-4.01   ,  5.73   , -3.172  ],\n",
      "       [-3.518  ,  5.754  , -3.535  ],\n",
      "       [-3.678  ,  5.49   , -3.264  ],\n",
      "       [-3.701  ,  3.094  , -0.5205 ],\n",
      "       [ 6.332  , -2.002  , -3.336  ],\n",
      "       [ 6.305  , -2.396  , -2.879  ],\n",
      "       [ 6.51   , -2.586  , -2.746  ],\n",
      "       [-4.246  ,  5.29   , -2.523  ],\n",
      "       [ 5.36   , -1.538  , -3.373  ],\n",
      "       [ 3.803  , -2.277  , -1.009  ],\n",
      "       [-4.723  ,  4.977  , -1.792  ],\n",
      "       [ 0.427  ,  3.307  , -4.645  ],\n",
      "       [ 5.3    , -1.172  , -3.64   ],\n",
      "       [-1.378  ,  2.547  , -2.113  ],\n",
      "       [-1.127  ,  3.746  , -3.906  ],\n",
      "       [ 5.996  , -2.28   , -2.543  ],\n",
      "       [-2.973  ,  5.4    , -3.803  ],\n",
      "       [ 5.574  , -1.101  , -3.719  ],\n",
      "       [-4.47   ,  5.668  , -2.53   ],\n",
      "       [-3.703  ,  5.945  , -3.201  ],\n",
      "       [-1.667  ,  3.348  , -2.785  ],\n",
      "       [-3.912  ,  5.86   , -3.098  ],\n",
      "       [ 5.516  , -1.393  , -3.256  ],\n",
      "       [-3.076  ,  5.434  , -3.709  ],\n",
      "       [-4.027  ,  1.08   ,  2.209  ],\n",
      "       [ 0.3645 , -1.946  ,  1.454  ],\n",
      "       [-0.642  ,  4.297  , -4.766  ],\n",
      "       [ 2.438  ,  2.72   , -5.39   ],\n",
      "       [-4.707  ,  5.277  , -2.115  ],\n",
      "       [ 6.16   , -2.904  , -2.256  ],\n",
      "       [-4.074  ,  5.324  , -2.69   ],\n",
      "       [-3.752  ,  5.85   , -3.312  ],\n",
      "       [-3.883  ,  5.836  , -3.098  ],\n",
      "       [-4.836  ,  5.156  , -1.58   ],\n",
      "       [-3.805  ,  5.89   , -3.307  ],\n",
      "       [-3.785  , -1.511  ,  4.38   ],\n",
      "       [-4.074  ,  5.406  , -2.867  ],\n",
      "       [-3.89   ,  5.67   , -3.168  ],\n",
      "       [-5.105  ,  2.812  ,  1.031  ],\n",
      "       [ 4.75   , -0.1219 , -4.105  ],\n",
      "       [-3.518  ,  5.812  , -3.504  ],\n",
      "       [-4.71   ,  5.348  , -2.17   ],\n",
      "       [-4.074  ,  5.848  , -3.074  ],\n",
      "       [-3.428  ,  5.527  , -3.443  ],\n",
      "       [-2.02   ,  2.52   , -1.707  ],\n",
      "       [-4.047  ,  5.85   , -3.088  ],\n",
      "       [-3.533  ,  5.758  , -3.39   ],\n",
      "       [-1.608  ,  4.273  , -3.994  ],\n",
      "       [-4.57   ,  5.7    , -2.51   ],\n",
      "       [-5.297  ,  1.664  ,  2.621  ],\n",
      "       [ 6.297  , -2.227  , -3.219  ],\n",
      "       [-3.908  ,  5.78   , -3.254  ],\n",
      "       [ 4.04   , -2.38   , -1.171  ],\n",
      "       [-3.629  ,  5.84   , -3.406  ],\n",
      "       [-3.627  ,  5.777  , -3.467  ],\n",
      "       [-4.33   ,  5.246  , -2.256  ],\n",
      "       [-2.207  ,  2.71   , -1.769  ],\n",
      "       [-4.71   ,  4.715  , -1.522  ],\n",
      "       [-3.865  ,  5.438  , -3.076  ],\n",
      "       [-4.01   ,  5.875  , -3.062  ],\n",
      "       [ 5.984  , -1.975  , -3.033  ],\n",
      "       [ 4.836  , -1.769  , -2.078  ],\n",
      "       [-4.01   ,  5.223  , -2.764  ],\n",
      "       [-4.36   ,  5.582  , -2.6    ],\n",
      "       [-3.02   ,  3.266  , -1.322  ],\n",
      "       [-3.893  ,  5.855  , -3.22   ],\n",
      "       [-3.828  ,  5.895  , -3.217  ],\n",
      "       [ 5.156  , -0.457  , -4.01   ],\n",
      "       [-4.125  ,  5.86   , -2.994  ],\n",
      "       [-3.266  ,  5.77   , -3.6    ],\n",
      "       [-3.795  ,  5.625  , -3.047  ],\n",
      "       [-3.875  ,  5.88   , -3.201  ],\n",
      "       [ 6.336  , -2.404  , -3.033  ],\n",
      "       [-2.992  ,  4.996  , -3.531  ],\n",
      "       [ 4.547  , -2.555  , -1.05   ],\n",
      "       [-3.38   ,  5.88   , -3.441  ],\n",
      "       [-3.861  ,  5.633  , -3.15   ],\n",
      "       [-3.2    ,  4.727  , -3.22   ],\n",
      "       [ 5.65   , -1.8125 , -2.854  ]], dtype=float16), label_ids=array([1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1,\n",
      "       1, 2, 0, 0, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 0, 1, 0, 2, 1, 1,\n",
      "       2, 0, 1, 1, 1, 0, 2, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 0, 2, 1, 2, 1,\n",
      "       1, 2, 0, 0, 1, 1, 2, 2, 2, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1,\n",
      "       1, 2, 1, 1, 2, 1, 2, 2, 0, 1, 1, 2, 0, 2, 1, 2, 1, 1, 1, 2, 1, 1,\n",
      "       2, 0, 1, 1, 2, 1, 1, 1, 2, 0, 2, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2,\n",
      "       1, 2, 1, 2, 1, 1, 2, 1, 0, 1, 1, 1, 2, 2, 0, 2, 1, 1, 1, 1, 2, 2,\n",
      "       0, 1, 1, 2, 1, 0, 0, 0, 2, 1, 1, 2, 1, 2, 0, 1, 0, 1, 2, 1, 1, 1,\n",
      "       1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 0, 0, 1, 2, 1,\n",
      "       1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 2, 0, 1, 1,\n",
      "       1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 0, 1, 1, 2]), metrics={'test_loss': 2.640110731124878, 'test_accuracy': 0.6495726495726496, 'test_precision': 0.6535872328405988, 'test_recall': 0.6495726495726496, 'test_f1': 0.6044536109052238, 'test_runtime': 1.1445, 'test_samples_per_second': 204.464, 'test_steps_per_second': 6.99})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d4e861c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "probabilities = torch.softmax(torch.tensor(test_results.predictions).to(torch.float32), dim=-1)\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)\n",
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1747566",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_save = []\n",
    "for idx in range(len(test_data)):\n",
    "    item = dataset['test'][idx]\n",
    "    actual_label = item['label']\n",
    "    predicted_label = predictions[idx]\n",
    "    claim = item['claim'] \n",
    "    premise = item['premise'] \n",
    "    category = item['category']\n",
    "    \n",
    "    # Append the information as a dictionary to the list\n",
    "    data_to_save.append({\n",
    "        'Claim': claim,\n",
    "        'Premise': premise,\n",
    "        'Actual Label': actual_label,\n",
    "        'Predicted Label': predicted_label,\n",
    "        'Category' : category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_to_save)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/home/elson/results/1.4.3_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f40c56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correctly classified instances\n",
    "correctly_classified = df[df['Actual Label'] == df['Predicted Label']]\n",
    "\n",
    "# Calculate misclassified instances\n",
    "misclassified = df[df['Actual Label'] != df['Predicted Label']]\n",
    "\n",
    "# Count the number of correctly classified and misclassified by category\n",
    "correct_classification_counts = correctly_classified['Category'].value_counts()\n",
    "misclassification_counts = misclassified['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61d30750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           39\n",
       "Bone health              15\n",
       "Diabetes                 12\n",
       "Fitness                  12\n",
       "Skin                     10\n",
       "Cardiovascular Health     9\n",
       "Cancer                    9\n",
       "Throat                    7\n",
       "Ear                       6\n",
       "COVID                     5\n",
       "Neurological health       5\n",
       "Men's health              4\n",
       "Women' s Health           4\n",
       "Eye                       4\n",
       "Blood                     4\n",
       "Hair                      3\n",
       "Mental Health             3\n",
       "Muscles                   1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "670ffadf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Skin                     14\n",
       "General Health           12\n",
       "Hair                      9\n",
       "Bone health               6\n",
       "Eye                       5\n",
       "Blood                     5\n",
       "Muscles                   5\n",
       "Neurological health       4\n",
       "Vascular                  3\n",
       "Dental Health             3\n",
       "Fitness                   3\n",
       "Cardiovascular Health     3\n",
       "Cancer                    3\n",
       "Women' s Health           2\n",
       "Men's health              2\n",
       "Throat                    2\n",
       "COVID                     1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
