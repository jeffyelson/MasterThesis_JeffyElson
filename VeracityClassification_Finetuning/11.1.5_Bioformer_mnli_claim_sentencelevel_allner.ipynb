{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-cfbf7584a6bb7c13\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 213.02it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('csv',data_files='dataset_sentenceattribution_nerfeatures_split.csv',delimiter=',',column_names=[\"claim\",\"premise\",\"label\",\"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\",\"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\",\"url\", \"entities\",\"entity_map\",\"gem_exp\",\"gem_label\",\"gpt_label\",\"gpt_exp\",\"gold_exp\",\"entity_map_ev\",\"entity_ev\", \"synonym\",\"voice\",\"split\"],skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "133f9357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-aa1fd4d2889f655e.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-9cd628f4430f2ace.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-df968f39da4ad12a.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01252e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\"claim\", \"premise\", \"label\",\"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\",\"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\"]\n",
    "all_columns = dataset[\"train\"].column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-3939f688401dfd1d.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-6e3e675e2ac00106.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-ec7578b7af56fb7d.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 2, 'entailment': 0, 'neutral': 1}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 2,\n",
    "    \"entailment\": 0,\n",
    "    \"neutral\": 1\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e15010ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='bioformers/bioformer-8L-mnli'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "        # Extracting claim and evidence texts\n",
    "        claim = item['claim'].lower() \n",
    "        evidences = item['premise']\n",
    "        item['premise']=evidences\n",
    "        item['claim']=claim\n",
    "        additional_features_evidence = [\n",
    "            \"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\"]\n",
    "    \n",
    "        for feature in additional_features_evidence:\n",
    "            if feature in item:\n",
    "                evidences += \"[SEP]\" + str(item[feature])\n",
    "        additional_features = [\n",
    "            \"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\"]\n",
    "    \n",
    "        for feature_ev in additional_features:\n",
    "            if feature_ev in item:\n",
    "                claim += \"[SEP]\" + str(item[feature_ev])\n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "            evidences,claim,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "         # Construct the output item\n",
    "        output_item = {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),  # Remove batch dimension\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),  # Remove batch dimension\n",
    "            'claim': claim,  # Include augmented claim text\n",
    "            'evidences': evidences  # Include original evidence text\n",
    "        }\n",
    "        \n",
    "        if 'label' in item:\n",
    "            output_item['label'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return output_item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62421eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(32768, 512, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 512)\n",
       "      (token_type_embeddings): Embedding(2, 512)\n",
       "      (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=512, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"bioformers/bioformer-8L-mnli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=512)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=3, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    return {\"accuracy\": acc, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f5cf584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([  101,  4916,   117,  5545,  5029,  8349,  2290,  3047,  4506,  1975,\n",
       "          1488,  1425,  2132,  4765,  2848,  9507,  1111,  1435,  2573,  1109,\n",
       "          4258,  3720,  6187,  3004,  2076,  4989,  1425,  8635,  1431, 17188,\n",
       "          1560,  3550, 14180,  1446, 19612,  1520,  2911,  3550,  2290,  3047,\n",
       "           119,   102,   121,   102,   121,   102,   121,   102,   121,   102,\n",
       "           121,   102,   121,   102,   121,   102,   121,   102,   121,   102,\n",
       "           121,   102,   121,   102,   121,   102,  2573,  1109,  4258,  3720,\n",
       "          6187,  1478,  8811,  1822,  1427,  3550,  5183,  4030,  1446,  3346,\n",
       "          2520,  1425,  6875,  1431,  1425,  3550,   119,   102,   121,   102,\n",
       "           121,   102,   121,   102,   121,   102,   121,   102,   121,   102,\n",
       "           121,   102,   121,   102,   121,   102,   121,   102,   121,   102,\n",
       "           121,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'claim': 'myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0',\n",
       " 'evidences': 'Additionally, laser doppler blood flow measurement showed that the frankincense and myrrh essential oil compound could promote the elimination of capillaries from skin epidermis to dermis by increasing skin blood flow.[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0',\n",
       " 'label': tensor(1)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 765\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='765' max='765' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [765/765 03:03, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.750100</td>\n",
       "      <td>0.893306</td>\n",
       "      <td>0.623656</td>\n",
       "      <td>0.584651</td>\n",
       "      <td>0.623656</td>\n",
       "      <td>0.558201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.682400</td>\n",
       "      <td>0.866269</td>\n",
       "      <td>0.623656</td>\n",
       "      <td>0.607509</td>\n",
       "      <td>0.623656</td>\n",
       "      <td>0.607620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.412200</td>\n",
       "      <td>0.953856</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>0.626985</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>0.622932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.245100</td>\n",
       "      <td>1.153296</td>\n",
       "      <td>0.621505</td>\n",
       "      <td>0.613409</td>\n",
       "      <td>0.621505</td>\n",
       "      <td>0.616217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.269600</td>\n",
       "      <td>1.214962</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.664729</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.659225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.174200</td>\n",
       "      <td>1.321029</td>\n",
       "      <td>0.634409</td>\n",
       "      <td>0.629937</td>\n",
       "      <td>0.634409</td>\n",
       "      <td>0.632075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.117900</td>\n",
       "      <td>1.521327</td>\n",
       "      <td>0.627957</td>\n",
       "      <td>0.632010</td>\n",
       "      <td>0.627957</td>\n",
       "      <td>0.629729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.067800</td>\n",
       "      <td>1.594450</td>\n",
       "      <td>0.632258</td>\n",
       "      <td>0.633376</td>\n",
       "      <td>0.632258</td>\n",
       "      <td>0.631891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.048400</td>\n",
       "      <td>1.738522</td>\n",
       "      <td>0.615054</td>\n",
       "      <td>0.610637</td>\n",
       "      <td>0.615054</td>\n",
       "      <td>0.610730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.065600</td>\n",
       "      <td>1.786933</td>\n",
       "      <td>0.627957</td>\n",
       "      <td>0.625219</td>\n",
       "      <td>0.627957</td>\n",
       "      <td>0.626542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.046600</td>\n",
       "      <td>1.858318</td>\n",
       "      <td>0.615054</td>\n",
       "      <td>0.615646</td>\n",
       "      <td>0.615054</td>\n",
       "      <td>0.615319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>1.918036</td>\n",
       "      <td>0.610753</td>\n",
       "      <td>0.608697</td>\n",
       "      <td>0.610753</td>\n",
       "      <td>0.609678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.042600</td>\n",
       "      <td>1.986476</td>\n",
       "      <td>0.608602</td>\n",
       "      <td>0.604969</td>\n",
       "      <td>0.608602</td>\n",
       "      <td>0.606176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.019100</td>\n",
       "      <td>1.986135</td>\n",
       "      <td>0.610753</td>\n",
       "      <td>0.608205</td>\n",
       "      <td>0.610753</td>\n",
       "      <td>0.608591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.031000</td>\n",
       "      <td>1.993221</td>\n",
       "      <td>0.608602</td>\n",
       "      <td>0.605996</td>\n",
       "      <td>0.608602</td>\n",
       "      <td>0.606542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.5_bioformer/checkpoint-51\n",
      "Configuration saved in /home/elson/11.1.5_bioformer/checkpoint-51/config.json\n",
      "Model weights saved in /home/elson/11.1.5_bioformer/checkpoint-51/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.5_bioformer/checkpoint-102\n",
      "Configuration saved in /home/elson/11.1.5_bioformer/checkpoint-102/config.json\n",
      "Model weights saved in /home/elson/11.1.5_bioformer/checkpoint-102/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.1.5_bioformer/checkpoint-51] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.5_bioformer/checkpoint-153\n",
      "Configuration saved in /home/elson/11.1.5_bioformer/checkpoint-153/config.json\n",
      "Model weights saved in /home/elson/11.1.5_bioformer/checkpoint-153/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.1.5_bioformer/checkpoint-102] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.5_bioformer/checkpoint-204\n",
      "Configuration saved in /home/elson/11.1.5_bioformer/checkpoint-204/config.json\n",
      "Model weights saved in /home/elson/11.1.5_bioformer/checkpoint-204/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.5_bioformer/checkpoint-255\n",
      "Configuration saved in /home/elson/11.1.5_bioformer/checkpoint-255/config.json\n",
      "Model weights saved in /home/elson/11.1.5_bioformer/checkpoint-255/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.1.5_bioformer/checkpoint-153] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/11.1.5_bioformer/checkpoint-204] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.5_bioformer/checkpoint-306\n",
      "Configuration saved in /home/elson/11.1.5_bioformer/checkpoint-306/config.json\n",
      "Model weights saved in /home/elson/11.1.5_bioformer/checkpoint-306/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.5_bioformer/checkpoint-357\n",
      "Configuration saved in /home/elson/11.1.5_bioformer/checkpoint-357/config.json\n",
      "Model weights saved in /home/elson/11.1.5_bioformer/checkpoint-357/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.1.5_bioformer/checkpoint-306] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.5_bioformer/checkpoint-408\n",
      "Configuration saved in /home/elson/11.1.5_bioformer/checkpoint-408/config.json\n",
      "Model weights saved in /home/elson/11.1.5_bioformer/checkpoint-408/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.1.5_bioformer/checkpoint-357] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.5_bioformer/checkpoint-459\n",
      "Configuration saved in /home/elson/11.1.5_bioformer/checkpoint-459/config.json\n",
      "Model weights saved in /home/elson/11.1.5_bioformer/checkpoint-459/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.1.5_bioformer/checkpoint-408] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.5_bioformer/checkpoint-510\n",
      "Configuration saved in /home/elson/11.1.5_bioformer/checkpoint-510/config.json\n",
      "Model weights saved in /home/elson/11.1.5_bioformer/checkpoint-510/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.1.5_bioformer/checkpoint-459] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.5_bioformer/checkpoint-561\n",
      "Configuration saved in /home/elson/11.1.5_bioformer/checkpoint-561/config.json\n",
      "Model weights saved in /home/elson/11.1.5_bioformer/checkpoint-561/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.1.5_bioformer/checkpoint-510] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.5_bioformer/checkpoint-612\n",
      "Configuration saved in /home/elson/11.1.5_bioformer/checkpoint-612/config.json\n",
      "Model weights saved in /home/elson/11.1.5_bioformer/checkpoint-612/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.1.5_bioformer/checkpoint-561] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.5_bioformer/checkpoint-663\n",
      "Configuration saved in /home/elson/11.1.5_bioformer/checkpoint-663/config.json\n",
      "Model weights saved in /home/elson/11.1.5_bioformer/checkpoint-663/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.1.5_bioformer/checkpoint-612] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.5_bioformer/checkpoint-714\n",
      "Configuration saved in /home/elson/11.1.5_bioformer/checkpoint-714/config.json\n",
      "Model weights saved in /home/elson/11.1.5_bioformer/checkpoint-714/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.1.5_bioformer/checkpoint-663] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.5_bioformer/checkpoint-765\n",
      "Configuration saved in /home/elson/11.1.5_bioformer/checkpoint-765/config.json\n",
      "Model weights saved in /home/elson/11.1.5_bioformer/checkpoint-765/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.1.5_bioformer/checkpoint-714] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/elson/11.1.5_bioformer/checkpoint-255 (score: 0.6592252062108296).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /home/elson/11.1.5_bioformer/best_model/config.json\n",
      "Model weights saved in /home/elson/11.1.5_bioformer/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/11.1.5_bioformer/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/11.1.5_bioformer/best_model/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/11.1.5_bioformer/best_model/tokenizer_config.json',\n",
       " '/home/elson/11.1.5_bioformer/best_model/special_tokens_map.json',\n",
       " '/home/elson/11.1.5_bioformer/best_model/vocab.txt',\n",
       " '/home/elson/11.1.5_bioformer/best_model/added_tokens.json',\n",
       " '/home/elson/11.1.5_bioformer/best_model/tokenizer.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/11.1.5_bioformer/',\n",
    "    num_train_epochs=15,\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.06,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/11.1.5_bioformer/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/11.1.5_bioformer/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63deaea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/11.1.5_bioformer/best_model/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"/home/elson/11.1.5_bioformer/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"finetuning_task\": \"mnli\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 512,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"entailment\",\n",
      "    \"1\": \"neutral\",\n",
      "    \"2\": \"contradiction\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2048,\n",
      "  \"label2id\": {\n",
      "    \"contradiction\": 2,\n",
      "    \"entailment\": 0,\n",
      "    \"neutral\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 8,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32768\n",
      "}\n",
      "\n",
      "loading weights file /home/elson/11.1.5_bioformer/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at /home/elson/11.1.5_bioformer/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 32\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/11.1.5_bioformer/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[-0.1477 ,  2.47   , -2.504  ],\n",
      "       [ 3.469  , -0.89   , -2.99   ],\n",
      "       [ 1.847  ,  0.10046, -2.346  ],\n",
      "       [-1.512  ,  1.262  ,  0.384  ],\n",
      "       [ 3.188  , -0.2449 , -2.98   ],\n",
      "       [ 3.81   , -1.289  , -2.797  ],\n",
      "       [ 3.746  , -1.913  , -2.28   ],\n",
      "       [ 3.76   , -1.388  , -2.713  ],\n",
      "       [ 1.938  ,  0.857  , -3.102  ],\n",
      "       [ 1.222  ,  0.7427 , -2.111  ],\n",
      "       [ 3.146  , -2.215  , -1.342  ],\n",
      "       [ 3.941  , -1.876  , -2.385  ],\n",
      "       [-3.3    ,  0.1407 ,  3.418  ],\n",
      "       [ 3.723  , -1.42   , -2.605  ],\n",
      "       [-0.2766 , -0.2522 ,  0.3237 ],\n",
      "       [-1.779  ,  1.339  ,  0.2686 ],\n",
      "       [ 3.5    , -0.565  , -3.334  ],\n",
      "       [ 3.107  , -0.6953 , -2.79   ],\n",
      "       [ 3.941  , -1.888  , -2.412  ],\n",
      "       [ 3.863  , -1.568  , -2.69   ],\n",
      "       [ 1.104  , -0.0815 , -1.421  ],\n",
      "       [ 1.668  ,  1.085  , -3.32   ],\n",
      "       [ 0.1324 ,  2.521  , -2.7    ],\n",
      "       [-0.1743 ,  0.919  , -0.974  ],\n",
      "       [-0.684  , -0.9487 ,  1.704  ],\n",
      "       [-3.166  , -0.5347 ,  4.04   ],\n",
      "       [ 4.043  , -1.256  , -2.922  ],\n",
      "       [-1.108  ,  0.658  ,  0.2004 ],\n",
      "       [-0.5264 , -0.2383 ,  0.781  ],\n",
      "       [-1.22   , -0.1564 ,  1.628  ],\n",
      "       [ 0.133  ,  0.5566 , -1.061  ],\n",
      "       [ 3.25   , -0.299  , -3.25   ],\n",
      "       [ 2.973  , -1.569  , -1.843  ],\n",
      "       [ 1.988  , -0.772  , -1.338  ],\n",
      "       [ 1.918  ,  0.2142 , -2.73   ],\n",
      "       [ 3.383  , -0.3494 , -3.385  ],\n",
      "       [ 2.787  ,  0.606  , -3.59   ],\n",
      "       [ 3.555  , -1.075  , -2.834  ],\n",
      "       [-1.75   ,  1.238  ,  0.503  ],\n",
      "       [ 3.447  , -0.882  , -3.084  ],\n",
      "       [-0.78   ,  2.197  , -1.696  ],\n",
      "       [ 2.654  ,  0.8477 , -3.846  ],\n",
      "       [ 3.145  , -1.832  , -1.615  ],\n",
      "       [-3.28   ,  2.057  ,  1.446  ],\n",
      "       [-0.9897 ,  2.262  , -1.483  ],\n",
      "       [ 0.346  ,  2.615  , -3.295  ],\n",
      "       [ 0.428  ,  0.795  , -1.873  ],\n",
      "       [ 3.615  , -0.7754 , -3.184  ],\n",
      "       [ 3.625  , -1.343  , -2.586  ],\n",
      "       [ 1.035  , -0.991  , -0.1777 ],\n",
      "       [-1.397  , -0.9917 ,  2.12   ],\n",
      "       [ 3.066  , -1.166  , -2.262  ],\n",
      "       [ 2.443  , -0.04126, -2.695  ],\n",
      "       [-0.3853 ,  1.976  , -1.73   ],\n",
      "       [-2.645  ,  0.531  ,  2.04   ],\n",
      "       [ 4.02   , -1.854  , -2.473  ],\n",
      "       [-2.85   ,  0.4424 ,  2.361  ],\n",
      "       [ 2.38   ,  0.503  , -3.521  ],\n",
      "       [ 3.314  , -0.841  , -2.914  ],\n",
      "       [ 3.867  , -0.8936 , -3.227  ],\n",
      "       [ 3.508  , -1.808  , -2.018  ],\n",
      "       [-2.61   ,  0.1035 ,  2.502  ],\n",
      "       [-0.4521 ,  2.197  , -1.755  ],\n",
      "       [ 2.838  ,  0.3906 , -3.367  ],\n",
      "       [ 1.378  ,  1.776  , -3.52   ],\n",
      "       [ 3.63   , -0.98   , -2.84   ],\n",
      "       [ 3.152  , -0.11206, -3.365  ],\n",
      "       [ 3.254  , -0.9263 , -2.709  ],\n",
      "       [ 2.527  , -1.94   , -0.95   ],\n",
      "       [-0.04675, -1.224  ,  1.186  ],\n",
      "       [ 0.4128 ,  1.49   , -2.025  ],\n",
      "       [-0.3647 ,  1.276  , -1.251  ],\n",
      "       [ 2.852  ,  0.3591 , -3.57   ],\n",
      "       [-3.25   , -0.2053 ,  3.719  ],\n",
      "       [ 2.35   , -0.7886 , -2.262  ],\n",
      "       [ 0.1775 ,  1.673  , -2.123  ],\n",
      "       [ 0.441  ,  0.558  , -0.865  ],\n",
      "       [ 3.795  , -1.237  , -2.822  ],\n",
      "       [ 2.996  , -1.523  , -1.949  ],\n",
      "       [ 3.223  , -1.644  , -2.123  ],\n",
      "       [ 3.56   , -1.816  , -2.16   ],\n",
      "       [ 3.85   , -1.715  , -2.525  ],\n",
      "       [ 3.64   , -1.588  , -2.506  ],\n",
      "       [ 3.895  , -2.174  , -2.016  ],\n",
      "       [ 3.717  , -1.143  , -2.898  ],\n",
      "       [-2.275  ,  2.105  ,  0.4778 ],\n",
      "       [ 2.469  , -0.03217, -2.693  ],\n",
      "       [-0.616  ,  1.771  , -1.181  ],\n",
      "       [ 2.336  , -0.2922 , -2.611  ],\n",
      "       [ 1.323  ,  1.373  , -2.969  ],\n",
      "       [ 3.1    , -1.517  , -1.943  ],\n",
      "       [ 3.9    , -1.632  , -2.582  ],\n",
      "       [-2.29   , -0.1302 ,  2.512  ],\n",
      "       [ 3.395  , -0.638  , -3.037  ],\n",
      "       [ 3.674  , -1.724  , -2.5    ],\n",
      "       [ 3.057  , -1.9375 , -1.404  ],\n",
      "       [ 1.256  , -0.2957 , -1.424  ],\n",
      "       [ 0.4917 ,  0.3735 , -1.224  ],\n",
      "       [ 3.488  , -0.821  , -3.066  ],\n",
      "       [ 3.89   , -1.248  , -2.91   ],\n",
      "       [ 1.821  , -1.911  , -0.0608 ],\n",
      "       [ 0.2737 ,  2.945  , -3.367  ],\n",
      "       [ 3.99   , -1.617  , -2.578  ],\n",
      "       [ 1.215  ,  1.948  , -3.557  ],\n",
      "       [ 2.049  ,  0.6953 , -3.127  ],\n",
      "       [ 3.19   , -0.979  , -2.557  ],\n",
      "       [ 2.594  ,  0.04626, -2.844  ],\n",
      "       [-1.861  ,  2.746  , -0.654  ],\n",
      "       [ 3.963  , -1.556  , -2.611  ],\n",
      "       [ 3.758  , -1.535  , -2.658  ],\n",
      "       [ 0.5103 ,  2.016  , -2.674  ],\n",
      "       [ 3.758  , -1.525  , -2.547  ],\n",
      "       [ 3.744  , -1.872  , -2.328  ],\n",
      "       [ 2.576  , -0.2673 , -2.541  ],\n",
      "       [ 3.695  , -0.6665 , -3.303  ],\n",
      "       [ 2.398  ,  0.2556 , -3.09   ],\n",
      "       [ 3.998  , -1.922  , -2.324  ],\n",
      "       [ 0.976  , -0.6753 , -0.3506 ],\n",
      "       [ 3.297  , -1.927  , -1.754  ],\n",
      "       [ 3.889  , -1.215  , -2.846  ],\n",
      "       [-0.1775 ,  2.885  , -2.785  ],\n",
      "       [ 3.91   , -1.5625 , -2.68   ],\n",
      "       [ 2.25   ,  0.6836 , -3.365  ],\n",
      "       [ 2.352  ,  1.256  , -3.744  ],\n",
      "       [-1.4795 ,  1.15   ,  0.5083 ],\n",
      "       [ 3.727  , -1.392  , -2.691  ],\n",
      "       [ 0.1731 ,  1.597  , -1.735  ],\n",
      "       [ 3.816  , -1.056  , -3.05   ],\n",
      "       [ 2.29   ,  0.5156 , -3.28   ],\n",
      "       [-0.1207 ,  1.512  , -1.736  ],\n",
      "       [ 0.6123 , -0.2418 , -0.4866 ],\n",
      "       [-0.862  ,  0.3838 ,  0.556  ],\n",
      "       [ 2.645  ,  0.1279 , -3.127  ],\n",
      "       [-2.857  ,  1.685  ,  1.006  ],\n",
      "       [ 2.959  , -0.1312 , -3.047  ],\n",
      "       [ 3.064  ,  0.62   , -3.754  ],\n",
      "       [ 3.023  , -1.578  , -2.062  ],\n",
      "       [-2.896  ,  1.081  ,  1.89   ],\n",
      "       [ 0.1587 ,  1.164  , -1.342  ],\n",
      "       [ 3.693  , -0.618  , -3.133  ],\n",
      "       [ 1.444  ,  0.1744 , -2.12   ],\n",
      "       [ 1.261  ,  1.307  , -2.86   ],\n",
      "       [ 1.678  , -1.205  , -0.4182 ],\n",
      "       [ 3.973  , -1.638  , -2.586  ],\n",
      "       [ 0.1456 ,  1.771  , -2.074  ],\n",
      "       [ 3.033  , -1.216  , -2.484  ],\n",
      "       [ 1.063  ,  1.061  , -2.516  ],\n",
      "       [ 1.135  , -0.08386, -1.31   ],\n",
      "       [ 2.941  ,  0.2727 , -3.412  ],\n",
      "       [-1.873  ,  1.074  ,  0.5347 ],\n",
      "       [-0.5835 ,  2.041  , -1.607  ],\n",
      "       [ 3.38   , -2.18   , -1.568  ],\n",
      "       [ 3.76   , -0.6997 , -3.285  ],\n",
      "       [ 3.951  , -1.618  , -2.666  ],\n",
      "       [ 3.484  , -0.4255 , -3.309  ],\n",
      "       [ 3.715  , -2.021  , -1.981  ],\n",
      "       [ 3.72   , -1.21   , -2.691  ],\n",
      "       [ 3.04   ,  0.62   , -3.771  ],\n",
      "       [-2.02   ,  0.7026 ,  1.269  ],\n",
      "       [-2.785  , -0.7734 ,  3.666  ],\n",
      "       [-2.574  ,  0.4475 ,  2.357  ],\n",
      "       [-3.203  , -0.51   ,  3.748  ],\n",
      "       [ 3.852  , -1.734  , -2.486  ],\n",
      "       [-0.4778 ,  0.0715 ,  0.03345],\n",
      "       [ 3.371  , -1.788  , -2.04   ],\n",
      "       [ 0.8564 , -0.6763 , -0.734  ],\n",
      "       [ 0.3198 ,  2.148  , -2.701  ],\n",
      "       [-2.158  ,  1.335  ,  0.727  ],\n",
      "       [-1.934  ,  0.8047 ,  1.151  ],\n",
      "       [ 1.6455 , -1.002  , -0.679  ],\n",
      "       [-3.248  ,  0.3142 ,  3.09   ],\n",
      "       [ 3.457  , -1.353  , -2.334  ],\n",
      "       [-1.891  ,  2.717  , -0.541  ],\n",
      "       [ 3.86   , -1.046  , -2.975  ],\n",
      "       [ 3.72   , -1.397  , -2.666  ],\n",
      "       [-1.286  ,  2.43   , -0.852  ],\n",
      "       [ 3.906  , -1.558  , -2.668  ],\n",
      "       [ 0.577  , -1.462  ,  0.988  ],\n",
      "       [ 2.73   , -0.2114 , -3.068  ],\n",
      "       [ 0.5386 ,  1.102  , -1.64   ],\n",
      "       [-2.326  ,  1.427  ,  0.8584 ],\n",
      "       [ 2.56   , -0.7773 , -2.13   ],\n",
      "       [-1.811  ,  1.729  ,  0.3242 ],\n",
      "       [ 1.535  ,  1.731  , -3.535  ],\n",
      "       [-1.722  ,  3.246  , -1.244  ],\n",
      "       [ 3.887  , -1.841  , -2.363  ],\n",
      "       [ 3.404  , -0.7935 , -2.953  ],\n",
      "       [ 3.4    , -0.4202 , -3.357  ],\n",
      "       [ 0.05743,  1.192  , -1.337  ],\n",
      "       [ 3.918  , -1.638  , -2.613  ],\n",
      "       [-3.16   ,  2.145  ,  1.182  ],\n",
      "       [-0.3132 ,  2.639  , -2.355  ],\n",
      "       [ 0.3564 ,  0.2334 , -0.8555 ],\n",
      "       [ 2.777  , -1.561  , -1.947  ],\n",
      "       [-1.256  ,  0.3171 ,  1.155  ],\n",
      "       [ 3.977  , -1.412  , -2.812  ],\n",
      "       [ 1.076  ,  1.639  , -3.217  ],\n",
      "       [ 3.775  , -1.136  , -2.873  ],\n",
      "       [ 3.885  , -1.754  , -2.361  ],\n",
      "       [ 0.2837 ,  1.79   , -2.12   ],\n",
      "       [ 3.277  , -1.605  , -2.084  ],\n",
      "       [ 3.799  , -0.9487 , -3.09   ],\n",
      "       [ 1.738  ,  1.221  , -3.186  ],\n",
      "       [ 3.475  , -0.676  , -3.021  ],\n",
      "       [ 0.1814 ,  0.9497 , -1.484  ],\n",
      "       [-0.4595 ,  1.112  , -0.98   ],\n",
      "       [ 3.988  , -1.249  , -2.969  ],\n",
      "       [ 0.46   , -0.10516, -0.809  ],\n",
      "       [ 3.775  , -1.296  , -2.719  ],\n",
      "       [ 3.162  , -0.8257 , -2.973  ],\n",
      "       [-0.3936 ,  2.193  , -1.719  ],\n",
      "       [ 0.5283 ,  0.0626 , -0.598  ],\n",
      "       [ 3.598  , -1.756  , -2.354  ],\n",
      "       [-0.4744 ,  2.123  , -1.396  ],\n",
      "       [ 3.898  , -1.47   , -2.756  ],\n",
      "       [-1.466  ,  2.041  , -0.7246 ],\n",
      "       [-2.795  ,  2.896  ,  0.03586],\n",
      "       [ 0.87   , -0.2515 , -0.5293 ],\n",
      "       [ 4.016  , -1.391  , -2.812  ],\n",
      "       [ 0.01251,  0.749  , -0.8125 ],\n",
      "       [ 3.729  , -1.003  , -3.086  ],\n",
      "       [ 3.287  , -0.4597 , -3.223  ],\n",
      "       [ 0.1294 , -1.416  ,  1.092  ],\n",
      "       [ 3.492  , -1.377  , -2.535  ],\n",
      "       [ 2.895  , -0.6777 , -2.773  ],\n",
      "       [ 3.92   , -1.251  , -2.912  ],\n",
      "       [ 3.695  , -1.372  , -2.65   ],\n",
      "       [-1.331  ,  0.4126 ,  0.9575 ],\n",
      "       [-1.047  ,  1.085  , -0.4001 ],\n",
      "       [ 0.9316 , -0.827  , -0.1098 ],\n",
      "       [ 0.1545 ,  0.3337 , -0.8667 ],\n",
      "       [ 3.979  , -1.654  , -2.574  ],\n",
      "       [ 3.15   , -0.659  , -2.977  ],\n",
      "       [-1.954  ,  0.905  ,  1.312  ]], dtype=float16), label_ids=array([1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 2, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n",
      "       1, 1, 1, 2, 0, 2, 1, 0, 0, 0, 0, 0, 1, 1, 2, 0, 2, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 2, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 2, 1, 0, 1, 0,\n",
      "       1, 0, 2, 1, 0, 1, 1, 1, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "       1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 2, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
      "       1, 0, 0, 0, 1, 0, 0, 0, 2, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
      "       0, 1, 0, 1, 0, 0, 1, 0, 2, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
      "       0, 0, 0, 1, 0, 0, 2, 2, 0, 2, 0, 1, 0, 1, 1, 0, 2, 0, 1, 0, 0, 1,\n",
      "       0, 1, 0, 0, 1, 2, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 2,\n",
      "       0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 2, 0, 0, 2]), metrics={'test_loss': 1.1479709148406982, 'test_accuracy': 0.6111111111111112, 'test_precision': 0.6087267933331706, 'test_recall': 0.6111111111111112, 'test_f1': 0.599488621986391, 'test_runtime': 0.5988, 'test_samples_per_second': 390.802, 'test_steps_per_second': 13.361})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "808dd68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48fb2163",
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = torch.softmax(torch.tensor(test_results.predictions).to(torch.float32), dim=-1)\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed6cfde2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")  # Adjust xticklabels and yticklabels as needed\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "346c6d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_save = []\n",
    "for idx in range(len(test_data)):\n",
    "    item = dataset['test'][idx]\n",
    "    actual_label = item['label']\n",
    "    predicted_label = predictions[idx]\n",
    "    claim = item['claim'] \n",
    "    premise = item['premise'] \n",
    "    category = item['category']\n",
    "    \n",
    "    # Append the information as a dictionary to the list\n",
    "    data_to_save.append({\n",
    "        'Claim': claim,\n",
    "        'Premise': premise,\n",
    "        'Actual Label': actual_label,\n",
    "        'Predicted Label': predicted_label,\n",
    "        'Category' : category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_to_save)\n",
    "\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/home/elson/results/11.1.5_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4543aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correctly classified instances\n",
    "correctly_classified = df[df['Actual Label'] == df['Predicted Label']]\n",
    "\n",
    "# Calculate misclassified instances\n",
    "misclassified = df[df['Actual Label'] != df['Predicted Label']]\n",
    "\n",
    "# Count the number of correctly classified and misclassified by category\n",
    "correct_classification_counts = correctly_classified['Category'].value_counts()\n",
    "misclassification_counts = misclassified['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad099d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           35\n",
       "Skin                     13\n",
       "Bone health              12\n",
       "Cancer                   12\n",
       "Fitness                   9\n",
       "Hair                      7\n",
       "Diabetes                  7\n",
       "Neurological health       6\n",
       "Throat                    6\n",
       "Cardiovascular Health     6\n",
       "Ear                       6\n",
       "Eye                       5\n",
       "Blood                     4\n",
       "COVID                     4\n",
       "Mental Health             3\n",
       "Muscles                   2\n",
       "Vascular                  2\n",
       "Men's health              2\n",
       "Women' s Health           1\n",
       "Dental Health             1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d45817c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           16\n",
       "Skin                     11\n",
       "Bone health               9\n",
       "Cardiovascular Health     6\n",
       "Fitness                   6\n",
       "Hair                      5\n",
       "Women' s Health           5\n",
       "Diabetes                  5\n",
       "Blood                     5\n",
       "Muscles                   4\n",
       "Men's health              4\n",
       "Eye                       4\n",
       "Throat                    3\n",
       "Neurological health       3\n",
       "COVID                     2\n",
       "Dental Health             2\n",
       "Vascular                  1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
