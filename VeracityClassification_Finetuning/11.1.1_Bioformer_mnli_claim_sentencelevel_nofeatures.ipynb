{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-cfbf7584a6bb7c13\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 209.40it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('csv',data_files='dataset_sentenceattribution_nerfeatures_split.csv',delimiter=',',column_names=[\"claim\",\"premise\",\"label\",\"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\",\"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\",\"url\", \"entities\",\"entity_map\",\"gem_exp\",\"gem_label\",\"gpt_label\",\"gpt_exp\",\"gold_exp\",\"entity_map_ev\",\"entity_ev\",\"synonym\",\"voice\",\"split\"],skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "133f9357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-aa1fd4d2889f655e.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-9cd628f4430f2ace.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-df968f39da4ad12a.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01252e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\"claim\", \"premise\", \"label\",\"category\"]\n",
    "all_columns = dataset[\"train\"].column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-ab3c8fa265c0f20f.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-f395a7570b738078.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cfbf7584a6bb7c13/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-90ab1fd7f46a781a.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 2, 'entailment': 0, 'neutral': 1}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 2,\n",
    "    \"entailment\": 0,\n",
    "    \"neutral\": 1\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e15010ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label', 'category'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='bioformers/bioformer-8L-mnli'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "        # Extracting claim and evidence texts\n",
    "\n",
    "        claim = item['claim']\n",
    "        evidences = item['premise']\n",
    "        item['premise']=evidences\n",
    "        item['claim']=claim\n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "            evidences, claim,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "        item['input_ids'] = inputs['input_ids'].squeeze()  # Remove batch dimension\n",
    "        item['attention_mask']= inputs['attention_mask'].squeeze() # Remove batch dimension\n",
    "        \n",
    "        if 'label' in item:\n",
    "            item['labels'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62421eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(32768, 512, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 512)\n",
       "      (token_type_embeddings): Embedding(2, 512)\n",
       "      (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=512, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"bioformers/bioformer-8L-mnli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=512)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=3, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    return {\"accuracy\": acc, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0f5cf584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'claim': 'Myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.',\n",
       " 'premise': 'Additionally, laser doppler blood flow measurement showed that the frankincense and myrrh essential oil compound could promote the elimination of capillaries from skin epidermis to dermis by increasing skin blood flow.',\n",
       " 'label': 1,\n",
       " 'category': 'General Health',\n",
       " 'input_ids': tensor([  101,  4916,   117,  5545,  5029,  8349,  2290,  3047,  4506,  1975,\n",
       "          1488,  1425,  2132,  4765,  2848,  9507,  1111,  1435,  2573,  1109,\n",
       "          4258,  3720,  6187,  3004,  2076,  4989,  1425,  8635,  1431, 17188,\n",
       "          1560,  3550, 14180,  1446, 19612,  1520,  2911,  3550,  2290,  3047,\n",
       "           119,   102, 31487,  4258,  3720,  6187,  1478,  8811,  1822,  1427,\n",
       "          3550,  5183,  4030,  1446,  3346,  2520,  1425,  6875,  1431,  1425,\n",
       "          3550,   119,   102,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'labels': tensor(1)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 765\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='765' max='765' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [765/765 03:02, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.728800</td>\n",
       "      <td>0.935671</td>\n",
       "      <td>0.619355</td>\n",
       "      <td>0.580316</td>\n",
       "      <td>0.619355</td>\n",
       "      <td>0.558167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.614700</td>\n",
       "      <td>0.919861</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.621623</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.625920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.347700</td>\n",
       "      <td>1.035016</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.638088</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.643340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.268800</td>\n",
       "      <td>1.238705</td>\n",
       "      <td>0.636559</td>\n",
       "      <td>0.621980</td>\n",
       "      <td>0.636559</td>\n",
       "      <td>0.627240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.218100</td>\n",
       "      <td>1.335483</td>\n",
       "      <td>0.636559</td>\n",
       "      <td>0.632608</td>\n",
       "      <td>0.636559</td>\n",
       "      <td>0.633444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.165200</td>\n",
       "      <td>1.384108</td>\n",
       "      <td>0.647312</td>\n",
       "      <td>0.639890</td>\n",
       "      <td>0.647312</td>\n",
       "      <td>0.643137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.110200</td>\n",
       "      <td>1.544155</td>\n",
       "      <td>0.640860</td>\n",
       "      <td>0.635222</td>\n",
       "      <td>0.640860</td>\n",
       "      <td>0.636156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.081100</td>\n",
       "      <td>1.663487</td>\n",
       "      <td>0.617204</td>\n",
       "      <td>0.616683</td>\n",
       "      <td>0.617204</td>\n",
       "      <td>0.616931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.038900</td>\n",
       "      <td>1.798218</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>0.624918</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>0.625128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.025100</td>\n",
       "      <td>1.878633</td>\n",
       "      <td>0.632258</td>\n",
       "      <td>0.627592</td>\n",
       "      <td>0.632258</td>\n",
       "      <td>0.628936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.038100</td>\n",
       "      <td>1.936316</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.630872</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.635350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>2.043282</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>0.615738</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>0.620071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>2.070530</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.629819</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.633285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.022900</td>\n",
       "      <td>2.068388</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.629674</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.633559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.029300</td>\n",
       "      <td>2.076763</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.630410</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.633825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.1_bioformer/checkpoint-51\n",
      "Configuration saved in /home/elson/11.1.1_bioformer/checkpoint-51/config.json\n",
      "Model weights saved in /home/elson/11.1.1_bioformer/checkpoint-51/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.1_bioformer/checkpoint-102\n",
      "Configuration saved in /home/elson/11.1.1_bioformer/checkpoint-102/config.json\n",
      "Model weights saved in /home/elson/11.1.1_bioformer/checkpoint-102/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.1.1_bioformer/checkpoint-51] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.1_bioformer/checkpoint-153\n",
      "Configuration saved in /home/elson/11.1.1_bioformer/checkpoint-153/config.json\n",
      "Model weights saved in /home/elson/11.1.1_bioformer/checkpoint-153/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.1.1_bioformer/checkpoint-102] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.1_bioformer/checkpoint-204\n",
      "Configuration saved in /home/elson/11.1.1_bioformer/checkpoint-204/config.json\n",
      "Model weights saved in /home/elson/11.1.1_bioformer/checkpoint-204/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.1_bioformer/checkpoint-255\n",
      "Configuration saved in /home/elson/11.1.1_bioformer/checkpoint-255/config.json\n",
      "Model weights saved in /home/elson/11.1.1_bioformer/checkpoint-255/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.1.1_bioformer/checkpoint-204] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.1_bioformer/checkpoint-306\n",
      "Configuration saved in /home/elson/11.1.1_bioformer/checkpoint-306/config.json\n",
      "Model weights saved in /home/elson/11.1.1_bioformer/checkpoint-306/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.1.1_bioformer/checkpoint-255] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.1_bioformer/checkpoint-357\n",
      "Configuration saved in /home/elson/11.1.1_bioformer/checkpoint-357/config.json\n",
      "Model weights saved in /home/elson/11.1.1_bioformer/checkpoint-357/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.1.1_bioformer/checkpoint-306] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.1_bioformer/checkpoint-408\n",
      "Configuration saved in /home/elson/11.1.1_bioformer/checkpoint-408/config.json\n",
      "Model weights saved in /home/elson/11.1.1_bioformer/checkpoint-408/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.1.1_bioformer/checkpoint-357] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.1_bioformer/checkpoint-459\n",
      "Configuration saved in /home/elson/11.1.1_bioformer/checkpoint-459/config.json\n",
      "Model weights saved in /home/elson/11.1.1_bioformer/checkpoint-459/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.1.1_bioformer/checkpoint-408] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.1_bioformer/checkpoint-510\n",
      "Configuration saved in /home/elson/11.1.1_bioformer/checkpoint-510/config.json\n",
      "Model weights saved in /home/elson/11.1.1_bioformer/checkpoint-510/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.1.1_bioformer/checkpoint-459] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.1_bioformer/checkpoint-561\n",
      "Configuration saved in /home/elson/11.1.1_bioformer/checkpoint-561/config.json\n",
      "Model weights saved in /home/elson/11.1.1_bioformer/checkpoint-561/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.1.1_bioformer/checkpoint-510] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.1_bioformer/checkpoint-612\n",
      "Configuration saved in /home/elson/11.1.1_bioformer/checkpoint-612/config.json\n",
      "Model weights saved in /home/elson/11.1.1_bioformer/checkpoint-612/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.1.1_bioformer/checkpoint-561] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.1_bioformer/checkpoint-663\n",
      "Configuration saved in /home/elson/11.1.1_bioformer/checkpoint-663/config.json\n",
      "Model weights saved in /home/elson/11.1.1_bioformer/checkpoint-663/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.1.1_bioformer/checkpoint-612] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.1_bioformer/checkpoint-714\n",
      "Configuration saved in /home/elson/11.1.1_bioformer/checkpoint-714/config.json\n",
      "Model weights saved in /home/elson/11.1.1_bioformer/checkpoint-714/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.1.1_bioformer/checkpoint-663] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/11.1.1_bioformer/checkpoint-765\n",
      "Configuration saved in /home/elson/11.1.1_bioformer/checkpoint-765/config.json\n",
      "Model weights saved in /home/elson/11.1.1_bioformer/checkpoint-765/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/11.1.1_bioformer/checkpoint-714] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/elson/11.1.1_bioformer/checkpoint-153 (score: 0.6559139784946236).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /home/elson/11.1.1_bioformer/best_model/config.json\n",
      "Model weights saved in /home/elson/11.1.1_bioformer/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/11.1.1_bioformer/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/11.1.1_bioformer/best_model/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/11.1.1_bioformer/best_model/tokenizer_config.json',\n",
       " '/home/elson/11.1.1_bioformer/best_model/special_tokens_map.json',\n",
       " '/home/elson/11.1.1_bioformer/best_model/vocab.txt',\n",
       " '/home/elson/11.1.1_bioformer/best_model/added_tokens.json',\n",
       " '/home/elson/11.1.1_bioformer/best_model/tokenizer.json')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/11.1.1_bioformer/',\n",
    "    num_train_epochs=15,\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.06,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/11.1.1_bioformer/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/11.1.1_bioformer/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63deaea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/11.1.1_bioformer/best_model/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"/home/elson/11.1.1_bioformer/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"finetuning_task\": \"mnli\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 512,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"entailment\",\n",
      "    \"1\": \"neutral\",\n",
      "    \"2\": \"contradiction\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2048,\n",
      "  \"label2id\": {\n",
      "    \"contradiction\": 2,\n",
      "    \"entailment\": 0,\n",
      "    \"neutral\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 8,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32768\n",
      "}\n",
      "\n",
      "loading weights file /home/elson/11.1.1_bioformer/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at /home/elson/11.1.1_bioformer/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 32\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/11.1.1_bioformer/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[ 2.91   , -0.66   , -2.61   ],\n",
      "       [ 2.807  , -0.9355 , -2.291  ],\n",
      "       [ 3.24   , -1.494  , -2.168  ],\n",
      "       [-1.362  ,  1.101  ,  0.2664 ],\n",
      "       [ 2.068  ,  0.2803 , -2.518  ],\n",
      "       [ 3.533  , -1.14   , -2.672  ],\n",
      "       [ 3.398  , -1.481  , -2.365  ],\n",
      "       [ 3.496  , -1.11   , -2.74   ],\n",
      "       [ 3.117  , -0.8833 , -2.59   ],\n",
      "       [ 0.978  ,  0.7627 , -2.125  ],\n",
      "       [ 3.352  , -1.957  , -1.787  ],\n",
      "       [ 3.664  , -1.574  , -2.441  ],\n",
      "       [-1.354  ,  0.822  ,  0.626  ],\n",
      "       [ 3.615  , -1.321  , -2.59   ],\n",
      "       [-0.0888 , -0.7925 ,  0.9844 ],\n",
      "       [ 0.4417 , -0.4062 , -0.568  ],\n",
      "       [ 3.486  , -0.838  , -3.076  ],\n",
      "       [ 3.03   , -0.5933 , -2.729  ],\n",
      "       [ 3.72   , -1.717  , -2.398  ],\n",
      "       [ 3.328  , -1.31   , -2.553  ],\n",
      "       [ 2.656  , -1.275  , -1.797  ],\n",
      "       [ 2.588  , -0.2566 , -2.795  ],\n",
      "       [-1.448  ,  3.158  , -1.458  ],\n",
      "       [-0.4167 ,  0.8813 , -0.77   ],\n",
      "       [ 0.0742 , -0.3027 ,  0.1763 ],\n",
      "       [-1.603  , -0.0702 ,  1.46   ],\n",
      "       [ 3.832  , -1.186  , -2.742  ],\n",
      "       [ 1.368  ,  0.1005 , -1.877  ],\n",
      "       [ 2.143  , -0.5923 , -2.047  ],\n",
      "       [ 1.132  , -0.8403 , -0.4448 ],\n",
      "       [ 2.107  , -0.536  , -1.847  ],\n",
      "       [ 3.445  , -0.9995 , -2.86   ],\n",
      "       [ 3.074  , -1.04   , -2.514  ],\n",
      "       [ 1.268  ,  0.587  , -2.082  ],\n",
      "       [ 2.824  , -0.3208 , -2.953  ],\n",
      "       [ 2.645  ,  0.681  , -3.604  ],\n",
      "       [ 3.182  , -0.09406, -3.287  ],\n",
      "       [ 3.365  , -1.273  , -2.49   ],\n",
      "       [-1.442  ,  0.444  ,  1.025  ],\n",
      "       [ 2.984  , -0.2377 , -3.193  ],\n",
      "       [-0.4722 ,  2.348  , -2.145  ],\n",
      "       [ 2.418  ,  0.943  , -3.688  ],\n",
      "       [ 2.1    , -1.188  , -1.105  ],\n",
      "       [-0.597  ,  1.648  , -1.188  ],\n",
      "       [ 1.351  ,  0.8804 , -2.97   ],\n",
      "       [ 2.105  ,  0.5947 , -3.041  ],\n",
      "       [-0.947  ,  2.832  , -2.09   ],\n",
      "       [ 3.139  , -0.4868 , -3.037  ],\n",
      "       [ 3.475  , -1.113  , -2.63   ],\n",
      "       [ 0.6313 , -1.061  ,  0.479  ],\n",
      "       [ 1.861  , -1.157  , -1.232  ],\n",
      "       [ 1.294  ,  0.5156 , -2.068  ],\n",
      "       [ 1.719  ,  0.517  , -2.625  ],\n",
      "       [ 0.2384 ,  0.8496 , -1.475  ],\n",
      "       [-1.365  ,  0.9883 ,  0.1931 ],\n",
      "       [ 3.703  , -1.488  , -2.54   ],\n",
      "       [-1.205  ,  0.2974 ,  0.841  ],\n",
      "       [ 1.178  ,  0.9785 , -2.678  ],\n",
      "       [ 2.299  ,  0.2854 , -3.078  ],\n",
      "       [ 3.389  , -0.607  , -3.139  ],\n",
      "       [ 2.889  , -1.278  , -1.935  ],\n",
      "       [-1.256  , -0.2083 ,  1.382  ],\n",
      "       [ 0.363  ,  1.278  , -1.835  ],\n",
      "       [ 2.033  ,  0.2688 , -2.441  ],\n",
      "       [ 1.827  ,  0.864  , -3.201  ],\n",
      "       [ 3.348  , -0.7695 , -2.713  ],\n",
      "       [ 3.373  , -0.8784 , -2.902  ],\n",
      "       [ 3.143  , -0.7295 , -2.709  ],\n",
      "       [ 2.922  , -1.547  , -1.857  ],\n",
      "       [-1.256  , -0.2334 ,  1.16   ],\n",
      "       [ 1.314  ,  0.2228 , -2.145  ],\n",
      "       [ 1.403  , -0.0843 , -1.806  ],\n",
      "       [ 2.     ,  1.083  , -3.527  ],\n",
      "       [-1.13   ,  0.995  ,  0.0828 ],\n",
      "       [ 2.428  , -0.7393 , -2.22   ],\n",
      "       [ 0.6665 , -0.2546 , -0.6943 ],\n",
      "       [ 2.06   , -0.5884 , -1.865  ],\n",
      "       [ 3.453  , -1.     , -2.584  ],\n",
      "       [ 3.428  , -1.431  , -2.418  ],\n",
      "       [ 3.027  , -1.12   , -2.406  ],\n",
      "       [ 3.434  , -1.296  , -2.465  ],\n",
      "       [ 3.215  , -0.48   , -3.193  ],\n",
      "       [ 3.547  , -1.234  , -2.682  ],\n",
      "       [ 3.547  , -1.594  , -2.275  ],\n",
      "       [ 3.291  , -0.8105 , -2.86   ],\n",
      "       [ 0.5576 ,  0.5835 , -1.555  ],\n",
      "       [ 1.8545 , -0.4563 , -1.735  ],\n",
      "       [ 2.135  , -0.2893 , -2.16   ],\n",
      "       [ 2.785  , -0.7607 , -2.611  ],\n",
      "       [ 0.9966 ,  1.014  , -2.324  ],\n",
      "       [ 3.2    , -1.723  , -1.946  ],\n",
      "       [ 3.363  , -0.9336 , -2.758  ],\n",
      "       [-2.77   , -0.3098 ,  3.002  ],\n",
      "       [ 2.99   , -0.4385 , -2.848  ],\n",
      "       [ 2.844  , -1.162  , -2.205  ],\n",
      "       [ 1.872  , -1.099  , -0.9526 ],\n",
      "       [ 0.1711 ,  0.3777 , -1.104  ],\n",
      "       [ 0.814  ,  0.3418 , -1.557  ],\n",
      "       [ 3.246  , -0.804  , -2.87   ],\n",
      "       [ 3.525  , -1.206  , -2.633  ],\n",
      "       [-0.2559 , -1.531  ,  1.783  ],\n",
      "       [ 2.203  ,  0.3938 , -3.072  ],\n",
      "       [ 3.568  , -1.148  , -2.74   ],\n",
      "       [ 1.854  ,  1.179  , -3.467  ],\n",
      "       [ 2.232  ,  0.457  , -3.094  ],\n",
      "       [ 2.465  , -0.188  , -2.555  ],\n",
      "       [ 2.957  , -0.708  , -2.473  ],\n",
      "       [-0.1118 ,  1.355  , -1.384  ],\n",
      "       [ 3.555  , -0.9966 , -2.766  ],\n",
      "       [ 0.4082 ,  0.8716 , -1.741  ],\n",
      "       [ 1.399  ,  1.195  , -2.842  ],\n",
      "       [ 3.492  , -1.088  , -2.768  ],\n",
      "       [ 3.602  , -1.236  , -2.72   ],\n",
      "       [ 2.332  , -0.2778 , -2.445  ],\n",
      "       [ 3.553  , -0.943  , -2.93   ],\n",
      "       [ 2.943  , -0.8066 , -2.574  ],\n",
      "       [ 3.797  , -1.737  , -2.352  ],\n",
      "       [ 2.484  , -0.6953 , -2.113  ],\n",
      "       [ 2.824  , -1.087  , -2.209  ],\n",
      "       [ 3.56   , -0.9927 , -2.756  ],\n",
      "       [ 1.211  ,  1.026  , -2.65   ],\n",
      "       [-0.8657 ,  1.644  , -0.771  ],\n",
      "       [ 1.654  ,  0.887  , -3.076  ],\n",
      "       [ 2.611  ,  0.662  , -3.477  ],\n",
      "       [-0.03464,  0.8804 , -1.084  ],\n",
      "       [ 3.615  , -1.495  , -2.457  ],\n",
      "       [ 1.252  ,  1.138  , -2.797  ],\n",
      "       [ 3.332  , -0.696  , -2.959  ],\n",
      "       [ 2.69   , -0.7236 , -2.562  ],\n",
      "       [ 0.5537 ,  0.517  , -1.825  ],\n",
      "       [ 2.527  , -1.309  , -1.459  ],\n",
      "       [-0.99   , -0.00589,  0.666  ],\n",
      "       [ 3.14   , -0.677  , -2.854  ],\n",
      "       [-0.847  ,  1.048  , -0.615  ],\n",
      "       [ 2.893  ,  0.1887 , -3.361  ],\n",
      "       [ 2.623  ,  0.872  , -3.549  ],\n",
      "       [ 2.59   , -0.833  , -2.219  ],\n",
      "       [ 0.9043 ,  0.533  , -2.041  ],\n",
      "       [-0.63   ,  1.264  , -0.7847 ],\n",
      "       [ 3.541  , -0.9414 , -2.791  ],\n",
      "       [ 2.05   ,  0.2673 , -2.664  ],\n",
      "       [ 0.4832 ,  1.827  , -2.63   ],\n",
      "       [ 1.321  ,  0.3489 , -2.035  ],\n",
      "       [ 3.707  , -1.356  , -2.592  ],\n",
      "       [-0.2136 ,  2.166  , -2.105  ],\n",
      "       [ 3.     , -0.695  , -2.918  ],\n",
      "       [-0.714  ,  2.453  , -1.895  ],\n",
      "       [ 0.9507 , -0.589  , -0.2832 ],\n",
      "       [ 2.268  ,  0.2155 , -2.746  ],\n",
      "       [ 1.043  ,  0.6333 , -2.203  ],\n",
      "       [ 1.502  ,  1.371  , -3.178  ],\n",
      "       [ 3.328  , -1.9375 , -1.837  ],\n",
      "       [ 3.613  , -0.94   , -2.969  ],\n",
      "       [ 3.691  , -1.089  , -2.86   ],\n",
      "       [ 3.352  , -0.5522 , -3.12   ],\n",
      "       [ 3.465  , -1.803  , -1.908  ],\n",
      "       [ 3.54   , -1.512  , -2.344  ],\n",
      "       [ 2.781  ,  0.6567 , -3.498  ],\n",
      "       [ 0.195  ,  1.003  , -1.506  ],\n",
      "       [-2.646  , -0.751  ,  3.373  ],\n",
      "       [-0.7007 ,  0.10266,  0.3276 ],\n",
      "       [-2.496  , -1.042  ,  3.354  ],\n",
      "       [-0.334  , -1.454  ,  1.578  ],\n",
      "       [ 0.6    , -0.5894 , -0.06036],\n",
      "       [ 2.809  , -1.393  , -1.771  ],\n",
      "       [ 2.36   , -1.027  , -1.763  ],\n",
      "       [ 0.812  ,  0.546  , -1.6875 ],\n",
      "       [-0.9595 ,  1.006  , -0.5483 ],\n",
      "       [-1.812  , -0.2314 ,  1.825  ],\n",
      "       [ 1.573  ,  0.02887, -1.856  ],\n",
      "       [-1.754  , -0.1098 ,  1.647  ],\n",
      "       [ 2.62   , -0.6685 , -2.285  ],\n",
      "       [ 0.1076 ,  1.34   , -1.563  ],\n",
      "       [ 3.541  , -1.025  , -2.697  ],\n",
      "       [ 3.348  , -1.015  , -2.715  ],\n",
      "       [ 0.7427 ,  0.9434 , -1.871  ],\n",
      "       [ 3.373  , -1.233  , -2.527  ],\n",
      "       [ 0.8086 , -0.7456 , -0.264  ],\n",
      "       [ 2.615  , -0.19   , -2.854  ],\n",
      "       [ 1.606  ,  0.38   , -2.105  ],\n",
      "       [ 0.05334,  1.111  , -1.563  ],\n",
      "       [ 2.146  , -0.789  , -1.644  ],\n",
      "       [-0.4595 ,  0.08813,  0.4514 ],\n",
      "       [ 3.148  , -0.5737 , -2.797  ],\n",
      "       [ 1.007  ,  1.44   , -2.803  ],\n",
      "       [ 3.766  , -1.685  , -2.4    ],\n",
      "       [ 3.215  , -0.04214, -3.37   ],\n",
      "       [ 3.43   , -1.009  , -2.803  ],\n",
      "       [ 0.4941 ,  0.3982 , -1.053  ],\n",
      "       [ 3.271  , -0.9897 , -2.633  ],\n",
      "       [-1.178  ,  0.846  , -0.01735],\n",
      "       [-0.792  ,  2.621  , -1.795  ],\n",
      "       [ 2.365  , -0.3223 , -2.545  ],\n",
      "       [ 2.33   , -0.617  , -2.436  ],\n",
      "       [ 0.0428 , -0.845  ,  0.9985 ],\n",
      "       [ 3.678  , -1.389  , -2.596  ],\n",
      "       [ 1.345  ,  0.9966 , -2.951  ],\n",
      "       [ 3.496  , -1.078  , -2.754  ],\n",
      "       [ 3.549  , -1.622  , -2.248  ],\n",
      "       [ 2.467  , -0.1246 , -2.67   ],\n",
      "       [ 3.045  , -1.429  , -2.057  ],\n",
      "       [ 3.258  , -0.603  , -2.982  ],\n",
      "       [ 2.832  , -0.1807 , -2.979  ],\n",
      "       [ 3.17   , -0.2744 , -3.133  ],\n",
      "       [ 2.352  , -0.0649 , -2.79   ],\n",
      "       [-0.514  ,  0.918  , -0.7134 ],\n",
      "       [ 3.684  , -1.226  , -2.785  ],\n",
      "       [ 1.945  , -0.781  , -1.677  ],\n",
      "       [ 3.135  , -0.7437 , -2.682  ],\n",
      "       [ 1.439  ,  0.52   , -2.672  ],\n",
      "       [ 1.366  ,  0.4624 , -2.074  ],\n",
      "       [ 0.713  ,  0.218  , -1.297  ],\n",
      "       [-1.519  , -0.8213 ,  2.096  ],\n",
      "       [ 0.9395 ,  0.8506 , -2.201  ],\n",
      "       [ 3.44   , -1.256  , -2.63   ],\n",
      "       [-0.597  ,  0.9907 , -0.613  ],\n",
      "       [-0.3088 ,  1.467  , -1.345  ],\n",
      "       [ 0.2715 ,  0.404  , -0.596  ],\n",
      "       [ 3.738  , -1.329  , -2.654  ],\n",
      "       [-0.3823 ,  1.296  , -0.979  ],\n",
      "       [ 3.732  , -1.225  , -2.807  ],\n",
      "       [ 2.924  , -0.3518 , -3.01   ],\n",
      "       [ 0.281  , -0.464  , -0.2454 ],\n",
      "       [ 3.186  , -0.9165 , -2.742  ],\n",
      "       [ 2.785  , -0.864  , -2.412  ],\n",
      "       [ 3.494  , -0.9355 , -2.861  ],\n",
      "       [ 3.447  , -1.06   , -2.688  ],\n",
      "       [-0.609  ,  0.3481 ,  0.0943 ],\n",
      "       [-0.3535 , -0.2048 ,  0.2444 ],\n",
      "       [ 2.566  , -0.8887 , -1.975  ],\n",
      "       [ 2.867  , -0.562  , -2.82   ],\n",
      "       [ 3.383  , -0.9717 , -2.633  ],\n",
      "       [ 3.084  , -0.935  , -2.502  ],\n",
      "       [-0.4023 ,  0.6123 , -0.2465 ]], dtype=float16), label_ids=array([1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 2, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n",
      "       1, 1, 1, 2, 0, 2, 1, 0, 0, 0, 0, 0, 1, 1, 2, 0, 2, 1, 1, 1, 0, 1,\n",
      "       1, 1, 1, 1, 1, 2, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 2, 1, 0, 1, 0,\n",
      "       1, 0, 2, 1, 0, 1, 1, 1, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "       1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 2, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
      "       1, 0, 0, 0, 1, 0, 0, 0, 2, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
      "       0, 1, 0, 1, 0, 0, 1, 0, 2, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
      "       0, 0, 0, 1, 0, 0, 2, 2, 0, 2, 0, 1, 0, 1, 1, 0, 2, 0, 1, 0, 0, 1,\n",
      "       0, 1, 0, 0, 1, 2, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 2,\n",
      "       0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 2, 0, 0, 2]), metrics={'test_loss': 1.0762064456939697, 'test_accuracy': 0.6367521367521367, 'test_precision': 0.6567836768494664, 'test_recall': 0.6367521367521367, 'test_f1': 0.6005983829776553, 'test_runtime': 0.5593, 'test_samples_per_second': 418.349, 'test_steps_per_second': 14.303})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "808dd68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "48fb2163",
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = torch.softmax(torch.tensor(test_results.predictions).to(torch.float32), dim=-1)\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed6cfde2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")  # Adjust xticklabels and yticklabels as needed\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "346c6d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_save = []\n",
    "for idx in range(len(test_data)):\n",
    "    item = test_data.__getitem__(idx)\n",
    "    actual_label = item['label']\n",
    "    predicted_label = predictions[idx]\n",
    "    claim = item['claim'] \n",
    "    premise = item['premise'] \n",
    "    category = item['category']\n",
    "    \n",
    "    # Append the information as a dictionary to the list\n",
    "    data_to_save.append({\n",
    "        'Claim': claim,\n",
    "        'Premise': premise,\n",
    "        'Actual Label': actual_label,\n",
    "        'Predicted Label': predicted_label,\n",
    "        'Category' : category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_to_save)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/home/elson/results/11.1.1_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4543aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correctly classified instances\n",
    "correctly_classified = df[df['Actual Label'] == df['Predicted Label']]\n",
    "\n",
    "# Calculate misclassified instances\n",
    "misclassified = df[df['Actual Label'] != df['Predicted Label']]\n",
    "\n",
    "# Count the number of correctly classified and misclassified by category\n",
    "correct_classification_counts = correctly_classified['Category'].value_counts()\n",
    "misclassification_counts = misclassified['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad099d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           36\n",
       "Bone health              13\n",
       "Skin                     11\n",
       "Fitness                  10\n",
       "Cancer                   10\n",
       "Diabetes                 10\n",
       "Cardiovascular Health     9\n",
       "Throat                    7\n",
       "Neurological health       7\n",
       "Hair                      6\n",
       "Ear                       6\n",
       "Blood                     4\n",
       "COVID                     4\n",
       "Muscles                   3\n",
       "Eye                       3\n",
       "Women' s Health           3\n",
       "Mental Health             3\n",
       "Vascular                  2\n",
       "Men's health              2\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d45817c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           15\n",
       "Skin                     13\n",
       "Bone health               8\n",
       "Eye                       6\n",
       "Hair                      6\n",
       "Blood                     5\n",
       "Fitness                   5\n",
       "Men's health              4\n",
       "Dental Health             3\n",
       "Muscles                   3\n",
       "Women' s Health           3\n",
       "Cardiovascular Health     3\n",
       "Diabetes                  2\n",
       "COVID                     2\n",
       "Cancer                    2\n",
       "Throat                    2\n",
       "Neurological health       2\n",
       "Vascular                  1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
