{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, balanced_accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19fa7042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr  8 21:19:09 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:61:00.0 Off |                    0 |\n",
      "| N/A   37C    P0    56W / 300W |   1668MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  Off  | 00000000:62:00.0 Off |                    0 |\n",
      "| N/A   38C    P0    67W / 300W |   7165MiB / 32768MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  Off  | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   36C    P0    59W / 300W |   1628MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  Off  | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   43C    P0    71W / 300W |   1636MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     11098      C   ...A-AVD/venv_ava/bin/python     1665MiB |\n",
      "|    1   N/A  N/A     11098      C   ...A-AVD/venv_ava/bin/python     1711MiB |\n",
      "|    1   N/A  N/A     11099      C   ...A-AVD/venv_ava/bin/python     2027MiB |\n",
      "|    1   N/A  N/A     11102      C   ...A-AVD/venv_ava/bin/python     1711MiB |\n",
      "|    1   N/A  N/A     11110      C   ...A-AVD/venv_ava/bin/python     1711MiB |\n",
      "|    2   N/A  N/A     11102      C   ...A-AVD/venv_ava/bin/python     1625MiB |\n",
      "|    3   N/A  N/A     11110      C   ...A-AVD/venv_ava/bin/python     1633MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-cac7855410b939be\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-cac7855410b939be/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 247.12it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('csv',data_files='dataset_sentenceattribution_nerfeatures_split.csv',delimiter=',',column_names=[\"claim\",\"premise\",\"label\",\"category\",\"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\",\"counte_bf\",\"counte_ca\",\"counte_dis\",\"counte_food\",\"counte_lipid\",\"counte_treat\",\"prese_bf\",\"prese_ca\",\"prese_dis\",\"prese_food\",\"prese_lipid\",\"prese_treat\",\"url\", \"entities\",\"entity_map\",\"gem_exp\",\"gem_label\",\"gpt_label\",\"gpt_exp\",\"gold_exp\",\"entity_map_ev\",\"entity_ev\",\"split\"],skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "133f9357",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cac7855410b939be/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-a932df0b74e1547a.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cac7855410b939be/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-926cef8097c290d1.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cac7855410b939be/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-2ec17003ffb0a917.arrow\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01252e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\"claim\", \"premise\", \"label\"]\n",
    "all_columns = dataset[\"train\"].column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cac7855410b939be/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-25128b691fbb2a7a.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cac7855410b939be/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-3cf6de4ed2bf1a77.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-cac7855410b939be/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-69ecd84e19cd49e7.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 2, 'entailment': 0, 'neutral': 1}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 2,\n",
    "    \"entailment\": 0,\n",
    "    \"neutral\": 1\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e15010ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['claim', 'premise', 'label'],\n",
       "        num_rows: 1623\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['claim', 'premise', 'label'],\n",
       "        num_rows: 465\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['claim', 'premise', 'label'],\n",
       "        num_rows: 234\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='MoritzLaurer/DeBERTa-v3-large-mnli-fever-anli-ling-wanli'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "        # Extracting claim and evidence texts\n",
    "\n",
    "        claim = item['claim'].lower()\n",
    "        evidences = item['premise'].lower()\n",
    "        item['premise']=evidences\n",
    "        item['claim']=claim\n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "            evidences, claim,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "        item['input_ids'] = inputs['input_ids'].squeeze()  # Remove batch dimension\n",
    "        item['attention_mask']= inputs['attention_mask'].squeeze() # Remove batch dimension\n",
    "        \n",
    "        if 'label' in item:\n",
    "            item['labels'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return item\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62421eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DebertaV2ForSequenceClassification(\n",
       "  (deberta): DebertaV2Model(\n",
       "    (embeddings): DebertaV2Embeddings(\n",
       "      (word_embeddings): Embedding(128100, 1024, padding_idx=0)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaV2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (1): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (2): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (3): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (4): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (5): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (6): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (7): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (8): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (9): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (10): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (11): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (12): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (13): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (14): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (15): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (16): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (17): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (18): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (19): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (20): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (21): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (22): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (23): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(512, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-07, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (pooler): ContextPooler(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (dropout): StableDropout()\n",
       "  )\n",
       "  (classifier): Linear(in_features=1024, out_features=3, bias=True)\n",
       "  (dropout): StableDropout()\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"MoritzLaurer/DeBERTa-v3-large-mnli-fever-anli-ling-wanli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=512)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=3, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    return {\"accuracy\": acc, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f5cf584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'claim': 'myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.',\n",
       " 'premise': 'additionally, laser doppler blood flow measurement showed that the frankincense and myrrh essential oil compound could promote the elimination of capillaries from skin epidermis to dermis by increasing skin blood flow.',\n",
       " 'label': 0,\n",
       " 'input_ids': tensor([    1,  7229,   261,  5042,   333, 73325,  1452,  2155,  6116,  1938,\n",
       "           272,   262, 88609,   263, 98237,  1830,  1080,  7355,   387,  2655,\n",
       "           262, 12682,   265, 65008,   292,  1158, 53245,   264, 75840,   293,\n",
       "          2376,  1158,  1452,  2155,   260,     2, 98237,  1830,  1080,   269,\n",
       "          1359,   427,   267, 17847,   633,   264,   408,  1300,   262,  2658,\n",
       "           265,   262,  1158,   260,     2,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'labels': tensor(0)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 2\n",
      "  Total optimization steps = 2020\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 46:15, Epoch 19/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.679900</td>\n",
       "      <td>0.834186</td>\n",
       "      <td>0.662366</td>\n",
       "      <td>0.682314</td>\n",
       "      <td>0.662366</td>\n",
       "      <td>0.669958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.453500</td>\n",
       "      <td>0.903339</td>\n",
       "      <td>0.664516</td>\n",
       "      <td>0.691897</td>\n",
       "      <td>0.664516</td>\n",
       "      <td>0.675816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.253400</td>\n",
       "      <td>1.283646</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.716630</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.674021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.096600</td>\n",
       "      <td>1.883038</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.712869</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.669701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>2.186362</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.706856</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.669979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.040200</td>\n",
       "      <td>2.413842</td>\n",
       "      <td>0.634409</td>\n",
       "      <td>0.716488</td>\n",
       "      <td>0.634409</td>\n",
       "      <td>0.665728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.021900</td>\n",
       "      <td>2.354975</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.716571</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.680234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.011600</td>\n",
       "      <td>2.484986</td>\n",
       "      <td>0.660215</td>\n",
       "      <td>0.718029</td>\n",
       "      <td>0.660215</td>\n",
       "      <td>0.684704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>2.533006</td>\n",
       "      <td>0.670968</td>\n",
       "      <td>0.723976</td>\n",
       "      <td>0.670968</td>\n",
       "      <td>0.694134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>2.579401</td>\n",
       "      <td>0.658065</td>\n",
       "      <td>0.722096</td>\n",
       "      <td>0.658065</td>\n",
       "      <td>0.685336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.712377</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.723494</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.676456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>2.657155</td>\n",
       "      <td>0.668817</td>\n",
       "      <td>0.716660</td>\n",
       "      <td>0.668817</td>\n",
       "      <td>0.688714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.703680</td>\n",
       "      <td>0.660215</td>\n",
       "      <td>0.713783</td>\n",
       "      <td>0.660215</td>\n",
       "      <td>0.683342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.730877</td>\n",
       "      <td>0.662366</td>\n",
       "      <td>0.723691</td>\n",
       "      <td>0.662366</td>\n",
       "      <td>0.689600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>2.769887</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.722055</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.684231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.865352</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.718008</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.677024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.879021</td>\n",
       "      <td>0.647312</td>\n",
       "      <td>0.719691</td>\n",
       "      <td>0.647312</td>\n",
       "      <td>0.677993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.796724</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.720958</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.690630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.837223</td>\n",
       "      <td>0.658065</td>\n",
       "      <td>0.720970</td>\n",
       "      <td>0.658065</td>\n",
       "      <td>0.685122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>2.836155</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.719151</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.682792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/4.1.1_deberta_ce/checkpoint-101\n",
      "Configuration saved in /home/elson/4.1.1_deberta_ce/checkpoint-101/config.json\n",
      "Model weights saved in /home/elson/4.1.1_deberta_ce/checkpoint-101/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/4.1.1_deberta_ce/checkpoint-202\n",
      "Configuration saved in /home/elson/4.1.1_deberta_ce/checkpoint-202/config.json\n",
      "Model weights saved in /home/elson/4.1.1_deberta_ce/checkpoint-202/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/4.1.1_deberta_ce/checkpoint-101] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/4.1.1_deberta_ce/checkpoint-303\n",
      "Configuration saved in /home/elson/4.1.1_deberta_ce/checkpoint-303/config.json\n",
      "Model weights saved in /home/elson/4.1.1_deberta_ce/checkpoint-303/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/4.1.1_deberta_ce/checkpoint-404\n",
      "Configuration saved in /home/elson/4.1.1_deberta_ce/checkpoint-404/config.json\n",
      "Model weights saved in /home/elson/4.1.1_deberta_ce/checkpoint-404/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/4.1.1_deberta_ce/checkpoint-303] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/4.1.1_deberta_ce/checkpoint-505\n",
      "Configuration saved in /home/elson/4.1.1_deberta_ce/checkpoint-505/config.json\n",
      "Model weights saved in /home/elson/4.1.1_deberta_ce/checkpoint-505/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/4.1.1_deberta_ce/checkpoint-404] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/4.1.1_deberta_ce/checkpoint-606\n",
      "Configuration saved in /home/elson/4.1.1_deberta_ce/checkpoint-606/config.json\n",
      "Model weights saved in /home/elson/4.1.1_deberta_ce/checkpoint-606/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/4.1.1_deberta_ce/checkpoint-505] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/4.1.1_deberta_ce/checkpoint-707\n",
      "Configuration saved in /home/elson/4.1.1_deberta_ce/checkpoint-707/config.json\n",
      "Model weights saved in /home/elson/4.1.1_deberta_ce/checkpoint-707/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/4.1.1_deberta_ce/checkpoint-606] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/4.1.1_deberta_ce/checkpoint-808\n",
      "Configuration saved in /home/elson/4.1.1_deberta_ce/checkpoint-808/config.json\n",
      "Model weights saved in /home/elson/4.1.1_deberta_ce/checkpoint-808/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/4.1.1_deberta_ce/checkpoint-707] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/4.1.1_deberta_ce/checkpoint-909\n",
      "Configuration saved in /home/elson/4.1.1_deberta_ce/checkpoint-909/config.json\n",
      "Model weights saved in /home/elson/4.1.1_deberta_ce/checkpoint-909/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/4.1.1_deberta_ce/checkpoint-202] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/4.1.1_deberta_ce/checkpoint-808] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/4.1.1_deberta_ce/checkpoint-1010\n",
      "Configuration saved in /home/elson/4.1.1_deberta_ce/checkpoint-1010/config.json\n",
      "Model weights saved in /home/elson/4.1.1_deberta_ce/checkpoint-1010/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/4.1.1_deberta_ce/checkpoint-1111\n",
      "Configuration saved in /home/elson/4.1.1_deberta_ce/checkpoint-1111/config.json\n",
      "Model weights saved in /home/elson/4.1.1_deberta_ce/checkpoint-1111/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/4.1.1_deberta_ce/checkpoint-1010] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/4.1.1_deberta_ce/checkpoint-1212\n",
      "Configuration saved in /home/elson/4.1.1_deberta_ce/checkpoint-1212/config.json\n",
      "Model weights saved in /home/elson/4.1.1_deberta_ce/checkpoint-1212/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/4.1.1_deberta_ce/checkpoint-1111] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/4.1.1_deberta_ce/checkpoint-1313\n",
      "Configuration saved in /home/elson/4.1.1_deberta_ce/checkpoint-1313/config.json\n",
      "Model weights saved in /home/elson/4.1.1_deberta_ce/checkpoint-1313/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/4.1.1_deberta_ce/checkpoint-1212] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/4.1.1_deberta_ce/checkpoint-1414\n",
      "Configuration saved in /home/elson/4.1.1_deberta_ce/checkpoint-1414/config.json\n",
      "Model weights saved in /home/elson/4.1.1_deberta_ce/checkpoint-1414/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/4.1.1_deberta_ce/checkpoint-1313] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/4.1.1_deberta_ce/checkpoint-1515\n",
      "Configuration saved in /home/elson/4.1.1_deberta_ce/checkpoint-1515/config.json\n",
      "Model weights saved in /home/elson/4.1.1_deberta_ce/checkpoint-1515/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/4.1.1_deberta_ce/checkpoint-1414] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/4.1.1_deberta_ce/checkpoint-1616\n",
      "Configuration saved in /home/elson/4.1.1_deberta_ce/checkpoint-1616/config.json\n",
      "Model weights saved in /home/elson/4.1.1_deberta_ce/checkpoint-1616/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/4.1.1_deberta_ce/checkpoint-1515] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/4.1.1_deberta_ce/checkpoint-1717\n",
      "Configuration saved in /home/elson/4.1.1_deberta_ce/checkpoint-1717/config.json\n",
      "Model weights saved in /home/elson/4.1.1_deberta_ce/checkpoint-1717/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/4.1.1_deberta_ce/checkpoint-1616] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/4.1.1_deberta_ce/checkpoint-1818\n",
      "Configuration saved in /home/elson/4.1.1_deberta_ce/checkpoint-1818/config.json\n",
      "Model weights saved in /home/elson/4.1.1_deberta_ce/checkpoint-1818/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/4.1.1_deberta_ce/checkpoint-1717] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/4.1.1_deberta_ce/checkpoint-1919\n",
      "Configuration saved in /home/elson/4.1.1_deberta_ce/checkpoint-1919/config.json\n",
      "Model weights saved in /home/elson/4.1.1_deberta_ce/checkpoint-1919/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/4.1.1_deberta_ce/checkpoint-1818] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to /home/elson/4.1.1_deberta_ce/checkpoint-2020\n",
      "Configuration saved in /home/elson/4.1.1_deberta_ce/checkpoint-2020/config.json\n",
      "Model weights saved in /home/elson/4.1.1_deberta_ce/checkpoint-2020/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/4.1.1_deberta_ce/checkpoint-1919] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/elson/4.1.1_deberta_ce/checkpoint-909 (score: 0.6709677419354839).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='89' max='59' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [59/59 00:23]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /home/elson/4.1.1_deberta_ce/best_model/config.json\n",
      "Model weights saved in /home/elson/4.1.1_deberta_ce/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/4.1.1_deberta_ce/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/4.1.1_deberta_ce/best_model/special_tokens_map.json\n",
      "added tokens file saved in /home/elson/4.1.1_deberta_ce/best_model/added_tokens.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/4.1.1_deberta_ce/best_model/tokenizer_config.json',\n",
       " '/home/elson/4.1.1_deberta_ce/best_model/special_tokens_map.json',\n",
       " '/home/elson/4.1.1_deberta_ce/best_model/spm.model',\n",
       " '/home/elson/4.1.1_deberta_ce/best_model/added_tokens.json')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/4.1.1_deberta_ce/',\n",
    "    learning_rate=5e-06,\n",
    "    num_train_epochs=20,\n",
    "    per_device_train_batch_size=8,   # batch size per device during training\n",
    "    gradient_accumulation_steps=2,    # doubles the effective batch_size to 32, while decreasing memory requirements\n",
    "    per_device_eval_batch_size=8,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.06,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(device),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/4.1.1_deberta_ce/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/4.1.1_deberta_ce/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "63deaea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/4.1.1_deberta_ce/best_model/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"/home/elson/4.1.1_deberta_ce/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"entailment\",\n",
      "    \"1\": \"neutral\",\n",
      "    \"2\": \"contradiction\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"contradiction\": 2,\n",
      "    \"entailment\": 0,\n",
      "    \"neutral\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 1024,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file /home/elson/4.1.1_deberta_ce/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at /home/elson/4.1.1_deberta_ce/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 8\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/4.1.1_deberta_ce/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[ 5.81   , -1.589  , -4.883  ],\n",
      "       [ 1.279  ,  3.3    , -5.977  ],\n",
      "       [ 7.332  , -3.752  , -3.52   ],\n",
      "       [-2.785  , -4.22   ,  6.617  ],\n",
      "       [ 4.23   ,  0.2524 , -4.55   ],\n",
      "       [ 7.367  , -3.615  , -3.668  ],\n",
      "       [ 7.113  , -3.49   , -3.73   ],\n",
      "       [ 7.33   , -3.61   , -3.69   ],\n",
      "       [ 7.336  , -3.6    , -3.783  ],\n",
      "       [ 6.918  , -4.227  , -2.543  ],\n",
      "       [ 6.05   , -4.355  , -1.859  ],\n",
      "       [ 7.39   , -3.672  , -3.693  ],\n",
      "       [ 7.133  , -3.79   , -3.383  ],\n",
      "       [ 7.28   , -3.525  , -3.8    ],\n",
      "       [-1.271  ,  4.83   , -4.965  ],\n",
      "       [-3.588  , -3.627  ,  6.91   ],\n",
      "       [ 7.26   , -3.188  , -4.07   ],\n",
      "       [ 2.055  ,  3.037  , -6.477  ],\n",
      "       [ 7.227  , -3.459  , -3.848  ],\n",
      "       [ 7.344  , -3.553  , -3.709  ],\n",
      "       [-4.12   ,  5.504  , -2.422  ],\n",
      "       [ 7.05   , -3.291  , -3.783  ],\n",
      "       [ 7.047  , -2.883  , -4.04   ],\n",
      "       [-4.215  , -1.874  ,  5.98   ],\n",
      "       [-2.826  , -4.3    ,  6.766  ],\n",
      "       [-3.576  , -3.746  ,  6.934  ],\n",
      "       [ 7.418  , -3.572  , -3.768  ],\n",
      "       [-3.025  ,  5.88   , -4.332  ],\n",
      "       [ 7.434  , -3.572  , -3.78   ],\n",
      "       [ 7.277  , -3.734  , -3.482  ],\n",
      "       [-0.0334 ,  4.01   , -5.31   ],\n",
      "       [ 7.043  , -3.414  , -3.566  ],\n",
      "       [ 7.41   , -3.602  , -3.76   ],\n",
      "       [ 7.22   , -3.852  , -3.371  ],\n",
      "       [-3.303  , -2.336  ,  5.492  ],\n",
      "       [ 6.71   , -2.441  , -4.285  ],\n",
      "       [-3.857  ,  4.957  , -2.133  ],\n",
      "       [ 7.39   , -3.486  , -3.734  ],\n",
      "       [-3.191  , -4.066  ,  6.93   ],\n",
      "       [ 6.59   , -2.451  , -4.246  ],\n",
      "       [ 6.793  , -4.16   , -2.666  ],\n",
      "       [ 5.445  , -0.2452 , -5.855  ],\n",
      "       [ 5.734  , -2.39   , -3.893  ],\n",
      "       [-4.027  , -2.947  ,  6.773  ],\n",
      "       [ 3.906  , -0.914  , -3.553  ],\n",
      "       [ 6.496  , -2.32   , -4.35   ],\n",
      "       [ 7.004  , -2.566  , -4.312  ],\n",
      "       [ 7.297  , -3.445  , -3.9    ],\n",
      "       [ 7.18   , -3.387  , -3.773  ],\n",
      "       [-3.092  , -3.217  ,  6.293  ],\n",
      "       [-4.41   ,  5.188  , -1.74   ],\n",
      "       [ 7.3    , -3.412  , -3.797  ],\n",
      "       [ 7.266  , -3.822  , -3.406  ],\n",
      "       [ 7.242  , -3.61   , -3.504  ],\n",
      "       [-3.02   ,  5.348  , -3.6    ],\n",
      "       [ 7.285  , -3.6    , -3.736  ],\n",
      "       [-4.25   ,  5.71   , -2.742  ],\n",
      "       [ 7.133  , -2.75   , -4.38   ],\n",
      "       [ 7.285  , -3.844  , -3.355  ],\n",
      "       [ 7.35   , -3.447  , -3.838  ],\n",
      "       [-1.99   , -2.459  ,  4.19   ],\n",
      "       [-3.523  , -3.54   ,  6.777  ],\n",
      "       [ 6.53   , -2.342  , -4.035  ],\n",
      "       [ 0.03256,  3.611  , -4.543  ],\n",
      "       [ 0.6963 ,  4.04   , -5.91   ],\n",
      "       [ 7.195  , -3.309  , -3.861  ],\n",
      "       [ 7.316  , -3.498  , -3.727  ],\n",
      "       [ 7.45   , -3.441  , -4.01   ],\n",
      "       [ 1.515  , -1.945  ,  0.0831 ],\n",
      "       [ 0.3064 , -4.957  ,  4.098  ],\n",
      "       [ 5.7    , -1.139  , -5.07   ],\n",
      "       [ 7.184  , -3.703  , -3.541  ],\n",
      "       [ 4.01   ,  1.245  , -5.906  ],\n",
      "       [ 7.004  , -3.621  , -3.459  ],\n",
      "       [ 6.43   , -3.191  , -3.42   ],\n",
      "       [-0.2341 , -1.706  ,  1.774  ],\n",
      "       [ 7.477  , -3.9    , -3.428  ],\n",
      "       [ 4.336  ,  0.4324 , -5.457  ],\n",
      "       [-0.517  , -3.936  ,  3.754  ],\n",
      "       [ 6.8    , -3.285  , -3.791  ],\n",
      "       [ 7.438  , -3.576  , -3.828  ],\n",
      "       [ 6.95   , -2.895  , -4.25   ],\n",
      "       [-2.338  ,  4.562  , -3.334  ],\n",
      "       [ 7.36   , -3.994  , -3.42   ],\n",
      "       [ 7.383  , -3.2    , -4.08   ],\n",
      "       [-3.703  ,  4.6    , -2.326  ],\n",
      "       [ 7.3    , -3.957  , -3.295  ],\n",
      "       [ 6.574  , -2.512  , -3.963  ],\n",
      "       [ 6.95   , -3.031  , -4.004  ],\n",
      "       [ 6.53   , -2.342  , -4.035  ],\n",
      "       [ 7.535  , -3.76   , -3.668  ],\n",
      "       [ 7.38   , -3.607  , -3.809  ],\n",
      "       [-2.932  , -4.41   ,  6.902  ],\n",
      "       [ 7.207  , -3.521  , -3.756  ],\n",
      "       [ 7.293  , -3.531  , -3.771  ],\n",
      "       [ 4.164  , -1.258  , -3.6    ],\n",
      "       [ 1.112  , -4.71   ,  3.273  ],\n",
      "       [ 7.316  , -3.455  , -3.812  ],\n",
      "       [ 6.004  , -2.932  , -3.148  ],\n",
      "       [ 7.047  , -2.629  , -4.508  ],\n",
      "       [-3.006  , -3.4    ,  6.285  ],\n",
      "       [ 5.066  , -0.07275, -5.598  ],\n",
      "       [ 7.367  , -3.59   , -3.725  ],\n",
      "       [ 5.008  ,  0.2205 , -5.8    ],\n",
      "       [ 7.33   , -3.582  , -3.74   ],\n",
      "       [ 7.19   , -3.387  , -3.818  ],\n",
      "       [ 7.098  , -2.9    , -4.13   ],\n",
      "       [-4.     ,  5.83   , -3.19   ],\n",
      "       [ 7.367  , -3.629  , -3.736  ],\n",
      "       [ 7.41   , -3.58   , -3.734  ],\n",
      "       [ 7.355  , -3.93   , -3.51   ],\n",
      "       [ 7.152  , -3.459  , -3.828  ],\n",
      "       [-5.16   ,  0.0111 ,  4.9    ],\n",
      "       [ 7.07   , -4.062  , -3.059  ],\n",
      "       [ 7.19   , -3.338  , -4.02   ],\n",
      "       [ 7.176  , -3.242  , -3.781  ],\n",
      "       [ 7.473  , -3.545  , -3.877  ],\n",
      "       [ 7.113  , -3.281  , -3.867  ],\n",
      "       [ 5.76   , -3.61   , -2.209  ],\n",
      "       [ 6.934  , -2.773  , -4.18   ],\n",
      "       [ 7.094  , -2.545  , -4.484  ],\n",
      "       [ 7.188  , -3.61   , -3.549  ],\n",
      "       [ 6.93   , -2.688  , -4.336  ],\n",
      "       [ 3.89   ,  0.531  , -4.63   ],\n",
      "       [ 7.254  , -3.787  , -3.482  ],\n",
      "       [ 6.48   , -2.848  , -3.686  ],\n",
      "       [ 0.01741,  3.605  , -4.785  ],\n",
      "       [ 7.28   , -3.402  , -3.91   ],\n",
      "       [ 6.97   , -2.945  , -4.145  ],\n",
      "       [ 6.24   , -1.598  , -5.094  ],\n",
      "       [-2.525  ,  5.81   , -4.746  ],\n",
      "       [-3.713  , -3.2    ,  6.695  ],\n",
      "       [ 7.273  , -2.852  , -4.285  ],\n",
      "       [-3.54   , -2.676  ,  6.19   ],\n",
      "       [ 4.914  , -0.03006, -5.36   ],\n",
      "       [-3.914  ,  4.94   , -1.674  ],\n",
      "       [ 7.195  , -3.72   , -3.654  ],\n",
      "       [-3.906  , -3.412  ,  6.92   ],\n",
      "       [ 0.4385 ,  3.797  , -5.668  ],\n",
      "       [ 7.22   , -3.484  , -3.744  ],\n",
      "       [ 7.16   , -2.953  , -4.13   ],\n",
      "       [ 7.24   , -3.438  , -3.81   ],\n",
      "       [ 7.348  , -3.8    , -3.486  ],\n",
      "       [ 7.45   , -3.62   , -3.709  ],\n",
      "       [ 1.539  ,  0.7964 , -2.963  ],\n",
      "       [-4.273  ,  5.707  , -2.574  ],\n",
      "       [ 7.03   , -4.043  , -2.908  ],\n",
      "       [-3.162  , -1.824  ,  4.895  ],\n",
      "       [ 7.098  , -2.965  , -4.086  ],\n",
      "       [-3.664  , -3.473  ,  6.895  ],\n",
      "       [ 0.4878 ,  4.004  , -5.84   ],\n",
      "       [ 7.477  , -3.67   , -3.67   ],\n",
      "       [ 7.227  , -3.217  , -4.094  ],\n",
      "       [-4.266  ,  1.796  ,  2.61   ],\n",
      "       [ 7.18   , -3.33   , -4.008  ],\n",
      "       [ 7.35   , -3.818  , -3.514  ],\n",
      "       [ 7.     , -4.59   , -2.47   ],\n",
      "       [-4.266  ,  3.846  ,  0.138  ],\n",
      "       [ 7.047  , -3.436  , -3.775  ],\n",
      "       [ 6.734  , -4.58   , -1.871  ],\n",
      "       [-3.656  , -3.58   ,  6.87   ],\n",
      "       [-2.982  , -4.45   ,  6.97   ],\n",
      "       [ 7.215  , -2.95   , -4.402  ],\n",
      "       [ 2.182  , -3.594  ,  1.502  ],\n",
      "       [-3.703  ,  4.473  , -1.668  ],\n",
      "       [-4.49   ,  1.527  ,  3.14   ],\n",
      "       [ 6.027  , -1.366  , -5.168  ],\n",
      "       [-3.145  , -4.082  ,  6.914  ],\n",
      "       [-3.557  , -2.744  ,  6.23   ],\n",
      "       [ 0.0259 , -2.7    ,  3.002  ],\n",
      "       [-3.477  , -3.734  ,  6.816  ],\n",
      "       [ 7.273  , -3.852  , -3.232  ],\n",
      "       [-3.607  ,  5.38   , -3.062  ],\n",
      "       [ 7.418  , -3.773  , -3.543  ],\n",
      "       [ 6.273  , -2.162  , -4.418  ],\n",
      "       [-2.963  ,  5.18   , -3.596  ],\n",
      "       [ 7.12   , -3.55   , -3.523  ],\n",
      "       [-2.02   , -4.793  ,  6.1    ],\n",
      "       [ 7.188  , -3.447  , -3.861  ],\n",
      "       [-2.963  , -3.8    ,  6.574  ],\n",
      "       [-3.748  , -2.883  ,  6.25   ],\n",
      "       [-1.537  , -4.168  ,  5.47   ],\n",
      "       [-3.285  , -4.027  ,  6.863  ],\n",
      "       [ 5.402  , -1.353  , -4.586  ],\n",
      "       [ 2.186  ,  1.916  , -5.21   ],\n",
      "       [ 7.312  , -3.334  , -4.008  ],\n",
      "       [ 7.086  , -3.602  , -3.543  ],\n",
      "       [ 7.254  , -3.41   , -3.953  ],\n",
      "       [-0.02725,  3.875  , -4.758  ],\n",
      "       [ 7.414  , -3.586  , -3.734  ],\n",
      "       [-3.05   , -1.633  ,  4.426  ],\n",
      "       [ 7.215  , -3.2    , -3.865  ],\n",
      "       [ 7.285  , -3.719  , -3.648  ],\n",
      "       [-4.195  ,  5.75   , -2.855  ],\n",
      "       [-3.23   , -4.14   ,  6.984  ],\n",
      "       [ 7.297  , -3.623  , -3.582  ],\n",
      "       [ 7.     , -3.508  , -3.637  ],\n",
      "       [ 7.48   , -3.664  , -3.686  ],\n",
      "       [ 6.465  , -3.623  , -2.98   ],\n",
      "       [ 7.254  , -3.238  , -3.861  ],\n",
      "       [ 6.324  , -2.498  , -4.094  ],\n",
      "       [ 7.297  , -3.137  , -4.12   ],\n",
      "       [ 2.084  ,  2.824  , -6.207  ],\n",
      "       [ 7.438  , -3.582  , -3.682  ],\n",
      "       [-2.682  ,  0.5767 ,  1.905  ],\n",
      "       [-4.516  ,  3.762  ,  0.5146 ],\n",
      "       [ 7.355  , -3.314  , -4.02   ],\n",
      "       [-3.357  ,  5.715  , -3.367  ],\n",
      "       [ 7.258  , -3.508  , -3.732  ],\n",
      "       [ 7.38   , -3.648  , -3.742  ],\n",
      "       [ 7.1    , -3.62   , -3.566  ],\n",
      "       [ 6.766  , -2.857  , -3.96   ],\n",
      "       [ 7.32   , -3.207  , -4.047  ],\n",
      "       [ 7.027  , -2.951  , -4.355  ],\n",
      "       [ 7.375  , -3.377  , -3.945  ],\n",
      "       [-3.39   , -2.975  ,  6.12   ],\n",
      "       [-3.27   , -3.139  ,  6.344  ],\n",
      "       [ 6.89   , -3.715  , -2.975  ],\n",
      "       [ 7.293  , -3.568  , -3.662  ],\n",
      "       [ 2.965  , -2.416  , -0.2822 ],\n",
      "       [ 7.426  , -3.543  , -3.773  ],\n",
      "       [ 7.383  , -3.627  , -3.662  ],\n",
      "       [ 3.273  , -3.744  ,  0.7607 ],\n",
      "       [ 4.523  , -2.94   , -1.778  ],\n",
      "       [ 7.03   , -2.895  , -4.21   ],\n",
      "       [ 7.414  , -3.445  , -3.87   ],\n",
      "       [ 7.426  , -3.346  , -3.926  ],\n",
      "       [-4.117  , -1.682  ,  5.934  ],\n",
      "       [-0.9414 , -3.873  ,  4.695  ],\n",
      "       [ 7.14   , -3.287  , -3.896  ],\n",
      "       [ 6.875  , -2.742  , -4.266  ],\n",
      "       [ 7.227  , -2.936  , -4.22   ],\n",
      "       [ 7.156  , -3.049  , -4.1    ],\n",
      "       [ 6.953  , -3.926  , -2.934  ]], dtype=float16), label_ids=array([0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 2,\n",
      "       0, 1, 2, 2, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 2, 1, 0, 0,\n",
      "       0, 2, 0, 0, 2, 2, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 2, 1, 0, 1, 2,\n",
      "       0, 0, 2, 2, 0, 0, 1, 1, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "       2, 1, 0, 0, 2, 0, 0, 0, 2, 0, 0, 1, 2, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "       1, 0, 1, 0, 1, 0, 0, 0, 2, 2, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2,\n",
      "       0, 1, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 2, 2, 0, 0, 0, 0, 1, 1,\n",
      "       0, 0, 0, 1, 0, 2, 2, 2, 0, 0, 0, 1, 0, 0, 2, 0, 2, 0, 1, 0, 0, 0,\n",
      "       0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 1, 0, 0, 0, 0, 1, 1, 2, 0, 0,\n",
      "       0, 0, 2, 0, 0, 0, 0, 1, 0, 0, 2, 0, 0, 2]), metrics={'test_loss': 2.5922043323516846, 'test_accuracy': 0.6752136752136753, 'test_precision': 0.6629536624481012, 'test_recall': 0.6752136752136753, 'test_f1': 0.6663001007147024, 'test_runtime': 5.7117, 'test_samples_per_second': 40.968, 'test_steps_per_second': 5.252})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
