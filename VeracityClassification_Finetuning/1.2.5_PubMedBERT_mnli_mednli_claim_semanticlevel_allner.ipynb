{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score,balanced_accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82806f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jul 29 19:09:45 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:61:00.0 Off |                    0 |\n",
      "| N/A   45C    P0    57W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  Off  | 00000000:62:00.0 Off |                    0 |\n",
      "| N/A   45C    P0    58W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  Off  | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   44C    P0    61W / 300W |      0MiB / 32768MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  Off  | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   44C    P0    60W / 300W |      3MiB / 32768MiB |      2%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-31dfe7adddcf5ced\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 191.12it/s]\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-ad71be204b279b28.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-e7b6b615907c24ca.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-bee802838a3bfaea.arrow\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset from the CSV file\n",
    "dataset = load_dataset(\n",
    "    'csv',\n",
    "    data_files='dataset_semanticattribution_nerfeatures_split.csv',\n",
    "    delimiter=',',\n",
    "    column_names=[\n",
    "        \"claim\", \"premise\", \"label\", \"category\", \"count_bf\", \"count_ca\", \"count_dis\",\n",
    "        \"count_food\", \"count_lipid\", \"count_treat\", \"pres_bf\", \"pres_ca\", \"pres_dis\",\n",
    "        \"pres_food\", \"pres_lipid\", \"pres_treat\", \"counte_bf\", \"counte_ca\", \"counte_dis\",\n",
    "        \"counte_food\", \"counte_lipid\", \"counte_treat\", \"prese_bf\", \"prese_ca\", \"prese_dis\",\n",
    "        \"prese_food\", \"prese_lipid\", \"prese_treat\", \"url\", \"entities\", \"entity_map\",\n",
    "        \"gold_exp\", \"gemini_exp\", \"gemini_label\",\"entity_ev\",\"entity_map_ev\", \"split\"\n",
    "    ],\n",
    "    skiprows=1\n",
    ")\n",
    "\n",
    "# Assuming 'split' column contains strings 'train', 'validation', 'test'\n",
    "# Filter the loaded dataset into subsets\n",
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'gold_exp', 'gemini_exp', 'gemini_label', 'entity_ev', 'entity_map_ev', 'split'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f3e71be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41f1db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['claim', 'premise', 'label','category','count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat','counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat']\n",
    "all_columns = train_dataset.column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-2b0030fb2dfa4c5c.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-2af2b7abf1a08f75.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-0bbf36fdf8be1d2b.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 0, 'entailment': 1, 'neutral': 2}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 0,\n",
    "    \"entailment\": 1,\n",
    "    \"neutral\": 2\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b5bb17f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "465"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['val']['claim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='pritamdeka/PubMedBERT-MNLI-MedNLI'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "        # Extracting claim and evidence texts\n",
    "\n",
    "        claim = item['claim']\n",
    "        premise = item['premise'].replace('\\n', '').replace('[','').replace(']','')\n",
    "        \n",
    "        additional_features = [\n",
    "            \"count_bf\",\"count_ca\",\"count_dis\",\"count_food\",\"count_lipid\",\"count_treat\",\"pres_bf\",\"pres_ca\",\"pres_dis\",\"pres_food\",\"pres_lipid\",\"pres_treat\"]\n",
    "    \n",
    "        for feature in additional_features:\n",
    "            if feature in item:\n",
    "                claim += \"[SEP]\" + str(item[feature])\n",
    "        \n",
    "        additional_features_ev = [\n",
    "            'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat']\n",
    "    \n",
    "        for feature_ev in additional_features_ev:\n",
    "            if feature_ev in item:\n",
    "                premise += \"[SEP]\" + str(item[feature])\n",
    "        item['claim']=claim\n",
    "        item['premise']=premise        \n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "             premise, claim,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "        item['input_ids'] = inputs['input_ids'].squeeze()  # Remove batch dimension\n",
    "        item['attention_mask']= inputs['attention_mask'].squeeze() # Remove batch dimension\n",
    "        \n",
    "        output_item = {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),  # Remove batch dimension\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),  # Remove batch dimension\n",
    "            'claim': claim,  # Include augmented claim text\n",
    "            'evidences': premise  # Include original evidence text\n",
    "        }\n",
    "        \n",
    "        if 'label' in item:\n",
    "            output_item['label'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return output_item\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62421eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"pritamdeka/PubMedBERT-MNLI-MedNLI\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=3, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f72c5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model is on device: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    bal_accuracy = balanced_accuracy_score(labels,preds)\n",
    "\n",
    "    return {\"accuracy\": acc, \"balanced_accuracy\":bal_accuracy, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17c5e0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([    2,    31,  2067, 29949,  2126,   240,    16,    56,    18,    31,\n",
       "          3363,  7369,  1019,   240,    16,    51,    18,    31,  7626,  5025,\n",
       "           240,  6235,  2165,  1019,   240,    16,    58,    18,    31,  4357,\n",
       "         23663,  1970, 25210,  1019,   240,    16,    55,    18,    31, 17725,\n",
       "          1037, 12518,  2165,  1019,   240,    16,    57,    18,    31, 28193,\n",
       "          8323, 12518,  2165,  1019,   240,    16,    52,    18, 14542,  4006,\n",
       "          4480,  1930, 14227,  5004,  4415, 16984,  1930, 10659,  2043,  4480,\n",
       "         13203,  1021,  3316,  2703,    17, 22248,  1927, 27041, 11638,  1036,\n",
       "            18,  8236,  5182,  1035,    16,    51,    18, 22719,    10,  4272,\n",
       "          9322,  1927, 26503,  4340,  7369,    12,    18,  5163,  3071,  1930,\n",
       "          6595,  4575, 18068,  1030,  2564,  1927,  2949,  1930,  2310, 11963,\n",
       "          1943,  1956, 14227,  5004,    12,  2689,  6285,  8846,  2629, 12492,\n",
       "          1024,    13, 19490,    18,  4415, 16984,    30,  9624,  2046, 18056,\n",
       "          1958,  4407,  2859,    18, 13297, 21783, 15777,  7446,  1012,    16,\n",
       "            56,    18,    31, 16080, 22284,  1029,    16,    45,    18,    31,\n",
       "         28374, 29834,    16,    52,    18,    31,  3009,  5002,    16,    57,\n",
       "            18,    31, 28098,    16,    55,    18,  5819,  6202,  2007,  4613,\n",
       "          4461,    30,    45,    18, 14227,  5004,  1019,  6691,  4072,  8147,\n",
       "         12709, 16527,    18,  8616,  1960,  7056,  1949,    16,    60,    18,\n",
       "            31,  8616,  1960,  7056,  1949,    16,    61,    18,    31,  8616,\n",
       "          1960,  7056,  1949,    16,    55,    18,    31, 26043,  5148,  3027,\n",
       "            16,    55,    18, 14542,  4006,  4480,    12,    43,  1574,  1216,\n",
       "          1021,  1793,  1062,  7399,   237, 27645,  2029,    31,    18,  3038,\n",
       "            13,    30,  2037,  1920,  4367,  1927,  6378,  5990,  1942,  1920,\n",
       "          4008, 25512, 20512,  1958,  1920,  5455,  1930,  2311,  1927,  7433,\n",
       "          3902,    18, 10021,  1930, 18659,  2455,  1927, 14542,  4006,  4480,\n",
       "          6691,    18, 15926,  3165, 16159, 11324,  2126,  6391,    18,    31,\n",
       "          9108,    16,    47,    18, 14542,  4006,  4480,  1930, 14227,  5004,\n",
       "          1966, 17186,  2062,  1922,  3069,    18,     3,    20,     3,    20,\n",
       "             3,    20,     3,    20,     3,    20,     3,    20,     3,    20,\n",
       "             3,    20,     3,    20,     3,    20,     3,    20,     3,    20,\n",
       "             3, 14227,  5004,  4415,  6691,  1977,  8929,  2251,  1922,  4407,\n",
       "          5715,  4461,  1942,  4087,  3326,  1920,  7818,  1927,  1920,  4407,\n",
       "            18,     3,    20,     3,    20,     3,    20,     3,    20,     3,\n",
       "            20,     3,    20,     3,    20,     3,    20,     3,    20,     3,\n",
       "            20,     3,    20,     3,    20,     3,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'claim': 'Myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0',\n",
       " 'evidences': '; UnkoviÄ‡, N.; DimkiÄ‡, I.; JanaÄ‡koviÄ‡, P.; GavriloviÄ‡, M.; StanojeviÄ‡, O.; VukojeviÄ‡, J. Frankincense and myrrh essential oils and burn incense fume against micro-inhabitants of sacral ambients.Shameem, I. Phytochemical & therapeutic potentials of Murr makki (.Oxidative stress and immunotoxic effects of lead and their amelioration with myrrh (Commiphora molmol) emulsion.Essential Oils: Magical Ingredients for Skin Care.Chakravarty, N.; Kellogg, C.; Alvarez, J.; Equils, O.; Morgan, M. UV Protection by Natural Products: C. myrrha Oil Versus Sunscreen.Hamidpour, R.; Hamidpour, S.; Hamidpour, M.; Shahlari, M. Frankincense (ä¹³é¦™ RÇ” XiÄ\\x81ng;.species): From the selection of traditional applications to the novel phytotherapy for the prevention and treatment of serious diseases.Chemistry and immunomodulatory activity of frankincense oil.Compositions containing Boswellia extracts.; Cooper, E. Frankincense and myrrh as remedies in children.[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0',\n",
       " 'label': tensor(1)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on device: cuda:0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='765' max='765' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [765/765 06:17, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.823700</td>\n",
       "      <td>0.846590</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.453245</td>\n",
       "      <td>0.619803</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.609049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.612300</td>\n",
       "      <td>0.846452</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.488761</td>\n",
       "      <td>0.650303</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.628516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.362800</td>\n",
       "      <td>1.220849</td>\n",
       "      <td>0.632258</td>\n",
       "      <td>0.477926</td>\n",
       "      <td>0.638194</td>\n",
       "      <td>0.632258</td>\n",
       "      <td>0.635046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.142600</td>\n",
       "      <td>1.710548</td>\n",
       "      <td>0.610753</td>\n",
       "      <td>0.519100</td>\n",
       "      <td>0.661441</td>\n",
       "      <td>0.610753</td>\n",
       "      <td>0.630772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.163800</td>\n",
       "      <td>1.483083</td>\n",
       "      <td>0.640860</td>\n",
       "      <td>0.512112</td>\n",
       "      <td>0.662129</td>\n",
       "      <td>0.640860</td>\n",
       "      <td>0.638163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>2.191268</td>\n",
       "      <td>0.584946</td>\n",
       "      <td>0.527446</td>\n",
       "      <td>0.673452</td>\n",
       "      <td>0.584946</td>\n",
       "      <td>0.612834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.062700</td>\n",
       "      <td>2.057341</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.514251</td>\n",
       "      <td>0.659583</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.647831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>2.467473</td>\n",
       "      <td>0.627957</td>\n",
       "      <td>0.537608</td>\n",
       "      <td>0.672148</td>\n",
       "      <td>0.627957</td>\n",
       "      <td>0.641254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>2.588481</td>\n",
       "      <td>0.636559</td>\n",
       "      <td>0.522894</td>\n",
       "      <td>0.664971</td>\n",
       "      <td>0.636559</td>\n",
       "      <td>0.645264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.057300</td>\n",
       "      <td>2.410230</td>\n",
       "      <td>0.653763</td>\n",
       "      <td>0.544110</td>\n",
       "      <td>0.674867</td>\n",
       "      <td>0.653763</td>\n",
       "      <td>0.662014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>2.716262</td>\n",
       "      <td>0.623656</td>\n",
       "      <td>0.546677</td>\n",
       "      <td>0.674463</td>\n",
       "      <td>0.623656</td>\n",
       "      <td>0.640847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.022700</td>\n",
       "      <td>2.753758</td>\n",
       "      <td>0.634409</td>\n",
       "      <td>0.547879</td>\n",
       "      <td>0.676602</td>\n",
       "      <td>0.634409</td>\n",
       "      <td>0.648759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>2.755496</td>\n",
       "      <td>0.647312</td>\n",
       "      <td>0.548686</td>\n",
       "      <td>0.677982</td>\n",
       "      <td>0.647312</td>\n",
       "      <td>0.657103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>2.777727</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.558034</td>\n",
       "      <td>0.683997</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.660666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>2.783432</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.547618</td>\n",
       "      <td>0.676891</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.655232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.5_pubmedbert/checkpoint-51\n",
      "Configuration saved in /home/elson/1.2.5_pubmedbert/checkpoint-51/config.json\n",
      "Model weights saved in /home/elson/1.2.5_pubmedbert/checkpoint-51/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.2.5_pubmedbert/checkpoint-510] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/1.2.5_pubmedbert/checkpoint-765] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.5_pubmedbert/checkpoint-102\n",
      "Configuration saved in /home/elson/1.2.5_pubmedbert/checkpoint-102/config.json\n",
      "Model weights saved in /home/elson/1.2.5_pubmedbert/checkpoint-102/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.5_pubmedbert/checkpoint-153\n",
      "Configuration saved in /home/elson/1.2.5_pubmedbert/checkpoint-153/config.json\n",
      "Model weights saved in /home/elson/1.2.5_pubmedbert/checkpoint-153/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.2.5_pubmedbert/checkpoint-51] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/1.2.5_pubmedbert/checkpoint-102] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.5_pubmedbert/checkpoint-204\n",
      "Configuration saved in /home/elson/1.2.5_pubmedbert/checkpoint-204/config.json\n",
      "Model weights saved in /home/elson/1.2.5_pubmedbert/checkpoint-204/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.5_pubmedbert/checkpoint-255\n",
      "Configuration saved in /home/elson/1.2.5_pubmedbert/checkpoint-255/config.json\n",
      "Model weights saved in /home/elson/1.2.5_pubmedbert/checkpoint-255/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.2.5_pubmedbert/checkpoint-153] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/1.2.5_pubmedbert/checkpoint-204] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.5_pubmedbert/checkpoint-306\n",
      "Configuration saved in /home/elson/1.2.5_pubmedbert/checkpoint-306/config.json\n",
      "Model weights saved in /home/elson/1.2.5_pubmedbert/checkpoint-306/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.5_pubmedbert/checkpoint-357\n",
      "Configuration saved in /home/elson/1.2.5_pubmedbert/checkpoint-357/config.json\n",
      "Model weights saved in /home/elson/1.2.5_pubmedbert/checkpoint-357/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.2.5_pubmedbert/checkpoint-306] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.5_pubmedbert/checkpoint-408\n",
      "Configuration saved in /home/elson/1.2.5_pubmedbert/checkpoint-408/config.json\n",
      "Model weights saved in /home/elson/1.2.5_pubmedbert/checkpoint-408/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.2.5_pubmedbert/checkpoint-357] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.5_pubmedbert/checkpoint-459\n",
      "Configuration saved in /home/elson/1.2.5_pubmedbert/checkpoint-459/config.json\n",
      "Model weights saved in /home/elson/1.2.5_pubmedbert/checkpoint-459/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.2.5_pubmedbert/checkpoint-408] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.5_pubmedbert/checkpoint-510\n",
      "Configuration saved in /home/elson/1.2.5_pubmedbert/checkpoint-510/config.json\n",
      "Model weights saved in /home/elson/1.2.5_pubmedbert/checkpoint-510/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.2.5_pubmedbert/checkpoint-255] due to args.save_total_limit\n",
      "Deleting older checkpoint [/home/elson/1.2.5_pubmedbert/checkpoint-459] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.5_pubmedbert/checkpoint-561\n",
      "Configuration saved in /home/elson/1.2.5_pubmedbert/checkpoint-561/config.json\n",
      "Model weights saved in /home/elson/1.2.5_pubmedbert/checkpoint-561/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.5_pubmedbert/checkpoint-612\n",
      "Configuration saved in /home/elson/1.2.5_pubmedbert/checkpoint-612/config.json\n",
      "Model weights saved in /home/elson/1.2.5_pubmedbert/checkpoint-612/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.2.5_pubmedbert/checkpoint-561] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.5_pubmedbert/checkpoint-663\n",
      "Configuration saved in /home/elson/1.2.5_pubmedbert/checkpoint-663/config.json\n",
      "Model weights saved in /home/elson/1.2.5_pubmedbert/checkpoint-663/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.2.5_pubmedbert/checkpoint-612] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.5_pubmedbert/checkpoint-714\n",
      "Configuration saved in /home/elson/1.2.5_pubmedbert/checkpoint-714/config.json\n",
      "Model weights saved in /home/elson/1.2.5_pubmedbert/checkpoint-714/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.2.5_pubmedbert/checkpoint-663] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n",
      "Saving model checkpoint to /home/elson/1.2.5_pubmedbert/checkpoint-765\n",
      "Configuration saved in /home/elson/1.2.5_pubmedbert/checkpoint-765/config.json\n",
      "Model weights saved in /home/elson/1.2.5_pubmedbert/checkpoint-765/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/1.2.5_pubmedbert/checkpoint-714] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/elson/1.2.5_pubmedbert/checkpoint-510 (score: 0.6537634408602151).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='23' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15/15 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /home/elson/1.2.5_pubmedbert/best_model/config.json\n",
      "Model weights saved in /home/elson/1.2.5_pubmedbert/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/1.2.5_pubmedbert/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/1.2.5_pubmedbert/best_model/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/1.2.5_pubmedbert/best_model/tokenizer_config.json',\n",
       " '/home/elson/1.2.5_pubmedbert/best_model/special_tokens_map.json',\n",
       " '/home/elson/1.2.5_pubmedbert/best_model/vocab.txt',\n",
       " '/home/elson/1.2.5_pubmedbert/best_model/added_tokens.json',\n",
       " '/home/elson/1.2.5_pubmedbert/best_model/tokenizer.json')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/1.2.5_pubmedbert/',\n",
    "    num_train_epochs=15,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.1,\n",
    "    weight_decay=0.1,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(\"cuda:0\"),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "print(f\"Model is on device: {next(model.parameters()).device}\")\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/1.2.5_pubmedbert/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/1.2.5_pubmedbert/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cdee1665",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/1.2.5_pubmedbert/best_model/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"/home/elson/1.2.5_pubmedbert/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"contradiction\",\n",
      "    \"1\": \"entailment\",\n",
      "    \"2\": \"neutral\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"contradiction\": 0,\n",
      "    \"entailment\": 1,\n",
      "    \"neutral\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file /home/elson/1.2.5_pubmedbert/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at /home/elson/1.2.5_pubmedbert/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 32\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/1.2.5_pubmedbert/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[ 5.0234e+00, -3.0547e+00, -9.8877e-01],\n",
      "       [-4.6289e+00,  5.8828e+00, -2.7285e+00],\n",
      "       [-4.6836e+00,  5.3633e+00, -2.2734e+00],\n",
      "       [-2.9590e+00,  5.3750e+00, -3.6914e+00],\n",
      "       [-4.9336e+00,  5.6133e+00, -2.2402e+00],\n",
      "       [-4.2461e+00,  6.0078e+00, -3.0352e+00],\n",
      "       [-4.5898e+00,  6.1016e+00, -2.7676e+00],\n",
      "       [-5.5898e+00,  5.3281e+00, -1.2090e+00],\n",
      "       [-4.5938e+00,  6.0625e+00, -2.7168e+00],\n",
      "       [-4.1602e+00,  6.0078e+00, -3.1094e+00],\n",
      "       [-3.2500e+00,  5.9922e+00, -3.7168e+00],\n",
      "       [-4.0898e+00,  6.0625e+00, -3.0586e+00],\n",
      "       [-4.4688e+00,  5.8438e+00, -2.7227e+00],\n",
      "       [-5.3008e+00,  5.6445e+00, -1.9033e+00],\n",
      "       [-5.0508e+00,  5.6641e+00, -2.0996e+00],\n",
      "       [ 6.2070e+00, -1.5967e+00, -3.8887e+00],\n",
      "       [-4.3516e+00,  6.1055e+00, -3.0664e+00],\n",
      "       [-4.6172e+00,  4.5820e+00, -1.3516e+00],\n",
      "       [-4.4180e+00,  6.0117e+00, -2.8340e+00],\n",
      "       [-4.5586e+00,  6.0156e+00, -2.8320e+00],\n",
      "       [-4.7109e+00,  5.8320e+00, -2.6094e+00],\n",
      "       [-5.6094e+00,  5.0234e+00, -8.8623e-01],\n",
      "       [-5.0234e+00,  5.2969e+00, -1.6182e+00],\n",
      "       [ 9.8877e-02, -4.0273e+00,  3.9062e+00],\n",
      "       [ 4.0586e+00, -6.6223e-02, -3.6191e+00],\n",
      "       [ 2.8047e+00, -3.1094e+00,  1.0449e+00],\n",
      "       [-3.6230e+00,  6.0625e+00, -3.4551e+00],\n",
      "       [-4.5039e+00,  5.9883e+00, -2.9062e+00],\n",
      "       [-4.6641e+00,  5.5703e+00, -2.4902e+00],\n",
      "       [-4.1367e+00,  6.1211e+00, -3.1855e+00],\n",
      "       [-3.0957e+00,  3.3340e+00, -1.0459e+00],\n",
      "       [-4.3711e+00,  6.0508e+00, -2.8848e+00],\n",
      "       [-4.2344e+00,  5.9453e+00, -3.0020e+00],\n",
      "       [-4.8164e+00,  1.2959e+00,  2.8770e+00],\n",
      "       [-4.7500e+00,  5.8320e+00, -2.4688e+00],\n",
      "       [-4.2734e+00,  6.1211e+00, -3.1016e+00],\n",
      "       [-4.3555e+00,  6.0820e+00, -2.9707e+00],\n",
      "       [-3.5410e+00,  5.9414e+00, -3.4258e+00],\n",
      "       [ 6.2422e+00, -1.4766e+00, -3.9121e+00],\n",
      "       [-4.2461e+00,  6.1094e+00, -3.1016e+00],\n",
      "       [ 5.0586e+00, -1.1602e+00, -3.2910e+00],\n",
      "       [-4.8438e+00,  5.8242e+00, -2.4512e+00],\n",
      "       [-3.9785e+00,  6.1016e+00, -3.2480e+00],\n",
      "       [ 1.6807e+00, -2.0566e+00,  5.7959e-01],\n",
      "       [-4.9688e+00,  5.3125e+00, -1.8086e+00],\n",
      "       [-4.5000e+00,  6.0781e+00, -2.8672e+00],\n",
      "       [ 2.0654e-01,  3.7520e+00, -4.4766e+00],\n",
      "       [-4.3203e+00,  6.0703e+00, -2.9922e+00],\n",
      "       [-3.7461e+00,  6.0352e+00, -3.5137e+00],\n",
      "       [ 6.2656e+00, -1.4678e+00, -3.8242e+00],\n",
      "       [-4.6797e+00,  3.9980e+00, -5.3906e-01],\n",
      "       [-3.2852e+00, -2.7686e-01,  3.2773e+00],\n",
      "       [-2.5781e+00,  5.1836e+00, -3.6328e+00],\n",
      "       [-4.7539e+00,  5.6875e+00, -2.4414e+00],\n",
      "       [ 5.6250e+00, -2.2617e+00, -2.4824e+00],\n",
      "       [-4.5117e+00,  6.0000e+00, -2.8633e+00],\n",
      "       [ 1.0938e+00,  1.0967e+00, -2.0254e+00],\n",
      "       [-5.2891e+00,  5.0859e+00, -1.4941e+00],\n",
      "       [-4.7656e+00,  5.6172e+00, -2.3848e+00],\n",
      "       [-4.0625e+00,  6.0547e+00, -3.2031e+00],\n",
      "       [-5.2383e+00,  4.8359e+00, -1.0850e+00],\n",
      "       [ 5.9609e+00, -1.2793e+00, -3.7461e+00],\n",
      "       [-3.3789e+00,  1.4563e-01,  3.1133e+00],\n",
      "       [-3.8203e+00,  5.8438e+00, -3.3770e+00],\n",
      "       [-4.4062e+00,  4.9180e+00, -2.0234e+00],\n",
      "       [-3.6621e+00,  5.9375e+00, -3.4902e+00],\n",
      "       [-4.0547e+00,  6.0586e+00, -3.1367e+00],\n",
      "       [-3.8027e+00,  6.0625e+00, -3.3496e+00],\n",
      "       [-3.6855e+00,  6.0703e+00, -3.4590e+00],\n",
      "       [ 4.6562e+00, -1.0273e+00, -2.9160e+00],\n",
      "       [-5.3594e+00,  4.8906e+00, -1.0410e+00],\n",
      "       [-5.3594e+00,  5.4766e+00, -1.6738e+00],\n",
      "       [-5.1797e+00,  5.3125e+00, -1.8066e+00],\n",
      "       [-4.6484e+00,  5.7578e+00, -2.5059e+00],\n",
      "       [-5.8594e+00,  2.3672e+00,  2.4609e+00],\n",
      "       [-3.7852e+00,  5.6484e+00, -3.2676e+00],\n",
      "       [-3.4980e+00,  5.7969e+00, -3.3320e+00],\n",
      "       [-4.9453e+00,  5.3906e+00, -2.0938e+00],\n",
      "       [-3.9922e+00,  6.0820e+00, -3.3184e+00],\n",
      "       [-3.8066e+00,  5.2305e+00, -2.6934e+00],\n",
      "       [-4.3906e+00,  6.0117e+00, -2.9062e+00],\n",
      "       [-4.4141e+00,  6.0664e+00, -2.9551e+00],\n",
      "       [-4.0000e+00,  6.1016e+00, -3.2695e+00],\n",
      "       [-3.9590e+00,  6.1172e+00, -3.3535e+00],\n",
      "       [-4.1562e+00,  6.0391e+00, -3.0859e+00],\n",
      "       [-4.4922e+00,  5.2773e+00, -2.2109e+00],\n",
      "       [-3.9844e+00,  5.8906e+00, -3.1367e+00],\n",
      "       [-1.5684e+00,  4.8008e+00, -4.3750e+00],\n",
      "       [-3.4727e+00, -3.7378e-01,  2.3262e+00],\n",
      "       [-2.4844e+00, -2.7383e+00,  5.2422e+00],\n",
      "       [-4.2500e+00,  5.6211e+00, -2.8418e+00],\n",
      "       [-3.8613e+00,  5.9648e+00, -3.2910e+00],\n",
      "       [ 5.0039e+00, -5.1465e-01, -3.9297e+00],\n",
      "       [-4.5469e+00,  5.9609e+00, -2.7910e+00],\n",
      "       [-3.3086e+00,  5.6875e+00, -3.5586e+00],\n",
      "       [-4.1016e+00,  5.6875e+00, -2.8945e+00],\n",
      "       [-2.9141e+00,  4.9648e+00, -3.3672e+00],\n",
      "       [-4.1680e+00,  6.0547e+00, -3.2207e+00],\n",
      "       [-4.0742e+00,  6.1172e+00, -3.2656e+00],\n",
      "       [-4.5977e+00,  5.2852e+00, -2.1367e+00],\n",
      "       [ 6.2891e+00, -1.3906e+00, -4.0312e+00],\n",
      "       [-3.5391e+00, -1.5508e+00,  4.8164e+00],\n",
      "       [-5.3945e+00,  5.4531e+00, -1.5898e+00],\n",
      "       [-2.8027e+00, -1.3477e+00,  3.7227e+00],\n",
      "       [-4.8477e+00,  5.1172e+00, -1.8545e+00],\n",
      "       [-4.2422e+00,  6.0312e+00, -3.0020e+00],\n",
      "       [-3.6562e+00,  5.6641e+00, -3.3242e+00],\n",
      "       [-1.4863e+00,  3.2344e+00, -2.3125e+00],\n",
      "       [-3.8750e+00,  6.0312e+00, -3.3340e+00],\n",
      "       [-4.1094e+00,  6.1562e+00, -3.1309e+00],\n",
      "       [-4.2109e+00,  5.6758e+00, -2.8086e+00],\n",
      "       [-5.3086e+00,  5.5430e+00, -1.7461e+00],\n",
      "       [-4.2422e+00,  6.0820e+00, -3.0664e+00],\n",
      "       [-4.3164e+00,  5.8867e+00, -2.8672e+00],\n",
      "       [-4.2031e+00,  6.0391e+00, -3.0605e+00],\n",
      "       [-4.5820e+00,  5.8398e+00, -2.5000e+00],\n",
      "       [-4.4492e+00,  6.0586e+00, -2.9082e+00],\n",
      "       [-2.1777e+00,  4.6289e-01,  1.3887e+00],\n",
      "       [-3.4512e+00,  6.0430e+00, -3.6309e+00],\n",
      "       [-4.1836e+00,  5.9531e+00, -3.0957e+00],\n",
      "       [-3.5371e+00,  2.3425e-01,  2.7285e+00],\n",
      "       [-3.5547e+00,  5.6797e+00, -3.1406e+00],\n",
      "       [-5.1758e+00,  2.7324e+00,  1.0049e+00],\n",
      "       [-4.9336e+00,  5.7852e+00, -2.3398e+00],\n",
      "       [-4.4844e+00,  5.9258e+00, -2.8066e+00],\n",
      "       [-4.2812e+00,  6.0430e+00, -3.0391e+00],\n",
      "       [-4.7305e+00,  5.8984e+00, -2.6074e+00],\n",
      "       [-4.0664e+00,  6.0820e+00, -3.2500e+00],\n",
      "       [-4.9453e+00,  5.3711e+00, -1.9414e+00],\n",
      "       [-4.5625e+00,  5.8672e+00, -2.7031e+00],\n",
      "       [-1.0352e+00,  3.0449e+00, -2.7969e+00],\n",
      "       [ 4.3711e+00, -1.0176e+00, -2.9512e+00],\n",
      "       [-4.6016e+00,  5.8164e+00, -2.4160e+00],\n",
      "       [-2.3379e+00,  3.5938e+00, -2.4590e+00],\n",
      "       [-4.7773e+00,  5.8594e+00, -2.4961e+00],\n",
      "       [-4.8438e+00,  5.7500e+00, -2.3359e+00],\n",
      "       [-4.2266e+00,  5.5938e+00, -2.8535e+00],\n",
      "       [ 6.0781e+00, -8.4961e-01, -4.2695e+00],\n",
      "       [ 5.9922e+00, -3.0488e+00, -1.9297e+00],\n",
      "       [-3.8574e+00, -2.1992e+00,  5.6250e+00],\n",
      "       [-4.1836e+00,  6.0859e+00, -3.1602e+00],\n",
      "       [-3.5996e+00, -9.2041e-01,  4.6680e+00],\n",
      "       [-4.7891e+00,  6.0196e-03,  4.2148e+00],\n",
      "       [-3.7969e+00,  6.0859e+00, -3.3594e+00],\n",
      "       [ 4.4961e+00, -3.0371e+00, -6.7090e-01],\n",
      "       [-5.4688e+00,  4.5156e+00, -6.6699e-01],\n",
      "       [ 5.9922e+00, -1.4688e+00, -3.8125e+00],\n",
      "       [ 2.9375e+00,  9.4434e-01, -4.1094e+00],\n",
      "       [-4.3086e+00,  6.0195e+00, -2.9941e+00],\n",
      "       [-4.8867e+00,  5.1680e+00, -1.8545e+00],\n",
      "       [-4.4844e+00,  5.9570e+00, -2.7676e+00],\n",
      "       [-4.2656e+00,  5.8984e+00, -2.9844e+00],\n",
      "       [-4.1836e+00,  6.0664e+00, -3.0410e+00],\n",
      "       [-4.2422e+00,  6.0742e+00, -3.0898e+00],\n",
      "       [-4.4766e+00,  6.0117e+00, -2.8867e+00],\n",
      "       [-4.5000e+00,  5.9766e+00, -2.7949e+00],\n",
      "       [-3.5293e+00,  5.8711e+00, -3.4980e+00],\n",
      "       [-4.7891e+00,  5.6914e+00, -2.3516e+00],\n",
      "       [ 2.3711e+00, -2.3164e+00,  8.6377e-01],\n",
      "       [ 6.3828e+00, -1.7158e+00, -3.7676e+00],\n",
      "       [ 1.6388e-02,  3.9966e-01, -9.0674e-01],\n",
      "       [ 6.1797e+00, -2.1328e+00, -2.8379e+00],\n",
      "       [-4.5547e+00,  6.0898e+00, -2.8066e+00],\n",
      "       [ 5.2812e+00, -3.5684e+00, -8.2178e-01],\n",
      "       [-3.5059e+00,  5.1250e+00, -2.8691e+00],\n",
      "       [-4.3047e+00,  5.7188e+00, -2.8945e+00],\n",
      "       [-4.1016e+00,  5.9297e+00, -3.1035e+00],\n",
      "       [-3.2734e+00,  5.6523e+00, -3.5859e+00],\n",
      "       [ 3.8257e-01,  2.3535e+00, -3.8164e+00],\n",
      "       [-4.4766e+00,  5.9492e+00, -2.8379e+00],\n",
      "       [ 3.3574e+00, -3.8145e+00,  1.5156e+00],\n",
      "       [-3.9102e+00,  5.6875e+00, -3.0195e+00],\n",
      "       [-3.0449e+00,  5.2188e+00, -3.2266e+00],\n",
      "       [-4.8516e+00,  5.9375e+00, -2.4453e+00],\n",
      "       [-4.2344e+00,  6.0547e+00, -3.0898e+00],\n",
      "       [-5.0430e+00,  5.1211e+00, -1.3691e+00],\n",
      "       [-3.6816e+00,  5.9141e+00, -3.3633e+00],\n",
      "       [ 5.9609e+00, -1.5283e+00, -3.4551e+00],\n",
      "       [-2.4512e+00,  5.7227e+00, -4.1758e+00],\n",
      "       [ 1.3477e+00,  3.8770e+00, -5.5625e+00],\n",
      "       [ 4.9922e+00, -1.9067e-01, -4.3438e+00],\n",
      "       [-2.0996e+00,  4.1992e+00, -3.1758e+00],\n",
      "       [ 6.1211e+00, -1.2910e+00, -4.0508e+00],\n",
      "       [-1.4736e+00, -3.4121e+00,  4.7422e+00],\n",
      "       [-4.6484e+00,  1.0273e+00,  2.4961e+00],\n",
      "       [-4.0508e+00,  6.1211e+00, -3.2207e+00],\n",
      "       [-4.1016e+00,  6.0156e+00, -3.0547e+00],\n",
      "       [-4.5234e+00,  6.0000e+00, -2.8262e+00],\n",
      "       [-4.4414e+00,  5.8203e+00, -2.8594e+00],\n",
      "       [-4.5039e+00,  6.0508e+00, -2.8398e+00],\n",
      "       [-4.7461e+00,  4.7461e+00, -1.6865e+00],\n",
      "       [-4.7891e+00,  5.7227e+00, -2.2168e+00],\n",
      "       [-4.4922e+00,  6.0742e+00, -2.7676e+00],\n",
      "       [-4.8359e+00,  4.5078e+00, -1.1465e+00],\n",
      "       [ 6.4219e+00, -1.8965e+00, -3.5898e+00],\n",
      "       [-4.1953e+00,  6.0781e+00, -3.0820e+00],\n",
      "       [-3.8105e+00,  4.5469e+00, -2.3965e+00],\n",
      "       [-5.4375e+00,  5.4570e+00, -1.5811e+00],\n",
      "       [-1.6113e+00,  4.7227e+00, -4.2617e+00],\n",
      "       [-4.5898e+00, -8.4180e-01,  4.7500e+00],\n",
      "       [-4.4883e+00,  6.0586e+00, -2.8145e+00],\n",
      "       [-4.2461e+00,  6.0312e+00, -3.0195e+00],\n",
      "       [ 1.0382e-01, -2.8691e+00,  2.6426e+00],\n",
      "       [-4.7344e+00,  5.9883e+00, -2.5957e+00],\n",
      "       [-4.8203e+00,  5.9062e+00, -2.4180e+00],\n",
      "       [-4.8203e+00,  1.3857e+00,  2.4707e+00],\n",
      "       [-4.3828e+00,  6.0664e+00, -2.9492e+00],\n",
      "       [-4.8828e+00,  5.5312e+00, -2.1719e+00],\n",
      "       [-4.2031e+00,  6.0742e+00, -3.0234e+00],\n",
      "       [-4.4141e+00,  6.0078e+00, -2.9883e+00],\n",
      "       [-4.7461e+00,  5.7617e+00, -2.5098e+00],\n",
      "       [-3.2227e+00, -2.1973e+00,  4.9492e+00],\n",
      "       [-3.9531e+00,  6.1289e+00, -3.3164e+00],\n",
      "       [-4.9414e+00,  5.8047e+00, -2.3379e+00],\n",
      "       [-4.3516e+00,  6.0156e+00, -2.8418e+00],\n",
      "       [ 5.3359e+00, -2.2773e+00, -2.2129e+00],\n",
      "       [ 2.0605e+00, -7.0264e-01, -1.4365e+00],\n",
      "       [-4.2930e+00,  5.7812e+00, -2.8633e+00],\n",
      "       [-4.3438e+00,  6.0625e+00, -2.9668e+00],\n",
      "       [-4.3008e+00,  5.9453e+00, -2.9844e+00],\n",
      "       [-3.5039e+00,  6.0508e+00, -3.5137e+00],\n",
      "       [-4.2461e+00,  6.0820e+00, -3.0645e+00],\n",
      "       [-4.2344e+00,  5.7578e+00, -2.9160e+00],\n",
      "       [-4.0625e+00,  6.0859e+00, -3.2441e+00],\n",
      "       [-2.9082e+00,  5.7969e+00, -3.7734e+00],\n",
      "       [-4.0352e+00,  5.9453e+00, -3.1719e+00],\n",
      "       [-4.0039e+00,  6.1289e+00, -3.2656e+00],\n",
      "       [ 4.6602e+00, -3.7344e+00, -2.0923e-01],\n",
      "       [-1.0508e+00, -2.6289e+00,  3.5195e+00],\n",
      "       [ 3.8027e+00, -3.0059e+00,  4.6265e-01],\n",
      "       [-4.1562e+00,  6.1055e+00, -3.1582e+00],\n",
      "       [-5.7070e+00,  3.7832e+00,  4.4434e-01],\n",
      "       [-3.7012e+00,  6.0273e+00, -3.3145e+00],\n",
      "       [ 5.2422e+00, -2.1914e+00, -1.9111e+00]], dtype=float16), label_ids=array([1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 2, 2, 1, 2, 1, 1, 2, 2,\n",
      "       1, 2, 0, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 0, 2, 1, 1,\n",
      "       1, 2, 1, 1, 1, 0, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 0, 2, 1, 2, 0,\n",
      "       1, 1, 0, 0, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       0, 2, 1, 2, 0, 1, 1, 1, 1, 1, 1, 2, 0, 2, 1, 2, 1, 1, 1, 2, 1, 1,\n",
      "       2, 1, 2, 1, 2, 1, 1, 1, 0, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 2, 1, 2, 1, 1, 1, 2, 0, 2, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2,\n",
      "       1, 1, 1, 2, 1, 0, 0, 0, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1,\n",
      "       1, 0, 1, 1, 1, 1, 0, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 0, 2, 1, 1, 1,\n",
      "       1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 0, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 0]), metrics={'test_loss': 2.275658130645752, 'test_accuracy': 0.6837606837606838, 'test_balanced_accuracy': 0.5546942618952971, 'test_precision': 0.6579420579420578, 'test_recall': 0.6837606837606838, 'test_f1': 0.650334491981505, 'test_runtime': 1.2825, 'test_samples_per_second': 182.452, 'test_steps_per_second': 6.238})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be81d0c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "probabilities = torch.softmax(torch.tensor(test_results.predictions).to(torch.float32), dim=-1)\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)\n",
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef4c67fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_save = []\n",
    "for idx in range(len(test_data)):\n",
    "    item = dataset['test'][idx]\n",
    "    actual_label = item['label']\n",
    "    predicted_label = predictions[idx]\n",
    "    claim = item['claim'] \n",
    "    premise = item['premise'] \n",
    "    category = item['category']\n",
    "    \n",
    "    # Append the information as a dictionary to the list\n",
    "    data_to_save.append({\n",
    "        'Claim': claim,\n",
    "        'Premise': premise,\n",
    "        'Actual Label': actual_label,\n",
    "        'Predicted Label': predicted_label,\n",
    "        'Category' : category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_to_save)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/home/elson/results/1.2.5_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a1a63a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correctly classified instances\n",
    "correctly_classified = df[df['Actual Label'] == df['Predicted Label']]\n",
    "\n",
    "# Calculate misclassified instances\n",
    "misclassified = df[df['Actual Label'] != df['Predicted Label']]\n",
    "\n",
    "# Count the number of correctly classified and misclassified by category\n",
    "correct_classification_counts = correctly_classified['Category'].value_counts()\n",
    "misclassification_counts = misclassified['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c4055e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           33\n",
       "Bone health              15\n",
       "Fitness                  14\n",
       "Cancer                   12\n",
       "Skin                     12\n",
       "Cardiovascular Health    11\n",
       "Diabetes                  9\n",
       "Neurological health       9\n",
       "Throat                    9\n",
       "Eye                       8\n",
       "Ear                       6\n",
       "Hair                      6\n",
       "Women' s Health           4\n",
       "Blood                     4\n",
       "Men's health              3\n",
       "Mental Health             2\n",
       "Muscles                   1\n",
       "Vascular                  1\n",
       "Dental Health             1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "117a1d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           18\n",
       "Skin                     12\n",
       "Bone health               6\n",
       "Hair                      6\n",
       "COVID                     6\n",
       "Muscles                   5\n",
       "Blood                     5\n",
       "Diabetes                  3\n",
       "Men's health              3\n",
       "Vascular                  2\n",
       "Women' s Health           2\n",
       "Dental Health             2\n",
       "Eye                       1\n",
       "Cardiovascular Health     1\n",
       "Fitness                   1\n",
       "Mental Health             1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
