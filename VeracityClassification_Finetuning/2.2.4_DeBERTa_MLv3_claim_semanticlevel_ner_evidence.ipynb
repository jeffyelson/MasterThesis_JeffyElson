{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ea42692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elson/factcheck/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score,balanced_accuracy_score\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict, ClassLabel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82806f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jul 29 19:45:35 2024       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:61:00.0 Off |                    0 |\r\n",
      "| N/A   42C    P0    56W / 300W |      0MiB / 32768MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla V100-SXM2...  Off  | 00000000:62:00.0 Off |                    0 |\r\n",
      "| N/A   61C    P0   228W / 300W |  25522MiB / 32768MiB |     99%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   2  Tesla V100-SXM2...  Off  | 00000000:89:00.0 Off |                    0 |\r\n",
      "| N/A   41C    P0    60W / 300W |      0MiB / 32768MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   3  Tesla V100-SXM2...  Off  | 00000000:8A:00.0 Off |                    0 |\r\n",
      "| N/A   41C    P0    59W / 300W |      0MiB / 32768MiB |      2%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    1   N/A  N/A     39308      C   ...son/factcheck/bin/python3    25519MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d65ca0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-31dfe7adddcf5ced\n",
      "Reusing dataset csv (/home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58)\n",
      "100%|██████████| 1/1 [00:00<00:00, 228.41it/s]\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-ad71be204b279b28.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-e7b6b615907c24ca.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-bee802838a3bfaea.arrow\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset from the CSV file\n",
    "dataset = load_dataset(\n",
    "    'csv',\n",
    "    data_files='dataset_semanticattribution_nerfeatures_split.csv',\n",
    "    delimiter=',',\n",
    "    column_names=[\n",
    "        \"claim\", \"premise\", \"label\", \"category\", \"count_bf\", \"count_ca\", \"count_dis\",\n",
    "        \"count_food\", \"count_lipid\", \"count_treat\", \"pres_bf\", \"pres_ca\", \"pres_dis\",\n",
    "        \"pres_food\", \"pres_lipid\", \"pres_treat\", \"counte_bf\", \"counte_ca\", \"counte_dis\",\n",
    "        \"counte_food\", \"counte_lipid\", \"counte_treat\", \"prese_bf\", \"prese_ca\", \"prese_dis\",\n",
    "        \"prese_food\", \"prese_lipid\", \"prese_treat\", \"url\", \"entities\", \"entity_map\",\n",
    "        \"gold_exp\", \"gemini_exp\", \"gemini_label\",\"entity_ev\",\"entity_map_ev\", \"split\"\n",
    "    ],\n",
    "    skiprows=1\n",
    ")\n",
    "\n",
    "# Assuming 'split' column contains strings 'train', 'validation', 'test'\n",
    "# Filter the loaded dataset into subsets\n",
    "train_dataset = dataset['train'].filter(lambda example: example['split'] == 'train')\n",
    "validation_dataset = dataset['train'].filter(lambda example: example['split'] == 'validation')\n",
    "test_dataset = dataset['train'].filter(lambda example: example['split'] == 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d368dccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category', 'count_bf', 'count_ca', 'count_dis', 'count_food', 'count_lipid', 'count_treat', 'pres_bf', 'pres_ca', 'pres_dis', 'pres_food', 'pres_lipid', 'pres_treat', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat', 'url', 'entities', 'entity_map', 'gold_exp', 'gemini_exp', 'gemini_label', 'entity_ev', 'entity_map_ev', 'split'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f3e71be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': validation_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41f1db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = ['claim', 'premise', 'label','category','counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat']\n",
    "all_columns = train_dataset.column_names\n",
    "\n",
    "columns_to_drop = [col for col in all_columns if col not in columns_to_keep]\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].remove_columns(columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae50f599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-192f7cd55308f437.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-628e09c96e321cd1.arrow\n",
      "Loading cached processed dataset at /home/elson/.cache/huggingface/datasets/csv/default-31dfe7adddcf5ced/0.0.0/51cce309a08df9c4d82ffd9363bbe090bf173197fc01a71b034e8594995a1a58/cache-1df942f735662e2b.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Encoding Mapping: {'contradiction': 0, 'entailment': 1, 'neutral': 2}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "label2id = {\n",
    "    \"contradiction\": 0,\n",
    "    \"entailment\": 1,\n",
    "    \"neutral\": 2\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "label_mapping = {\n",
    "    'SUPPORTED': 'entailment',\n",
    "    'REFUTED': 'contradiction',\n",
    "    'NOT ENOUGH INFORMATION': 'neutral'\n",
    "}\n",
    "\n",
    "def map_and_encode_labels(example):\n",
    "    # Map original dataset labels to new labels ('entailment', 'contradiction', 'neutral')\n",
    "    mapped_label = label_mapping[example['label']]\n",
    "    # Encode mapped labels using label2id\n",
    "    example['label'] = label2id[mapped_label]\n",
    "    return example\n",
    "\n",
    "for split in dataset.keys():\n",
    "    dataset[split] = dataset[split].map(map_and_encode_labels)\n",
    "\n",
    "\n",
    "# Show the label encoding mapping\n",
    "print(\"Label Encoding Mapping:\", label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b5bb17f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "465"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset['val']['claim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7095b2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(dataset['train']['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b93ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import torch.utils.data\n",
    "\n",
    "class MediClaimDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer_name='MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli'):\n",
    "        self.dataset = dataset\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        idx = int(idx)  # Ensure idx is an integer\n",
    "        item = self.dataset[idx]  # Access the dataset item at idx\n",
    "        \n",
    "        # Extracting claim and evidence texts\n",
    "        category = item['category'].lower()\n",
    "\n",
    "        claim = item['claim'].lower() + \"[\" + category + \"]\"\n",
    "        premise = item['premise'].lower().replace('\\n', '').replace('[','').replace(']','')\n",
    "        additional_features = [\n",
    "            'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat']\n",
    "    \n",
    "        for feature in additional_features:\n",
    "            if feature in item:\n",
    "                premise += \"[SEP]\" + str(item[feature])\n",
    "        item['claim']=claim\n",
    "        item['premise']=premise        \n",
    "        # Tokenize the texts\n",
    "        inputs = self.tokenizer(\n",
    "             premise, claim,\n",
    "            return_tensors=\"pt\",  # Ensure PyTorch tensors are returned\n",
    "            padding='max_length',  # Apply padding to the maximum length\n",
    "            truncation='longest_first',  # Truncate to the maximum length if necessary\n",
    "            max_length=512,  # Specify the maximum length\n",
    "            add_special_tokens=True  # Add special tokens like [CLS], [SEP]\n",
    "        )\n",
    "        \n",
    "        item['input_ids'] = inputs['input_ids'].squeeze()  # Remove batch dimension\n",
    "        item['attention_mask']= inputs['attention_mask'].squeeze() # Remove batch dimension\n",
    "        \n",
    "        output_item = {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),  # Remove batch dimension\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),  # Remove batch dimension\n",
    "            'claim': claim,  # Include augmented claim text\n",
    "            'evidences': premise  # Include original evidence text\n",
    "        }\n",
    "        \n",
    "        if 'label' in item:\n",
    "            output_item['label'] = torch.tensor(item['label'], dtype=torch.long)\n",
    "        \n",
    "        return output_item\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5a24af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Available GPUs:\n",
      "GPU 0: Tesla V100-SXM2-32GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())\n",
    "print(\"Available GPUs:\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62421eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name,\n",
    "                                 num_labels=3, ignore_mismatched_sizes=True)\n",
    "device = \"cuda:0\"\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f72c5df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model is on device: {next(model.parameters()).device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "377ee0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    prec = precision_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "    recall = recall_score(labels, preds, average=\"weighted\")  # Specify average method\n",
    "\n",
    "    bal_accuracy = balanced_accuracy_score(labels,preds)\n",
    "\n",
    "    return {\"accuracy\": acc, \"balanced_accuracy\":bal_accuracy, \"precision\": prec, \"recall\": recall, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd17ef30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['claim', 'premise', 'label', 'category', 'counte_bf', 'counte_ca', 'counte_dis', 'counte_food', 'counte_lipid', 'counte_treat', 'prese_bf', 'prese_ca', 'prese_dis', 'prese_food', 'prese_lipid', 'prese_treat'],\n",
       "    num_rows: 1623\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63c2b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "# Clearing the cache\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "# Checking GPU memory, making sure to reset peak memory stats\n",
    "torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6efe88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current CUDA device: GPU 0\n"
     ]
    }
   ],
   "source": [
    "current_device = torch.cuda.current_device()\n",
    "print(f\"Current CUDA device: GPU {current_device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "614620f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset['train']\n",
    "eval_data = dataset['val']\n",
    "model = model.to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3f97ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = MediClaimDataset(train_data)\n",
    "vdata = MediClaimDataset(eval_data)\n",
    "test_data = MediClaimDataset(dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17c5e0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([     1,   2600,   1655,  16876,    667,  15726,  61593,    261,   2030,\n",
       "            260,    346,  15302,   6848,  15726,  61593,    261,    584,    260,\n",
       "            346,  33770,    452,  15726,  61593,  16876,    667,  15726,  61593,\n",
       "            261,    845,    260,    346,  14033,   2179,  24360,  34984,  15726,\n",
       "          61593,    261,   1917,    260,    346,  51194,  73907,   8007,  15726,\n",
       "          61593,    261,   2673,    260,    346,   1942,   3359,  73907,   8007,\n",
       "          15726,  61593,    261,   4402,    260,  88609,    263,  98237,   1830,\n",
       "           6725,    263,   5134,  30055,  77487,    532,   4014,    271,    547,\n",
       "          52263,  16224,    265,  86207,  14178,    268,    260,  62713,   4379,\n",
       "            261,    584,    260,  41529,  23399,    429,   8068,   1068,    268,\n",
       "            265,  42543,    834,   1917, 110269,    287,    260, 116367,   2148,\n",
       "            263,  25348,  20413,   1563,    265,    917,    263,    308,    266,\n",
       "          84530,  62542,    275,  98237,    287,    549,   6177,  65073,  44845,\n",
       "          22317,    285,  36774,    260,  30689,   6725,    294,   6162,   2731,\n",
       "            270,   1158,    599,    260,  46362,  41546,  71547,    261,   2030,\n",
       "            260,    346,  10918,    436,  80984,    261,   2285,    260,    346,\n",
       "            266,  46177,  28220,    261,   4402,    260,    346,  56545,  15150,\n",
       "            261,   2673,    260,    346,  95311,    261,   1917,    260,  54761,\n",
       "           1856,    293,   1008,    633,    294,   2285,    260,  98237,    452,\n",
       "           1080,   4796,  18839,    260,   5720,   4765,  39151,    261,   3638,\n",
       "            260,    346,  11965,   4765,  39151,    261,   1550,    260,    346,\n",
       "          11965,   4765,  39151,    261,   1917,    260,    346,  93607,  60641,\n",
       "            261,   1917,    260,  88609,    287,  15726,   2209,   5858,  25499,\n",
       "           3004,   3638,  27197,    318,  58813,  15726,    198,    133,   5900,\n",
       "            346,    260,  43427,    285,    294,    292,    262,   1857,    265,\n",
       "           1471,   1567,    264,    262,   2626,  41529,  28479,    270,    262,\n",
       "           5937,    263,   1035,    265,   1721,   4253,    260,  35753,    263,\n",
       "         121470,   1506,    265,  88609,   1080,    260,  99352,    268,   4086,\n",
       "          75371,   4191,   2767,  15808,    260,    346,  62510,    261,    865,\n",
       "            260,  88609,    263,  98237,    283,  11882,    267,    572,    260,\n",
       "              2,    767,      2,    767,      2,    767,      2,    767,      2,\n",
       "            767,      2,    767,      2,    767,      2,    767,      2,    767,\n",
       "              2,    767,      2,    767,      2,    767,      2,  98237,   1830,\n",
       "           1080,    269,   1359,    427,    267,  17847,    633,    264,    408,\n",
       "           1300,    262,   2658,    265,    262,   1158,    260,   2550,  21428,\n",
       "            622,    592,      2,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
       "              0,      0,      0,      0,      0,      0,      0,      0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'claim': 'myrrh essential oil is sometimes used in skincare products to help improve the appearance of the skin.[general health]',\n",
       " 'evidences': '; unkoviä‡, n.; dimkiä‡, i.; janaä‡koviä‡, p.; gavriloviä‡, m.; stanojeviä‡, o.; vukojeviä‡, j. frankincense and myrrh essential oils and burn incense fume against micro-inhabitants of sacral ambients.shameem, i. phytochemical & therapeutic potentials of murr makki (.oxidative stress and immunotoxic effects of lead and their amelioration with myrrh (commiphora molmol) emulsion.essential oils: magical ingredients for skin care.chakravarty, n.; kellogg, c.; alvarez, j.; equils, o.; morgan, m. uv protection by natural products: c. myrrha oil versus sunscreen.hamidpour, r.; hamidpour, s.; hamidpour, m.; shahlari, m. frankincense (ä¹³é¦™ rç” xiä\\x81ng;.species): from the selection of traditional applications to the novel phytotherapy for the prevention and treatment of serious diseases.chemistry and immunomodulatory activity of frankincense oil.compositions containing boswellia extracts.; cooper, e. frankincense and myrrh as remedies in children.[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0[SEP]0',\n",
       " 'label': tensor(1)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f4cd4c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n",
      "/home/elson/factcheck/lib/python3.6/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 1623\n",
      "  Num Epochs = 15\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on device: cuda:0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1530' max='1530' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1530/1530 12:36, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.785600</td>\n",
       "      <td>0.830763</td>\n",
       "      <td>0.686022</td>\n",
       "      <td>0.409479</td>\n",
       "      <td>0.658793</td>\n",
       "      <td>0.686022</td>\n",
       "      <td>0.608740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.554500</td>\n",
       "      <td>0.957075</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.522457</td>\n",
       "      <td>0.675821</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.655561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.408300</td>\n",
       "      <td>1.121595</td>\n",
       "      <td>0.623656</td>\n",
       "      <td>0.497029</td>\n",
       "      <td>0.658601</td>\n",
       "      <td>0.623656</td>\n",
       "      <td>0.638566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.201800</td>\n",
       "      <td>1.419068</td>\n",
       "      <td>0.660215</td>\n",
       "      <td>0.477465</td>\n",
       "      <td>0.653174</td>\n",
       "      <td>0.660215</td>\n",
       "      <td>0.653506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.226900</td>\n",
       "      <td>1.481661</td>\n",
       "      <td>0.653763</td>\n",
       "      <td>0.503955</td>\n",
       "      <td>0.670282</td>\n",
       "      <td>0.653763</td>\n",
       "      <td>0.660856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.103300</td>\n",
       "      <td>1.698185</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>0.506377</td>\n",
       "      <td>0.670254</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>0.644455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.083700</td>\n",
       "      <td>2.132897</td>\n",
       "      <td>0.636559</td>\n",
       "      <td>0.495408</td>\n",
       "      <td>0.659698</td>\n",
       "      <td>0.636559</td>\n",
       "      <td>0.646957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.153300</td>\n",
       "      <td>2.372413</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.501332</td>\n",
       "      <td>0.653391</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.645100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.043100</td>\n",
       "      <td>2.543519</td>\n",
       "      <td>0.634409</td>\n",
       "      <td>0.482636</td>\n",
       "      <td>0.643346</td>\n",
       "      <td>0.634409</td>\n",
       "      <td>0.637329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>2.700744</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.497400</td>\n",
       "      <td>0.662377</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.651057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>2.752353</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.507992</td>\n",
       "      <td>0.658584</td>\n",
       "      <td>0.651613</td>\n",
       "      <td>0.654974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>2.902422</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.499827</td>\n",
       "      <td>0.653876</td>\n",
       "      <td>0.643011</td>\n",
       "      <td>0.648128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>2.894879</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.484057</td>\n",
       "      <td>0.645894</td>\n",
       "      <td>0.638710</td>\n",
       "      <td>0.642125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>2.926652</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.508386</td>\n",
       "      <td>0.659947</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.654426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>2.942237</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.505710</td>\n",
       "      <td>0.660204</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.654481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.2.4_deberta/checkpoint-102\n",
      "Configuration saved in /home/elson/2.2.4_deberta/checkpoint-102/config.json\n",
      "Model weights saved in /home/elson/2.2.4_deberta/checkpoint-102/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.2.4_deberta/checkpoint-204\n",
      "Configuration saved in /home/elson/2.2.4_deberta/checkpoint-204/config.json\n",
      "Model weights saved in /home/elson/2.2.4_deberta/checkpoint-204/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.2.4_deberta/checkpoint-306\n",
      "Configuration saved in /home/elson/2.2.4_deberta/checkpoint-306/config.json\n",
      "Model weights saved in /home/elson/2.2.4_deberta/checkpoint-306/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.4_deberta/checkpoint-204] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.2.4_deberta/checkpoint-408\n",
      "Configuration saved in /home/elson/2.2.4_deberta/checkpoint-408/config.json\n",
      "Model weights saved in /home/elson/2.2.4_deberta/checkpoint-408/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.4_deberta/checkpoint-306] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.2.4_deberta/checkpoint-510\n",
      "Configuration saved in /home/elson/2.2.4_deberta/checkpoint-510/config.json\n",
      "Model weights saved in /home/elson/2.2.4_deberta/checkpoint-510/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.4_deberta/checkpoint-408] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.2.4_deberta/checkpoint-612\n",
      "Configuration saved in /home/elson/2.2.4_deberta/checkpoint-612/config.json\n",
      "Model weights saved in /home/elson/2.2.4_deberta/checkpoint-612/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.4_deberta/checkpoint-510] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.2.4_deberta/checkpoint-714\n",
      "Configuration saved in /home/elson/2.2.4_deberta/checkpoint-714/config.json\n",
      "Model weights saved in /home/elson/2.2.4_deberta/checkpoint-714/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.4_deberta/checkpoint-612] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.2.4_deberta/checkpoint-816\n",
      "Configuration saved in /home/elson/2.2.4_deberta/checkpoint-816/config.json\n",
      "Model weights saved in /home/elson/2.2.4_deberta/checkpoint-816/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.4_deberta/checkpoint-714] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.2.4_deberta/checkpoint-918\n",
      "Configuration saved in /home/elson/2.2.4_deberta/checkpoint-918/config.json\n",
      "Model weights saved in /home/elson/2.2.4_deberta/checkpoint-918/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.4_deberta/checkpoint-816] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.2.4_deberta/checkpoint-1020\n",
      "Configuration saved in /home/elson/2.2.4_deberta/checkpoint-1020/config.json\n",
      "Model weights saved in /home/elson/2.2.4_deberta/checkpoint-1020/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.4_deberta/checkpoint-918] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.2.4_deberta/checkpoint-1122\n",
      "Configuration saved in /home/elson/2.2.4_deberta/checkpoint-1122/config.json\n",
      "Model weights saved in /home/elson/2.2.4_deberta/checkpoint-1122/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.4_deberta/checkpoint-1020] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.2.4_deberta/checkpoint-1224\n",
      "Configuration saved in /home/elson/2.2.4_deberta/checkpoint-1224/config.json\n",
      "Model weights saved in /home/elson/2.2.4_deberta/checkpoint-1224/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.4_deberta/checkpoint-1122] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.2.4_deberta/checkpoint-1326\n",
      "Configuration saved in /home/elson/2.2.4_deberta/checkpoint-1326/config.json\n",
      "Model weights saved in /home/elson/2.2.4_deberta/checkpoint-1326/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.4_deberta/checkpoint-1224] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.2.4_deberta/checkpoint-1428\n",
      "Configuration saved in /home/elson/2.2.4_deberta/checkpoint-1428/config.json\n",
      "Model weights saved in /home/elson/2.2.4_deberta/checkpoint-1428/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.4_deberta/checkpoint-1326] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to /home/elson/2.2.4_deberta/checkpoint-1530\n",
      "Configuration saved in /home/elson/2.2.4_deberta/checkpoint-1530/config.json\n",
      "Model weights saved in /home/elson/2.2.4_deberta/checkpoint-1530/pytorch_model.bin\n",
      "Deleting older checkpoint [/home/elson/2.2.4_deberta/checkpoint-1428] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from /home/elson/2.2.4_deberta/checkpoint-102 (score: 0.6860215053763441).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 465\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /home/elson/2.2.4_deberta/best_model/config.json\n",
      "Model weights saved in /home/elson/2.2.4_deberta/best_model/pytorch_model.bin\n",
      "tokenizer config file saved in /home/elson/2.2.4_deberta/best_model/tokenizer_config.json\n",
      "Special tokens file saved in /home/elson/2.2.4_deberta/best_model/special_tokens_map.json\n",
      "added tokens file saved in /home/elson/2.2.4_deberta/best_model/added_tokens.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/home/elson/2.2.4_deberta/best_model/tokenizer_config.json',\n",
       " '/home/elson/2.2.4_deberta/best_model/special_tokens_map.json',\n",
       " '/home/elson/2.2.4_deberta/best_model/spm.model',\n",
       " '/home/elson/2.2.4_deberta/best_model/added_tokens.json')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback, Trainer, TrainingArguments,DataCollatorWithPadding\n",
    "\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding=True)\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=f'/home/elson/2.2.4_deberta/',\n",
    "    num_train_epochs=15,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    dataloader_pin_memory=True,\n",
    "    dataloader_num_workers=4,\n",
    "    fp16=True,\n",
    "    warmup_ratio=0.06,\n",
    "    weight_decay=0.1,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model.to(\"cuda:0\"),\n",
    "    args=training_args,\n",
    "    train_dataset=tdata,\n",
    "    eval_dataset=vdata,\n",
    "    #tokenizer=tokenizer,\n",
    "    #data_collator = data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.01)]\n",
    ")\n",
    "print(f\"Model is on device: {next(model.parameters()).device}\")\n",
    "# Training and Evaluation\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate(vdata)\n",
    "\n",
    "# Save the best model and tokenizer\n",
    "model.save_pretrained(f'/home/elson/2.2.4_deberta/best_model')\n",
    "tokenizer.save_pretrained(f'/home/elson/2.2.4_deberta/best_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cdee1665",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file /home/elson/2.2.4_deberta/best_model/config.json\n",
      "Model config DebertaV2Config {\n",
      "  \"_name_or_path\": \"/home/elson/2.2.4_deberta/best_model/\",\n",
      "  \"architectures\": [\n",
      "    \"DebertaV2ForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"entailment\",\n",
      "    \"1\": \"neutral\",\n",
      "    \"2\": \"contradiction\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"contradiction\": 2,\n",
      "    \"entailment\": 0,\n",
      "    \"neutral\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 768,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n",
      "loading weights file /home/elson/2.2.4_deberta/best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing DebertaV2ForSequenceClassification.\n",
      "\n",
      "All the weights of DebertaV2ForSequenceClassification were initialized from the model checkpoint at /home/elson/2.2.4_deberta/best_model/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DebertaV2ForSequenceClassification for predictions without further training.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 234\n",
      "  Batch size = 16\n"
     ]
    }
   ],
   "source": [
    "model_path = \"/home/elson/2.2.4_deberta/best_model/\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path).to('cuda:0')\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_results = trainer.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a7b8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PredictionOutput(predictions=array([[-6.5820e-01,  1.2285e+00, -6.3721e-01],\n",
      "       [-1.5488e+00,  2.1699e+00, -6.6211e-01],\n",
      "       [-1.5498e+00,  2.4805e+00, -9.7705e-01],\n",
      "       [-5.2100e-01,  1.4580e+00, -1.0195e+00],\n",
      "       [-7.1484e-01,  1.6895e+00, -1.0273e+00],\n",
      "       [-1.6758e+00,  2.7734e+00, -1.1934e+00],\n",
      "       [-5.4590e-01,  1.5889e+00, -1.2188e+00],\n",
      "       [-1.6045e+00,  2.4355e+00, -8.7305e-01],\n",
      "       [-1.5791e+00,  2.5410e+00, -9.9561e-01],\n",
      "       [-1.1572e+00,  2.3516e+00, -1.2764e+00],\n",
      "       [-1.3359e+00,  2.3770e+00, -1.1338e+00],\n",
      "       [-8.6475e-01,  1.9795e+00, -1.2500e+00],\n",
      "       [-1.4121e+00,  2.3613e+00, -9.8389e-01],\n",
      "       [-1.7803e+00,  2.7012e+00, -9.8584e-01],\n",
      "       [-1.3262e+00,  2.1777e+00, -9.3311e-01],\n",
      "       [-6.8018e-01,  1.3906e+00, -7.3535e-01],\n",
      "       [-1.6416e+00,  1.8389e+00, -1.7712e-01],\n",
      "       [-1.3584e+00,  1.9004e+00, -5.3564e-01],\n",
      "       [-1.1133e+00,  2.0840e+00, -1.0654e+00],\n",
      "       [-1.1357e+00,  2.0547e+00, -1.0088e+00],\n",
      "       [-1.2646e+00,  2.1289e+00, -9.6143e-01],\n",
      "       [-1.3516e+00,  2.1055e+00, -7.9736e-01],\n",
      "       [-1.4600e+00,  2.1523e+00, -7.3340e-01],\n",
      "       [-1.0577e-01,  5.0049e-01, -5.0293e-01],\n",
      "       [-2.1155e-01,  8.0176e-01, -6.8848e-01],\n",
      "       [-1.8295e-02, -8.7695e-01,  6.8164e-01],\n",
      "       [-8.8916e-01,  2.1816e+00, -1.4404e+00],\n",
      "       [-1.4170e+00,  2.1660e+00, -7.7295e-01],\n",
      "       [-1.6318e+00,  2.3848e+00, -7.9492e-01],\n",
      "       [-8.3984e-01,  2.0156e+00, -1.2900e+00],\n",
      "       [-1.3684e-01,  2.0117e-01, -2.4341e-01],\n",
      "       [-1.6455e+00,  2.6152e+00, -1.0664e+00],\n",
      "       [-1.2256e+00,  2.3594e+00, -1.2520e+00],\n",
      "       [-1.1260e+00,  2.1738e+00, -1.1182e+00],\n",
      "       [-1.3398e+00,  1.9053e+00, -6.3525e-01],\n",
      "       [-1.5771e+00,  2.0566e+00, -4.6875e-01],\n",
      "       [-1.1787e+00,  2.0352e+00, -9.2627e-01],\n",
      "       [-1.0264e+00,  2.0273e+00, -9.7656e-01],\n",
      "       [-3.6084e-01,  1.0537e+00, -7.8271e-01],\n",
      "       [-1.3604e+00,  1.7334e+00, -3.2544e-01],\n",
      "       [-7.7295e-01,  1.3066e+00, -5.8057e-01],\n",
      "       [-1.3545e+00,  2.4062e+00, -1.1240e+00],\n",
      "       [-7.1680e-01,  1.3389e+00, -6.4160e-01],\n",
      "       [-6.3574e-01,  1.3008e+00, -6.7285e-01],\n",
      "       [-1.0781e+00,  1.5938e+00, -6.0938e-01],\n",
      "       [-1.6631e+00,  2.3711e+00, -7.6025e-01],\n",
      "       [-1.8252e+00,  2.5566e+00, -7.7148e-01],\n",
      "       [-1.0273e+00,  1.9336e+00, -9.3311e-01],\n",
      "       [-8.8037e-01,  2.0254e+00, -1.2412e+00],\n",
      "       [ 4.1840e-02,  4.7070e-01, -6.6016e-01],\n",
      "       [-8.5059e-01,  1.5098e+00, -6.9141e-01],\n",
      "       [-1.1475e+00,  2.0469e+00, -9.6240e-01],\n",
      "       [-1.2373e+00,  2.2773e+00, -1.0654e+00],\n",
      "       [-1.3438e+00,  2.2598e+00, -9.9609e-01],\n",
      "       [-1.1387e+00,  1.9414e+00, -8.5986e-01],\n",
      "       [-1.1289e+00,  2.1328e+00, -1.1035e+00],\n",
      "       [-5.3760e-01,  1.1846e+00, -6.8750e-01],\n",
      "       [-1.4375e+00,  2.3242e+00, -9.5947e-01],\n",
      "       [-1.4385e+00,  2.4512e+00, -1.1016e+00],\n",
      "       [-1.1494e+00,  2.1172e+00, -1.0205e+00],\n",
      "       [-8.9844e-01,  1.7129e+00, -8.9844e-01],\n",
      "       [ 1.3672e-01,  5.9961e-01, -8.5303e-01],\n",
      "       [-1.3525e+00,  1.9717e+00, -6.6943e-01],\n",
      "       [-7.8955e-01,  1.8066e+00, -1.0742e+00],\n",
      "       [-1.4033e+00,  1.9463e+00, -5.3418e-01],\n",
      "       [-1.0459e+00,  2.0742e+00, -1.0850e+00],\n",
      "       [-1.5977e+00,  2.5723e+00, -1.0596e+00],\n",
      "       [-1.3174e+00,  2.1816e+00, -9.0918e-01],\n",
      "       [-1.4365e+00,  2.4219e+00, -1.0684e+00],\n",
      "       [-5.9180e-01,  1.3623e+00, -8.6865e-01],\n",
      "       [-1.2861e+00,  1.9883e+00, -7.2021e-01],\n",
      "       [-1.3936e+00,  1.8799e+00, -4.9341e-01],\n",
      "       [-1.3887e+00,  1.7910e+00, -4.2603e-01],\n",
      "       [-1.4941e+00,  2.1641e+00, -6.7871e-01],\n",
      "       [-6.3135e-01,  1.1133e+00, -5.4150e-01],\n",
      "       [-8.3008e-01,  1.6514e+00, -8.4424e-01],\n",
      "       [-7.8467e-01,  1.4531e+00, -6.8213e-01],\n",
      "       [-1.3027e+00,  2.3203e+00, -1.0889e+00],\n",
      "       [-1.2646e+00,  2.3594e+00, -1.1963e+00],\n",
      "       [-5.1758e-01,  1.0859e+00, -6.1621e-01],\n",
      "       [-1.1885e+00,  2.2422e+00, -1.1338e+00],\n",
      "       [-1.5967e+00,  2.4668e+00, -9.2139e-01],\n",
      "       [-1.5312e+00,  2.2461e+00, -7.5146e-01],\n",
      "       [-1.6123e+00,  2.6328e+00, -1.0986e+00],\n",
      "       [-1.6953e+00,  2.5703e+00, -9.3164e-01],\n",
      "       [-3.1006e-01,  1.2725e+00, -1.0645e+00],\n",
      "       [-6.8066e-01,  1.4717e+00, -8.0957e-01],\n",
      "       [-1.6895e+00,  2.5039e+00, -8.3008e-01],\n",
      "       [-1.0527e+00,  1.6338e+00, -6.0791e-01],\n",
      "       [-1.1680e+00,  2.0273e+00, -9.1064e-01],\n",
      "       [-1.4824e+00,  2.4434e+00, -1.0010e+00],\n",
      "       [-1.5264e+00,  2.3848e+00, -8.9746e-01],\n",
      "       [-7.2754e-01,  1.5420e+00, -9.4629e-01],\n",
      "       [-1.0625e+00,  2.0039e+00, -9.9219e-01],\n",
      "       [-1.4678e+00,  2.1016e+00, -6.5918e-01],\n",
      "       [-8.0469e-01,  1.3252e+00, -5.5420e-01],\n",
      "       [-1.0234e+00,  1.9229e+00, -9.4824e-01],\n",
      "       [-1.4990e+00,  2.0762e+00, -5.9082e-01],\n",
      "       [-1.2920e+00,  2.3594e+00, -1.1611e+00],\n",
      "       [-1.1875e+00,  2.0938e+00, -9.6777e-01],\n",
      "       [ 4.6216e-01, -2.5537e-01, -4.2017e-01],\n",
      "       [-1.2822e+00,  2.1504e+00, -9.3311e-01],\n",
      "       [-1.6689e+00,  2.4922e+00, -8.5840e-01],\n",
      "       [-1.4590e+00,  2.1582e+00, -7.2217e-01],\n",
      "       [-2.6050e-01, -1.3782e-01,  2.4719e-01],\n",
      "       [-1.5830e+00,  2.5547e+00, -9.8096e-01],\n",
      "       [-1.8506e+00,  2.6680e+00, -8.2227e-01],\n",
      "       [-2.6758e-01,  8.4863e-01, -6.5967e-01],\n",
      "       [-1.6025e+00,  2.5098e+00, -9.3262e-01],\n",
      "       [-1.5283e+00,  2.5156e+00, -1.0537e+00],\n",
      "       [-1.4492e+00,  2.0508e+00, -6.1523e-01],\n",
      "       [-1.6396e+00,  2.5586e+00, -9.7217e-01],\n",
      "       [-1.6396e+00,  2.3027e+00, -6.9434e-01],\n",
      "       [-6.3232e-01,  1.2930e+00, -6.7383e-01],\n",
      "       [-1.5312e+00,  2.3867e+00, -9.2285e-01],\n",
      "       [-1.4043e+00,  2.4512e+00, -1.0762e+00],\n",
      "       [-9.8242e-01,  2.1230e+00, -1.2598e+00],\n",
      "       [-3.6133e-01,  8.3984e-01, -5.4102e-01],\n",
      "       [-1.4180e+00,  2.3809e+00, -1.0420e+00],\n",
      "       [-1.1943e+00,  2.2578e+00, -1.1592e+00],\n",
      "       [-1.2715e+00,  2.1055e+00, -9.0527e-01],\n",
      "       [-1.4932e+00,  2.4238e+00, -9.7266e-01],\n",
      "       [-1.5361e+00,  2.1836e+00, -7.1582e-01],\n",
      "       [-9.8291e-01,  1.4258e+00, -5.0195e-01],\n",
      "       [-1.2646e+00,  2.2031e+00, -9.8193e-01],\n",
      "       [-1.1953e+00,  2.0918e+00, -9.8926e-01],\n",
      "       [-1.0693e+00,  1.6074e+00, -5.4590e-01],\n",
      "       [-9.8730e-01,  1.9336e+00, -1.0293e+00],\n",
      "       [-1.2227e+00,  1.9717e+00, -7.9199e-01],\n",
      "       [-1.5684e+00,  2.1699e+00, -6.1621e-01],\n",
      "       [-1.0498e+00,  1.9941e+00, -1.0156e+00],\n",
      "       [-2.7563e-01,  7.7441e-01, -6.2109e-01],\n",
      "       [-1.4072e+00,  2.4844e+00, -1.0986e+00],\n",
      "       [-9.4092e-01,  1.9102e+00, -1.0371e+00],\n",
      "       [-1.4863e+00,  2.3711e+00, -9.4189e-01],\n",
      "       [-1.3760e+00,  2.0020e+00, -6.4600e-01],\n",
      "       [-6.1133e-01,  1.1133e+00, -5.4346e-01],\n",
      "       [-9.2871e-01,  1.4199e+00, -5.3076e-01],\n",
      "       [-1.1250e+00,  1.9336e+00, -8.5547e-01],\n",
      "       [-1.4912e+00,  2.2461e+00, -7.7490e-01],\n",
      "       [-1.5762e+00,  2.4922e+00, -1.0137e+00],\n",
      "       [-1.4170e+00,  2.1191e+00, -7.5586e-01],\n",
      "       [-1.1211e+00,  2.0312e+00, -9.8291e-01],\n",
      "       [-5.8887e-01,  1.9746e+00, -1.5752e+00],\n",
      "       [-7.5049e-01,  1.1826e+00, -3.6816e-01],\n",
      "       [-1.2617e+00,  1.8291e+00, -5.5273e-01],\n",
      "       [-6.3135e-01,  1.3184e+00, -7.4316e-01],\n",
      "       [-4.9976e-01,  1.0586e+00, -6.5918e-01],\n",
      "       [-1.2559e+00,  2.0781e+00, -8.5205e-01],\n",
      "       [-8.3350e-01,  1.6064e+00, -8.4229e-01],\n",
      "       [-1.7236e+00,  2.4707e+00, -7.7441e-01],\n",
      "       [-1.3906e+00,  2.3398e+00, -9.8145e-01],\n",
      "       [-1.3438e+00,  2.1914e+00, -8.9648e-01],\n",
      "       [-1.2109e+00,  2.0527e+00, -8.9355e-01],\n",
      "       [-1.8799e+00,  2.8359e+00, -1.0420e+00],\n",
      "       [-1.4238e+00,  2.3086e+00, -9.5605e-01],\n",
      "       [-1.6328e+00,  2.5938e+00, -1.0303e+00],\n",
      "       [-1.4072e+00,  2.0215e+00, -6.5527e-01],\n",
      "       [-3.5767e-01,  9.8779e-01, -6.8848e-01],\n",
      "       [-3.5669e-01,  7.7637e-01, -4.4263e-01],\n",
      "       [ 1.0443e-03, -8.8867e-01,  6.8457e-01],\n",
      "       [ 1.1853e-01, -2.2186e-02, -2.2876e-01],\n",
      "       [-1.7236e+00,  2.3301e+00, -6.1230e-01],\n",
      "       [-1.0557e+00,  1.9033e+00, -9.0332e-01],\n",
      "       [-5.2441e-01,  9.8535e-01, -5.1221e-01],\n",
      "       [-9.9219e-01,  1.8672e+00, -9.0283e-01],\n",
      "       [-1.1475e+00,  2.2168e+00, -1.1504e+00],\n",
      "       [-5.8105e-01,  1.5117e+00, -1.0137e+00],\n",
      "       [-3.4375e-01,  8.2324e-01, -5.7910e-01],\n",
      "       [-5.8105e-01,  1.4707e+00, -9.3848e-01],\n",
      "       [-5.2826e-02, -5.9619e-01,  4.8438e-01],\n",
      "       [-6.8701e-01,  1.8760e+00, -1.3154e+00],\n",
      "       [-3.3252e-01,  8.8330e-01, -6.2109e-01],\n",
      "       [-8.0811e-01,  1.7197e+00, -1.0205e+00],\n",
      "       [-1.3984e+00,  2.4180e+00, -1.1064e+00],\n",
      "       [ 2.2392e-03, -3.2886e-01,  1.2451e-01],\n",
      "       [-1.4814e+00,  2.4141e+00, -9.9658e-01],\n",
      "       [-2.1204e-01,  8.0859e-01, -6.9336e-01],\n",
      "       [-1.1143e+00,  1.9863e+00, -9.3994e-01],\n",
      "       [-5.5664e-01,  1.3691e+00, -8.7061e-01],\n",
      "       [-6.3232e-01,  1.1104e+00, -5.0879e-01],\n",
      "       [-8.6572e-01,  1.6523e+00, -8.2080e-01],\n",
      "       [-3.5669e-01,  1.0713e+00, -8.3838e-01],\n",
      "       [-1.0801e+00,  1.8047e+00, -7.7197e-01],\n",
      "       [-4.3311e-01,  5.5713e-01, -2.7710e-01],\n",
      "       [-6.8945e-01,  1.8223e+00, -1.2607e+00],\n",
      "       [-1.1816e+00,  2.0312e+00, -8.8623e-01],\n",
      "       [-1.7363e+00,  2.6973e+00, -1.0557e+00],\n",
      "       [-7.3340e-01,  1.5918e+00, -8.8232e-01],\n",
      "       [-9.3066e-01,  2.0352e+00, -1.2334e+00],\n",
      "       [-1.0469e+00,  1.5186e+00, -5.5273e-01],\n",
      "       [-1.1787e+00,  2.1211e+00, -9.9023e-01],\n",
      "       [-6.8970e-02,  1.4297e+00, -1.5205e+00],\n",
      "       [-1.4189e+00,  2.1680e+00, -7.7246e-01],\n",
      "       [-4.3115e-01,  1.1963e+00, -8.7842e-01],\n",
      "       [-1.3701e+00,  2.5703e+00, -1.3018e+00],\n",
      "       [-1.2363e+00,  2.0391e+00, -8.6328e-01],\n",
      "       [-1.6768e+00,  2.5586e+00, -9.3945e-01],\n",
      "       [-1.6260e+00,  2.3438e+00, -7.9248e-01],\n",
      "       [-1.4443e+00,  1.9502e+00, -5.2637e-01],\n",
      "       [-4.1602e-01,  1.6533e+00, -1.3633e+00],\n",
      "       [-1.5049e+00,  2.7070e+00, -1.3232e+00],\n",
      "       [-9.7852e-01,  1.7012e+00, -8.0908e-01],\n",
      "       [-1.2881e+00,  1.9609e+00, -7.2998e-01],\n",
      "       [-1.2715e+00,  1.9453e+00, -7.1777e-01],\n",
      "       [-3.4863e-01,  7.7100e-01, -5.0635e-01],\n",
      "       [-9.6680e-01,  2.0957e+00, -1.2373e+00],\n",
      "       [-1.3223e+00,  1.9805e+00, -6.8066e-01],\n",
      "       [-1.5459e+00,  2.4922e+00, -9.9121e-01],\n",
      "       [-1.4980e+00,  2.1152e+00, -6.4990e-01],\n",
      "       [-1.4883e+00,  2.5000e+00, -1.0674e+00],\n",
      "       [-1.1123e+00,  1.4746e+00, -3.7964e-01],\n",
      "       [-9.3115e-01,  2.0957e+00, -1.2988e+00],\n",
      "       [-1.5000e+00,  2.4453e+00, -9.5752e-01],\n",
      "       [-1.8818e+00,  2.7148e+00, -8.6523e-01],\n",
      "       [-1.3281e+00,  2.0332e+00, -7.5928e-01],\n",
      "       [-1.0596e+00,  1.7441e+00, -7.2070e-01],\n",
      "       [-9.4482e-01,  1.7441e+00, -8.0322e-01],\n",
      "       [-1.4980e+00,  2.6602e+00, -1.2500e+00],\n",
      "       [-3.5107e-01,  1.2725e+00, -1.0088e+00],\n",
      "       [-8.5889e-01,  2.1230e+00, -1.4160e+00],\n",
      "       [-1.3311e+00,  2.4199e+00, -1.2041e+00],\n",
      "       [-8.5986e-01,  1.5596e+00, -7.0605e-01],\n",
      "       [-1.1982e+00,  2.2891e+00, -1.2041e+00],\n",
      "       [-1.0498e+00,  1.9951e+00, -1.0156e+00],\n",
      "       [-1.6201e+00,  2.7520e+00, -1.2451e+00],\n",
      "       [-1.1787e+00,  2.1191e+00, -1.0244e+00],\n",
      "       [-3.7280e-01,  8.9062e-01, -6.0645e-01],\n",
      "       [-1.3350e+00,  2.1113e+00, -8.1885e-01],\n",
      "       [-4.5746e-02, -5.7159e-02, -4.3449e-03],\n",
      "       [-1.4385e+00,  2.4805e+00, -1.1543e+00],\n",
      "       [-1.1816e+00,  2.1934e+00, -1.0762e+00],\n",
      "       [-1.0117e+00,  1.8135e+00, -8.6377e-01],\n",
      "       [-6.4795e-01,  1.1621e+00, -4.6997e-01]], dtype=float16), label_ids=array([1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 2, 1, 2, 2, 1, 2, 1, 1, 2, 2,\n",
      "       1, 2, 0, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 1, 0, 2, 1, 1,\n",
      "       1, 2, 1, 1, 1, 0, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 0, 2, 1, 2, 0,\n",
      "       1, 1, 0, 0, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       0, 2, 1, 2, 0, 1, 1, 1, 1, 1, 1, 2, 0, 2, 1, 2, 1, 1, 1, 2, 1, 1,\n",
      "       2, 1, 2, 1, 2, 1, 1, 1, 0, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "       1, 2, 1, 2, 1, 1, 1, 2, 0, 2, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2,\n",
      "       1, 1, 1, 2, 1, 0, 0, 0, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1,\n",
      "       1, 0, 1, 1, 1, 1, 0, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 0, 2, 1, 1, 1,\n",
      "       1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 0, 1, 1,\n",
      "       1, 1, 0, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 0]), metrics={'test_loss': 1.022766351699829, 'test_accuracy': 0.6410256410256411, 'test_balanced_accuracy': 0.35366465651157747, 'test_precision': 0.5821231374328719, 'test_recall': 0.6410256410256411, 'test_f1': 0.5269141181779156, 'test_runtime': 2.3077, 'test_samples_per_second': 101.399, 'test_steps_per_second': 6.5})\n"
     ]
    }
   ],
   "source": [
    "print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be81d0c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "probabilities = torch.softmax(torch.tensor(test_results.predictions).to(torch.float32), dim=-1)\n",
    "predictions = np.argmax(probabilities.numpy(), axis=1)\n",
    "true_labels = test_results.label_ids\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel(\"Actual Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ef4c67fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_to_save = []\n",
    "for idx in range(len(test_data)):\n",
    "    item = dataset['test'][idx]\n",
    "    actual_label = item['label']\n",
    "    predicted_label = predictions[idx]\n",
    "    claim = item['claim'] \n",
    "    premise = item['premise'] \n",
    "    category = item['category']\n",
    "    \n",
    "    # Append the information as a dictionary to the list\n",
    "    data_to_save.append({\n",
    "        'Claim': claim,\n",
    "        'Premise': premise,\n",
    "        'Actual Label': actual_label,\n",
    "        'Predicted Label': predicted_label,\n",
    "        'Category' : category\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data_to_save)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('/home/elson/results/2.2.4_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a1a63a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correctly classified instances\n",
    "correctly_classified = df[df['Actual Label'] == df['Predicted Label']]\n",
    "\n",
    "# Calculate misclassified instances\n",
    "misclassified = df[df['Actual Label'] != df['Predicted Label']]\n",
    "\n",
    "# Count the number of correctly classified and misclassified by category\n",
    "correct_classification_counts = correctly_classified['Category'].value_counts()\n",
    "misclassification_counts = misclassified['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9c4055e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           34\n",
       "Fitness                  13\n",
       "Cancer                   12\n",
       "Bone health              12\n",
       "Skin                     10\n",
       "Neurological health       9\n",
       "Diabetes                  9\n",
       "Hair                      9\n",
       "Throat                    9\n",
       "Ear                       6\n",
       "Cardiovascular Health     6\n",
       "COVID                     5\n",
       "Eye                       5\n",
       "Blood                     4\n",
       "Muscles                   2\n",
       "Women' s Health           2\n",
       "Mental Health             2\n",
       "Vascular                  1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classification_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "117a1d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "General Health           17\n",
       "Skin                     14\n",
       "Bone health               9\n",
       "Cardiovascular Health     6\n",
       "Men's health              6\n",
       "Blood                     5\n",
       "Muscles                   4\n",
       "Women' s Health           4\n",
       "Eye                       4\n",
       "Diabetes                  3\n",
       "Dental Health             3\n",
       "Hair                      3\n",
       "Fitness                   2\n",
       "Vascular                  2\n",
       "COVID                     1\n",
       "Mental Health             1\n",
       "Name: Category, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassification_counts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
